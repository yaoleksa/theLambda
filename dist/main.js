/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	var __webpack_modules__ = ({

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/build.js":
/*!********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/build.js ***!
  \********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = build;\n\nexports.usage = 'Attempts to compile the module by dispatching to node-gyp or nw-gyp';\n\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst compile = __webpack_require__(/*! ./util/compile.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js\");\nconst handle_gyp_opts = __webpack_require__(/*! ./util/handle_gyp_opts.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js\");\nconst configure = __webpack_require__(/*! ./configure.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/configure.js\");\n\nfunction do_build(gyp, argv, callback) {\n  handle_gyp_opts(gyp, argv, (err, result) => {\n    let final_args = ['build'].concat(result.gyp).concat(result.pre);\n    if (result.unparsed.length > 0) {\n      final_args = final_args.\n        concat(['--']).\n        concat(result.unparsed);\n    }\n    if (!err && result.opts.napi_build_version) {\n      napi.swap_build_dir_in(result.opts.napi_build_version);\n    }\n    compile.run_gyp(final_args, result.opts, (err2) => {\n      if (result.opts.napi_build_version) {\n        napi.swap_build_dir_out(result.opts.napi_build_version);\n      }\n      return callback(err2);\n    });\n  });\n}\n\nfunction build(gyp, argv, callback) {\n\n  // Form up commands to pass to node-gyp:\n  // We map `node-pre-gyp build` to `node-gyp configure build` so that we do not\n  // trigger a clean and therefore do not pay the penalty of a full recompile\n  if (argv.length && (argv.indexOf('rebuild') > -1)) {\n    argv.shift(); // remove `rebuild`\n    // here we map `node-pre-gyp rebuild` to `node-gyp rebuild` which internally means\n    // \"clean + configure + build\" and triggers a full recompile\n    compile.run_gyp(['clean'], {}, (err3) => {\n      if (err3) return callback(err3);\n      configure(gyp, argv, (err4) => {\n        if (err4) return callback(err4);\n        return do_build(gyp, argv, callback);\n      });\n    });\n  } else {\n    return do_build(gyp, argv, callback);\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/build.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/clean.js":
/*!********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/clean.js ***!
  \********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = clean;\n\nexports.usage = 'Removes the entire folder containing the compiled .node module';\n\nconst rm = __webpack_require__(/*! rimraf */ \"./node_modules/rimraf/rimraf.js\");\nconst exists = (__webpack_require__(/*! fs */ \"?12c0\").exists) || (__webpack_require__(/*! path */ \"./node_modules/path/path.js\").exists);\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\n\nfunction clean(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  const to_delete = opts.module_path;\n  if (!to_delete) {\n    return callback(new Error('module_path is empty, refusing to delete'));\n  } else if (path.normalize(to_delete) === path.normalize(process.cwd())) {\n    return callback(new Error('module_path is not set, refusing to delete'));\n  } else {\n    exists(to_delete, (found) => {\n      if (found) {\n        if (!gyp.opts.silent_clean) console.log('[' + package_json.name + '] Removing \"%s\"', to_delete);\n        return rm(to_delete, callback);\n      }\n      return callback();\n    });\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/clean.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/configure.js":
/*!************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/configure.js ***!
  \************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = configure;\n\nexports.usage = 'Attempts to configure node-gyp or nw-gyp build';\n\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst compile = __webpack_require__(/*! ./util/compile.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js\");\nconst handle_gyp_opts = __webpack_require__(/*! ./util/handle_gyp_opts.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js\");\n\nfunction configure(gyp, argv, callback) {\n  handle_gyp_opts(gyp, argv, (err, result) => {\n    let final_args = result.gyp.concat(result.pre);\n    // pull select node-gyp configure options out of the npm environ\n    const known_gyp_args = ['dist-url', 'python', 'nodedir', 'msvs_version'];\n    known_gyp_args.forEach((key) => {\n      const val = gyp.opts[key] || gyp.opts[key.replace('-', '_')];\n      if (val) {\n        final_args.push('--' + key + '=' + val);\n      }\n    });\n    // --ensure=false tell node-gyp to re-install node development headers\n    // but it is only respected by node-gyp install, so we have to call install\n    // as a separate step if the user passes it\n    if (gyp.opts.ensure === false) {\n      const install_args = final_args.concat(['install', '--ensure=false']);\n      compile.run_gyp(install_args, result.opts, (err2) => {\n        if (err2) return callback(err2);\n        if (result.unparsed.length > 0) {\n          final_args = final_args.\n            concat(['--']).\n            concat(result.unparsed);\n        }\n        compile.run_gyp(['configure'].concat(final_args), result.opts, (err3) => {\n          return callback(err3);\n        });\n      });\n    } else {\n      if (result.unparsed.length > 0) {\n        final_args = final_args.\n          concat(['--']).\n          concat(result.unparsed);\n      }\n      compile.run_gyp(['configure'].concat(final_args), result.opts, (err4) => {\n        if (!err4 && result.opts.napi_build_version) {\n          napi.swap_build_dir_out(result.opts.napi_build_version);\n        }\n        return callback(err4);\n      });\n    }\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/configure.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/info.js":
/*!*******************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/info.js ***!
  \*******************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = info;\n\nexports.usage = 'Lists all published binaries (requires aws-sdk)';\n\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst s3_setup = __webpack_require__(/*! ./util/s3_setup.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js\");\n\nfunction info(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const opts = versioning.evaluate(package_json, gyp.opts);\n  const config = {};\n  s3_setup.detect(opts, config);\n  const s3 = s3_setup.get_s3(config);\n  const s3_opts = {\n    Bucket: config.bucket,\n    Prefix: config.prefix\n  };\n  s3.listObjects(s3_opts, (err, meta) => {\n    if (err && err.code === 'NotFound') {\n      return callback(new Error('[' + package_json.name + '] Not found: https://' + s3_opts.Bucket + '.s3.amazonaws.com/' + config.prefix));\n    } else if (err) {\n      return callback(err);\n    } else {\n      log.verbose(JSON.stringify(meta, null, 1));\n      if (meta && meta.Contents) {\n        meta.Contents.forEach((obj) => {\n          console.log(obj.Key);\n        });\n      } else {\n        console.error('[' + package_json.name + '] No objects found at https://' + s3_opts.Bucket + '.s3.amazonaws.com/' + config.prefix);\n      }\n      return callback();\n    }\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/info.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/install.js":
/*!**********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/install.js ***!
  \**********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("var __dirname = \"/\";\n\n\nmodule.exports = exports = install;\n\nexports.usage = 'Attempts to install pre-built binary for module';\n\nconst fs = __webpack_require__(/*! fs */ \"?12c0\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst existsAsync = fs.exists || path.exists;\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst makeDir = __webpack_require__(/*! make-dir */ \"./node_modules/make-dir/index.js\");\n// for fetching binaries\nconst fetch = __webpack_require__(/*! node-fetch */ \"./node_modules/node-fetch/browser.js\");\nconst tar = __webpack_require__(/*! tar */ \"./node_modules/tar/index.js\");\n\nlet npgVersion = 'unknown';\ntry {\n  // Read own package.json to get the current node-pre-pyp version.\n  const ownPackageJSON = fs.readFileSync(path.join(__dirname, '..', 'package.json'), 'utf8');\n  npgVersion = JSON.parse(ownPackageJSON).version;\n} catch (e) {\n  // do nothing\n}\n\nfunction place_binary(uri, targetDir, opts, callback) {\n  log.http('GET', uri);\n\n  // Try getting version info from the currently running npm.\n  const envVersionInfo = process.env.npm_config_user_agent ||\n        'node ' + process.version;\n\n  const sanitized = uri.replace('+', '%2B');\n  const requestOpts = {\n    uri: sanitized,\n    headers: {\n      'User-Agent': 'node-pre-gyp (v' + npgVersion + ', ' + envVersionInfo + ')'\n    },\n    follow_max: 10\n  };\n\n  if (opts.cafile) {\n    try {\n      requestOpts.ca = fs.readFileSync(opts.cafile);\n    } catch (e) {\n      return callback(e);\n    }\n  } else if (opts.ca) {\n    requestOpts.ca = opts.ca;\n  }\n\n  const proxyUrl = opts.proxy ||\n                    process.env.http_proxy ||\n                    process.env.HTTP_PROXY ||\n                    process.env.npm_config_proxy;\n  let agent;\n  if (proxyUrl) {\n    const ProxyAgent = __webpack_require__(/*! https-proxy-agent */ \"./node_modules/https-proxy-agent/dist/index.js\");\n    agent = new ProxyAgent(proxyUrl);\n    log.http('download', 'proxy agent configured using: \"%s\"', proxyUrl);\n  }\n\n  fetch(sanitized, { agent })\n    .then((res) => {\n      if (!res.ok) {\n        throw new Error(`response status ${res.status} ${res.statusText} on ${sanitized}`);\n      }\n      const dataStream = res.body;\n\n      return new Promise((resolve, reject) => {\n        let extractions = 0;\n        const countExtractions = (entry) => {\n          extractions += 1;\n          log.info('install', 'unpacking %s', entry.path);\n        };\n\n        dataStream.pipe(extract(targetDir, countExtractions))\n          .on('error', (e) => {\n            reject(e);\n          });\n        dataStream.on('end', () => {\n          resolve(`extracted file count: ${extractions}`);\n        });\n        dataStream.on('error', (e) => {\n          reject(e);\n        });\n      });\n    })\n    .then((text) => {\n      log.info(text);\n      callback();\n    })\n    .catch((e) => {\n      log.error(`install ${e.message}`);\n      callback(e);\n    });\n}\n\nfunction extract(to, onentry) {\n  return tar.extract({\n    cwd: to,\n    strip: 1,\n    onentry\n  });\n}\n\nfunction extract_from_local(from, targetDir, callback) {\n  if (!fs.existsSync(from)) {\n    return callback(new Error('Cannot find file ' + from));\n  }\n  log.info('Found local file to extract from ' + from);\n\n  // extract helpers\n  let extractCount = 0;\n  function countExtractions(entry) {\n    extractCount += 1;\n    log.info('install', 'unpacking ' + entry.path);\n  }\n  function afterExtract(err) {\n    if (err) return callback(err);\n    if (extractCount === 0) {\n      return callback(new Error('There was a fatal problem while extracting the tarball'));\n    }\n    log.info('tarball', 'done parsing tarball');\n    callback();\n  }\n\n  fs.createReadStream(from).pipe(extract(targetDir, countExtractions))\n    .on('close', afterExtract)\n    .on('error', afterExtract);\n}\n\nfunction do_build(gyp, argv, callback) {\n  const args = ['rebuild'].concat(argv);\n  gyp.todo.push({ name: 'build', args: args });\n  process.nextTick(callback);\n}\n\nfunction print_fallback_error(err, opts, package_json) {\n  const fallback_message = ' (falling back to source compile with node-gyp)';\n  let full_message = '';\n  if (err.statusCode !== undefined) {\n    // If we got a network response it but failed to download\n    // it means remote binaries are not available, so let's try to help\n    // the user/developer with the info to debug why\n    full_message = 'Pre-built binaries not found for ' + package_json.name + '@' + package_json.version;\n    full_message += ' and ' + opts.runtime + '@' + (opts.target || process.versions.node) + ' (' + opts.node_abi + ' ABI, ' + opts.libc + ')';\n    full_message += fallback_message;\n    log.warn('Tried to download(' + err.statusCode + '): ' + opts.hosted_tarball);\n    log.warn(full_message);\n    log.http(err.message);\n  } else {\n    // If we do not have a statusCode that means an unexpected error\n    // happened and prevented an http response, so we output the exact error\n    full_message = 'Pre-built binaries not installable for ' + package_json.name + '@' + package_json.version;\n    full_message += ' and ' + opts.runtime + '@' + (opts.target || process.versions.node) + ' (' + opts.node_abi + ' ABI, ' + opts.libc + ')';\n    full_message += fallback_message;\n    log.warn(full_message);\n    log.warn('Hit error ' + err.message);\n  }\n}\n\n//\n// install\n//\nfunction install(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const source_build = gyp.opts['build-from-source'] || gyp.opts.build_from_source;\n  const update_binary = gyp.opts['update-binary'] || gyp.opts.update_binary;\n  const should_do_source_build = source_build === package_json.name || (source_build === true || source_build === 'true');\n  if (should_do_source_build) {\n    log.info('build', 'requesting source compile');\n    return do_build(gyp, argv, callback);\n  } else {\n    const fallback_to_build = gyp.opts['fallback-to-build'] || gyp.opts.fallback_to_build;\n    let should_do_fallback_build = fallback_to_build === package_json.name || (fallback_to_build === true || fallback_to_build === 'true');\n    // but allow override from npm\n    if (process.env.npm_config_argv) {\n      const cooked = JSON.parse(process.env.npm_config_argv).cooked;\n      const match = cooked.indexOf('--fallback-to-build');\n      if (match > -1 && cooked.length > match && cooked[match + 1] === 'false') {\n        should_do_fallback_build = false;\n        log.info('install', 'Build fallback disabled via npm flag: --fallback-to-build=false');\n      }\n    }\n    let opts;\n    try {\n      opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n    } catch (err) {\n      return callback(err);\n    }\n\n    opts.ca = gyp.opts.ca;\n    opts.cafile = gyp.opts.cafile;\n\n    const from = opts.hosted_tarball;\n    const to = opts.module_path;\n    const binary_module = path.join(to, opts.module_name + '.node');\n    existsAsync(binary_module, (found) => {\n      if (!update_binary) {\n        if (found) {\n          console.log('[' + package_json.name + '] Success: \"' + binary_module + '\" already installed');\n          console.log('Pass --update-binary to reinstall or --build-from-source to recompile');\n          return callback();\n        }\n        log.info('check', 'checked for \"' + binary_module + '\" (not found)');\n      }\n\n      makeDir(to).then(() => {\n        const fileName = from.startsWith('file://') && from.slice('file://'.length);\n        if (fileName) {\n          extract_from_local(fileName, to, after_place);\n        } else {\n          place_binary(from, to, opts, after_place);\n        }\n      }).catch((err) => {\n        after_place(err);\n      });\n\n      function after_place(err) {\n        if (err && should_do_fallback_build) {\n          print_fallback_error(err, opts, package_json);\n          return do_build(gyp, argv, callback);\n        } else if (err) {\n          return callback(err);\n        } else {\n          console.log('[' + package_json.name + '] Success: \"' + binary_module + '\" is installed via remote');\n          return callback();\n        }\n      }\n    });\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/install.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/main.js":
/*!*******************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/main.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n/**\n * Set the title.\n */\n\nprocess.title = 'node-pre-gyp';\n\nconst node_pre_gyp = __webpack_require__(/*! ../ */ \"./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\n\n/**\n * Process and execute the selected commands.\n */\n\nconst prog = new node_pre_gyp.Run({ argv: process.argv });\nlet completed = false;\n\nif (prog.todo.length === 0) {\n  if (~process.argv.indexOf('-v') || ~process.argv.indexOf('--version')) {\n    console.log('v%s', prog.version);\n    process.exit(0);\n  } else if (~process.argv.indexOf('-h') || ~process.argv.indexOf('--help')) {\n    console.log('%s', prog.usage());\n    process.exit(0);\n  }\n  console.log('%s', prog.usage());\n  process.exit(1);\n}\n\n// if --no-color is passed\nif (prog.opts && Object.hasOwnProperty.call(prog, 'color') && !prog.opts.color) {\n  log.disableColor();\n}\n\nlog.info('it worked if it ends with', 'ok');\nlog.verbose('cli', process.argv);\nlog.info('using', process.title + '@%s', prog.version);\nlog.info('using', 'node@%s | %s | %s', process.versions.node, process.platform, process.arch);\n\n\n/**\n * Change dir if -C/--directory was passed.\n */\n\nconst dir = prog.opts.directory;\nif (dir) {\n  const fs = __webpack_require__(/*! fs */ \"?12c0\");\n  try {\n    const stat = fs.statSync(dir);\n    if (stat.isDirectory()) {\n      log.info('chdir', dir);\n      process.chdir(dir);\n    } else {\n      log.warn('chdir', dir + ' is not a directory');\n    }\n  } catch (e) {\n    if (e.code === 'ENOENT') {\n      log.warn('chdir', dir + ' is not a directory');\n    } else {\n      log.warn('chdir', 'error during chdir() \"%s\"', e.message);\n    }\n  }\n}\n\nfunction run() {\n  const command = prog.todo.shift();\n  if (!command) {\n    // done!\n    completed = true;\n    log.info('ok');\n    return;\n  }\n\n  // set binary.host when appropriate. host determines the s3 target bucket.\n  const target = prog.setBinaryHostProperty(command.name);\n  if (target && ['install', 'publish', 'unpublish', 'info'].indexOf(command.name) >= 0) {\n    log.info('using binary.host: ' + prog.package_json.binary.host);\n  }\n\n  prog.commands[command.name](command.args, function(err) {\n    if (err) {\n      log.error(command.name + ' error');\n      log.error('stack', err.stack);\n      errorMessage();\n      log.error('not ok');\n      console.log(err.message);\n      return process.exit(1);\n    }\n    const args_array = [].slice.call(arguments, 1);\n    if (args_array.length) {\n      console.log.apply(console, args_array);\n    }\n    // now run the next command in the queue\n    process.nextTick(run);\n  });\n}\n\nprocess.on('exit', (code) => {\n  if (!completed && !code) {\n    log.error('Completion callback never invoked!');\n    errorMessage();\n    process.exit(6);\n  }\n});\n\nprocess.on('uncaughtException', (err) => {\n  log.error('UNCAUGHT EXCEPTION');\n  log.error('stack', err.stack);\n  errorMessage();\n  process.exit(7);\n});\n\nfunction errorMessage() {\n  // copied from npm's lib/util/error-handler.js\n  const os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n  log.error('System', os.type() + ' ' + os.release());\n  log.error('command', process.argv.map(JSON.stringify).join(' '));\n  log.error('cwd', process.cwd());\n  log.error('node -v', process.version);\n  log.error(process.title + ' -v', 'v' + prog.package.version);\n}\n\n// start running the given commands!\nrun();\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/main.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js":
/*!***************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js ***!
  \***************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("var __dirname = \"/\";\n\n\n/**\n * Module exports.\n */\n\nmodule.exports = exports;\n\n/**\n * Module dependencies.\n */\n\n// load mocking control function for accessing s3 via https. the function is a noop always returning\n// false if not mocking.\nexports.mockS3Http = (__webpack_require__(/*! ./util/s3_setup */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js\").get_mockS3Http)();\nexports.mockS3Http('on');\nconst mocking = exports.mockS3Http('get');\n\n\nconst fs = __webpack_require__(/*! fs */ \"?12c0\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst nopt = __webpack_require__(/*! nopt */ \"./node_modules/nopt/lib/nopt.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nlog.disableProgress();\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\nconst EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter);\nconst inherits = (__webpack_require__(/*! util */ \"./node_modules/util/util.js\").inherits);\nconst cli_commands = [\n  'clean',\n  'install',\n  'reinstall',\n  'build',\n  'rebuild',\n  'package',\n  'testpackage',\n  'publish',\n  'unpublish',\n  'info',\n  'testbinary',\n  'reveal',\n  'configure'\n];\nconst aliases = {};\n\n// differentiate node-pre-gyp's logs from npm's\nlog.heading = 'node-pre-gyp';\n\nif (mocking) {\n  log.warn(`mocking s3 to ${process.env.node_pre_gyp_mock_s3}`);\n}\n\n// this is a getter to avoid circular reference warnings with node v14.\nObject.defineProperty(exports, \"find\", ({\n  get: function() {\n    return (__webpack_require__(/*! ./pre-binding */ \"./node_modules/@mapbox/node-pre-gyp/lib/pre-binding.js\").find);\n  },\n  enumerable: true\n}));\n\n// in the following, \"my_module\" is using node-pre-gyp to\n// prebuild and install pre-built binaries. \"main_module\"\n// is using \"my_module\".\n//\n// \"bin/node-pre-gyp\" invokes Run() without a path. the\n// expectation is that the working directory is the package\n// root \"my_module\". this is true because in all cases npm is\n// executing a script in the context of \"my_module\".\n//\n// \"pre-binding.find()\" is executed by \"my_module\" but in the\n// context of \"main_module\". this is because \"main_module\" is\n// executing and requires \"my_module\" which is then executing\n// \"pre-binding.find()\" via \"node-pre-gyp.find()\", so the working\n// directory is that of \"main_module\".\n//\n// that's why \"find()\" must pass the path to package.json.\n//\nfunction Run({ package_json_path = './package.json', argv }) {\n  this.package_json_path = package_json_path;\n  this.commands = {};\n\n  const self = this;\n  cli_commands.forEach((command) => {\n    self.commands[command] = function(argvx, callback) {\n      log.verbose('command', command, argvx);\n      return __webpack_require__(\"./node_modules/@mapbox/node-pre-gyp/lib sync recursive ^\\\\.\\\\/.*$\")(\"./\" + command)(self, argvx, callback);\n    };\n  });\n\n  this.parseArgv(argv);\n\n  // this is set to true after the binary.host property was set to\n  // either staging_host or production_host.\n  this.binaryHostSet = false;\n}\ninherits(Run, EE);\nexports.Run = Run;\nconst proto = Run.prototype;\n\n/**\n * Export the contents of the package.json.\n */\n\nproto.package = __webpack_require__(/*! ../package.json */ \"./node_modules/@mapbox/node-pre-gyp/package.json\");\n\n/**\n * nopt configuration definitions\n */\n\nproto.configDefs = {\n  help: Boolean,     // everywhere\n  arch: String,      // 'configure'\n  debug: Boolean,    // 'build'\n  directory: String, // bin\n  proxy: String,     // 'install'\n  loglevel: String  // everywhere\n};\n\n/**\n * nopt shorthands\n */\n\nproto.shorthands = {\n  release: '--no-debug',\n  C: '--directory',\n  debug: '--debug',\n  j: '--jobs',\n  silent: '--loglevel=silent',\n  silly: '--loglevel=silly',\n  verbose: '--loglevel=verbose'\n};\n\n/**\n * expose the command aliases for the bin file to use.\n */\n\nproto.aliases = aliases;\n\n/**\n * Parses the given argv array and sets the 'opts', 'argv',\n * 'command', and 'package_json' properties.\n */\n\nproto.parseArgv = function parseOpts(argv) {\n  this.opts = nopt(this.configDefs, this.shorthands, argv);\n  this.argv = this.opts.argv.remain.slice();\n  const commands = this.todo = [];\n\n  // create a copy of the argv array with aliases mapped\n  argv = this.argv.map((arg) => {\n    // is this an alias?\n    if (arg in this.aliases) {\n      arg = this.aliases[arg];\n    }\n    return arg;\n  });\n\n  // process the mapped args into \"command\" objects (\"name\" and \"args\" props)\n  argv.slice().forEach((arg) => {\n    if (arg in this.commands) {\n      const args = argv.splice(0, argv.indexOf(arg));\n      argv.shift();\n      if (commands.length > 0) {\n        commands[commands.length - 1].args = args;\n      }\n      commands.push({ name: arg, args: [] });\n    }\n  });\n  if (commands.length > 0) {\n    commands[commands.length - 1].args = argv.splice(0);\n  }\n\n\n  // if a directory was specified package.json is assumed to be relative\n  // to it.\n  let package_json_path = this.package_json_path;\n  if (this.opts.directory) {\n    package_json_path = path.join(this.opts.directory, package_json_path);\n  }\n\n  this.package_json = JSON.parse(fs.readFileSync(package_json_path));\n\n  // expand commands entries for multiple napi builds\n  this.todo = napi.expand_commands(this.package_json, this.opts, commands);\n\n  // support for inheriting config env variables from npm\n  const npm_config_prefix = 'npm_config_';\n  Object.keys(process.env).forEach((name) => {\n    if (name.indexOf(npm_config_prefix) !== 0) return;\n    const val = process.env[name];\n    if (name === npm_config_prefix + 'loglevel') {\n      log.level = val;\n    } else {\n      // add the user-defined options to the config\n      name = name.substring(npm_config_prefix.length);\n      // avoid npm argv clobber already present args\n      // which avoids problem of 'npm test' calling\n      // script that runs unique npm install commands\n      if (name === 'argv') {\n        if (this.opts.argv &&\n             this.opts.argv.remain &&\n             this.opts.argv.remain.length) {\n          // do nothing\n        } else {\n          this.opts[name] = val;\n        }\n      } else {\n        this.opts[name] = val;\n      }\n    }\n  });\n\n  if (this.opts.loglevel) {\n    log.level = this.opts.loglevel;\n  }\n  log.resume();\n};\n\n/**\n * allow the binary.host property to be set at execution time.\n *\n * for this to take effect requires all the following to be true.\n * - binary is a property in package.json\n * - binary.host is falsey\n * - binary.staging_host is not empty\n * - binary.production_host is not empty\n *\n * if any of the previous checks fail then the function returns an empty string\n * and makes no changes to package.json's binary property.\n *\n *\n * if command is \"publish\" then the default is set to \"binary.staging_host\"\n * if command is not \"publish\" the the default is set to \"binary.production_host\"\n *\n * if the command-line option '--s3_host' is set to \"staging\" or \"production\" then\n * \"binary.host\" is set to the specified \"staging_host\" or \"production_host\". if\n * '--s3_host' is any other value an exception is thrown.\n *\n * if '--s3_host' is not present then \"binary.host\" is set to the default as above.\n *\n * this strategy was chosen so that any command other than \"publish\" or \"unpublish\" uses \"production\"\n * as the default without requiring any command-line options but that \"publish\" and \"unpublish\" require\n * '--s3_host production_host' to be specified in order to *really* publish (or unpublish). publishing\n * to staging can be done freely without worrying about disturbing any production releases.\n */\nproto.setBinaryHostProperty = function(command) {\n  if (this.binaryHostSet) {\n    return this.package_json.binary.host;\n  }\n  const p = this.package_json;\n  // don't set anything if host is present. it must be left blank to trigger this.\n  if (!p || !p.binary || p.binary.host) {\n    return '';\n  }\n  // and both staging and production must be present. errors will be reported later.\n  if (!p.binary.staging_host || !p.binary.production_host) {\n    return '';\n  }\n  let target = 'production_host';\n  if (command === 'publish' || command === 'unpublish') {\n    target = 'staging_host';\n  }\n  // the environment variable has priority over the default or the command line. if\n  // either the env var or the command line option are invalid throw an error.\n  const npg_s3_host = process.env.node_pre_gyp_s3_host;\n  if (npg_s3_host === 'staging' || npg_s3_host === 'production') {\n    target = `${npg_s3_host}_host`;\n  } else if (this.opts['s3_host'] === 'staging' || this.opts['s3_host'] === 'production') {\n    target = `${this.opts['s3_host']}_host`;\n  } else if (this.opts['s3_host'] || npg_s3_host) {\n    throw new Error(`invalid s3_host ${this.opts['s3_host'] || npg_s3_host}`);\n  }\n\n  p.binary.host = p.binary[target];\n  this.binaryHostSet = true;\n\n  return p.binary.host;\n};\n\n/**\n * Returns the usage instructions for node-pre-gyp.\n */\n\nproto.usage = function usage() {\n  const str = [\n    '',\n    '  Usage: node-pre-gyp <command> [options]',\n    '',\n    '  where <command> is one of:',\n    cli_commands.map((c) => {\n      return '    - ' + c + ' - ' + __webpack_require__(\"./node_modules/@mapbox/node-pre-gyp/lib sync recursive ^\\\\.\\\\/.*$\")(\"./\" + c).usage;\n    }).join('\\n'),\n    '',\n    'node-pre-gyp@' + this.version + '  ' + path.resolve(__dirname, '..'),\n    'node@' + process.versions.node\n  ].join('\\n');\n  return str;\n};\n\n/**\n * Version number getter.\n */\n\nObject.defineProperty(proto, 'version', {\n  get: function() {\n    return this.package.version;\n  },\n  enumerable: true\n});\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/package.js":
/*!**********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/package.js ***!
  \**********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = _package;\n\nexports.usage = 'Packs binary (and enclosing directory) into locally staged tarball';\n\nconst fs = __webpack_require__(/*! fs */ \"?12c0\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst existsAsync = fs.exists || path.exists;\nconst makeDir = __webpack_require__(/*! make-dir */ \"./node_modules/make-dir/index.js\");\nconst tar = __webpack_require__(/*! tar */ \"./node_modules/tar/index.js\");\n\nfunction readdirSync(dir) {\n  let list = [];\n  const files = fs.readdirSync(dir);\n\n  files.forEach((file) => {\n    const stats = fs.lstatSync(path.join(dir, file));\n    if (stats.isDirectory()) {\n      list = list.concat(readdirSync(path.join(dir, file)));\n    } else {\n      list.push(path.join(dir, file));\n    }\n  });\n  return list;\n}\n\nfunction _package(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  const from = opts.module_path;\n  const binary_module = path.join(from, opts.module_name + '.node');\n  existsAsync(binary_module, (found) => {\n    if (!found) {\n      return callback(new Error('Cannot package because ' + binary_module + ' missing: run `node-pre-gyp rebuild` first'));\n    }\n    const tarball = opts.staged_tarball;\n    const filter_func = function(entry) {\n      const basename = path.basename(entry);\n      if (basename.length && basename[0] !== '.') {\n        console.log('packing ' + entry);\n        return true;\n      } else {\n        console.log('skipping ' + entry);\n      }\n      return false;\n    };\n    makeDir(path.dirname(tarball)).then(() => {\n      let files = readdirSync(from);\n      const base = path.basename(from);\n      files = files.map((file) => {\n        return path.join(base, path.relative(from, file));\n      });\n      tar.create({\n        portable: false,\n        gzip: true,\n        filter: filter_func,\n        file: tarball,\n        cwd: path.dirname(from)\n      }, files, (err2) => {\n        if (err2)  console.error('[' + package_json.name + '] ' + err2.message);\n        else log.info('package', 'Binary staged at \"' + tarball + '\"');\n        return callback(err2);\n      });\n    }).catch((err) => {\n      return callback(err);\n    });\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/package.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/pre-binding.js":
/*!**************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/pre-binding.js ***!
  \**************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst npg = __webpack_require__(/*! .. */ \"./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js\");\nconst versioning = __webpack_require__(/*! ../lib/util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ../lib/util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst existsSync = (__webpack_require__(/*! fs */ \"?12c0\").existsSync) || (__webpack_require__(/*! path */ \"./node_modules/path/path.js\").existsSync);\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\n\nmodule.exports = exports;\n\nexports.usage = 'Finds the require path for the node-pre-gyp installed module';\n\nexports.validate = function(package_json, opts) {\n  versioning.validate_config(package_json, opts);\n};\n\nexports.find = function(package_json_path, opts) {\n  if (!existsSync(package_json_path)) {\n    throw new Error(package_json_path + 'does not exist');\n  }\n  const prog = new npg.Run({ package_json_path, argv: process.argv });\n  prog.setBinaryHostProperty();\n  const package_json = prog.package_json;\n\n  versioning.validate_config(package_json, opts);\n  let napi_build_version;\n  if (napi.get_napi_build_versions(package_json, opts)) {\n    napi_build_version = napi.get_best_napi_build_version(package_json, opts);\n  }\n  opts = opts || {};\n  if (!opts.module_root) opts.module_root = path.dirname(package_json_path);\n  const meta = versioning.evaluate(package_json, opts, napi_build_version);\n  return meta.module;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/pre-binding.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/publish.js":
/*!**********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/publish.js ***!
  \**********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = publish;\n\nexports.usage = 'Publishes pre-built binary (requires aws-sdk)';\n\nconst fs = __webpack_require__(/*! fs */ \"?12c0\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst s3_setup = __webpack_require__(/*! ./util/s3_setup.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js\");\nconst existsAsync = fs.exists || path.exists;\nconst url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\");\n\nfunction publish(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  const tarball = opts.staged_tarball;\n  existsAsync(tarball, (found) => {\n    if (!found) {\n      return callback(new Error('Cannot publish because ' + tarball + ' missing: run `node-pre-gyp package` first'));\n    }\n\n    log.info('publish', 'Detecting s3 credentials');\n    const config = {};\n    s3_setup.detect(opts, config);\n    const s3 = s3_setup.get_s3(config);\n\n    const key_name = url.resolve(config.prefix, opts.package_name);\n    const s3_opts = {\n      Bucket: config.bucket,\n      Key: key_name\n    };\n    log.info('publish', 'Authenticating with s3');\n    log.info('publish', config);\n\n    log.info('publish', 'Checking for existing binary at ' + opts.hosted_path);\n    s3.headObject(s3_opts, (err, meta) => {\n      if (meta) log.info('publish', JSON.stringify(meta));\n      if (err && err.code === 'NotFound') {\n        // we are safe to publish because\n        // the object does not already exist\n        log.info('publish', 'Preparing to put object');\n        const s3_put_opts = {\n          ACL: 'public-read',\n          Body: fs.createReadStream(tarball),\n          Key: key_name,\n          Bucket: config.bucket\n        };\n        log.info('publish', 'Putting object', s3_put_opts.ACL, s3_put_opts.Bucket, s3_put_opts.Key);\n        try {\n          s3.putObject(s3_put_opts, (err2, resp) => {\n            log.info('publish', 'returned from putting object');\n            if (err2) {\n              log.info('publish', 's3 putObject error: \"' + err2 + '\"');\n              return callback(err2);\n            }\n            if (resp) log.info('publish', 's3 putObject response: \"' + JSON.stringify(resp) + '\"');\n            log.info('publish', 'successfully put object');\n            console.log('[' + package_json.name + '] published to ' + opts.hosted_path);\n            return callback();\n          });\n        } catch (err3) {\n          log.info('publish', 's3 putObject error: \"' + err3 + '\"');\n          return callback(err3);\n        }\n      } else if (err) {\n        log.info('publish', 's3 headObject error: \"' + err + '\"');\n        return callback(err);\n      } else {\n        log.error('publish', 'Cannot publish over existing version');\n        log.error('publish', \"Update the 'version' field in package.json and try again\");\n        log.error('publish', 'If the previous version was published in error see:');\n        log.error('publish', '\\t node-pre-gyp unpublish');\n        return callback(new Error('Failed publishing to ' + opts.hosted_path));\n      }\n    });\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/publish.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/rebuild.js":
/*!**********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/rebuild.js ***!
  \**********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = rebuild;\n\nexports.usage = 'Runs \"clean\" and \"build\" at once';\n\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\nfunction rebuild(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  let commands = [\n    { name: 'clean', args: [] },\n    { name: 'build', args: ['rebuild'] }\n  ];\n  commands = napi.expand_commands(package_json, gyp.opts, commands);\n  for (let i = commands.length; i !== 0; i--) {\n    gyp.todo.unshift(commands[i - 1]);\n  }\n  process.nextTick(callback);\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/rebuild.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/reinstall.js":
/*!************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/reinstall.js ***!
  \************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = rebuild;\n\nexports.usage = 'Runs \"clean\" and \"install\" at once';\n\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\nfunction rebuild(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  let installArgs = [];\n  const napi_build_version = napi.get_best_napi_build_version(package_json, gyp.opts);\n  if (napi_build_version != null) installArgs = [napi.get_command_arg(napi_build_version)];\n  gyp.todo.unshift(\n    { name: 'clean', args: [] },\n    { name: 'install', args: installArgs }\n  );\n  process.nextTick(callback);\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/reinstall.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/reveal.js":
/*!*********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/reveal.js ***!
  \*********************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = reveal;\n\nexports.usage = 'Reveals data on the versioned binary';\n\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\nfunction unix_paths(key, val) {\n  return val && val.replace ? val.replace(/\\\\/g, '/') : val;\n}\n\nfunction reveal(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  let hit = false;\n  // if a second arg is passed look to see\n  // if it is a known option\n  // console.log(JSON.stringify(gyp.opts,null,1))\n  const remain = gyp.opts.argv.remain[gyp.opts.argv.remain.length - 1];\n  if (remain && Object.hasOwnProperty.call(opts, remain)) {\n    console.log(opts[remain].replace(/\\\\/g, '/'));\n    hit = true;\n  }\n  // otherwise return all options as json\n  if (!hit) {\n    console.log(JSON.stringify(opts, unix_paths, 2));\n  }\n  return callback();\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/reveal.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/testbinary.js":
/*!*************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/testbinary.js ***!
  \*************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("var __dirname = \"/\";\n\n\nmodule.exports = exports = testbinary;\n\nexports.usage = 'Tests that the binary.node can be required';\n\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst cp = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'child_process'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\nfunction testbinary(gyp, argv, callback) {\n  const args = [];\n  const options = {};\n  let shell_cmd = process.execPath;\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  // skip validation for runtimes we don't explicitly support (like electron)\n  if (opts.runtime &&\n        opts.runtime !== 'node-webkit' &&\n        opts.runtime !== 'node') {\n    return callback();\n  }\n  const nw = (opts.runtime && opts.runtime === 'node-webkit');\n  // ensure on windows that / are used for require path\n  const binary_module = opts.module.replace(/\\\\/g, '/');\n  if ((process.arch !== opts.target_arch) ||\n        (process.platform !== opts.target_platform)) {\n    let msg = 'skipping validation since host platform/arch (';\n    msg += process.platform + '/' + process.arch + ')';\n    msg += ' does not match target (';\n    msg += opts.target_platform + '/' + opts.target_arch + ')';\n    log.info('validate', msg);\n    return callback();\n  }\n  if (nw) {\n    options.timeout = 5000;\n    if (process.platform === 'darwin') {\n      shell_cmd = 'node-webkit';\n    } else if (process.platform === 'win32') {\n      shell_cmd = 'nw.exe';\n    } else {\n      shell_cmd = 'nw';\n    }\n    const modulePath = path.resolve(binary_module);\n    const appDir = path.join(__dirname, 'util', 'nw-pre-gyp');\n    args.push(appDir);\n    args.push(modulePath);\n    log.info('validate', \"Running test command: '\" + shell_cmd + ' ' + args.join(' ') + \"'\");\n    cp.execFile(shell_cmd, args, options, (err, stdout, stderr) => {\n      // check for normal timeout for node-webkit\n      if (err) {\n        if (err.killed === true && err.signal && err.signal.indexOf('SIG') > -1) {\n          return callback();\n        }\n        const stderrLog = stderr.toString();\n        log.info('stderr', stderrLog);\n        if (/^\\s*Xlib:\\s*extension\\s*\"RANDR\"\\s*missing\\s*on\\s*display\\s*\":\\d+\\.\\d+\"\\.\\s*$/.test(stderrLog)) {\n          log.info('RANDR', 'stderr contains only RANDR error, ignored');\n          return callback();\n        }\n        return callback(err);\n      }\n      return callback();\n    });\n    return;\n  }\n  args.push('--eval');\n  args.push(\"require('\" + binary_module.replace(/'/g, '\\'') + \"')\");\n  log.info('validate', \"Running test command: '\" + shell_cmd + ' ' + args.join(' ') + \"'\");\n  cp.execFile(shell_cmd, args, options, (err, stdout, stderr) => {\n    if (err) {\n      return callback(err, { stdout: stdout, stderr: stderr });\n    }\n    return callback();\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/testbinary.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/testpackage.js":
/*!**************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/testpackage.js ***!
  \**************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = testpackage;\n\nexports.usage = 'Tests that the staged package is valid';\n\nconst fs = __webpack_require__(/*! fs */ \"?12c0\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst existsAsync = fs.exists || path.exists;\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst testbinary = __webpack_require__(/*! ./testbinary.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/testbinary.js\");\nconst tar = __webpack_require__(/*! tar */ \"./node_modules/tar/index.js\");\nconst makeDir = __webpack_require__(/*! make-dir */ \"./node_modules/make-dir/index.js\");\n\nfunction testpackage(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  const tarball = opts.staged_tarball;\n  existsAsync(tarball, (found) => {\n    if (!found) {\n      return callback(new Error('Cannot test package because ' + tarball + ' missing: run `node-pre-gyp package` first'));\n    }\n    const to = opts.module_path;\n    function filter_func(entry) {\n      log.info('install', 'unpacking [' + entry.path + ']');\n    }\n\n    makeDir(to).then(() => {\n      tar.extract({\n        file: tarball,\n        cwd: to,\n        strip: 1,\n        onentry: filter_func\n      }).then(after_extract, callback);\n    }).catch((err) => {\n      return callback(err);\n    });\n\n    function after_extract() {\n      testbinary(gyp, argv, (err) => {\n        if (err) {\n          return callback(err);\n        } else {\n          console.log('[' + package_json.name + '] Package appears valid');\n          return callback();\n        }\n      });\n    }\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/testpackage.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/unpublish.js":
/*!************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/unpublish.js ***!
  \************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = unpublish;\n\nexports.usage = 'Unpublishes pre-built binary (requires aws-sdk)';\n\nconst log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\nconst versioning = __webpack_require__(/*! ./util/versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./util/napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\nconst s3_setup = __webpack_require__(/*! ./util/s3_setup.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js\");\nconst url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\");\n\nfunction unpublish(gyp, argv, callback) {\n  const package_json = gyp.package_json;\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(package_json, gyp.opts, napi_build_version);\n  const config = {};\n  s3_setup.detect(opts, config);\n  const s3 = s3_setup.get_s3(config);\n  const key_name = url.resolve(config.prefix, opts.package_name);\n  const s3_opts = {\n    Bucket: config.bucket,\n    Key: key_name\n  };\n  s3.headObject(s3_opts, (err, meta) => {\n    if (err && err.code === 'NotFound') {\n      console.log('[' + package_json.name + '] Not found: https://' + s3_opts.Bucket + '.s3.amazonaws.com/' + s3_opts.Key);\n      return callback();\n    } else if (err) {\n      return callback(err);\n    } else {\n      log.info('unpublish', JSON.stringify(meta));\n      s3.deleteObject(s3_opts, (err2, resp) => {\n        if (err2) return callback(err2);\n        log.info(JSON.stringify(resp));\n        console.log('[' + package_json.name + '] Success: removed https://' + s3_opts.Bucket + '.s3.amazonaws.com/' + s3_opts.Key);\n        return callback();\n      });\n    }\n  });\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/unpublish.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js":
/*!***************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js ***!
  \***************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports;\n\nconst fs = __webpack_require__(/*! fs */ \"?bb19\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst win = process.platform === 'win32';\nconst existsSync = fs.existsSync || path.existsSync;\nconst cp = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'child_process'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n\n// try to build up the complete path to node-gyp\n/* priority:\n  - node-gyp on ENV:npm_config_node_gyp (https://github.com/npm/npm/pull/4887)\n  - node-gyp on NODE_PATH\n  - node-gyp inside npm on NODE_PATH (ignore on iojs)\n  - node-gyp inside npm beside node exe\n*/\nfunction which_node_gyp() {\n  let node_gyp_bin;\n  if (process.env.npm_config_node_gyp) {\n    try {\n      node_gyp_bin = process.env.npm_config_node_gyp;\n      if (existsSync(node_gyp_bin)) {\n        return node_gyp_bin;\n      }\n    } catch (err) {\n      // do nothing\n    }\n  }\n  try {\n    const node_gyp_main = /*require.resolve*/(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'node-gyp'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())); // eslint-disable-line node/no-missing-require\n    node_gyp_bin = path.join(path.dirname(\n      path.dirname(node_gyp_main)),\n    'bin/node-gyp.js');\n    if (existsSync(node_gyp_bin)) {\n      return node_gyp_bin;\n    }\n  } catch (err) {\n    // do nothing\n  }\n  if (process.execPath.indexOf('iojs') === -1) {\n    try {\n      const npm_main = /*require.resolve*/(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'npm'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())); // eslint-disable-line node/no-missing-require\n      node_gyp_bin = path.join(path.dirname(\n        path.dirname(npm_main)),\n      'node_modules/node-gyp/bin/node-gyp.js');\n      if (existsSync(node_gyp_bin)) {\n        return node_gyp_bin;\n      }\n    } catch (err) {\n      // do nothing\n    }\n  }\n  const npm_base = path.join(path.dirname(\n    path.dirname(process.execPath)),\n  'lib/node_modules/npm/');\n  node_gyp_bin = path.join(npm_base, 'node_modules/node-gyp/bin/node-gyp.js');\n  if (existsSync(node_gyp_bin)) {\n    return node_gyp_bin;\n  }\n}\n\nmodule.exports.run_gyp = function(args, opts, callback) {\n  let shell_cmd = '';\n  const cmd_args = [];\n  if (opts.runtime && opts.runtime === 'node-webkit') {\n    shell_cmd = 'nw-gyp';\n    if (win) shell_cmd += '.cmd';\n  } else {\n    const node_gyp_path = which_node_gyp();\n    if (node_gyp_path) {\n      shell_cmd = process.execPath;\n      cmd_args.push(node_gyp_path);\n    } else {\n      shell_cmd = 'node-gyp';\n      if (win) shell_cmd += '.cmd';\n    }\n  }\n  const final_args = cmd_args.concat(args);\n  const cmd = cp.spawn(shell_cmd, final_args, { cwd: undefined, env: process.env, stdio: [0, 1, 2] });\n  cmd.on('error', (err) => {\n    if (err) {\n      return callback(new Error(\"Failed to execute '\" + shell_cmd + ' ' + final_args.join(' ') + \"' (\" + err + ')'));\n    }\n    callback(null, opts);\n  });\n  cmd.on('close', (code) => {\n    if (code && code !== 0) {\n      return callback(new Error(\"Failed to execute '\" + shell_cmd + ' ' + final_args.join(' ') + \"' (\" + code + ')'));\n    }\n    callback(null, opts);\n  });\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js ***!
  \***********************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports = handle_gyp_opts;\n\nconst versioning = __webpack_require__(/*! ./versioning.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\");\nconst napi = __webpack_require__(/*! ./napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\n/*\n\nHere we gather node-pre-gyp generated options (from versioning) and pass them along to node-gyp.\n\nWe massage the args and options slightly to account for differences in what commands mean between\nnode-pre-gyp and node-gyp (e.g. see the difference between \"build\" and \"rebuild\" below)\n\nKeep in mind: the values inside `argv` and `gyp.opts` below are different depending on whether\nnode-pre-gyp is called directory, or if it is called in a `run-script` phase of npm.\n\nWe also try to preserve any command line options that might have been passed to npm or node-pre-gyp.\nBut this is fairly difficult without passing way to much through. For example `gyp.opts` contains all\nthe process.env and npm pushes a lot of variables into process.env which node-pre-gyp inherits. So we have\nto be very selective about what we pass through.\n\nFor example:\n\n`npm install --build-from-source` will give:\n\nargv == [ 'rebuild' ]\ngyp.opts.argv == { remain: [ 'install' ],\n  cooked: [ 'install', '--fallback-to-build' ],\n  original: [ 'install', '--fallback-to-build' ] }\n\n`./bin/node-pre-gyp build` will give:\n\nargv == []\ngyp.opts.argv == { remain: [ 'build' ],\n  cooked: [ 'build' ],\n  original: [ '-C', 'test/app1', 'build' ] }\n\n*/\n\n// select set of node-pre-gyp versioning info\n// to share with node-gyp\nconst share_with_node_gyp = [\n  'module',\n  'module_name',\n  'module_path',\n  'napi_version',\n  'node_abi_napi',\n  'napi_build_version',\n  'node_napi_label'\n];\n\nfunction handle_gyp_opts(gyp, argv, callback) {\n\n  // Collect node-pre-gyp specific variables to pass to node-gyp\n  const node_pre_gyp_options = [];\n  // generate custom node-pre-gyp versioning info\n  const napi_build_version = napi.get_napi_build_version_from_command_args(argv);\n  const opts = versioning.evaluate(gyp.package_json, gyp.opts, napi_build_version);\n  share_with_node_gyp.forEach((key) => {\n    const val = opts[key];\n    if (val) {\n      node_pre_gyp_options.push('--' + key + '=' + val);\n    } else if (key === 'napi_build_version') {\n      node_pre_gyp_options.push('--' + key + '=0');\n    } else {\n      if (key !== 'napi_version' && key !== 'node_abi_napi')\n        return callback(new Error('Option ' + key + ' required but not found by node-pre-gyp'));\n    }\n  });\n\n  // Collect options that follow the special -- which disables nopt parsing\n  const unparsed_options = [];\n  let double_hyphen_found = false;\n  gyp.opts.argv.original.forEach((opt) => {\n    if (double_hyphen_found) {\n      unparsed_options.push(opt);\n    }\n    if (opt === '--') {\n      double_hyphen_found = true;\n    }\n  });\n\n  // We try respect and pass through remaining command\n  // line options (like --foo=bar) to node-gyp\n  const cooked = gyp.opts.argv.cooked;\n  const node_gyp_options = [];\n  cooked.forEach((value) => {\n    if (value.length > 2 && value.slice(0, 2) === '--') {\n      const key = value.slice(2);\n      const val = cooked[cooked.indexOf(value) + 1];\n      if (val && val.indexOf('--') === -1) { // handle '--foo=bar' or ['--foo','bar']\n        node_gyp_options.push('--' + key + '=' + val);\n      } else { // pass through --foo\n        node_gyp_options.push(value);\n      }\n    }\n  });\n\n  const result = { 'opts': opts, 'gyp': node_gyp_options, 'pre': node_pre_gyp_options, 'unparsed': unparsed_options };\n  return callback(null, result);\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js":
/*!************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js ***!
  \************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst fs = __webpack_require__(/*! fs */ \"?bb19\");\n\nmodule.exports = exports;\n\nconst versionArray = process.version\n  .substr(1)\n  .replace(/-.*$/, '')\n  .split('.')\n  .map((item) => {\n    return +item;\n  });\n\nconst napi_multiple_commands = [\n  'build',\n  'clean',\n  'configure',\n  'package',\n  'publish',\n  'reveal',\n  'testbinary',\n  'testpackage',\n  'unpublish'\n];\n\nconst napi_build_version_tag = 'napi_build_version=';\n\nmodule.exports.get_napi_version = function() {\n  // returns the non-zero numeric napi version or undefined if napi is not supported.\n  // correctly supporting target requires an updated cross-walk\n  let version = process.versions.napi; // can be undefined\n  if (!version) { // this code should never need to be updated\n    if (versionArray[0] === 9 && versionArray[1] >= 3) version = 2; // 9.3.0+\n    else if (versionArray[0] === 8) version = 1; // 8.0.0+\n  }\n  return version;\n};\n\nmodule.exports.get_napi_version_as_string = function(target) {\n  // returns the napi version as a string or an empty string if napi is not supported.\n  const version = module.exports.get_napi_version(target);\n  return version ? '' + version : '';\n};\n\nmodule.exports.validate_package_json = function(package_json, opts) { // throws Error\n\n  const binary = package_json.binary;\n  const module_path_ok = pathOK(binary.module_path);\n  const remote_path_ok = pathOK(binary.remote_path);\n  const package_name_ok = pathOK(binary.package_name);\n  const napi_build_versions = module.exports.get_napi_build_versions(package_json, opts, true);\n  const napi_build_versions_raw = module.exports.get_napi_build_versions_raw(package_json);\n\n  if (napi_build_versions) {\n    napi_build_versions.forEach((napi_build_version)=> {\n      if (!(parseInt(napi_build_version, 10) === napi_build_version && napi_build_version > 0)) {\n        throw new Error('All values specified in napi_versions must be positive integers.');\n      }\n    });\n  }\n\n  if (napi_build_versions && (!module_path_ok || (!remote_path_ok && !package_name_ok))) {\n    throw new Error('When napi_versions is specified; module_path and either remote_path or ' +\n\t\t\t\"package_name must contain the substitution string '{napi_build_version}`.\");\n  }\n\n  if ((module_path_ok || remote_path_ok || package_name_ok) && !napi_build_versions_raw) {\n    throw new Error(\"When the substitution string '{napi_build_version}` is specified in \" +\n\t\t\t'module_path, remote_path, or package_name; napi_versions must also be specified.');\n  }\n\n  if (napi_build_versions && !module.exports.get_best_napi_build_version(package_json, opts) &&\n\tmodule.exports.build_napi_only(package_json)) {\n    throw new Error(\n      'The Node-API version of this Node instance is ' + module.exports.get_napi_version(opts ? opts.target : undefined) + '. ' +\n\t\t\t'This module supports Node-API version(s) ' + module.exports.get_napi_build_versions_raw(package_json) + '. ' +\n\t\t\t'This Node instance cannot run this module.');\n  }\n\n  if (napi_build_versions_raw && !napi_build_versions && module.exports.build_napi_only(package_json)) {\n    throw new Error(\n      'The Node-API version of this Node instance is ' + module.exports.get_napi_version(opts ? opts.target : undefined) + '. ' +\n\t\t\t'This module supports Node-API version(s) ' + module.exports.get_napi_build_versions_raw(package_json) + '. ' +\n\t\t\t'This Node instance cannot run this module.');\n  }\n\n};\n\nfunction pathOK(path) {\n  return path && (path.indexOf('{napi_build_version}') !== -1 || path.indexOf('{node_napi_label}') !== -1);\n}\n\nmodule.exports.expand_commands = function(package_json, opts, commands) {\n  const expanded_commands = [];\n  const napi_build_versions = module.exports.get_napi_build_versions(package_json, opts);\n  commands.forEach((command)=> {\n    if (napi_build_versions && command.name === 'install') {\n      const napi_build_version = module.exports.get_best_napi_build_version(package_json, opts);\n      const args = napi_build_version ? [napi_build_version_tag + napi_build_version] : [];\n      expanded_commands.push({ name: command.name, args: args });\n    } else if (napi_build_versions && napi_multiple_commands.indexOf(command.name) !== -1) {\n      napi_build_versions.forEach((napi_build_version)=> {\n        const args = command.args.slice();\n        args.push(napi_build_version_tag + napi_build_version);\n        expanded_commands.push({ name: command.name, args: args });\n      });\n    } else {\n      expanded_commands.push(command);\n    }\n  });\n  return expanded_commands;\n};\n\nmodule.exports.get_napi_build_versions = function(package_json, opts, warnings) { // opts may be undefined\n  const log = __webpack_require__(/*! npmlog */ \"./node_modules/npmlog/log.js\");\n  let napi_build_versions = [];\n  const supported_napi_version = module.exports.get_napi_version(opts ? opts.target : undefined);\n  // remove duplicates, verify each napi version can actaully be built\n  if (package_json.binary && package_json.binary.napi_versions) {\n    package_json.binary.napi_versions.forEach((napi_version) => {\n      const duplicated = napi_build_versions.indexOf(napi_version) !== -1;\n      if (!duplicated && supported_napi_version && napi_version <= supported_napi_version) {\n        napi_build_versions.push(napi_version);\n      } else if (warnings && !duplicated && supported_napi_version) {\n        log.info('This Node instance does not support builds for Node-API version', napi_version);\n      }\n    });\n  }\n  if (opts && opts['build-latest-napi-version-only']) {\n    let latest_version = 0;\n    napi_build_versions.forEach((napi_version) => {\n      if (napi_version > latest_version) latest_version = napi_version;\n    });\n    napi_build_versions = latest_version ? [latest_version] : [];\n  }\n  return napi_build_versions.length ? napi_build_versions : undefined;\n};\n\nmodule.exports.get_napi_build_versions_raw = function(package_json) {\n  const napi_build_versions = [];\n  // remove duplicates\n  if (package_json.binary && package_json.binary.napi_versions) {\n    package_json.binary.napi_versions.forEach((napi_version) => {\n      if (napi_build_versions.indexOf(napi_version) === -1) {\n        napi_build_versions.push(napi_version);\n      }\n    });\n  }\n  return napi_build_versions.length ? napi_build_versions : undefined;\n};\n\nmodule.exports.get_command_arg = function(napi_build_version) {\n  return napi_build_version_tag + napi_build_version;\n};\n\nmodule.exports.get_napi_build_version_from_command_args = function(command_args) {\n  for (let i = 0; i < command_args.length; i++) {\n    const arg = command_args[i];\n    if (arg.indexOf(napi_build_version_tag) === 0) {\n      return parseInt(arg.substr(napi_build_version_tag.length), 10);\n    }\n  }\n  return undefined;\n};\n\nmodule.exports.swap_build_dir_out = function(napi_build_version) {\n  if (napi_build_version) {\n    const rm = __webpack_require__(/*! rimraf */ \"./node_modules/rimraf/rimraf.js\");\n    rm.sync(module.exports.get_build_dir(napi_build_version));\n    fs.renameSync('build', module.exports.get_build_dir(napi_build_version));\n  }\n};\n\nmodule.exports.swap_build_dir_in = function(napi_build_version) {\n  if (napi_build_version) {\n    const rm = __webpack_require__(/*! rimraf */ \"./node_modules/rimraf/rimraf.js\");\n    rm.sync('build');\n    fs.renameSync(module.exports.get_build_dir(napi_build_version), 'build');\n  }\n};\n\nmodule.exports.get_build_dir = function(napi_build_version) {\n  return 'build-tmp-napi-v' + napi_build_version;\n};\n\nmodule.exports.get_best_napi_build_version = function(package_json, opts) {\n  let best_napi_build_version = 0;\n  const napi_build_versions = module.exports.get_napi_build_versions(package_json, opts);\n  if (napi_build_versions) {\n    const our_napi_version = module.exports.get_napi_version(opts ? opts.target : undefined);\n    napi_build_versions.forEach((napi_build_version)=> {\n      if (napi_build_version > best_napi_build_version &&\n\t\t\t\tnapi_build_version <= our_napi_version) {\n        best_napi_build_version = napi_build_version;\n      }\n    });\n  }\n  return best_napi_build_version === 0 ? undefined : best_napi_build_version;\n};\n\nmodule.exports.build_napi_only = function(package_json) {\n  return package_json.binary && package_json.binary.package_name &&\n\tpackage_json.binary.package_name.indexOf('{node_napi_label}') === -1;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/index.html":
/*!**************************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/index.html ***!
  \**************************************************************************/
/***/ (() => {

eval("throw new Error(\"Module parse failed: Unexpected token (1:0)\\nYou may need an appropriate loader to handle this file type, currently no loaders are configured to process this file. See https://webpack.js.org/concepts#loaders\\n> <!doctype html>\\n| <html>\\n| <head>\");\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/index.html?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js":
/*!****************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js ***!
  \****************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports;\n\nconst url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\");\nconst fs = __webpack_require__(/*! fs */ \"?bb19\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\n\nmodule.exports.detect = function(opts, config) {\n  const to = opts.hosted_path;\n  const uri = url.parse(to);\n  config.prefix = (!uri.pathname || uri.pathname === '/') ? '' : uri.pathname.replace('/', '');\n  if (opts.bucket && opts.region) {\n    config.bucket = opts.bucket;\n    config.region = opts.region;\n    config.endpoint = opts.host;\n    config.s3ForcePathStyle = opts.s3ForcePathStyle;\n  } else {\n    const parts = uri.hostname.split('.s3');\n    const bucket = parts[0];\n    if (!bucket) {\n      return;\n    }\n    if (!config.bucket) {\n      config.bucket = bucket;\n    }\n    if (!config.region) {\n      const region = parts[1].slice(1).split('.')[0];\n      if (region === 'amazonaws') {\n        config.region = 'us-east-1';\n      } else {\n        config.region = region;\n      }\n    }\n  }\n};\n\nmodule.exports.get_s3 = function(config) {\n\n  if (process.env.node_pre_gyp_mock_s3) {\n    // here we're mocking. node_pre_gyp_mock_s3 is the scratch directory\n    // for the mock code.\n    const AWSMock = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'mock-aws-s3'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n    const os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n\n    AWSMock.config.basePath = `${os.tmpdir()}/mock`;\n\n    const s3 = AWSMock.S3();\n\n    // wrapped callback maker. fs calls return code of ENOENT but AWS.S3 returns\n    // NotFound.\n    const wcb = (fn) => (err, ...args) => {\n      if (err && err.code === 'ENOENT') {\n        err.code = 'NotFound';\n      }\n      return fn(err, ...args);\n    };\n\n    return {\n      listObjects(params, callback) {\n        return s3.listObjects(params, wcb(callback));\n      },\n      headObject(params, callback) {\n        return s3.headObject(params, wcb(callback));\n      },\n      deleteObject(params, callback) {\n        return s3.deleteObject(params, wcb(callback));\n      },\n      putObject(params, callback) {\n        return s3.putObject(params, wcb(callback));\n      }\n    };\n  }\n\n  // if not mocking then setup real s3.\n  const AWS = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'aws-sdk'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n\n  AWS.config.update(config);\n  const s3 = new AWS.S3();\n\n  // need to change if additional options need to be specified.\n  return {\n    listObjects(params, callback) {\n      return s3.listObjects(params, callback);\n    },\n    headObject(params, callback) {\n      return s3.headObject(params, callback);\n    },\n    deleteObject(params, callback) {\n      return s3.deleteObject(params, callback);\n    },\n    putObject(params, callback) {\n      return s3.putObject(params, callback);\n    }\n  };\n\n\n\n};\n\n//\n// function to get the mocking control function. if not mocking it returns a no-op.\n//\n// if mocking it sets up the mock http interceptors that use the mocked s3 file system\n// to fulfill reponses.\nmodule.exports.get_mockS3Http = function() {\n  let mock_s3 = false;\n  if (!process.env.node_pre_gyp_mock_s3) {\n    return () => mock_s3;\n  }\n\n  const nock = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'nock'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n  // the bucket used for testing, as addressed by https.\n  const host = 'https://mapbox-node-pre-gyp-public-testing-bucket.s3.us-east-1.amazonaws.com';\n  const mockDir = process.env.node_pre_gyp_mock_s3 + '/mapbox-node-pre-gyp-public-testing-bucket';\n\n  // function to setup interceptors. they are \"turned off\" by setting mock_s3 to false.\n  const mock_http = () => {\n    // eslint-disable-next-line no-unused-vars\n    function get(uri, requestBody) {\n      const filepath = path.join(mockDir, uri.replace('%2B', '+'));\n\n      try {\n        fs.accessSync(filepath, fs.constants.R_OK);\n      } catch (e) {\n        return [404, 'not found\\n'];\n      }\n\n      // the mock s3 functions just write to disk, so just read from it.\n      return [200, fs.createReadStream(filepath)];\n    }\n\n    // eslint-disable-next-line no-unused-vars\n    return nock(host)\n      .persist()\n      .get(() => mock_s3) // mock any uri for s3 when true\n      .reply(get);\n  };\n\n  // setup interceptors. they check the mock_s3 flag to determine whether to intercept.\n  mock_http(nock, host, mockDir);\n  // function to turn matching all requests to s3 on/off.\n  const mockS3Http = (action) => {\n    const previous = mock_s3;\n    if (action === 'off') {\n      mock_s3 = false;\n    } else if (action === 'on') {\n      mock_s3 = true;\n    } else if (action !== 'get') {\n      throw new Error(`illegal action for setMockHttp ${action}`);\n    }\n    return previous;\n  };\n\n  // call mockS3Http with the argument\n  // - 'on' - turn it on\n  // - 'off' - turn it off (used by fetch.test.js so it doesn't interfere with redirects)\n  // - 'get' - return true or false for 'on' or 'off'\n  return mockS3Http;\n};\n\n\n\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js":
/*!******************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js ***!
  \******************************************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\nmodule.exports = exports;\n\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst semver = __webpack_require__(/*! semver */ \"./node_modules/semver/index.js\");\nconst url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\");\nconst detect_libc = __webpack_require__(/*! detect-libc */ \"./node_modules/detect-libc/lib/detect-libc.js\");\nconst napi = __webpack_require__(/*! ./napi.js */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\");\n\nlet abi_crosswalk;\n\n// This is used for unit testing to provide a fake\n// ABI crosswalk that emulates one that is not updated\n// for the current version\nif (process.env.NODE_PRE_GYP_ABI_CROSSWALK) {\n  abi_crosswalk = __webpack_require__(\"./node_modules/@mapbox/node-pre-gyp/lib/util sync recursive\")(process.env.NODE_PRE_GYP_ABI_CROSSWALK);\n} else {\n  abi_crosswalk = __webpack_require__(/*! ./abi_crosswalk.json */ \"./node_modules/@mapbox/node-pre-gyp/lib/util/abi_crosswalk.json\");\n}\n\nconst major_versions = {};\nObject.keys(abi_crosswalk).forEach((v) => {\n  const major = v.split('.')[0];\n  if (!major_versions[major]) {\n    major_versions[major] = v;\n  }\n});\n\nfunction get_electron_abi(runtime, target_version) {\n  if (!runtime) {\n    throw new Error('get_electron_abi requires valid runtime arg');\n  }\n  if (typeof target_version === 'undefined') {\n    // erroneous CLI call\n    throw new Error('Empty target version is not supported if electron is the target.');\n  }\n  // Electron guarantees that patch version update won't break native modules.\n  const sem_ver = semver.parse(target_version);\n  return runtime + '-v' + sem_ver.major + '.' + sem_ver.minor;\n}\nmodule.exports.get_electron_abi = get_electron_abi;\n\nfunction get_node_webkit_abi(runtime, target_version) {\n  if (!runtime) {\n    throw new Error('get_node_webkit_abi requires valid runtime arg');\n  }\n  if (typeof target_version === 'undefined') {\n    // erroneous CLI call\n    throw new Error('Empty target version is not supported if node-webkit is the target.');\n  }\n  return runtime + '-v' + target_version;\n}\nmodule.exports.get_node_webkit_abi = get_node_webkit_abi;\n\nfunction get_node_abi(runtime, versions) {\n  if (!runtime) {\n    throw new Error('get_node_abi requires valid runtime arg');\n  }\n  if (!versions) {\n    throw new Error('get_node_abi requires valid process.versions object');\n  }\n  const sem_ver = semver.parse(versions.node);\n  if (sem_ver.major === 0 && sem_ver.minor % 2) { // odd series\n    // https://github.com/mapbox/node-pre-gyp/issues/124\n    return runtime + '-v' + versions.node;\n  } else {\n    // process.versions.modules added in >= v0.10.4 and v0.11.7\n    // https://github.com/joyent/node/commit/ccabd4a6fa8a6eb79d29bc3bbe9fe2b6531c2d8e\n    return versions.modules ? runtime + '-v' + (+versions.modules) :\n      'v8-' + versions.v8.split('.').slice(0, 2).join('.');\n  }\n}\nmodule.exports.get_node_abi = get_node_abi;\n\nfunction get_runtime_abi(runtime, target_version) {\n  if (!runtime) {\n    throw new Error('get_runtime_abi requires valid runtime arg');\n  }\n  if (runtime === 'node-webkit') {\n    return get_node_webkit_abi(runtime, target_version || process.versions['node-webkit']);\n  } else if (runtime === 'electron') {\n    return get_electron_abi(runtime, target_version || process.versions.electron);\n  } else {\n    if (runtime !== 'node') {\n      throw new Error(\"Unknown Runtime: '\" + runtime + \"'\");\n    }\n    if (!target_version) {\n      return get_node_abi(runtime, process.versions);\n    } else {\n      let cross_obj;\n      // abi_crosswalk generated with ./scripts/abi_crosswalk.js\n      if (abi_crosswalk[target_version]) {\n        cross_obj = abi_crosswalk[target_version];\n      } else {\n        const target_parts = target_version.split('.').map((i) => { return +i; });\n        if (target_parts.length !== 3) { // parse failed\n          throw new Error('Unknown target version: ' + target_version);\n        }\n        /*\n                    The below code tries to infer the last known ABI compatible version\n                    that we have recorded in the abi_crosswalk.json when an exact match\n                    is not possible. The reasons for this to exist are complicated:\n\n                       - We support passing --target to be able to allow developers to package binaries for versions of node\n                         that are not the same one as they are running. This might also be used in combination with the\n                         --target_arch or --target_platform flags to also package binaries for alternative platforms\n                       - When --target is passed we can't therefore determine the ABI (process.versions.modules) from the node\n                         version that is running in memory\n                       - So, therefore node-pre-gyp keeps an \"ABI crosswalk\" (lib/util/abi_crosswalk.json) to be able to look\n                         this info up for all versions\n                       - But we cannot easily predict what the future ABI will be for released versions\n                       - And node-pre-gyp needs to be a `bundledDependency` in apps that depend on it in order to work correctly\n                         by being fully available at install time.\n                       - So, the speed of node releases and the bundled nature of node-pre-gyp mean that a new node-pre-gyp release\n                         need to happen for every node.js/io.js/node-webkit/nw.js/atom-shell/etc release that might come online if\n                         you want the `--target` flag to keep working for the latest version\n                       - Which is impractical ^^\n                       - Hence the below code guesses about future ABI to make the need to update node-pre-gyp less demanding.\n\n                    In practice then you can have a dependency of your app like `node-sqlite3` that bundles a `node-pre-gyp` that\n                    only knows about node v0.10.33 in the `abi_crosswalk.json` but target node v0.10.34 (which is assumed to be\n                    ABI compatible with v0.10.33).\n\n                    TODO: use semver module instead of custom version parsing\n                */\n        const major = target_parts[0];\n        let minor = target_parts[1];\n        let patch = target_parts[2];\n        // io.js: yeah if node.js ever releases 1.x this will break\n        // but that is unlikely to happen: https://github.com/iojs/io.js/pull/253#issuecomment-69432616\n        if (major === 1) {\n          // look for last release that is the same major version\n          // e.g. we assume io.js 1.x is ABI compatible with >= 1.0.0\n          while (true) {\n            if (minor > 0) --minor;\n            if (patch > 0) --patch;\n            const new_iojs_target = '' + major + '.' + minor + '.' + patch;\n            if (abi_crosswalk[new_iojs_target]) {\n              cross_obj = abi_crosswalk[new_iojs_target];\n              console.log('Warning: node-pre-gyp could not find exact match for ' + target_version);\n              console.log('Warning: but node-pre-gyp successfully choose ' + new_iojs_target + ' as ABI compatible target');\n              break;\n            }\n            if (minor === 0 && patch === 0) {\n              break;\n            }\n          }\n        } else if (major >= 2) {\n          // look for last release that is the same major version\n          if (major_versions[major]) {\n            cross_obj = abi_crosswalk[major_versions[major]];\n            console.log('Warning: node-pre-gyp could not find exact match for ' + target_version);\n            console.log('Warning: but node-pre-gyp successfully choose ' + major_versions[major] + ' as ABI compatible target');\n          }\n        } else if (major === 0) { // node.js\n          if (target_parts[1] % 2 === 0) { // for stable/even node.js series\n            // look for the last release that is the same minor release\n            // e.g. we assume node 0.10.x is ABI compatible with >= 0.10.0\n            while (--patch > 0) {\n              const new_node_target = '' + major + '.' + minor + '.' + patch;\n              if (abi_crosswalk[new_node_target]) {\n                cross_obj = abi_crosswalk[new_node_target];\n                console.log('Warning: node-pre-gyp could not find exact match for ' + target_version);\n                console.log('Warning: but node-pre-gyp successfully choose ' + new_node_target + ' as ABI compatible target');\n                break;\n              }\n            }\n          }\n        }\n      }\n      if (!cross_obj) {\n        throw new Error('Unsupported target version: ' + target_version);\n      }\n      // emulate process.versions\n      const versions_obj = {\n        node: target_version,\n        v8: cross_obj.v8 + '.0',\n        // abi_crosswalk uses 1 for node versions lacking process.versions.modules\n        // process.versions.modules added in >= v0.10.4 and v0.11.7\n        modules: cross_obj.node_abi > 1 ? cross_obj.node_abi : undefined\n      };\n      return get_node_abi(runtime, versions_obj);\n    }\n  }\n}\nmodule.exports.get_runtime_abi = get_runtime_abi;\n\nconst required_parameters = [\n  'module_name',\n  'module_path',\n  'host'\n];\n\nfunction validate_config(package_json, opts) {\n  const msg = package_json.name + ' package.json is not node-pre-gyp ready:\\n';\n  const missing = [];\n  if (!package_json.main) {\n    missing.push('main');\n  }\n  if (!package_json.version) {\n    missing.push('version');\n  }\n  if (!package_json.name) {\n    missing.push('name');\n  }\n  if (!package_json.binary) {\n    missing.push('binary');\n  }\n  const o = package_json.binary;\n  if (o) {\n    required_parameters.forEach((p) => {\n      if (!o[p] || typeof o[p] !== 'string') {\n        missing.push('binary.' + p);\n      }\n    });\n  }\n\n  if (missing.length >= 1) {\n    throw new Error(msg + 'package.json must declare these properties: \\n' + missing.join('\\n'));\n  }\n  if (o) {\n    // enforce https over http\n    const protocol = url.parse(o.host).protocol;\n    if (protocol === 'http:') {\n      throw new Error(\"'host' protocol (\" + protocol + \") is invalid - only 'https:' is accepted\");\n    }\n  }\n  napi.validate_package_json(package_json, opts);\n}\n\nmodule.exports.validate_config = validate_config;\n\nfunction eval_template(template, opts) {\n  Object.keys(opts).forEach((key) => {\n    const pattern = '{' + key + '}';\n    while (template.indexOf(pattern) > -1) {\n      template = template.replace(pattern, opts[key]);\n    }\n  });\n  return template;\n}\n\n// url.resolve needs single trailing slash\n// to behave correctly, otherwise a double slash\n// may end up in the url which breaks requests\n// and a lacking slash may not lead to proper joining\nfunction fix_slashes(pathname) {\n  if (pathname.slice(-1) !== '/') {\n    return pathname + '/';\n  }\n  return pathname;\n}\n\n// remove double slashes\n// note: path.normalize will not work because\n// it will convert forward to back slashes\nfunction drop_double_slashes(pathname) {\n  return pathname.replace(/\\/\\//g, '/');\n}\n\nfunction get_process_runtime(versions) {\n  let runtime = 'node';\n  if (versions['node-webkit']) {\n    runtime = 'node-webkit';\n  } else if (versions.electron) {\n    runtime = 'electron';\n  }\n  return runtime;\n}\n\nmodule.exports.get_process_runtime = get_process_runtime;\n\nconst default_package_name = '{module_name}-v{version}-{node_abi}-{platform}-{arch}.tar.gz';\nconst default_remote_path = '';\n\nmodule.exports.evaluate = function(package_json, options, napi_build_version) {\n  options = options || {};\n  validate_config(package_json, options); // options is a suitable substitute for opts in this case\n  const v = package_json.version;\n  const module_version = semver.parse(v);\n  const runtime = options.runtime || get_process_runtime(process.versions);\n  const opts = {\n    name: package_json.name,\n    configuration: options.debug ? 'Debug' : 'Release',\n    debug: options.debug,\n    module_name: package_json.binary.module_name,\n    version: module_version.version,\n    prerelease: module_version.prerelease.length ? module_version.prerelease.join('.') : '',\n    build: module_version.build.length ? module_version.build.join('.') : '',\n    major: module_version.major,\n    minor: module_version.minor,\n    patch: module_version.patch,\n    runtime: runtime,\n    node_abi: get_runtime_abi(runtime, options.target),\n    node_abi_napi: napi.get_napi_version(options.target) ? 'napi' : get_runtime_abi(runtime, options.target),\n    napi_version: napi.get_napi_version(options.target), // non-zero numeric, undefined if unsupported\n    napi_build_version: napi_build_version || '',\n    node_napi_label: napi_build_version ? 'napi-v' + napi_build_version : get_runtime_abi(runtime, options.target),\n    target: options.target || '',\n    platform: options.target_platform || process.platform,\n    target_platform: options.target_platform || process.platform,\n    arch: options.target_arch || process.arch,\n    target_arch: options.target_arch || process.arch,\n    libc: options.target_libc || detect_libc.familySync() || 'unknown',\n    module_main: package_json.main,\n    toolset: options.toolset || '', // address https://github.com/mapbox/node-pre-gyp/issues/119\n    bucket: package_json.binary.bucket,\n    region: package_json.binary.region,\n    s3ForcePathStyle: package_json.binary.s3ForcePathStyle || false\n  };\n    // support host mirror with npm config `--{module_name}_binary_host_mirror`\n    // e.g.: https://github.com/node-inspector/v8-profiler/blob/master/package.json#L25\n    // > npm install v8-profiler --profiler_binary_host_mirror=https://npm.taobao.org/mirrors/node-inspector/\n  const validModuleName = opts.module_name.replace('-', '_');\n  const host = process.env['npm_config_' + validModuleName + '_binary_host_mirror'] || package_json.binary.host;\n  opts.host = fix_slashes(eval_template(host, opts));\n  opts.module_path = eval_template(package_json.binary.module_path, opts);\n  // now we resolve the module_path to ensure it is absolute so that binding.gyp variables work predictably\n  if (options.module_root) {\n    // resolve relative to known module root: works for pre-binding require\n    opts.module_path = path.join(options.module_root, opts.module_path);\n  } else {\n    // resolve relative to current working directory: works for node-pre-gyp commands\n    opts.module_path = path.resolve(opts.module_path);\n  }\n  opts.module = path.join(opts.module_path, opts.module_name + '.node');\n  opts.remote_path = package_json.binary.remote_path ? drop_double_slashes(fix_slashes(eval_template(package_json.binary.remote_path, opts))) : default_remote_path;\n  const package_name = package_json.binary.package_name ? package_json.binary.package_name : default_package_name;\n  opts.package_name = eval_template(package_name, opts);\n  opts.staged_tarball = path.join('build/stage', opts.remote_path, opts.package_name);\n  opts.hosted_path = url.resolve(opts.host, opts.remote_path);\n  opts.hosted_tarball = url.resolve(opts.hosted_path, opts.package_name);\n  return opts;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util sync recursive":
/*!**********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/ sync ***!
  \**********************************************************/
/***/ ((module) => {

eval("function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = () => ([]);\nwebpackEmptyContext.resolve = webpackEmptyContext;\nwebpackEmptyContext.id = \"./node_modules/@mapbox/node-pre-gyp/lib/util sync recursive\";\nmodule.exports = webpackEmptyContext;\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/_sync?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib sync recursive ^\\.\\/.*$":
/*!**************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/ sync ^\.\/.*$ ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var map = {\n\t\"./build\": \"./node_modules/@mapbox/node-pre-gyp/lib/build.js\",\n\t\"./build.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/build.js\",\n\t\"./clean\": \"./node_modules/@mapbox/node-pre-gyp/lib/clean.js\",\n\t\"./clean.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/clean.js\",\n\t\"./configure\": \"./node_modules/@mapbox/node-pre-gyp/lib/configure.js\",\n\t\"./configure.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/configure.js\",\n\t\"./info\": \"./node_modules/@mapbox/node-pre-gyp/lib/info.js\",\n\t\"./info.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/info.js\",\n\t\"./install\": \"./node_modules/@mapbox/node-pre-gyp/lib/install.js\",\n\t\"./install.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/install.js\",\n\t\"./main\": \"./node_modules/@mapbox/node-pre-gyp/lib/main.js\",\n\t\"./main.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/main.js\",\n\t\"./node-pre-gyp\": \"./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js\",\n\t\"./node-pre-gyp.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js\",\n\t\"./package\": \"./node_modules/@mapbox/node-pre-gyp/lib/package.js\",\n\t\"./package.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/package.js\",\n\t\"./pre-binding\": \"./node_modules/@mapbox/node-pre-gyp/lib/pre-binding.js\",\n\t\"./pre-binding.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/pre-binding.js\",\n\t\"./publish\": \"./node_modules/@mapbox/node-pre-gyp/lib/publish.js\",\n\t\"./publish.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/publish.js\",\n\t\"./rebuild\": \"./node_modules/@mapbox/node-pre-gyp/lib/rebuild.js\",\n\t\"./rebuild.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/rebuild.js\",\n\t\"./reinstall\": \"./node_modules/@mapbox/node-pre-gyp/lib/reinstall.js\",\n\t\"./reinstall.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/reinstall.js\",\n\t\"./reveal\": \"./node_modules/@mapbox/node-pre-gyp/lib/reveal.js\",\n\t\"./reveal.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/reveal.js\",\n\t\"./testbinary\": \"./node_modules/@mapbox/node-pre-gyp/lib/testbinary.js\",\n\t\"./testbinary.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/testbinary.js\",\n\t\"./testpackage\": \"./node_modules/@mapbox/node-pre-gyp/lib/testpackage.js\",\n\t\"./testpackage.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/testpackage.js\",\n\t\"./unpublish\": \"./node_modules/@mapbox/node-pre-gyp/lib/unpublish.js\",\n\t\"./unpublish.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/unpublish.js\",\n\t\"./util/abi_crosswalk\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/abi_crosswalk.json\",\n\t\"./util/abi_crosswalk.json\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/abi_crosswalk.json\",\n\t\"./util/compile\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js\",\n\t\"./util/compile.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/compile.js\",\n\t\"./util/handle_gyp_opts\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js\",\n\t\"./util/handle_gyp_opts.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/handle_gyp_opts.js\",\n\t\"./util/napi\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\",\n\t\"./util/napi.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/napi.js\",\n\t\"./util/nw-pre-gyp/index.html\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/index.html\",\n\t\"./util/nw-pre-gyp/package\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/package.json\",\n\t\"./util/nw-pre-gyp/package.json\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/package.json\",\n\t\"./util/s3_setup\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js\",\n\t\"./util/s3_setup.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/s3_setup.js\",\n\t\"./util/versioning\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\",\n\t\"./util/versioning.js\": \"./node_modules/@mapbox/node-pre-gyp/lib/util/versioning.js\"\n};\n\n\nfunction webpackContext(req) {\n\tvar id = webpackContextResolve(req);\n\treturn __webpack_require__(id);\n}\nfunction webpackContextResolve(req) {\n\tif(!__webpack_require__.o(map, req)) {\n\t\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\t\te.code = 'MODULE_NOT_FOUND';\n\t\tthrow e;\n\t}\n\treturn map[req];\n}\nwebpackContext.keys = function webpackContextKeys() {\n\treturn Object.keys(map);\n};\nwebpackContext.resolve = webpackContextResolve;\nmodule.exports = webpackContext;\nwebpackContext.id = \"./node_modules/@mapbox/node-pre-gyp/lib sync recursive ^\\\\.\\\\/.*$\";\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/_sync_^\\.\\/.*$?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/AuthAdminApi.js":
/*!********************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/AuthAdminApi.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _GoTrueAdminApi__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./GoTrueAdminApi */ \"./node_modules/@supabase/auth-js/dist/module/GoTrueAdminApi.js\");\n\nconst AuthAdminApi = _GoTrueAdminApi__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AuthAdminApi);\n//# sourceMappingURL=AuthAdminApi.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/AuthAdminApi.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/AuthClient.js":
/*!******************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/AuthClient.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _GoTrueClient__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./GoTrueClient */ \"./node_modules/@supabase/auth-js/dist/module/GoTrueClient.js\");\n\nconst AuthClient = _GoTrueClient__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (AuthClient);\n//# sourceMappingURL=AuthClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/AuthClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/GoTrueAdminApi.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/GoTrueAdminApi.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ GoTrueAdminApi)\n/* harmony export */ });\n/* harmony import */ var _lib_fetch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/fetch */ \"./node_modules/@supabase/auth-js/dist/module/lib/fetch.js\");\n/* harmony import */ var _lib_helpers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/helpers */ \"./node_modules/@supabase/auth-js/dist/module/lib/helpers.js\");\n/* harmony import */ var _lib_errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/errors */ \"./node_modules/@supabase/auth-js/dist/module/lib/errors.js\");\nvar __rest = (undefined && undefined.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\n\n\n\nclass GoTrueAdminApi {\n    constructor({ url = '', headers = {}, fetch, }) {\n        this.url = url;\n        this.headers = headers;\n        this.fetch = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_1__.resolveFetch)(fetch);\n        this.mfa = {\n            listFactors: this._listFactors.bind(this),\n            deleteFactor: this._deleteFactor.bind(this),\n        };\n    }\n    /**\n     * Removes a logged-in session.\n     * @param jwt A valid, logged-in JWT.\n     * @param scope The logout sope.\n     */\n    async signOut(jwt, scope = 'global') {\n        try {\n            await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'POST', `${this.url}/logout?scope=${scope}`, {\n                headers: this.headers,\n                jwt,\n                noResolveJson: true,\n            });\n            return { data: null, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Sends an invite link to an email address.\n     * @param email The email address of the user.\n     * @param options Additional options to be included when inviting.\n     */\n    async inviteUserByEmail(email, options = {}) {\n        try {\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'POST', `${this.url}/invite`, {\n                body: { email, data: options.data },\n                headers: this.headers,\n                redirectTo: options.redirectTo,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._userResponse,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Generates email links and OTPs to be sent via a custom email provider.\n     * @param email The user's email.\n     * @param options.password User password. For signup only.\n     * @param options.data Optional user metadata. For signup only.\n     * @param options.redirectTo The redirect url which should be appended to the generated link\n     */\n    async generateLink(params) {\n        try {\n            const { options } = params, rest = __rest(params, [\"options\"]);\n            const body = Object.assign(Object.assign({}, rest), options);\n            if ('newEmail' in rest) {\n                // replace newEmail with new_email in request body\n                body.new_email = rest === null || rest === void 0 ? void 0 : rest.newEmail;\n                delete body['newEmail'];\n            }\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'POST', `${this.url}/admin/generate_link`, {\n                body: body,\n                headers: this.headers,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._generateLinkResponse,\n                redirectTo: options === null || options === void 0 ? void 0 : options.redirectTo,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return {\n                    data: {\n                        properties: null,\n                        user: null,\n                    },\n                    error,\n                };\n            }\n            throw error;\n        }\n    }\n    // User Admin API\n    /**\n     * Creates a new user.\n     * This function should only be called on a server. Never expose your `service_role` key in the browser.\n     */\n    async createUser(attributes) {\n        try {\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'POST', `${this.url}/admin/users`, {\n                body: attributes,\n                headers: this.headers,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._userResponse,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Get a list of users.\n     *\n     * This function should only be called on a server. Never expose your `service_role` key in the browser.\n     * @param params An object which supports `page` and `perPage` as numbers, to alter the paginated results.\n     */\n    async listUsers(params) {\n        var _a, _b, _c, _d, _e, _f, _g;\n        try {\n            const pagination = { nextPage: null, lastPage: 0, total: 0 };\n            const response = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'GET', `${this.url}/admin/users`, {\n                headers: this.headers,\n                noResolveJson: true,\n                query: {\n                    page: (_b = (_a = params === null || params === void 0 ? void 0 : params.page) === null || _a === void 0 ? void 0 : _a.toString()) !== null && _b !== void 0 ? _b : '',\n                    per_page: (_d = (_c = params === null || params === void 0 ? void 0 : params.perPage) === null || _c === void 0 ? void 0 : _c.toString()) !== null && _d !== void 0 ? _d : '',\n                },\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._noResolveJsonResponse,\n            });\n            if (response.error)\n                throw response.error;\n            const users = await response.json();\n            const total = (_e = response.headers.get('x-total-count')) !== null && _e !== void 0 ? _e : 0;\n            const links = (_g = (_f = response.headers.get('link')) === null || _f === void 0 ? void 0 : _f.split(',')) !== null && _g !== void 0 ? _g : [];\n            if (links.length > 0) {\n                links.forEach((link) => {\n                    const page = parseInt(link.split(';')[0].split('=')[1].substring(0, 1));\n                    const rel = JSON.parse(link.split(';')[1].split('=')[1]);\n                    pagination[`${rel}Page`] = page;\n                });\n                pagination.total = parseInt(total);\n            }\n            return { data: Object.assign(Object.assign({}, users), pagination), error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { users: [] }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Get user by id.\n     *\n     * @param uid The user's unique identifier\n     *\n     * This function should only be called on a server. Never expose your `service_role` key in the browser.\n     */\n    async getUserById(uid) {\n        try {\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'GET', `${this.url}/admin/users/${uid}`, {\n                headers: this.headers,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._userResponse,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Updates the user data.\n     *\n     * @param attributes The data you want to update.\n     *\n     * This function should only be called on a server. Never expose your `service_role` key in the browser.\n     */\n    async updateUserById(uid, attributes) {\n        try {\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'PUT', `${this.url}/admin/users/${uid}`, {\n                body: attributes,\n                headers: this.headers,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._userResponse,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Delete a user. Requires a `service_role` key.\n     *\n     * @param id The user id you want to remove.\n     * @param shouldSoftDelete If true, then the user will be soft-deleted (setting `deleted_at` to the current timestamp and disabling their account while preserving their data) from the auth schema.\n     * Defaults to false for backward compatibility.\n     *\n     * This function should only be called on a server. Never expose your `service_role` key in the browser.\n     */\n    async deleteUser(id, shouldSoftDelete = false) {\n        try {\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'DELETE', `${this.url}/admin/users/${id}`, {\n                headers: this.headers,\n                body: {\n                    should_soft_delete: shouldSoftDelete,\n                },\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_0__._userResponse,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    async _listFactors(params) {\n        try {\n            const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'GET', `${this.url}/admin/users/${params.userId}/factors`, {\n                headers: this.headers,\n                xform: (factors) => {\n                    return { data: { factors }, error: null };\n                },\n            });\n            return { data, error };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    async _deleteFactor(params) {\n        try {\n            const data = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_0__._request)(this.fetch, 'DELETE', `${this.url}/admin/users/${params.userId}/factors/${params.id}`, {\n                headers: this.headers,\n            });\n            return { data, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n}\n//# sourceMappingURL=GoTrueAdminApi.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/GoTrueAdminApi.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/GoTrueClient.js":
/*!********************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/GoTrueClient.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ GoTrueClient)\n/* harmony export */ });\n/* harmony import */ var _GoTrueAdminApi__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./GoTrueAdminApi */ \"./node_modules/@supabase/auth-js/dist/module/GoTrueAdminApi.js\");\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/constants */ \"./node_modules/@supabase/auth-js/dist/module/lib/constants.js\");\n/* harmony import */ var _lib_errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/errors */ \"./node_modules/@supabase/auth-js/dist/module/lib/errors.js\");\n/* harmony import */ var _lib_fetch__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/fetch */ \"./node_modules/@supabase/auth-js/dist/module/lib/fetch.js\");\n/* harmony import */ var _lib_helpers__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/helpers */ \"./node_modules/@supabase/auth-js/dist/module/lib/helpers.js\");\n/* harmony import */ var _lib_local_storage__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/local-storage */ \"./node_modules/@supabase/auth-js/dist/module/lib/local-storage.js\");\n/* harmony import */ var _lib_polyfills__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/polyfills */ \"./node_modules/@supabase/auth-js/dist/module/lib/polyfills.js\");\n/* harmony import */ var _lib_version__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./lib/version */ \"./node_modules/@supabase/auth-js/dist/module/lib/version.js\");\n/* harmony import */ var _lib_locks__WEBPACK_IMPORTED_MODULE_8__ = __webpack_require__(/*! ./lib/locks */ \"./node_modules/@supabase/auth-js/dist/module/lib/locks.js\");\n\n\n\n\n\n\n\n\n\n(0,_lib_polyfills__WEBPACK_IMPORTED_MODULE_6__.polyfillGlobalThis)(); // Make \"globalThis\" available\nconst DEFAULT_OPTIONS = {\n    url: _lib_constants__WEBPACK_IMPORTED_MODULE_1__.GOTRUE_URL,\n    storageKey: _lib_constants__WEBPACK_IMPORTED_MODULE_1__.STORAGE_KEY,\n    autoRefreshToken: true,\n    persistSession: true,\n    detectSessionInUrl: true,\n    headers: _lib_constants__WEBPACK_IMPORTED_MODULE_1__.DEFAULT_HEADERS,\n    flowType: 'implicit',\n    debug: false,\n    hasCustomAuthorizationHeader: false,\n};\n/** Current session will be checked for refresh at this interval. */\nconst AUTO_REFRESH_TICK_DURATION = 30 * 1000;\n/**\n * A token refresh will be attempted this many ticks before the current session expires. */\nconst AUTO_REFRESH_TICK_THRESHOLD = 3;\nasync function lockNoOp(name, acquireTimeout, fn) {\n    return await fn();\n}\nclass GoTrueClient {\n    /**\n     * Create a new client for use in the browser.\n     */\n    constructor(options) {\n        var _a, _b;\n        this.memoryStorage = null;\n        this.stateChangeEmitters = new Map();\n        this.autoRefreshTicker = null;\n        this.visibilityChangedCallback = null;\n        this.refreshingDeferred = null;\n        /**\n         * Keeps track of the async client initialization.\n         * When null or not yet resolved the auth state is `unknown`\n         * Once resolved the the auth state is known and it's save to call any further client methods.\n         * Keep extra care to never reject or throw uncaught errors\n         */\n        this.initializePromise = null;\n        this.detectSessionInUrl = true;\n        this.hasCustomAuthorizationHeader = false;\n        this.suppressGetSessionWarning = false;\n        this.lockAcquired = false;\n        this.pendingInLock = [];\n        /**\n         * Used to broadcast state change events to other tabs listening.\n         */\n        this.broadcastChannel = null;\n        this.logger = console.log;\n        this.instanceID = GoTrueClient.nextInstanceID;\n        GoTrueClient.nextInstanceID += 1;\n        if (this.instanceID > 0 && (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)()) {\n            console.warn('Multiple GoTrueClient instances detected in the same browser context. It is not an error, but this should be avoided as it may produce undefined behavior when used concurrently under the same storage key.');\n        }\n        const settings = Object.assign(Object.assign({}, DEFAULT_OPTIONS), options);\n        this.logDebugMessages = !!settings.debug;\n        if (typeof settings.debug === 'function') {\n            this.logger = settings.debug;\n        }\n        this.persistSession = settings.persistSession;\n        this.storageKey = settings.storageKey;\n        this.autoRefreshToken = settings.autoRefreshToken;\n        this.admin = new _GoTrueAdminApi__WEBPACK_IMPORTED_MODULE_0__[\"default\"]({\n            url: settings.url,\n            headers: settings.headers,\n            fetch: settings.fetch,\n        });\n        this.url = settings.url;\n        this.headers = settings.headers;\n        this.fetch = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.resolveFetch)(settings.fetch);\n        this.lock = settings.lock || lockNoOp;\n        this.detectSessionInUrl = settings.detectSessionInUrl;\n        this.flowType = settings.flowType;\n        this.hasCustomAuthorizationHeader = settings.hasCustomAuthorizationHeader;\n        if (settings.lock) {\n            this.lock = settings.lock;\n        }\n        else if ((0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() && ((_a = globalThis === null || globalThis === void 0 ? void 0 : globalThis.navigator) === null || _a === void 0 ? void 0 : _a.locks)) {\n            this.lock = _lib_locks__WEBPACK_IMPORTED_MODULE_8__.navigatorLock;\n        }\n        else {\n            this.lock = lockNoOp;\n        }\n        this.mfa = {\n            verify: this._verify.bind(this),\n            enroll: this._enroll.bind(this),\n            unenroll: this._unenroll.bind(this),\n            challenge: this._challenge.bind(this),\n            listFactors: this._listFactors.bind(this),\n            challengeAndVerify: this._challengeAndVerify.bind(this),\n            getAuthenticatorAssuranceLevel: this._getAuthenticatorAssuranceLevel.bind(this),\n        };\n        if (this.persistSession) {\n            if (settings.storage) {\n                this.storage = settings.storage;\n            }\n            else {\n                if ((0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.supportsLocalStorage)()) {\n                    this.storage = _lib_local_storage__WEBPACK_IMPORTED_MODULE_5__.localStorageAdapter;\n                }\n                else {\n                    this.memoryStorage = {};\n                    this.storage = (0,_lib_local_storage__WEBPACK_IMPORTED_MODULE_5__.memoryLocalStorageAdapter)(this.memoryStorage);\n                }\n            }\n        }\n        else {\n            this.memoryStorage = {};\n            this.storage = (0,_lib_local_storage__WEBPACK_IMPORTED_MODULE_5__.memoryLocalStorageAdapter)(this.memoryStorage);\n        }\n        if ((0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() && globalThis.BroadcastChannel && this.persistSession && this.storageKey) {\n            try {\n                this.broadcastChannel = new globalThis.BroadcastChannel(this.storageKey);\n            }\n            catch (e) {\n                console.error('Failed to create a new BroadcastChannel, multi-tab state changes will not be available', e);\n            }\n            (_b = this.broadcastChannel) === null || _b === void 0 ? void 0 : _b.addEventListener('message', async (event) => {\n                this._debug('received broadcast notification from other tab or client', event);\n                await this._notifyAllSubscribers(event.data.event, event.data.session, false); // broadcast = false so we don't get an endless loop of messages\n            });\n        }\n        this.initialize();\n    }\n    _debug(...args) {\n        if (this.logDebugMessages) {\n            this.logger(`GoTrueClient@${this.instanceID} (${_lib_version__WEBPACK_IMPORTED_MODULE_7__.version}) ${new Date().toISOString()}`, ...args);\n        }\n        return this;\n    }\n    /**\n     * Initializes the client session either from the url or from storage.\n     * This method is automatically called when instantiating the client, but should also be called\n     * manually when checking for an error from an auth redirect (oauth, magiclink, password recovery, etc).\n     */\n    async initialize() {\n        if (this.initializePromise) {\n            return await this.initializePromise;\n        }\n        this.initializePromise = (async () => {\n            return await this._acquireLock(-1, async () => {\n                return await this._initialize();\n            });\n        })();\n        return await this.initializePromise;\n    }\n    /**\n     * IMPORTANT:\n     * 1. Never throw in this method, as it is called from the constructor\n     * 2. Never return a session from this method as it would be cached over\n     *    the whole lifetime of the client\n     */\n    async _initialize() {\n        try {\n            const isPKCEFlow = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() ? await this._isPKCEFlow() : false;\n            this._debug('#_initialize()', 'begin', 'is PKCE flow', isPKCEFlow);\n            if (isPKCEFlow || (this.detectSessionInUrl && this._isImplicitGrantFlow())) {\n                const { data, error } = await this._getSessionFromURL(isPKCEFlow);\n                if (error) {\n                    this._debug('#_initialize()', 'error detecting session from URL', error);\n                    // hacky workaround to keep the existing session if there's an error returned from identity linking\n                    // TODO: once error codes are ready, we should match against it instead of the message\n                    if ((error === null || error === void 0 ? void 0 : error.message) === 'Identity is already linked' ||\n                        (error === null || error === void 0 ? void 0 : error.message) === 'Identity is already linked to another user') {\n                        return { error };\n                    }\n                    // failed login attempt via url,\n                    // remove old session as in verifyOtp, signUp and signInWith*\n                    await this._removeSession();\n                    return { error };\n                }\n                const { session, redirectType } = data;\n                this._debug('#_initialize()', 'detected session in URL', session, 'redirect type', redirectType);\n                await this._saveSession(session);\n                setTimeout(async () => {\n                    if (redirectType === 'recovery') {\n                        await this._notifyAllSubscribers('PASSWORD_RECOVERY', session);\n                    }\n                    else {\n                        await this._notifyAllSubscribers('SIGNED_IN', session);\n                    }\n                }, 0);\n                return { error: null };\n            }\n            // no login attempt via callback url try to recover session from storage\n            await this._recoverAndRefresh();\n            return { error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { error };\n            }\n            return {\n                error: new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthUnknownError('Unexpected error during initialization', error),\n            };\n        }\n        finally {\n            await this._handleVisibilityChange();\n            this._debug('#_initialize()', 'end');\n        }\n    }\n    /**\n     * Creates a new anonymous user.\n     *\n     * @returns A session where the is_anonymous claim in the access token JWT set to true\n     */\n    async signInAnonymously(credentials) {\n        var _a, _b, _c;\n        try {\n            const res = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/signup`, {\n                headers: this.headers,\n                body: {\n                    data: (_b = (_a = credentials === null || credentials === void 0 ? void 0 : credentials.options) === null || _a === void 0 ? void 0 : _a.data) !== null && _b !== void 0 ? _b : {},\n                    gotrue_meta_security: { captcha_token: (_c = credentials === null || credentials === void 0 ? void 0 : credentials.options) === null || _c === void 0 ? void 0 : _c.captchaToken },\n                },\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n            });\n            const { data, error } = res;\n            if (error || !data) {\n                return { data: { user: null, session: null }, error: error };\n            }\n            const session = data.session;\n            const user = data.user;\n            if (data.session) {\n                await this._saveSession(data.session);\n                await this._notifyAllSubscribers('SIGNED_IN', session);\n            }\n            return { data: { user, session }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Creates a new user.\n     *\n     * Be aware that if a user account exists in the system you may get back an\n     * error message that attempts to hide this information from the user.\n     * This method has support for PKCE via email signups. The PKCE flow cannot be used when autoconfirm is enabled.\n     *\n     * @returns A logged-in session if the server has \"autoconfirm\" ON\n     * @returns A user if the server has \"autoconfirm\" OFF\n     */\n    async signUp(credentials) {\n        var _a, _b, _c;\n        try {\n            let res;\n            if ('email' in credentials) {\n                const { email, password, options } = credentials;\n                let codeChallenge = null;\n                let codeChallengeMethod = null;\n                if (this.flowType === 'pkce') {\n                    ;\n                    [codeChallenge, codeChallengeMethod] = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getCodeChallengeAndMethod)(this.storage, this.storageKey);\n                }\n                res = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/signup`, {\n                    headers: this.headers,\n                    redirectTo: options === null || options === void 0 ? void 0 : options.emailRedirectTo,\n                    body: {\n                        email,\n                        password,\n                        data: (_a = options === null || options === void 0 ? void 0 : options.data) !== null && _a !== void 0 ? _a : {},\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                        code_challenge: codeChallenge,\n                        code_challenge_method: codeChallengeMethod,\n                    },\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n                });\n            }\n            else if ('phone' in credentials) {\n                const { phone, password, options } = credentials;\n                res = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/signup`, {\n                    headers: this.headers,\n                    body: {\n                        phone,\n                        password,\n                        data: (_b = options === null || options === void 0 ? void 0 : options.data) !== null && _b !== void 0 ? _b : {},\n                        channel: (_c = options === null || options === void 0 ? void 0 : options.channel) !== null && _c !== void 0 ? _c : 'sms',\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                    },\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n                });\n            }\n            else {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidCredentialsError('You must provide either an email or phone number and a password');\n            }\n            const { data, error } = res;\n            if (error || !data) {\n                return { data: { user: null, session: null }, error: error };\n            }\n            const session = data.session;\n            const user = data.user;\n            if (data.session) {\n                await this._saveSession(data.session);\n                await this._notifyAllSubscribers('SIGNED_IN', session);\n            }\n            return { data: { user, session }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Log in an existing user with an email and password or phone and password.\n     *\n     * Be aware that you may get back an error message that will not distinguish\n     * between the cases where the account does not exist or that the\n     * email/phone and password combination is wrong or that the account can only\n     * be accessed via social login.\n     */\n    async signInWithPassword(credentials) {\n        try {\n            let res;\n            if ('email' in credentials) {\n                const { email, password, options } = credentials;\n                res = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/token?grant_type=password`, {\n                    headers: this.headers,\n                    body: {\n                        email,\n                        password,\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                    },\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponsePassword,\n                });\n            }\n            else if ('phone' in credentials) {\n                const { phone, password, options } = credentials;\n                res = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/token?grant_type=password`, {\n                    headers: this.headers,\n                    body: {\n                        phone,\n                        password,\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                    },\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponsePassword,\n                });\n            }\n            else {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidCredentialsError('You must provide either an email or phone number and a password');\n            }\n            const { data, error } = res;\n            if (error) {\n                return { data: { user: null, session: null }, error };\n            }\n            else if (!data || !data.session || !data.user) {\n                return { data: { user: null, session: null }, error: new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidTokenResponseError() };\n            }\n            if (data.session) {\n                await this._saveSession(data.session);\n                await this._notifyAllSubscribers('SIGNED_IN', data.session);\n            }\n            return {\n                data: Object.assign({ user: data.user, session: data.session }, (data.weak_password ? { weakPassword: data.weak_password } : null)),\n                error,\n            };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Log in an existing user via a third-party provider.\n     * This method supports the PKCE flow.\n     */\n    async signInWithOAuth(credentials) {\n        var _a, _b, _c, _d;\n        return await this._handleProviderSignIn(credentials.provider, {\n            redirectTo: (_a = credentials.options) === null || _a === void 0 ? void 0 : _a.redirectTo,\n            scopes: (_b = credentials.options) === null || _b === void 0 ? void 0 : _b.scopes,\n            queryParams: (_c = credentials.options) === null || _c === void 0 ? void 0 : _c.queryParams,\n            skipBrowserRedirect: (_d = credentials.options) === null || _d === void 0 ? void 0 : _d.skipBrowserRedirect,\n        });\n    }\n    /**\n     * Log in an existing user by exchanging an Auth Code issued during the PKCE flow.\n     */\n    async exchangeCodeForSession(authCode) {\n        await this.initializePromise;\n        return this._acquireLock(-1, async () => {\n            return this._exchangeCodeForSession(authCode);\n        });\n    }\n    async _exchangeCodeForSession(authCode) {\n        const storageItem = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getItemAsync)(this.storage, `${this.storageKey}-code-verifier`);\n        const [codeVerifier, redirectType] = (storageItem !== null && storageItem !== void 0 ? storageItem : '').split('/');\n        const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/token?grant_type=pkce`, {\n            headers: this.headers,\n            body: {\n                auth_code: authCode,\n                code_verifier: codeVerifier,\n            },\n            xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n        });\n        await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.removeItemAsync)(this.storage, `${this.storageKey}-code-verifier`);\n        if (error) {\n            return { data: { user: null, session: null, redirectType: null }, error };\n        }\n        else if (!data || !data.session || !data.user) {\n            return {\n                data: { user: null, session: null, redirectType: null },\n                error: new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidTokenResponseError(),\n            };\n        }\n        if (data.session) {\n            await this._saveSession(data.session);\n            await this._notifyAllSubscribers('SIGNED_IN', data.session);\n        }\n        return { data: Object.assign(Object.assign({}, data), { redirectType: redirectType !== null && redirectType !== void 0 ? redirectType : null }), error };\n    }\n    /**\n     * Allows signing in with an OIDC ID token. The authentication provider used\n     * should be enabled and configured.\n     */\n    async signInWithIdToken(credentials) {\n        try {\n            const { options, provider, token, access_token, nonce } = credentials;\n            const res = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/token?grant_type=id_token`, {\n                headers: this.headers,\n                body: {\n                    provider,\n                    id_token: token,\n                    access_token,\n                    nonce,\n                    gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                },\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n            });\n            const { data, error } = res;\n            if (error) {\n                return { data: { user: null, session: null }, error };\n            }\n            else if (!data || !data.session || !data.user) {\n                return {\n                    data: { user: null, session: null },\n                    error: new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidTokenResponseError(),\n                };\n            }\n            if (data.session) {\n                await this._saveSession(data.session);\n                await this._notifyAllSubscribers('SIGNED_IN', data.session);\n            }\n            return { data, error };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Log in a user using magiclink or a one-time password (OTP).\n     *\n     * If the `{{ .ConfirmationURL }}` variable is specified in the email template, a magiclink will be sent.\n     * If the `{{ .Token }}` variable is specified in the email template, an OTP will be sent.\n     * If you're using phone sign-ins, only an OTP will be sent. You won't be able to send a magiclink for phone sign-ins.\n     *\n     * Be aware that you may get back an error message that will not distinguish\n     * between the cases where the account does not exist or, that the account\n     * can only be accessed via social login.\n     *\n     * Do note that you will need to configure a Whatsapp sender on Twilio\n     * if you are using phone sign in with the 'whatsapp' channel. The whatsapp\n     * channel is not supported on other providers\n     * at this time.\n     * This method supports PKCE when an email is passed.\n     */\n    async signInWithOtp(credentials) {\n        var _a, _b, _c, _d, _e;\n        try {\n            if ('email' in credentials) {\n                const { email, options } = credentials;\n                let codeChallenge = null;\n                let codeChallengeMethod = null;\n                if (this.flowType === 'pkce') {\n                    ;\n                    [codeChallenge, codeChallengeMethod] = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getCodeChallengeAndMethod)(this.storage, this.storageKey);\n                }\n                const { error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/otp`, {\n                    headers: this.headers,\n                    body: {\n                        email,\n                        data: (_a = options === null || options === void 0 ? void 0 : options.data) !== null && _a !== void 0 ? _a : {},\n                        create_user: (_b = options === null || options === void 0 ? void 0 : options.shouldCreateUser) !== null && _b !== void 0 ? _b : true,\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                        code_challenge: codeChallenge,\n                        code_challenge_method: codeChallengeMethod,\n                    },\n                    redirectTo: options === null || options === void 0 ? void 0 : options.emailRedirectTo,\n                });\n                return { data: { user: null, session: null }, error };\n            }\n            if ('phone' in credentials) {\n                const { phone, options } = credentials;\n                const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/otp`, {\n                    headers: this.headers,\n                    body: {\n                        phone,\n                        data: (_c = options === null || options === void 0 ? void 0 : options.data) !== null && _c !== void 0 ? _c : {},\n                        create_user: (_d = options === null || options === void 0 ? void 0 : options.shouldCreateUser) !== null && _d !== void 0 ? _d : true,\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                        channel: (_e = options === null || options === void 0 ? void 0 : options.channel) !== null && _e !== void 0 ? _e : 'sms',\n                    },\n                });\n                return { data: { user: null, session: null, messageId: data === null || data === void 0 ? void 0 : data.message_id }, error };\n            }\n            throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidCredentialsError('You must provide either an email or phone number.');\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Log in a user given a User supplied OTP or TokenHash received through mobile or email.\n     */\n    async verifyOtp(params) {\n        var _a, _b;\n        try {\n            let redirectTo = undefined;\n            let captchaToken = undefined;\n            if ('options' in params) {\n                redirectTo = (_a = params.options) === null || _a === void 0 ? void 0 : _a.redirectTo;\n                captchaToken = (_b = params.options) === null || _b === void 0 ? void 0 : _b.captchaToken;\n            }\n            const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/verify`, {\n                headers: this.headers,\n                body: Object.assign(Object.assign({}, params), { gotrue_meta_security: { captcha_token: captchaToken } }),\n                redirectTo,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n            });\n            if (error) {\n                throw error;\n            }\n            if (!data) {\n                throw new Error('An error occurred on token verification.');\n            }\n            const session = data.session;\n            const user = data.user;\n            if (session === null || session === void 0 ? void 0 : session.access_token) {\n                await this._saveSession(session);\n                await this._notifyAllSubscribers(params.type == 'recovery' ? 'PASSWORD_RECOVERY' : 'SIGNED_IN', session);\n            }\n            return { data: { user, session }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Attempts a single-sign on using an enterprise Identity Provider. A\n     * successful SSO attempt will redirect the current page to the identity\n     * provider authorization page. The redirect URL is implementation and SSO\n     * protocol specific.\n     *\n     * You can use it by providing a SSO domain. Typically you can extract this\n     * domain by asking users for their email address. If this domain is\n     * registered on the Auth instance the redirect will use that organization's\n     * currently active SSO Identity Provider for the login.\n     *\n     * If you have built an organization-specific login page, you can use the\n     * organization's SSO Identity Provider UUID directly instead.\n     */\n    async signInWithSSO(params) {\n        var _a, _b, _c;\n        try {\n            let codeChallenge = null;\n            let codeChallengeMethod = null;\n            if (this.flowType === 'pkce') {\n                ;\n                [codeChallenge, codeChallengeMethod] = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getCodeChallengeAndMethod)(this.storage, this.storageKey);\n            }\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/sso`, {\n                body: Object.assign(Object.assign(Object.assign(Object.assign(Object.assign({}, ('providerId' in params ? { provider_id: params.providerId } : null)), ('domain' in params ? { domain: params.domain } : null)), { redirect_to: (_b = (_a = params.options) === null || _a === void 0 ? void 0 : _a.redirectTo) !== null && _b !== void 0 ? _b : undefined }), (((_c = params === null || params === void 0 ? void 0 : params.options) === null || _c === void 0 ? void 0 : _c.captchaToken)\n                    ? { gotrue_meta_security: { captcha_token: params.options.captchaToken } }\n                    : null)), { skip_http_redirect: true, code_challenge: codeChallenge, code_challenge_method: codeChallengeMethod }),\n                headers: this.headers,\n                xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._ssoResponse,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Sends a reauthentication OTP to the user's email or phone number.\n     * Requires the user to be signed-in.\n     */\n    async reauthenticate() {\n        await this.initializePromise;\n        return await this._acquireLock(-1, async () => {\n            return await this._reauthenticate();\n        });\n    }\n    async _reauthenticate() {\n        try {\n            return await this._useSession(async (result) => {\n                const { data: { session }, error: sessionError, } = result;\n                if (sessionError)\n                    throw sessionError;\n                if (!session)\n                    throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError();\n                const { error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'GET', `${this.url}/reauthenticate`, {\n                    headers: this.headers,\n                    jwt: session.access_token,\n                });\n                return { data: { user: null, session: null }, error };\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Resends an existing signup confirmation email, email change email, SMS OTP or phone change OTP.\n     */\n    async resend(credentials) {\n        try {\n            const endpoint = `${this.url}/resend`;\n            if ('email' in credentials) {\n                const { email, type, options } = credentials;\n                const { error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', endpoint, {\n                    headers: this.headers,\n                    body: {\n                        email,\n                        type,\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                    },\n                    redirectTo: options === null || options === void 0 ? void 0 : options.emailRedirectTo,\n                });\n                return { data: { user: null, session: null }, error };\n            }\n            else if ('phone' in credentials) {\n                const { phone, type, options } = credentials;\n                const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', endpoint, {\n                    headers: this.headers,\n                    body: {\n                        phone,\n                        type,\n                        gotrue_meta_security: { captcha_token: options === null || options === void 0 ? void 0 : options.captchaToken },\n                    },\n                });\n                return { data: { user: null, session: null, messageId: data === null || data === void 0 ? void 0 : data.message_id }, error };\n            }\n            throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthInvalidCredentialsError('You must provide either an email or phone number and a type');\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Returns the session, refreshing it if necessary.\n     *\n     * The session returned can be null if the session is not detected which can happen in the event a user is not signed-in or has logged out.\n     *\n     * **IMPORTANT:** This method loads values directly from the storage attached\n     * to the client. If that storage is based on request cookies for example,\n     * the values in it may not be authentic and therefore it's strongly advised\n     * against using this method and its results in such circumstances. A warning\n     * will be emitted if this is detected. Use {@link #getUser()} instead.\n     */\n    async getSession() {\n        await this.initializePromise;\n        const result = await this._acquireLock(-1, async () => {\n            return this._useSession(async (result) => {\n                return result;\n            });\n        });\n        return result;\n    }\n    /**\n     * Acquires a global lock based on the storage key.\n     */\n    async _acquireLock(acquireTimeout, fn) {\n        this._debug('#_acquireLock', 'begin', acquireTimeout);\n        try {\n            if (this.lockAcquired) {\n                const last = this.pendingInLock.length\n                    ? this.pendingInLock[this.pendingInLock.length - 1]\n                    : Promise.resolve();\n                const result = (async () => {\n                    await last;\n                    return await fn();\n                })();\n                this.pendingInLock.push((async () => {\n                    try {\n                        await result;\n                    }\n                    catch (e) {\n                        // we just care if it finished\n                    }\n                })());\n                return result;\n            }\n            return await this.lock(`lock:${this.storageKey}`, acquireTimeout, async () => {\n                this._debug('#_acquireLock', 'lock acquired for storage key', this.storageKey);\n                try {\n                    this.lockAcquired = true;\n                    const result = fn();\n                    this.pendingInLock.push((async () => {\n                        try {\n                            await result;\n                        }\n                        catch (e) {\n                            // we just care if it finished\n                        }\n                    })());\n                    await result;\n                    // keep draining the queue until there's nothing to wait on\n                    while (this.pendingInLock.length) {\n                        const waitOn = [...this.pendingInLock];\n                        await Promise.all(waitOn);\n                        this.pendingInLock.splice(0, waitOn.length);\n                    }\n                    return await result;\n                }\n                finally {\n                    this._debug('#_acquireLock', 'lock released for storage key', this.storageKey);\n                    this.lockAcquired = false;\n                }\n            });\n        }\n        finally {\n            this._debug('#_acquireLock', 'end');\n        }\n    }\n    /**\n     * Use instead of {@link #getSession} inside the library. It is\n     * semantically usually what you want, as getting a session involves some\n     * processing afterwards that requires only one client operating on the\n     * session at once across multiple tabs or processes.\n     */\n    async _useSession(fn) {\n        this._debug('#_useSession', 'begin');\n        try {\n            // the use of __loadSession here is the only correct use of the function!\n            const result = await this.__loadSession();\n            return await fn(result);\n        }\n        finally {\n            this._debug('#_useSession', 'end');\n        }\n    }\n    /**\n     * NEVER USE DIRECTLY!\n     *\n     * Always use {@link #_useSession}.\n     */\n    async __loadSession() {\n        this._debug('#__loadSession()', 'begin');\n        if (!this.lockAcquired) {\n            this._debug('#__loadSession()', 'used outside of an acquired lock!', new Error().stack);\n        }\n        try {\n            let currentSession = null;\n            const maybeSession = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getItemAsync)(this.storage, this.storageKey);\n            this._debug('#getSession()', 'session from storage', maybeSession);\n            if (maybeSession !== null) {\n                if (this._isValidSession(maybeSession)) {\n                    currentSession = maybeSession;\n                }\n                else {\n                    this._debug('#getSession()', 'session from storage is not valid');\n                    await this._removeSession();\n                }\n            }\n            if (!currentSession) {\n                return { data: { session: null }, error: null };\n            }\n            const hasExpired = currentSession.expires_at\n                ? currentSession.expires_at <= Date.now() / 1000\n                : false;\n            this._debug('#__loadSession()', `session has${hasExpired ? '' : ' not'} expired`, 'expires_at', currentSession.expires_at);\n            if (!hasExpired) {\n                if (this.storage.isServer) {\n                    let suppressWarning = this.suppressGetSessionWarning;\n                    const proxySession = new Proxy(currentSession, {\n                        get: (target, prop, receiver) => {\n                            if (!suppressWarning && prop === 'user') {\n                                // only show warning when the user object is being accessed from the server\n                                console.warn('Using the user object as returned from supabase.auth.getSession() or from some supabase.auth.onAuthStateChange() events could be insecure! This value comes directly from the storage medium (usually cookies on the server) and many not be authentic. Use supabase.auth.getUser() instead which authenticates the data by contacting the Supabase Auth server.');\n                                suppressWarning = true; // keeps this proxy instance from logging additional warnings\n                                this.suppressGetSessionWarning = true; // keeps this client's future proxy instances from warning\n                            }\n                            return Reflect.get(target, prop, receiver);\n                        },\n                    });\n                    currentSession = proxySession;\n                }\n                return { data: { session: currentSession }, error: null };\n            }\n            const { session, error } = await this._callRefreshToken(currentSession.refresh_token);\n            if (error) {\n                return { data: { session: null }, error };\n            }\n            return { data: { session }, error: null };\n        }\n        finally {\n            this._debug('#__loadSession()', 'end');\n        }\n    }\n    /**\n     * Gets the current user details if there is an existing session. This method\n     * performs a network request to the Supabase Auth server, so the returned\n     * value is authentic and can be used to base authorization rules on.\n     *\n     * @param jwt Takes in an optional access token JWT. If no JWT is provided, the JWT from the current session is used.\n     */\n    async getUser(jwt) {\n        if (jwt) {\n            return await this._getUser(jwt);\n        }\n        await this.initializePromise;\n        const result = await this._acquireLock(-1, async () => {\n            return await this._getUser();\n        });\n        return result;\n    }\n    async _getUser(jwt) {\n        try {\n            if (jwt) {\n                return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'GET', `${this.url}/user`, {\n                    headers: this.headers,\n                    jwt: jwt,\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._userResponse,\n                });\n            }\n            return await this._useSession(async (result) => {\n                var _a, _b, _c;\n                const { data, error } = result;\n                if (error) {\n                    throw error;\n                }\n                // returns an error if there is no access_token or custom authorization header\n                if (!((_a = data.session) === null || _a === void 0 ? void 0 : _a.access_token) && !this.hasCustomAuthorizationHeader) {\n                    return { data: { user: null }, error: new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError() };\n                }\n                return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'GET', `${this.url}/user`, {\n                    headers: this.headers,\n                    jwt: (_c = (_b = data.session) === null || _b === void 0 ? void 0 : _b.access_token) !== null && _c !== void 0 ? _c : undefined,\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._userResponse,\n                });\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Updates user data for a logged in user.\n     */\n    async updateUser(attributes, options = {}) {\n        await this.initializePromise;\n        return await this._acquireLock(-1, async () => {\n            return await this._updateUser(attributes, options);\n        });\n    }\n    async _updateUser(attributes, options = {}) {\n        try {\n            return await this._useSession(async (result) => {\n                const { data: sessionData, error: sessionError } = result;\n                if (sessionError) {\n                    throw sessionError;\n                }\n                if (!sessionData.session) {\n                    throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError();\n                }\n                const session = sessionData.session;\n                let codeChallenge = null;\n                let codeChallengeMethod = null;\n                if (this.flowType === 'pkce' && attributes.email != null) {\n                    ;\n                    [codeChallenge, codeChallengeMethod] = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getCodeChallengeAndMethod)(this.storage, this.storageKey);\n                }\n                const { data, error: userError } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'PUT', `${this.url}/user`, {\n                    headers: this.headers,\n                    redirectTo: options === null || options === void 0 ? void 0 : options.emailRedirectTo,\n                    body: Object.assign(Object.assign({}, attributes), { code_challenge: codeChallenge, code_challenge_method: codeChallengeMethod }),\n                    jwt: session.access_token,\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._userResponse,\n                });\n                if (userError)\n                    throw userError;\n                session.user = data.user;\n                await this._saveSession(session);\n                await this._notifyAllSubscribers('USER_UPDATED', session);\n                return { data: { user: session.user }, error: null };\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Decodes a JWT (without performing any validation).\n     */\n    _decodeJWT(jwt) {\n        return (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.decodeJWTPayload)(jwt);\n    }\n    /**\n     * Sets the session data from the current session. If the current session is expired, setSession will take care of refreshing it to obtain a new session.\n     * If the refresh token or access token in the current session is invalid, an error will be thrown.\n     * @param currentSession The current session that minimally contains an access token and refresh token.\n     */\n    async setSession(currentSession) {\n        await this.initializePromise;\n        return await this._acquireLock(-1, async () => {\n            return await this._setSession(currentSession);\n        });\n    }\n    async _setSession(currentSession) {\n        try {\n            if (!currentSession.access_token || !currentSession.refresh_token) {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError();\n            }\n            const timeNow = Date.now() / 1000;\n            let expiresAt = timeNow;\n            let hasExpired = true;\n            let session = null;\n            const payload = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.decodeJWTPayload)(currentSession.access_token);\n            if (payload.exp) {\n                expiresAt = payload.exp;\n                hasExpired = expiresAt <= timeNow;\n            }\n            if (hasExpired) {\n                const { session: refreshedSession, error } = await this._callRefreshToken(currentSession.refresh_token);\n                if (error) {\n                    return { data: { user: null, session: null }, error: error };\n                }\n                if (!refreshedSession) {\n                    return { data: { user: null, session: null }, error: null };\n                }\n                session = refreshedSession;\n            }\n            else {\n                const { data, error } = await this._getUser(currentSession.access_token);\n                if (error) {\n                    throw error;\n                }\n                session = {\n                    access_token: currentSession.access_token,\n                    refresh_token: currentSession.refresh_token,\n                    user: data.user,\n                    token_type: 'bearer',\n                    expires_in: expiresAt - timeNow,\n                    expires_at: expiresAt,\n                };\n                await this._saveSession(session);\n                await this._notifyAllSubscribers('SIGNED_IN', session);\n            }\n            return { data: { user: session.user, session }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { session: null, user: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Returns a new session, regardless of expiry status.\n     * Takes in an optional current session. If not passed in, then refreshSession() will attempt to retrieve it from getSession().\n     * If the current session's refresh token is invalid, an error will be thrown.\n     * @param currentSession The current session. If passed in, it must contain a refresh token.\n     */\n    async refreshSession(currentSession) {\n        await this.initializePromise;\n        return await this._acquireLock(-1, async () => {\n            return await this._refreshSession(currentSession);\n        });\n    }\n    async _refreshSession(currentSession) {\n        try {\n            return await this._useSession(async (result) => {\n                var _a;\n                if (!currentSession) {\n                    const { data, error } = result;\n                    if (error) {\n                        throw error;\n                    }\n                    currentSession = (_a = data.session) !== null && _a !== void 0 ? _a : undefined;\n                }\n                if (!(currentSession === null || currentSession === void 0 ? void 0 : currentSession.refresh_token)) {\n                    throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError();\n                }\n                const { session, error } = await this._callRefreshToken(currentSession.refresh_token);\n                if (error) {\n                    return { data: { user: null, session: null }, error: error };\n                }\n                if (!session) {\n                    return { data: { user: null, session: null }, error: null };\n                }\n                return { data: { user: session.user, session }, error: null };\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { user: null, session: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Gets the session data from a URL string\n     */\n    async _getSessionFromURL(isPKCEFlow) {\n        try {\n            if (!(0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)())\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthImplicitGrantRedirectError('No browser detected.');\n            if (this.flowType === 'implicit' && !this._isImplicitGrantFlow()) {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthImplicitGrantRedirectError('Not a valid implicit grant flow url.');\n            }\n            else if (this.flowType == 'pkce' && !isPKCEFlow) {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthPKCEGrantCodeExchangeError('Not a valid PKCE flow url.');\n            }\n            const params = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.parseParametersFromURL)(window.location.href);\n            if (isPKCEFlow) {\n                if (!params.code)\n                    throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthPKCEGrantCodeExchangeError('No code detected.');\n                const { data, error } = await this._exchangeCodeForSession(params.code);\n                if (error)\n                    throw error;\n                const url = new URL(window.location.href);\n                url.searchParams.delete('code');\n                window.history.replaceState(window.history.state, '', url.toString());\n                return { data: { session: data.session, redirectType: null }, error: null };\n            }\n            if (params.error || params.error_description || params.error_code) {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthImplicitGrantRedirectError(params.error_description || 'Error in URL with unspecified error_description', {\n                    error: params.error || 'unspecified_error',\n                    code: params.error_code || 'unspecified_code',\n                });\n            }\n            const { provider_token, provider_refresh_token, access_token, refresh_token, expires_in, expires_at, token_type, } = params;\n            if (!access_token || !expires_in || !refresh_token || !token_type) {\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthImplicitGrantRedirectError('No session defined in URL');\n            }\n            const timeNow = Math.round(Date.now() / 1000);\n            const expiresIn = parseInt(expires_in);\n            let expiresAt = timeNow + expiresIn;\n            if (expires_at) {\n                expiresAt = parseInt(expires_at);\n            }\n            const actuallyExpiresIn = expiresAt - timeNow;\n            if (actuallyExpiresIn * 1000 <= AUTO_REFRESH_TICK_DURATION) {\n                console.warn(`@supabase/gotrue-js: Session as retrieved from URL expires in ${actuallyExpiresIn}s, should have been closer to ${expiresIn}s`);\n            }\n            const issuedAt = expiresAt - expiresIn;\n            if (timeNow - issuedAt >= 120) {\n                console.warn('@supabase/gotrue-js: Session as retrieved from URL was issued over 120s ago, URL could be stale', issuedAt, expiresAt, timeNow);\n            }\n            else if (timeNow - issuedAt < 0) {\n                console.warn('@supabase/gotrue-js: Session as retrieved from URL was issued in the future? Check the device clok for skew', issuedAt, expiresAt, timeNow);\n            }\n            const { data, error } = await this._getUser(access_token);\n            if (error)\n                throw error;\n            const session = {\n                provider_token,\n                provider_refresh_token,\n                access_token,\n                expires_in: expiresIn,\n                expires_at: expiresAt,\n                refresh_token,\n                token_type,\n                user: data.user,\n            };\n            // Remove tokens from URL\n            window.location.hash = '';\n            this._debug('#_getSessionFromURL()', 'clearing window.location.hash');\n            return { data: { session, redirectType: params.type }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { session: null, redirectType: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Checks if the current URL contains parameters given by an implicit oauth grant flow (https://www.rfc-editor.org/rfc/rfc6749.html#section-4.2)\n     */\n    _isImplicitGrantFlow() {\n        const params = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.parseParametersFromURL)(window.location.href);\n        return !!((0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() && (params.access_token || params.error_description));\n    }\n    /**\n     * Checks if the current URL and backing storage contain parameters given by a PKCE flow\n     */\n    async _isPKCEFlow() {\n        const params = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.parseParametersFromURL)(window.location.href);\n        const currentStorageContent = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getItemAsync)(this.storage, `${this.storageKey}-code-verifier`);\n        return !!(params.code && currentStorageContent);\n    }\n    /**\n     * Inside a browser context, `signOut()` will remove the logged in user from the browser session and log them out - removing all items from localstorage and then trigger a `\"SIGNED_OUT\"` event.\n     *\n     * For server-side management, you can revoke all refresh tokens for a user by passing a user's JWT through to `auth.api.signOut(JWT: string)`.\n     * There is no way to revoke a user's access token jwt until it expires. It is recommended to set a shorter expiry on the jwt for this reason.\n     *\n     * If using `others` scope, no `SIGNED_OUT` event is fired!\n     */\n    async signOut(options = { scope: 'global' }) {\n        await this.initializePromise;\n        return await this._acquireLock(-1, async () => {\n            return await this._signOut(options);\n        });\n    }\n    async _signOut({ scope } = { scope: 'global' }) {\n        return await this._useSession(async (result) => {\n            var _a;\n            const { data, error: sessionError } = result;\n            if (sessionError) {\n                return { error: sessionError };\n            }\n            const accessToken = (_a = data.session) === null || _a === void 0 ? void 0 : _a.access_token;\n            if (accessToken) {\n                const { error } = await this.admin.signOut(accessToken, scope);\n                if (error) {\n                    // ignore 404s since user might not exist anymore\n                    // ignore 401s since an invalid or expired JWT should sign out the current session\n                    if (!((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthApiError)(error) &&\n                        (error.status === 404 || error.status === 401 || error.status === 403))) {\n                        return { error };\n                    }\n                }\n            }\n            if (scope !== 'others') {\n                await this._removeSession();\n                await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.removeItemAsync)(this.storage, `${this.storageKey}-code-verifier`);\n                await this._notifyAllSubscribers('SIGNED_OUT', null);\n            }\n            return { error: null };\n        });\n    }\n    /**\n     * Receive a notification every time an auth event happens.\n     * @param callback A callback function to be invoked when an auth event happens.\n     */\n    onAuthStateChange(callback) {\n        const id = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.uuid)();\n        const subscription = {\n            id,\n            callback,\n            unsubscribe: () => {\n                this._debug('#unsubscribe()', 'state change callback with id removed', id);\n                this.stateChangeEmitters.delete(id);\n            },\n        };\n        this._debug('#onAuthStateChange()', 'registered callback with id', id);\n        this.stateChangeEmitters.set(id, subscription);\n        (async () => {\n            await this.initializePromise;\n            await this._acquireLock(-1, async () => {\n                this._emitInitialSession(id);\n            });\n        })();\n        return { data: { subscription } };\n    }\n    async _emitInitialSession(id) {\n        return await this._useSession(async (result) => {\n            var _a, _b;\n            try {\n                const { data: { session }, error, } = result;\n                if (error)\n                    throw error;\n                await ((_a = this.stateChangeEmitters.get(id)) === null || _a === void 0 ? void 0 : _a.callback('INITIAL_SESSION', session));\n                this._debug('INITIAL_SESSION', 'callback id', id, 'session', session);\n            }\n            catch (err) {\n                await ((_b = this.stateChangeEmitters.get(id)) === null || _b === void 0 ? void 0 : _b.callback('INITIAL_SESSION', null));\n                this._debug('INITIAL_SESSION', 'callback id', id, 'error', err);\n                console.error(err);\n            }\n        });\n    }\n    /**\n     * Sends a password reset request to an email address. This method supports the PKCE flow.\n     *\n     * @param email The email address of the user.\n     * @param options.redirectTo The URL to send the user to after they click the password reset link.\n     * @param options.captchaToken Verification token received when the user completes the captcha on the site.\n     */\n    async resetPasswordForEmail(email, options = {}) {\n        let codeChallenge = null;\n        let codeChallengeMethod = null;\n        if (this.flowType === 'pkce') {\n            ;\n            [codeChallenge, codeChallengeMethod] = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getCodeChallengeAndMethod)(this.storage, this.storageKey, true // isPasswordRecovery\n            );\n        }\n        try {\n            return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/recover`, {\n                body: {\n                    email,\n                    code_challenge: codeChallenge,\n                    code_challenge_method: codeChallengeMethod,\n                    gotrue_meta_security: { captcha_token: options.captchaToken },\n                },\n                headers: this.headers,\n                redirectTo: options.redirectTo,\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Gets all the identities linked to a user.\n     */\n    async getUserIdentities() {\n        var _a;\n        try {\n            const { data, error } = await this.getUser();\n            if (error)\n                throw error;\n            return { data: { identities: (_a = data.user.identities) !== null && _a !== void 0 ? _a : [] }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Links an oauth identity to an existing user.\n     * This method supports the PKCE flow.\n     */\n    async linkIdentity(credentials) {\n        var _a;\n        try {\n            const { data, error } = await this._useSession(async (result) => {\n                var _a, _b, _c, _d, _e;\n                const { data, error } = result;\n                if (error)\n                    throw error;\n                const url = await this._getUrlForProvider(`${this.url}/user/identities/authorize`, credentials.provider, {\n                    redirectTo: (_a = credentials.options) === null || _a === void 0 ? void 0 : _a.redirectTo,\n                    scopes: (_b = credentials.options) === null || _b === void 0 ? void 0 : _b.scopes,\n                    queryParams: (_c = credentials.options) === null || _c === void 0 ? void 0 : _c.queryParams,\n                    skipBrowserRedirect: true,\n                });\n                return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'GET', url, {\n                    headers: this.headers,\n                    jwt: (_e = (_d = data.session) === null || _d === void 0 ? void 0 : _d.access_token) !== null && _e !== void 0 ? _e : undefined,\n                });\n            });\n            if (error)\n                throw error;\n            if ((0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() && !((_a = credentials.options) === null || _a === void 0 ? void 0 : _a.skipBrowserRedirect)) {\n                window.location.assign(data === null || data === void 0 ? void 0 : data.url);\n            }\n            return { data: { provider: credentials.provider, url: data === null || data === void 0 ? void 0 : data.url }, error: null };\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { provider: credentials.provider, url: null }, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Unlinks an identity from a user by deleting it. The user will no longer be able to sign in with that identity once it's unlinked.\n     */\n    async unlinkIdentity(identity) {\n        try {\n            return await this._useSession(async (result) => {\n                var _a, _b;\n                const { data, error } = result;\n                if (error) {\n                    throw error;\n                }\n                return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'DELETE', `${this.url}/user/identities/${identity.identity_id}`, {\n                    headers: this.headers,\n                    jwt: (_b = (_a = data.session) === null || _a === void 0 ? void 0 : _a.access_token) !== null && _b !== void 0 ? _b : undefined,\n                });\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * Generates a new JWT.\n     * @param refreshToken A valid refresh token that was returned on login.\n     */\n    async _refreshAccessToken(refreshToken) {\n        const debugName = `#_refreshAccessToken(${refreshToken.substring(0, 5)}...)`;\n        this._debug(debugName, 'begin');\n        try {\n            const startedAt = Date.now();\n            // will attempt to refresh the token with exponential backoff\n            return await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.retryable)(async (attempt) => {\n                if (attempt > 0) {\n                    await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.sleep)(200 * Math.pow(2, attempt - 1)); // 200, 400, 800, ...\n                }\n                this._debug(debugName, 'refreshing attempt', attempt);\n                return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/token?grant_type=refresh_token`, {\n                    body: { refresh_token: refreshToken },\n                    headers: this.headers,\n                    xform: _lib_fetch__WEBPACK_IMPORTED_MODULE_3__._sessionResponse,\n                });\n            }, (attempt, error) => {\n                const nextBackOffInterval = 200 * Math.pow(2, attempt);\n                return (error &&\n                    (0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthRetryableFetchError)(error) &&\n                    // retryable only if the request can be sent before the backoff overflows the tick duration\n                    Date.now() + nextBackOffInterval - startedAt < AUTO_REFRESH_TICK_DURATION);\n            });\n        }\n        catch (error) {\n            this._debug(debugName, 'error', error);\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: { session: null, user: null }, error };\n            }\n            throw error;\n        }\n        finally {\n            this._debug(debugName, 'end');\n        }\n    }\n    _isValidSession(maybeSession) {\n        const isValidSession = typeof maybeSession === 'object' &&\n            maybeSession !== null &&\n            'access_token' in maybeSession &&\n            'refresh_token' in maybeSession &&\n            'expires_at' in maybeSession;\n        return isValidSession;\n    }\n    async _handleProviderSignIn(provider, options) {\n        const url = await this._getUrlForProvider(`${this.url}/authorize`, provider, {\n            redirectTo: options.redirectTo,\n            scopes: options.scopes,\n            queryParams: options.queryParams,\n        });\n        this._debug('#_handleProviderSignIn()', 'provider', provider, 'options', options, 'url', url);\n        // try to open on the browser\n        if ((0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() && !options.skipBrowserRedirect) {\n            window.location.assign(url);\n        }\n        return { data: { provider, url }, error: null };\n    }\n    /**\n     * Recovers the session from LocalStorage and refreshes\n     * Note: this method is async to accommodate for AsyncStorage e.g. in React native.\n     */\n    async _recoverAndRefresh() {\n        var _a;\n        const debugName = '#_recoverAndRefresh()';\n        this._debug(debugName, 'begin');\n        try {\n            const currentSession = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getItemAsync)(this.storage, this.storageKey);\n            this._debug(debugName, 'session from storage', currentSession);\n            if (!this._isValidSession(currentSession)) {\n                this._debug(debugName, 'session is not valid');\n                if (currentSession !== null) {\n                    await this._removeSession();\n                }\n                return;\n            }\n            const timeNow = Math.round(Date.now() / 1000);\n            const expiresWithMargin = ((_a = currentSession.expires_at) !== null && _a !== void 0 ? _a : Infinity) < timeNow + _lib_constants__WEBPACK_IMPORTED_MODULE_1__.EXPIRY_MARGIN;\n            this._debug(debugName, `session has${expiresWithMargin ? '' : ' not'} expired with margin of ${_lib_constants__WEBPACK_IMPORTED_MODULE_1__.EXPIRY_MARGIN}s`);\n            if (expiresWithMargin) {\n                if (this.autoRefreshToken && currentSession.refresh_token) {\n                    const { error } = await this._callRefreshToken(currentSession.refresh_token);\n                    if (error) {\n                        console.error(error);\n                        if (!(0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthRetryableFetchError)(error)) {\n                            this._debug(debugName, 'refresh failed with a non-retryable error, removing the session', error);\n                            await this._removeSession();\n                        }\n                    }\n                }\n            }\n            else {\n                // no need to persist currentSession again, as we just loaded it from\n                // local storage; persisting it again may overwrite a value saved by\n                // another client with access to the same local storage\n                await this._notifyAllSubscribers('SIGNED_IN', currentSession);\n            }\n        }\n        catch (err) {\n            this._debug(debugName, 'error', err);\n            console.error(err);\n            return;\n        }\n        finally {\n            this._debug(debugName, 'end');\n        }\n    }\n    async _callRefreshToken(refreshToken) {\n        var _a, _b;\n        if (!refreshToken) {\n            throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError();\n        }\n        // refreshing is already in progress\n        if (this.refreshingDeferred) {\n            return this.refreshingDeferred.promise;\n        }\n        const debugName = `#_callRefreshToken(${refreshToken.substring(0, 5)}...)`;\n        this._debug(debugName, 'begin');\n        try {\n            this.refreshingDeferred = new _lib_helpers__WEBPACK_IMPORTED_MODULE_4__.Deferred();\n            const { data, error } = await this._refreshAccessToken(refreshToken);\n            if (error)\n                throw error;\n            if (!data.session)\n                throw new _lib_errors__WEBPACK_IMPORTED_MODULE_2__.AuthSessionMissingError();\n            await this._saveSession(data.session);\n            await this._notifyAllSubscribers('TOKEN_REFRESHED', data.session);\n            const result = { session: data.session, error: null };\n            this.refreshingDeferred.resolve(result);\n            return result;\n        }\n        catch (error) {\n            this._debug(debugName, 'error', error);\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                const result = { session: null, error };\n                if (!(0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthRetryableFetchError)(error)) {\n                    await this._removeSession();\n                    await this._notifyAllSubscribers('SIGNED_OUT', null);\n                }\n                (_a = this.refreshingDeferred) === null || _a === void 0 ? void 0 : _a.resolve(result);\n                return result;\n            }\n            (_b = this.refreshingDeferred) === null || _b === void 0 ? void 0 : _b.reject(error);\n            throw error;\n        }\n        finally {\n            this.refreshingDeferred = null;\n            this._debug(debugName, 'end');\n        }\n    }\n    async _notifyAllSubscribers(event, session, broadcast = true) {\n        const debugName = `#_notifyAllSubscribers(${event})`;\n        this._debug(debugName, 'begin', session, `broadcast = ${broadcast}`);\n        try {\n            if (this.broadcastChannel && broadcast) {\n                this.broadcastChannel.postMessage({ event, session });\n            }\n            const errors = [];\n            const promises = Array.from(this.stateChangeEmitters.values()).map(async (x) => {\n                try {\n                    await x.callback(event, session);\n                }\n                catch (e) {\n                    errors.push(e);\n                }\n            });\n            await Promise.all(promises);\n            if (errors.length > 0) {\n                for (let i = 0; i < errors.length; i += 1) {\n                    console.error(errors[i]);\n                }\n                throw errors[0];\n            }\n        }\n        finally {\n            this._debug(debugName, 'end');\n        }\n    }\n    /**\n     * set currentSession and currentUser\n     * process to _startAutoRefreshToken if possible\n     */\n    async _saveSession(session) {\n        this._debug('#_saveSession()', session);\n        // _saveSession is always called whenever a new session has been acquired\n        // so we can safely suppress the warning returned by future getSession calls\n        this.suppressGetSessionWarning = true;\n        await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.setItemAsync)(this.storage, this.storageKey, session);\n    }\n    async _removeSession() {\n        this._debug('#_removeSession()');\n        await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.removeItemAsync)(this.storage, this.storageKey);\n    }\n    /**\n     * Removes any registered visibilitychange callback.\n     *\n     * {@see #startAutoRefresh}\n     * {@see #stopAutoRefresh}\n     */\n    _removeVisibilityChangedCallback() {\n        this._debug('#_removeVisibilityChangedCallback()');\n        const callback = this.visibilityChangedCallback;\n        this.visibilityChangedCallback = null;\n        try {\n            if (callback && (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() && (window === null || window === void 0 ? void 0 : window.removeEventListener)) {\n                window.removeEventListener('visibilitychange', callback);\n            }\n        }\n        catch (e) {\n            console.error('removing visibilitychange callback failed', e);\n        }\n    }\n    /**\n     * This is the private implementation of {@link #startAutoRefresh}. Use this\n     * within the library.\n     */\n    async _startAutoRefresh() {\n        await this._stopAutoRefresh();\n        this._debug('#_startAutoRefresh()');\n        const ticker = setInterval(() => this._autoRefreshTokenTick(), AUTO_REFRESH_TICK_DURATION);\n        this.autoRefreshTicker = ticker;\n        if (ticker && typeof ticker === 'object' && typeof ticker.unref === 'function') {\n            // ticker is a NodeJS Timeout object that has an `unref` method\n            // https://nodejs.org/api/timers.html#timeoutunref\n            // When auto refresh is used in NodeJS (like for testing) the\n            // `setInterval` is preventing the process from being marked as\n            // finished and tests run endlessly. This can be prevented by calling\n            // `unref()` on the returned object.\n            ticker.unref();\n            // @ts-ignore\n        }\n        else if (typeof Deno !== 'undefined' && typeof Deno.unrefTimer === 'function') {\n            // similar like for NodeJS, but with the Deno API\n            // https://deno.land/api@latest?unstable&s=Deno.unrefTimer\n            // @ts-ignore\n            Deno.unrefTimer(ticker);\n        }\n        // run the tick immediately, but in the next pass of the event loop so that\n        // #_initialize can be allowed to complete without recursively waiting on\n        // itself\n        setTimeout(async () => {\n            await this.initializePromise;\n            await this._autoRefreshTokenTick();\n        }, 0);\n    }\n    /**\n     * This is the private implementation of {@link #stopAutoRefresh}. Use this\n     * within the library.\n     */\n    async _stopAutoRefresh() {\n        this._debug('#_stopAutoRefresh()');\n        const ticker = this.autoRefreshTicker;\n        this.autoRefreshTicker = null;\n        if (ticker) {\n            clearInterval(ticker);\n        }\n    }\n    /**\n     * Starts an auto-refresh process in the background. The session is checked\n     * every few seconds. Close to the time of expiration a process is started to\n     * refresh the session. If refreshing fails it will be retried for as long as\n     * necessary.\n     *\n     * If you set the {@link GoTrueClientOptions#autoRefreshToken} you don't need\n     * to call this function, it will be called for you.\n     *\n     * On browsers the refresh process works only when the tab/window is in the\n     * foreground to conserve resources as well as prevent race conditions and\n     * flooding auth with requests. If you call this method any managed\n     * visibility change callback will be removed and you must manage visibility\n     * changes on your own.\n     *\n     * On non-browser platforms the refresh process works *continuously* in the\n     * background, which may not be desirable. You should hook into your\n     * platform's foreground indication mechanism and call these methods\n     * appropriately to conserve resources.\n     *\n     * {@see #stopAutoRefresh}\n     */\n    async startAutoRefresh() {\n        this._removeVisibilityChangedCallback();\n        await this._startAutoRefresh();\n    }\n    /**\n     * Stops an active auto refresh process running in the background (if any).\n     *\n     * If you call this method any managed visibility change callback will be\n     * removed and you must manage visibility changes on your own.\n     *\n     * See {@link #startAutoRefresh} for more details.\n     */\n    async stopAutoRefresh() {\n        this._removeVisibilityChangedCallback();\n        await this._stopAutoRefresh();\n    }\n    /**\n     * Runs the auto refresh token tick.\n     */\n    async _autoRefreshTokenTick() {\n        this._debug('#_autoRefreshTokenTick()', 'begin');\n        try {\n            await this._acquireLock(0, async () => {\n                try {\n                    const now = Date.now();\n                    try {\n                        return await this._useSession(async (result) => {\n                            const { data: { session }, } = result;\n                            if (!session || !session.refresh_token || !session.expires_at) {\n                                this._debug('#_autoRefreshTokenTick()', 'no session');\n                                return;\n                            }\n                            // session will expire in this many ticks (or has already expired if <= 0)\n                            const expiresInTicks = Math.floor((session.expires_at * 1000 - now) / AUTO_REFRESH_TICK_DURATION);\n                            this._debug('#_autoRefreshTokenTick()', `access token expires in ${expiresInTicks} ticks, a tick lasts ${AUTO_REFRESH_TICK_DURATION}ms, refresh threshold is ${AUTO_REFRESH_TICK_THRESHOLD} ticks`);\n                            if (expiresInTicks <= AUTO_REFRESH_TICK_THRESHOLD) {\n                                await this._callRefreshToken(session.refresh_token);\n                            }\n                        });\n                    }\n                    catch (e) {\n                        console.error('Auto refresh tick failed with error. This is likely a transient error.', e);\n                    }\n                }\n                finally {\n                    this._debug('#_autoRefreshTokenTick()', 'end');\n                }\n            });\n        }\n        catch (e) {\n            if (e.isAcquireTimeout || e instanceof _lib_locks__WEBPACK_IMPORTED_MODULE_8__.LockAcquireTimeoutError) {\n                this._debug('auto refresh token tick lock not available');\n            }\n            else {\n                throw e;\n            }\n        }\n    }\n    /**\n     * Registers callbacks on the browser / platform, which in-turn run\n     * algorithms when the browser window/tab are in foreground. On non-browser\n     * platforms it assumes always foreground.\n     */\n    async _handleVisibilityChange() {\n        this._debug('#_handleVisibilityChange()');\n        if (!(0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.isBrowser)() || !(window === null || window === void 0 ? void 0 : window.addEventListener)) {\n            if (this.autoRefreshToken) {\n                // in non-browser environments the refresh token ticker runs always\n                this.startAutoRefresh();\n            }\n            return false;\n        }\n        try {\n            this.visibilityChangedCallback = async () => await this._onVisibilityChanged(false);\n            window === null || window === void 0 ? void 0 : window.addEventListener('visibilitychange', this.visibilityChangedCallback);\n            // now immediately call the visbility changed callback to setup with the\n            // current visbility state\n            await this._onVisibilityChanged(true); // initial call\n        }\n        catch (error) {\n            console.error('_handleVisibilityChange', error);\n        }\n    }\n    /**\n     * Callback registered with `window.addEventListener('visibilitychange')`.\n     */\n    async _onVisibilityChanged(calledFromInitialize) {\n        const methodName = `#_onVisibilityChanged(${calledFromInitialize})`;\n        this._debug(methodName, 'visibilityState', document.visibilityState);\n        if (document.visibilityState === 'visible') {\n            if (this.autoRefreshToken) {\n                // in browser environments the refresh token ticker runs only on focused tabs\n                // which prevents race conditions\n                this._startAutoRefresh();\n            }\n            if (!calledFromInitialize) {\n                // called when the visibility has changed, i.e. the browser\n                // transitioned from hidden -> visible so we need to see if the session\n                // should be recovered immediately... but to do that we need to acquire\n                // the lock first asynchronously\n                await this.initializePromise;\n                await this._acquireLock(-1, async () => {\n                    if (document.visibilityState !== 'visible') {\n                        this._debug(methodName, 'acquired the lock to recover the session, but the browser visibilityState is no longer visible, aborting');\n                        // visibility has changed while waiting for the lock, abort\n                        return;\n                    }\n                    // recover the session\n                    await this._recoverAndRefresh();\n                });\n            }\n        }\n        else if (document.visibilityState === 'hidden') {\n            if (this.autoRefreshToken) {\n                this._stopAutoRefresh();\n            }\n        }\n    }\n    /**\n     * Generates the relevant login URL for a third-party provider.\n     * @param options.redirectTo A URL or mobile address to send the user to after they are confirmed.\n     * @param options.scopes A space-separated list of scopes granted to the OAuth application.\n     * @param options.queryParams An object of key-value pairs containing query parameters granted to the OAuth application.\n     */\n    async _getUrlForProvider(url, provider, options) {\n        const urlParams = [`provider=${encodeURIComponent(provider)}`];\n        if (options === null || options === void 0 ? void 0 : options.redirectTo) {\n            urlParams.push(`redirect_to=${encodeURIComponent(options.redirectTo)}`);\n        }\n        if (options === null || options === void 0 ? void 0 : options.scopes) {\n            urlParams.push(`scopes=${encodeURIComponent(options.scopes)}`);\n        }\n        if (this.flowType === 'pkce') {\n            const [codeChallenge, codeChallengeMethod] = await (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_4__.getCodeChallengeAndMethod)(this.storage, this.storageKey);\n            const flowParams = new URLSearchParams({\n                code_challenge: `${encodeURIComponent(codeChallenge)}`,\n                code_challenge_method: `${encodeURIComponent(codeChallengeMethod)}`,\n            });\n            urlParams.push(flowParams.toString());\n        }\n        if (options === null || options === void 0 ? void 0 : options.queryParams) {\n            const query = new URLSearchParams(options.queryParams);\n            urlParams.push(query.toString());\n        }\n        if (options === null || options === void 0 ? void 0 : options.skipBrowserRedirect) {\n            urlParams.push(`skip_http_redirect=${options.skipBrowserRedirect}`);\n        }\n        return `${url}?${urlParams.join('&')}`;\n    }\n    async _unenroll(params) {\n        try {\n            return await this._useSession(async (result) => {\n                var _a;\n                const { data: sessionData, error: sessionError } = result;\n                if (sessionError) {\n                    return { data: null, error: sessionError };\n                }\n                return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'DELETE', `${this.url}/factors/${params.factorId}`, {\n                    headers: this.headers,\n                    jwt: (_a = sessionData === null || sessionData === void 0 ? void 0 : sessionData.session) === null || _a === void 0 ? void 0 : _a.access_token,\n                });\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * {@see GoTrueMFAApi#enroll}\n     */\n    async _enroll(params) {\n        try {\n            return await this._useSession(async (result) => {\n                var _a, _b;\n                const { data: sessionData, error: sessionError } = result;\n                if (sessionError) {\n                    return { data: null, error: sessionError };\n                }\n                const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/factors`, {\n                    body: {\n                        friendly_name: params.friendlyName,\n                        factor_type: params.factorType,\n                        issuer: params.issuer,\n                    },\n                    headers: this.headers,\n                    jwt: (_a = sessionData === null || sessionData === void 0 ? void 0 : sessionData.session) === null || _a === void 0 ? void 0 : _a.access_token,\n                });\n                if (error) {\n                    return { data: null, error };\n                }\n                if ((_b = data === null || data === void 0 ? void 0 : data.totp) === null || _b === void 0 ? void 0 : _b.qr_code) {\n                    data.totp.qr_code = `data:image/svg+xml;utf-8,${data.totp.qr_code}`;\n                }\n                return { data, error: null };\n            });\n        }\n        catch (error) {\n            if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                return { data: null, error };\n            }\n            throw error;\n        }\n    }\n    /**\n     * {@see GoTrueMFAApi#verify}\n     */\n    async _verify(params) {\n        return this._acquireLock(-1, async () => {\n            try {\n                return await this._useSession(async (result) => {\n                    var _a;\n                    const { data: sessionData, error: sessionError } = result;\n                    if (sessionError) {\n                        return { data: null, error: sessionError };\n                    }\n                    const { data, error } = await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/factors/${params.factorId}/verify`, {\n                        body: { code: params.code, challenge_id: params.challengeId },\n                        headers: this.headers,\n                        jwt: (_a = sessionData === null || sessionData === void 0 ? void 0 : sessionData.session) === null || _a === void 0 ? void 0 : _a.access_token,\n                    });\n                    if (error) {\n                        return { data: null, error };\n                    }\n                    await this._saveSession(Object.assign({ expires_at: Math.round(Date.now() / 1000) + data.expires_in }, data));\n                    await this._notifyAllSubscribers('MFA_CHALLENGE_VERIFIED', data);\n                    return { data, error };\n                });\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * {@see GoTrueMFAApi#challenge}\n     */\n    async _challenge(params) {\n        return this._acquireLock(-1, async () => {\n            try {\n                return await this._useSession(async (result) => {\n                    var _a;\n                    const { data: sessionData, error: sessionError } = result;\n                    if (sessionError) {\n                        return { data: null, error: sessionError };\n                    }\n                    return await (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_3__._request)(this.fetch, 'POST', `${this.url}/factors/${params.factorId}/challenge`, {\n                        headers: this.headers,\n                        jwt: (_a = sessionData === null || sessionData === void 0 ? void 0 : sessionData.session) === null || _a === void 0 ? void 0 : _a.access_token,\n                    });\n                });\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_2__.isAuthError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * {@see GoTrueMFAApi#challengeAndVerify}\n     */\n    async _challengeAndVerify(params) {\n        // both _challenge and _verify independently acquire the lock, so no need\n        // to acquire it here\n        const { data: challengeData, error: challengeError } = await this._challenge({\n            factorId: params.factorId,\n        });\n        if (challengeError) {\n            return { data: null, error: challengeError };\n        }\n        return await this._verify({\n            factorId: params.factorId,\n            challengeId: challengeData.id,\n            code: params.code,\n        });\n    }\n    /**\n     * {@see GoTrueMFAApi#listFactors}\n     */\n    async _listFactors() {\n        // use #getUser instead of #_getUser as the former acquires a lock\n        const { data: { user }, error: userError, } = await this.getUser();\n        if (userError) {\n            return { data: null, error: userError };\n        }\n        const factors = (user === null || user === void 0 ? void 0 : user.factors) || [];\n        const totp = factors.filter((factor) => factor.factor_type === 'totp' && factor.status === 'verified');\n        return {\n            data: {\n                all: factors,\n                totp,\n            },\n            error: null,\n        };\n    }\n    /**\n     * {@see GoTrueMFAApi#getAuthenticatorAssuranceLevel}\n     */\n    async _getAuthenticatorAssuranceLevel() {\n        return this._acquireLock(-1, async () => {\n            return await this._useSession(async (result) => {\n                var _a, _b;\n                const { data: { session }, error: sessionError, } = result;\n                if (sessionError) {\n                    return { data: null, error: sessionError };\n                }\n                if (!session) {\n                    return {\n                        data: { currentLevel: null, nextLevel: null, currentAuthenticationMethods: [] },\n                        error: null,\n                    };\n                }\n                const payload = this._decodeJWT(session.access_token);\n                let currentLevel = null;\n                if (payload.aal) {\n                    currentLevel = payload.aal;\n                }\n                let nextLevel = currentLevel;\n                const verifiedFactors = (_b = (_a = session.user.factors) === null || _a === void 0 ? void 0 : _a.filter((factor) => factor.status === 'verified')) !== null && _b !== void 0 ? _b : [];\n                if (verifiedFactors.length > 0) {\n                    nextLevel = 'aal2';\n                }\n                const currentAuthenticationMethods = payload.amr || [];\n                return { data: { currentLevel, nextLevel, currentAuthenticationMethods }, error: null };\n            });\n        });\n    }\n}\nGoTrueClient.nextInstanceID = 0;\n//# sourceMappingURL=GoTrueClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/GoTrueClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/index.js":
/*!*************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/index.js ***!
  \*************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AuthAdminApi: () => (/* reexport safe */ _AuthAdminApi__WEBPACK_IMPORTED_MODULE_2__[\"default\"]),\n/* harmony export */   AuthApiError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthApiError),\n/* harmony export */   AuthClient: () => (/* reexport safe */ _AuthClient__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   AuthError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthError),\n/* harmony export */   AuthImplicitGrantRedirectError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthImplicitGrantRedirectError),\n/* harmony export */   AuthInvalidCredentialsError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthInvalidCredentialsError),\n/* harmony export */   AuthInvalidTokenResponseError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthInvalidTokenResponseError),\n/* harmony export */   AuthPKCEGrantCodeExchangeError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthPKCEGrantCodeExchangeError),\n/* harmony export */   AuthRetryableFetchError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthRetryableFetchError),\n/* harmony export */   AuthSessionMissingError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthSessionMissingError),\n/* harmony export */   AuthUnknownError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthUnknownError),\n/* harmony export */   AuthWeakPasswordError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.AuthWeakPasswordError),\n/* harmony export */   CustomAuthError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.CustomAuthError),\n/* harmony export */   GoTrueAdminApi: () => (/* reexport safe */ _GoTrueAdminApi__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   GoTrueClient: () => (/* reexport safe */ _GoTrueClient__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   NavigatorLockAcquireTimeoutError: () => (/* reexport safe */ _lib_locks__WEBPACK_IMPORTED_MODULE_6__.NavigatorLockAcquireTimeoutError),\n/* harmony export */   isAuthApiError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.isAuthApiError),\n/* harmony export */   isAuthError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.isAuthError),\n/* harmony export */   isAuthRetryableFetchError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.isAuthRetryableFetchError),\n/* harmony export */   isAuthWeakPasswordError: () => (/* reexport safe */ _lib_errors__WEBPACK_IMPORTED_MODULE_5__.isAuthWeakPasswordError),\n/* harmony export */   lockInternals: () => (/* reexport safe */ _lib_locks__WEBPACK_IMPORTED_MODULE_6__.internals),\n/* harmony export */   navigatorLock: () => (/* reexport safe */ _lib_locks__WEBPACK_IMPORTED_MODULE_6__.navigatorLock)\n/* harmony export */ });\n/* harmony import */ var _GoTrueAdminApi__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./GoTrueAdminApi */ \"./node_modules/@supabase/auth-js/dist/module/GoTrueAdminApi.js\");\n/* harmony import */ var _GoTrueClient__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./GoTrueClient */ \"./node_modules/@supabase/auth-js/dist/module/GoTrueClient.js\");\n/* harmony import */ var _AuthAdminApi__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./AuthAdminApi */ \"./node_modules/@supabase/auth-js/dist/module/AuthAdminApi.js\");\n/* harmony import */ var _AuthClient__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./AuthClient */ \"./node_modules/@supabase/auth-js/dist/module/AuthClient.js\");\n/* harmony import */ var _lib_types__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/types */ \"./node_modules/@supabase/auth-js/dist/module/lib/types.js\");\n/* harmony import */ var _lib_errors__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./lib/errors */ \"./node_modules/@supabase/auth-js/dist/module/lib/errors.js\");\n/* harmony import */ var _lib_locks__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./lib/locks */ \"./node_modules/@supabase/auth-js/dist/module/lib/locks.js\");\n\n\n\n\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/index.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/constants.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/constants.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   API_VERSIONS: () => (/* binding */ API_VERSIONS),\n/* harmony export */   API_VERSION_HEADER_NAME: () => (/* binding */ API_VERSION_HEADER_NAME),\n/* harmony export */   AUDIENCE: () => (/* binding */ AUDIENCE),\n/* harmony export */   DEFAULT_HEADERS: () => (/* binding */ DEFAULT_HEADERS),\n/* harmony export */   EXPIRY_MARGIN: () => (/* binding */ EXPIRY_MARGIN),\n/* harmony export */   GOTRUE_URL: () => (/* binding */ GOTRUE_URL),\n/* harmony export */   NETWORK_FAILURE: () => (/* binding */ NETWORK_FAILURE),\n/* harmony export */   STORAGE_KEY: () => (/* binding */ STORAGE_KEY)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./version */ \"./node_modules/@supabase/auth-js/dist/module/lib/version.js\");\n\nconst GOTRUE_URL = 'http://localhost:9999';\nconst STORAGE_KEY = 'supabase.auth.token';\nconst AUDIENCE = '';\nconst DEFAULT_HEADERS = { 'X-Client-Info': `gotrue-js/${_version__WEBPACK_IMPORTED_MODULE_0__.version}` };\nconst EXPIRY_MARGIN = 10; // in seconds\nconst NETWORK_FAILURE = {\n    MAX_RETRIES: 10,\n    RETRY_INTERVAL: 2, // in deciseconds\n};\nconst API_VERSION_HEADER_NAME = 'X-Supabase-Api-Version';\nconst API_VERSIONS = {\n    '2024-01-01': {\n        timestamp: Date.parse('2024-01-01T00:00:00.0Z'),\n        name: '2024-01-01',\n    },\n};\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/constants.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/errors.js":
/*!******************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/errors.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AuthApiError: () => (/* binding */ AuthApiError),\n/* harmony export */   AuthError: () => (/* binding */ AuthError),\n/* harmony export */   AuthImplicitGrantRedirectError: () => (/* binding */ AuthImplicitGrantRedirectError),\n/* harmony export */   AuthInvalidCredentialsError: () => (/* binding */ AuthInvalidCredentialsError),\n/* harmony export */   AuthInvalidTokenResponseError: () => (/* binding */ AuthInvalidTokenResponseError),\n/* harmony export */   AuthPKCEGrantCodeExchangeError: () => (/* binding */ AuthPKCEGrantCodeExchangeError),\n/* harmony export */   AuthRetryableFetchError: () => (/* binding */ AuthRetryableFetchError),\n/* harmony export */   AuthSessionMissingError: () => (/* binding */ AuthSessionMissingError),\n/* harmony export */   AuthUnknownError: () => (/* binding */ AuthUnknownError),\n/* harmony export */   AuthWeakPasswordError: () => (/* binding */ AuthWeakPasswordError),\n/* harmony export */   CustomAuthError: () => (/* binding */ CustomAuthError),\n/* harmony export */   isAuthApiError: () => (/* binding */ isAuthApiError),\n/* harmony export */   isAuthError: () => (/* binding */ isAuthError),\n/* harmony export */   isAuthRetryableFetchError: () => (/* binding */ isAuthRetryableFetchError),\n/* harmony export */   isAuthWeakPasswordError: () => (/* binding */ isAuthWeakPasswordError)\n/* harmony export */ });\nclass AuthError extends Error {\n    constructor(message, status, code) {\n        super(message);\n        this.__isAuthError = true;\n        this.name = 'AuthError';\n        this.status = status;\n        this.code = code;\n    }\n}\nfunction isAuthError(error) {\n    return typeof error === 'object' && error !== null && '__isAuthError' in error;\n}\nclass AuthApiError extends AuthError {\n    constructor(message, status, code) {\n        super(message, status, code);\n        this.name = 'AuthApiError';\n        this.status = status;\n        this.code = code;\n    }\n}\nfunction isAuthApiError(error) {\n    return isAuthError(error) && error.name === 'AuthApiError';\n}\nclass AuthUnknownError extends AuthError {\n    constructor(message, originalError) {\n        super(message);\n        this.name = 'AuthUnknownError';\n        this.originalError = originalError;\n    }\n}\nclass CustomAuthError extends AuthError {\n    constructor(message, name, status, code) {\n        super(message, status, code);\n        this.name = name;\n        this.status = status;\n    }\n}\nclass AuthSessionMissingError extends CustomAuthError {\n    constructor() {\n        super('Auth session missing!', 'AuthSessionMissingError', 400, undefined);\n    }\n}\nclass AuthInvalidTokenResponseError extends CustomAuthError {\n    constructor() {\n        super('Auth session or user missing', 'AuthInvalidTokenResponseError', 500, undefined);\n    }\n}\nclass AuthInvalidCredentialsError extends CustomAuthError {\n    constructor(message) {\n        super(message, 'AuthInvalidCredentialsError', 400, undefined);\n    }\n}\nclass AuthImplicitGrantRedirectError extends CustomAuthError {\n    constructor(message, details = null) {\n        super(message, 'AuthImplicitGrantRedirectError', 500, undefined);\n        this.details = null;\n        this.details = details;\n    }\n    toJSON() {\n        return {\n            name: this.name,\n            message: this.message,\n            status: this.status,\n            details: this.details,\n        };\n    }\n}\nclass AuthPKCEGrantCodeExchangeError extends CustomAuthError {\n    constructor(message, details = null) {\n        super(message, 'AuthPKCEGrantCodeExchangeError', 500, undefined);\n        this.details = null;\n        this.details = details;\n    }\n    toJSON() {\n        return {\n            name: this.name,\n            message: this.message,\n            status: this.status,\n            details: this.details,\n        };\n    }\n}\nclass AuthRetryableFetchError extends CustomAuthError {\n    constructor(message, status) {\n        super(message, 'AuthRetryableFetchError', status, undefined);\n    }\n}\nfunction isAuthRetryableFetchError(error) {\n    return isAuthError(error) && error.name === 'AuthRetryableFetchError';\n}\n/**\n * This error is thrown on certain methods when the password used is deemed\n * weak. Inspect the reasons to identify what password strength rules are\n * inadequate.\n */\nclass AuthWeakPasswordError extends CustomAuthError {\n    constructor(message, status, reasons) {\n        super(message, 'AuthWeakPasswordError', status, 'weak_password');\n        this.reasons = reasons;\n    }\n}\nfunction isAuthWeakPasswordError(error) {\n    return isAuthError(error) && error.name === 'AuthWeakPasswordError';\n}\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/errors.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/fetch.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/fetch.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   _generateLinkResponse: () => (/* binding */ _generateLinkResponse),\n/* harmony export */   _noResolveJsonResponse: () => (/* binding */ _noResolveJsonResponse),\n/* harmony export */   _request: () => (/* binding */ _request),\n/* harmony export */   _sessionResponse: () => (/* binding */ _sessionResponse),\n/* harmony export */   _sessionResponsePassword: () => (/* binding */ _sessionResponsePassword),\n/* harmony export */   _ssoResponse: () => (/* binding */ _ssoResponse),\n/* harmony export */   _userResponse: () => (/* binding */ _userResponse),\n/* harmony export */   handleError: () => (/* binding */ handleError)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ \"./node_modules/@supabase/auth-js/dist/module/lib/constants.js\");\n/* harmony import */ var _helpers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./helpers */ \"./node_modules/@supabase/auth-js/dist/module/lib/helpers.js\");\n/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./errors */ \"./node_modules/@supabase/auth-js/dist/module/lib/errors.js\");\nvar __rest = (undefined && undefined.__rest) || function (s, e) {\n    var t = {};\n    for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0)\n        t[p] = s[p];\n    if (s != null && typeof Object.getOwnPropertySymbols === \"function\")\n        for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n            if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i]))\n                t[p[i]] = s[p[i]];\n        }\n    return t;\n};\n\n\n\nconst _getErrorMessage = (err) => err.msg || err.message || err.error_description || err.error || JSON.stringify(err);\nconst NETWORK_ERROR_CODES = [502, 503, 504];\nasync function handleError(error) {\n    var _a;\n    if (!(0,_helpers__WEBPACK_IMPORTED_MODULE_1__.looksLikeFetchResponse)(error)) {\n        throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthRetryableFetchError(_getErrorMessage(error), 0);\n    }\n    if (NETWORK_ERROR_CODES.includes(error.status)) {\n        // status in 500...599 range - server had an error, request might be retryed.\n        throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthRetryableFetchError(_getErrorMessage(error), error.status);\n    }\n    let data;\n    try {\n        data = await error.json();\n    }\n    catch (e) {\n        throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthUnknownError(_getErrorMessage(e), e);\n    }\n    let errorCode = undefined;\n    const responseAPIVersion = (0,_helpers__WEBPACK_IMPORTED_MODULE_1__.parseResponseAPIVersion)(error);\n    if (responseAPIVersion &&\n        responseAPIVersion.getTime() >= _constants__WEBPACK_IMPORTED_MODULE_0__.API_VERSIONS['2024-01-01'].timestamp &&\n        typeof data === 'object' &&\n        data &&\n        typeof data.code === 'string') {\n        errorCode = data.code;\n    }\n    else if (typeof data === 'object' && data && typeof data.error_code === 'string') {\n        errorCode = data.error_code;\n    }\n    if (!errorCode) {\n        // Legacy support for weak password errors, when there were no error codes\n        if (typeof data === 'object' &&\n            data &&\n            typeof data.weak_password === 'object' &&\n            data.weak_password &&\n            Array.isArray(data.weak_password.reasons) &&\n            data.weak_password.reasons.length &&\n            data.weak_password.reasons.reduce((a, i) => a && typeof i === 'string', true)) {\n            throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthWeakPasswordError(_getErrorMessage(data), error.status, data.weak_password.reasons);\n        }\n    }\n    else if (errorCode === 'weak_password') {\n        throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthWeakPasswordError(_getErrorMessage(data), error.status, ((_a = data.weak_password) === null || _a === void 0 ? void 0 : _a.reasons) || []);\n    }\n    throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthApiError(_getErrorMessage(data), error.status || 500, errorCode);\n}\nconst _getRequestParams = (method, options, parameters, body) => {\n    const params = { method, headers: (options === null || options === void 0 ? void 0 : options.headers) || {} };\n    if (method === 'GET') {\n        return params;\n    }\n    params.headers = Object.assign({ 'Content-Type': 'application/json;charset=UTF-8' }, options === null || options === void 0 ? void 0 : options.headers);\n    params.body = JSON.stringify(body);\n    return Object.assign(Object.assign({}, params), parameters);\n};\nasync function _request(fetcher, method, url, options) {\n    var _a;\n    const headers = Object.assign({}, options === null || options === void 0 ? void 0 : options.headers);\n    if (!headers[_constants__WEBPACK_IMPORTED_MODULE_0__.API_VERSION_HEADER_NAME]) {\n        headers[_constants__WEBPACK_IMPORTED_MODULE_0__.API_VERSION_HEADER_NAME] = _constants__WEBPACK_IMPORTED_MODULE_0__.API_VERSIONS['2024-01-01'].name;\n    }\n    if (options === null || options === void 0 ? void 0 : options.jwt) {\n        headers['Authorization'] = `Bearer ${options.jwt}`;\n    }\n    const qs = (_a = options === null || options === void 0 ? void 0 : options.query) !== null && _a !== void 0 ? _a : {};\n    if (options === null || options === void 0 ? void 0 : options.redirectTo) {\n        qs['redirect_to'] = options.redirectTo;\n    }\n    const queryString = Object.keys(qs).length ? '?' + new URLSearchParams(qs).toString() : '';\n    const data = await _handleRequest(fetcher, method, url + queryString, {\n        headers,\n        noResolveJson: options === null || options === void 0 ? void 0 : options.noResolveJson,\n    }, {}, options === null || options === void 0 ? void 0 : options.body);\n    return (options === null || options === void 0 ? void 0 : options.xform) ? options === null || options === void 0 ? void 0 : options.xform(data) : { data: Object.assign({}, data), error: null };\n}\nasync function _handleRequest(fetcher, method, url, options, parameters, body) {\n    const requestParams = _getRequestParams(method, options, parameters, body);\n    let result;\n    try {\n        result = await fetcher(url, Object.assign({}, requestParams));\n    }\n    catch (e) {\n        console.error(e);\n        // fetch failed, likely due to a network or CORS error\n        throw new _errors__WEBPACK_IMPORTED_MODULE_2__.AuthRetryableFetchError(_getErrorMessage(e), 0);\n    }\n    if (!result.ok) {\n        await handleError(result);\n    }\n    if (options === null || options === void 0 ? void 0 : options.noResolveJson) {\n        return result;\n    }\n    try {\n        return await result.json();\n    }\n    catch (e) {\n        await handleError(e);\n    }\n}\nfunction _sessionResponse(data) {\n    var _a;\n    let session = null;\n    if (hasSession(data)) {\n        session = Object.assign({}, data);\n        if (!data.expires_at) {\n            session.expires_at = (0,_helpers__WEBPACK_IMPORTED_MODULE_1__.expiresAt)(data.expires_in);\n        }\n    }\n    const user = (_a = data.user) !== null && _a !== void 0 ? _a : data;\n    return { data: { session, user }, error: null };\n}\nfunction _sessionResponsePassword(data) {\n    const response = _sessionResponse(data);\n    if (!response.error &&\n        data.weak_password &&\n        typeof data.weak_password === 'object' &&\n        Array.isArray(data.weak_password.reasons) &&\n        data.weak_password.reasons.length &&\n        data.weak_password.message &&\n        typeof data.weak_password.message === 'string' &&\n        data.weak_password.reasons.reduce((a, i) => a && typeof i === 'string', true)) {\n        response.data.weak_password = data.weak_password;\n    }\n    return response;\n}\nfunction _userResponse(data) {\n    var _a;\n    const user = (_a = data.user) !== null && _a !== void 0 ? _a : data;\n    return { data: { user }, error: null };\n}\nfunction _ssoResponse(data) {\n    return { data, error: null };\n}\nfunction _generateLinkResponse(data) {\n    const { action_link, email_otp, hashed_token, redirect_to, verification_type } = data, rest = __rest(data, [\"action_link\", \"email_otp\", \"hashed_token\", \"redirect_to\", \"verification_type\"]);\n    const properties = {\n        action_link,\n        email_otp,\n        hashed_token,\n        redirect_to,\n        verification_type,\n    };\n    const user = Object.assign({}, rest);\n    return {\n        data: {\n            properties,\n            user,\n        },\n        error: null,\n    };\n}\nfunction _noResolveJsonResponse(data) {\n    return data;\n}\n/**\n * hasSession checks if the response object contains a valid session\n * @param data A response object\n * @returns true if a session is in the response\n */\nfunction hasSession(data) {\n    return data.access_token && data.refresh_token && data.expires_in;\n}\n//# sourceMappingURL=fetch.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/fetch.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/helpers.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/helpers.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Deferred: () => (/* binding */ Deferred),\n/* harmony export */   decodeBase64URL: () => (/* binding */ decodeBase64URL),\n/* harmony export */   decodeJWTPayload: () => (/* binding */ decodeJWTPayload),\n/* harmony export */   expiresAt: () => (/* binding */ expiresAt),\n/* harmony export */   generatePKCEChallenge: () => (/* binding */ generatePKCEChallenge),\n/* harmony export */   generatePKCEVerifier: () => (/* binding */ generatePKCEVerifier),\n/* harmony export */   getCodeChallengeAndMethod: () => (/* binding */ getCodeChallengeAndMethod),\n/* harmony export */   getItemAsync: () => (/* binding */ getItemAsync),\n/* harmony export */   isBrowser: () => (/* binding */ isBrowser),\n/* harmony export */   looksLikeFetchResponse: () => (/* binding */ looksLikeFetchResponse),\n/* harmony export */   parseParametersFromURL: () => (/* binding */ parseParametersFromURL),\n/* harmony export */   parseResponseAPIVersion: () => (/* binding */ parseResponseAPIVersion),\n/* harmony export */   removeItemAsync: () => (/* binding */ removeItemAsync),\n/* harmony export */   resolveFetch: () => (/* binding */ resolveFetch),\n/* harmony export */   retryable: () => (/* binding */ retryable),\n/* harmony export */   setItemAsync: () => (/* binding */ setItemAsync),\n/* harmony export */   sleep: () => (/* binding */ sleep),\n/* harmony export */   supportsLocalStorage: () => (/* binding */ supportsLocalStorage),\n/* harmony export */   uuid: () => (/* binding */ uuid)\n/* harmony export */ });\n/* harmony import */ var _constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./constants */ \"./node_modules/@supabase/auth-js/dist/module/lib/constants.js\");\n\nfunction expiresAt(expiresIn) {\n    const timeNow = Math.round(Date.now() / 1000);\n    return timeNow + expiresIn;\n}\nfunction uuid() {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n        const r = (Math.random() * 16) | 0, v = c == 'x' ? r : (r & 0x3) | 0x8;\n        return v.toString(16);\n    });\n}\nconst isBrowser = () => typeof document !== 'undefined';\nconst localStorageWriteTests = {\n    tested: false,\n    writable: false,\n};\n/**\n * Checks whether localStorage is supported on this browser.\n */\nconst supportsLocalStorage = () => {\n    if (!isBrowser()) {\n        return false;\n    }\n    try {\n        if (typeof globalThis.localStorage !== 'object') {\n            return false;\n        }\n    }\n    catch (e) {\n        // DOM exception when accessing `localStorage`\n        return false;\n    }\n    if (localStorageWriteTests.tested) {\n        return localStorageWriteTests.writable;\n    }\n    const randomKey = `lswt-${Math.random()}${Math.random()}`;\n    try {\n        globalThis.localStorage.setItem(randomKey, randomKey);\n        globalThis.localStorage.removeItem(randomKey);\n        localStorageWriteTests.tested = true;\n        localStorageWriteTests.writable = true;\n    }\n    catch (e) {\n        // localStorage can't be written to\n        // https://www.chromium.org/for-testers/bug-reporting-guidelines/uncaught-securityerror-failed-to-read-the-localstorage-property-from-window-access-is-denied-for-this-document\n        localStorageWriteTests.tested = true;\n        localStorageWriteTests.writable = false;\n    }\n    return localStorageWriteTests.writable;\n};\n/**\n * Extracts parameters encoded in the URL both in the query and fragment.\n */\nfunction parseParametersFromURL(href) {\n    const result = {};\n    const url = new URL(href);\n    if (url.hash && url.hash[0] === '#') {\n        try {\n            const hashSearchParams = new URLSearchParams(url.hash.substring(1));\n            hashSearchParams.forEach((value, key) => {\n                result[key] = value;\n            });\n        }\n        catch (e) {\n            // hash is not a query string\n        }\n    }\n    // search parameters take precedence over hash parameters\n    url.searchParams.forEach((value, key) => {\n        result[key] = value;\n    });\n    return result;\n}\nconst resolveFetch = (customFetch) => {\n    let _fetch;\n    if (customFetch) {\n        _fetch = customFetch;\n    }\n    else if (typeof fetch === 'undefined') {\n        _fetch = (...args) => Promise.resolve(/*! import() */).then(__webpack_require__.bind(__webpack_require__, /*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\")).then(({ default: fetch }) => fetch(...args));\n    }\n    else {\n        _fetch = fetch;\n    }\n    return (...args) => _fetch(...args);\n};\nconst looksLikeFetchResponse = (maybeResponse) => {\n    return (typeof maybeResponse === 'object' &&\n        maybeResponse !== null &&\n        'status' in maybeResponse &&\n        'ok' in maybeResponse &&\n        'json' in maybeResponse &&\n        typeof maybeResponse.json === 'function');\n};\n// Storage helpers\nconst setItemAsync = async (storage, key, data) => {\n    await storage.setItem(key, JSON.stringify(data));\n};\nconst getItemAsync = async (storage, key) => {\n    const value = await storage.getItem(key);\n    if (!value) {\n        return null;\n    }\n    try {\n        return JSON.parse(value);\n    }\n    catch (_a) {\n        return value;\n    }\n};\nconst removeItemAsync = async (storage, key) => {\n    await storage.removeItem(key);\n};\nfunction decodeBase64URL(value) {\n    const key = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/=';\n    let base64 = '';\n    let chr1, chr2, chr3;\n    let enc1, enc2, enc3, enc4;\n    let i = 0;\n    value = value.replace('-', '+').replace('_', '/');\n    while (i < value.length) {\n        enc1 = key.indexOf(value.charAt(i++));\n        enc2 = key.indexOf(value.charAt(i++));\n        enc3 = key.indexOf(value.charAt(i++));\n        enc4 = key.indexOf(value.charAt(i++));\n        chr1 = (enc1 << 2) | (enc2 >> 4);\n        chr2 = ((enc2 & 15) << 4) | (enc3 >> 2);\n        chr3 = ((enc3 & 3) << 6) | enc4;\n        base64 = base64 + String.fromCharCode(chr1);\n        if (enc3 != 64 && chr2 != 0) {\n            base64 = base64 + String.fromCharCode(chr2);\n        }\n        if (enc4 != 64 && chr3 != 0) {\n            base64 = base64 + String.fromCharCode(chr3);\n        }\n    }\n    return base64;\n}\n/**\n * A deferred represents some asynchronous work that is not yet finished, which\n * may or may not culminate in a value.\n * Taken from: https://github.com/mike-north/types/blob/master/src/async.ts\n */\nclass Deferred {\n    constructor() {\n        // eslint-disable-next-line @typescript-eslint/no-extra-semi\n        ;\n        this.promise = new Deferred.promiseConstructor((res, rej) => {\n            // eslint-disable-next-line @typescript-eslint/no-extra-semi\n            ;\n            this.resolve = res;\n            this.reject = rej;\n        });\n    }\n}\nDeferred.promiseConstructor = Promise;\n// Taken from: https://stackoverflow.com/questions/38552003/how-to-decode-jwt-token-in-javascript-without-using-a-library\nfunction decodeJWTPayload(token) {\n    // Regex checks for base64url format\n    const base64UrlRegex = /^([a-z0-9_-]{4})*($|[a-z0-9_-]{3}=?$|[a-z0-9_-]{2}(==)?$)$/i;\n    const parts = token.split('.');\n    if (parts.length !== 3) {\n        throw new Error('JWT is not valid: not a JWT structure');\n    }\n    if (!base64UrlRegex.test(parts[1])) {\n        throw new Error('JWT is not valid: payload is not in base64url format');\n    }\n    const base64Url = parts[1];\n    return JSON.parse(decodeBase64URL(base64Url));\n}\n/**\n * Creates a promise that resolves to null after some time.\n */\nasync function sleep(time) {\n    return await new Promise((accept) => {\n        setTimeout(() => accept(null), time);\n    });\n}\n/**\n * Converts the provided async function into a retryable function. Each result\n * or thrown error is sent to the isRetryable function which should return true\n * if the function should run again.\n */\nfunction retryable(fn, isRetryable) {\n    const promise = new Promise((accept, reject) => {\n        // eslint-disable-next-line @typescript-eslint/no-extra-semi\n        ;\n        (async () => {\n            for (let attempt = 0; attempt < Infinity; attempt++) {\n                try {\n                    const result = await fn(attempt);\n                    if (!isRetryable(attempt, null, result)) {\n                        accept(result);\n                        return;\n                    }\n                }\n                catch (e) {\n                    if (!isRetryable(attempt, e)) {\n                        reject(e);\n                        return;\n                    }\n                }\n            }\n        })();\n    });\n    return promise;\n}\nfunction dec2hex(dec) {\n    return ('0' + dec.toString(16)).substr(-2);\n}\n// Functions below taken from: https://stackoverflow.com/questions/63309409/creating-a-code-verifier-and-challenge-for-pkce-auth-on-spotify-api-in-reactjs\nfunction generatePKCEVerifier() {\n    const verifierLength = 56;\n    const array = new Uint32Array(verifierLength);\n    if (typeof crypto === 'undefined') {\n        const charSet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-._~';\n        const charSetLen = charSet.length;\n        let verifier = '';\n        for (let i = 0; i < verifierLength; i++) {\n            verifier += charSet.charAt(Math.floor(Math.random() * charSetLen));\n        }\n        return verifier;\n    }\n    crypto.getRandomValues(array);\n    return Array.from(array, dec2hex).join('');\n}\nasync function sha256(randomString) {\n    const encoder = new TextEncoder();\n    const encodedData = encoder.encode(randomString);\n    const hash = await crypto.subtle.digest('SHA-256', encodedData);\n    const bytes = new Uint8Array(hash);\n    return Array.from(bytes)\n        .map((c) => String.fromCharCode(c))\n        .join('');\n}\nfunction base64urlencode(str) {\n    return btoa(str).replace(/\\+/g, '-').replace(/\\//g, '_').replace(/=+$/, '');\n}\nasync function generatePKCEChallenge(verifier) {\n    const hasCryptoSupport = typeof crypto !== 'undefined' &&\n        typeof crypto.subtle !== 'undefined' &&\n        typeof TextEncoder !== 'undefined';\n    if (!hasCryptoSupport) {\n        console.warn('WebCrypto API is not supported. Code challenge method will default to use plain instead of sha256.');\n        return verifier;\n    }\n    const hashed = await sha256(verifier);\n    return base64urlencode(hashed);\n}\nasync function getCodeChallengeAndMethod(storage, storageKey, isPasswordRecovery = false) {\n    const codeVerifier = generatePKCEVerifier();\n    let storedCodeVerifier = codeVerifier;\n    if (isPasswordRecovery) {\n        storedCodeVerifier += '/PASSWORD_RECOVERY';\n    }\n    await setItemAsync(storage, `${storageKey}-code-verifier`, storedCodeVerifier);\n    const codeChallenge = await generatePKCEChallenge(codeVerifier);\n    const codeChallengeMethod = codeVerifier === codeChallenge ? 'plain' : 's256';\n    return [codeChallenge, codeChallengeMethod];\n}\n/** Parses the API version which is 2YYY-MM-DD. */\nconst API_VERSION_REGEX = /^2[0-9]{3}-(0[1-9]|1[0-2])-(0[1-9]|1[0-9]|2[0-9]|3[0-1])$/i;\nfunction parseResponseAPIVersion(response) {\n    const apiVersion = response.headers.get(_constants__WEBPACK_IMPORTED_MODULE_0__.API_VERSION_HEADER_NAME);\n    if (!apiVersion) {\n        return null;\n    }\n    if (!apiVersion.match(API_VERSION_REGEX)) {\n        return null;\n    }\n    try {\n        const date = new Date(`${apiVersion}T00:00:00.0Z`);\n        return date;\n    }\n    catch (e) {\n        return null;\n    }\n}\n//# sourceMappingURL=helpers.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/helpers.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/local-storage.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/local-storage.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   localStorageAdapter: () => (/* binding */ localStorageAdapter),\n/* harmony export */   memoryLocalStorageAdapter: () => (/* binding */ memoryLocalStorageAdapter)\n/* harmony export */ });\n/* harmony import */ var _helpers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./helpers */ \"./node_modules/@supabase/auth-js/dist/module/lib/helpers.js\");\n\n/**\n * Provides safe access to the globalThis.localStorage property.\n */\nconst localStorageAdapter = {\n    getItem: (key) => {\n        if (!(0,_helpers__WEBPACK_IMPORTED_MODULE_0__.supportsLocalStorage)()) {\n            return null;\n        }\n        return globalThis.localStorage.getItem(key);\n    },\n    setItem: (key, value) => {\n        if (!(0,_helpers__WEBPACK_IMPORTED_MODULE_0__.supportsLocalStorage)()) {\n            return;\n        }\n        globalThis.localStorage.setItem(key, value);\n    },\n    removeItem: (key) => {\n        if (!(0,_helpers__WEBPACK_IMPORTED_MODULE_0__.supportsLocalStorage)()) {\n            return;\n        }\n        globalThis.localStorage.removeItem(key);\n    },\n};\n/**\n * Returns a localStorage-like object that stores the key-value pairs in\n * memory.\n */\nfunction memoryLocalStorageAdapter(store = {}) {\n    return {\n        getItem: (key) => {\n            return store[key] || null;\n        },\n        setItem: (key, value) => {\n            store[key] = value;\n        },\n        removeItem: (key) => {\n            delete store[key];\n        },\n    };\n}\n//# sourceMappingURL=local-storage.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/local-storage.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/locks.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/locks.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   LockAcquireTimeoutError: () => (/* binding */ LockAcquireTimeoutError),\n/* harmony export */   NavigatorLockAcquireTimeoutError: () => (/* binding */ NavigatorLockAcquireTimeoutError),\n/* harmony export */   internals: () => (/* binding */ internals),\n/* harmony export */   navigatorLock: () => (/* binding */ navigatorLock)\n/* harmony export */ });\n/* harmony import */ var _helpers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./helpers */ \"./node_modules/@supabase/auth-js/dist/module/lib/helpers.js\");\n\n/**\n * @experimental\n */\nconst internals = {\n    /**\n     * @experimental\n     */\n    debug: !!(globalThis &&\n        (0,_helpers__WEBPACK_IMPORTED_MODULE_0__.supportsLocalStorage)() &&\n        globalThis.localStorage &&\n        globalThis.localStorage.getItem('supabase.gotrue-js.locks.debug') === 'true'),\n};\n/**\n * An error thrown when a lock cannot be acquired after some amount of time.\n *\n * Use the {@link #isAcquireTimeout} property instead of checking with `instanceof`.\n */\nclass LockAcquireTimeoutError extends Error {\n    constructor(message) {\n        super(message);\n        this.isAcquireTimeout = true;\n    }\n}\nclass NavigatorLockAcquireTimeoutError extends LockAcquireTimeoutError {\n}\n/**\n * Implements a global exclusive lock using the Navigator LockManager API. It\n * is available on all browsers released after 2022-03-15 with Safari being the\n * last one to release support. If the API is not available, this function will\n * throw. Make sure you check availablility before configuring {@link\n * GoTrueClient}.\n *\n * You can turn on debugging by setting the `supabase.gotrue-js.locks.debug`\n * local storage item to `true`.\n *\n * Internals:\n *\n * Since the LockManager API does not preserve stack traces for the async\n * function passed in the `request` method, a trick is used where acquiring the\n * lock releases a previously started promise to run the operation in the `fn`\n * function. The lock waits for that promise to finish (with or without error),\n * while the function will finally wait for the result anyway.\n *\n * @param name Name of the lock to be acquired.\n * @param acquireTimeout If negative, no timeout. If 0 an error is thrown if\n *                       the lock can't be acquired without waiting. If positive, the lock acquire\n *                       will time out after so many milliseconds. An error is\n *                       a timeout if it has `isAcquireTimeout` set to true.\n * @param fn The operation to run once the lock is acquired.\n */\nasync function navigatorLock(name, acquireTimeout, fn) {\n    if (internals.debug) {\n        console.log('@supabase/gotrue-js: navigatorLock: acquire lock', name, acquireTimeout);\n    }\n    const abortController = new globalThis.AbortController();\n    if (acquireTimeout > 0) {\n        setTimeout(() => {\n            abortController.abort();\n            if (internals.debug) {\n                console.log('@supabase/gotrue-js: navigatorLock acquire timed out', name);\n            }\n        }, acquireTimeout);\n    }\n    // MDN article: https://developer.mozilla.org/en-US/docs/Web/API/LockManager/request\n    return await globalThis.navigator.locks.request(name, acquireTimeout === 0\n        ? {\n            mode: 'exclusive',\n            ifAvailable: true,\n        }\n        : {\n            mode: 'exclusive',\n            signal: abortController.signal,\n        }, async (lock) => {\n        if (lock) {\n            if (internals.debug) {\n                console.log('@supabase/gotrue-js: navigatorLock: acquired', name, lock.name);\n            }\n            try {\n                return await fn();\n            }\n            finally {\n                if (internals.debug) {\n                    console.log('@supabase/gotrue-js: navigatorLock: released', name, lock.name);\n                }\n            }\n        }\n        else {\n            if (acquireTimeout === 0) {\n                if (internals.debug) {\n                    console.log('@supabase/gotrue-js: navigatorLock: not immediately available', name);\n                }\n                throw new NavigatorLockAcquireTimeoutError(`Acquiring an exclusive Navigator LockManager lock \"${name}\" immediately failed`);\n            }\n            else {\n                if (internals.debug) {\n                    try {\n                        const result = await globalThis.navigator.locks.query();\n                        console.log('@supabase/gotrue-js: Navigator LockManager state', JSON.stringify(result, null, '  '));\n                    }\n                    catch (e) {\n                        console.warn('@supabase/gotrue-js: Error when querying Navigator LockManager state', e);\n                    }\n                }\n                // Browser is not following the Navigator LockManager spec, it\n                // returned a null lock when we didn't use ifAvailable. So we can\n                // pretend the lock is acquired in the name of backward compatibility\n                // and user experience and just run the function.\n                console.warn('@supabase/gotrue-js: Navigator LockManager returned a null lock when using #request without ifAvailable set to true, it appears this browser is not following the LockManager spec https://developer.mozilla.org/en-US/docs/Web/API/LockManager/request');\n                return await fn();\n            }\n        }\n    });\n}\n//# sourceMappingURL=locks.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/locks.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/polyfills.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/polyfills.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   polyfillGlobalThis: () => (/* binding */ polyfillGlobalThis)\n/* harmony export */ });\n/**\n * https://mathiasbynens.be/notes/globalthis\n */\nfunction polyfillGlobalThis() {\n    if (typeof globalThis === 'object')\n        return;\n    try {\n        Object.defineProperty(Object.prototype, '__magic__', {\n            get: function () {\n                return this;\n            },\n            configurable: true,\n        });\n        // @ts-expect-error 'Allow access to magic'\n        __magic__.globalThis = __magic__;\n        // @ts-expect-error 'Allow access to magic'\n        delete Object.prototype.__magic__;\n    }\n    catch (e) {\n        if (typeof self !== 'undefined') {\n            // @ts-expect-error 'Allow access to globals'\n            self.globalThis = self;\n        }\n    }\n}\n//# sourceMappingURL=polyfills.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/polyfills.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/types.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/types.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/types.js?");

/***/ }),

/***/ "./node_modules/@supabase/auth-js/dist/module/lib/version.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@supabase/auth-js/dist/module/lib/version.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   version: () => (/* binding */ version)\n/* harmony export */ });\nconst version = '2.64.4';\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/auth-js/dist/module/lib/version.js?");

/***/ }),

/***/ "./node_modules/@supabase/functions-js/dist/module/FunctionsClient.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@supabase/functions-js/dist/module/FunctionsClient.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FunctionsClient: () => (/* binding */ FunctionsClient)\n/* harmony export */ });\n/* harmony import */ var _helper__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./helper */ \"./node_modules/@supabase/functions-js/dist/module/helper.js\");\n/* harmony import */ var _types__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./types */ \"./node_modules/@supabase/functions-js/dist/module/types.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nclass FunctionsClient {\n    constructor(url, { headers = {}, customFetch, region = _types__WEBPACK_IMPORTED_MODULE_0__.FunctionRegion.Any, } = {}) {\n        this.url = url;\n        this.headers = headers;\n        this.region = region;\n        this.fetch = (0,_helper__WEBPACK_IMPORTED_MODULE_1__.resolveFetch)(customFetch);\n    }\n    /**\n     * Updates the authorization header\n     * @param token - the new jwt token sent in the authorisation header\n     */\n    setAuth(token) {\n        this.headers.Authorization = `Bearer ${token}`;\n    }\n    /**\n     * Invokes a function\n     * @param functionName - The name of the Function to invoke.\n     * @param options - Options for invoking the Function.\n     */\n    invoke(functionName, options = {}) {\n        var _a;\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const { headers, method, body: functionArgs } = options;\n                let _headers = {};\n                let { region } = options;\n                if (!region) {\n                    region = this.region;\n                }\n                if (region && region !== 'any') {\n                    _headers['x-region'] = region;\n                }\n                let body;\n                if (functionArgs &&\n                    ((headers && !Object.prototype.hasOwnProperty.call(headers, 'Content-Type')) || !headers)) {\n                    if ((typeof Blob !== 'undefined' && functionArgs instanceof Blob) ||\n                        functionArgs instanceof ArrayBuffer) {\n                        // will work for File as File inherits Blob\n                        // also works for ArrayBuffer as it is the same underlying structure as a Blob\n                        _headers['Content-Type'] = 'application/octet-stream';\n                        body = functionArgs;\n                    }\n                    else if (typeof functionArgs === 'string') {\n                        // plain string\n                        _headers['Content-Type'] = 'text/plain';\n                        body = functionArgs;\n                    }\n                    else if (typeof FormData !== 'undefined' && functionArgs instanceof FormData) {\n                        // don't set content-type headers\n                        // Request will automatically add the right boundary value\n                        body = functionArgs;\n                    }\n                    else {\n                        // default, assume this is JSON\n                        _headers['Content-Type'] = 'application/json';\n                        body = JSON.stringify(functionArgs);\n                    }\n                }\n                const response = yield this.fetch(`${this.url}/${functionName}`, {\n                    method: method || 'POST',\n                    // headers priority is (high to low):\n                    // 1. invoke-level headers\n                    // 2. client-level headers\n                    // 3. default Content-Type header\n                    headers: Object.assign(Object.assign(Object.assign({}, _headers), this.headers), headers),\n                    body,\n                }).catch((fetchError) => {\n                    throw new _types__WEBPACK_IMPORTED_MODULE_0__.FunctionsFetchError(fetchError);\n                });\n                const isRelayError = response.headers.get('x-relay-error');\n                if (isRelayError && isRelayError === 'true') {\n                    throw new _types__WEBPACK_IMPORTED_MODULE_0__.FunctionsRelayError(response);\n                }\n                if (!response.ok) {\n                    throw new _types__WEBPACK_IMPORTED_MODULE_0__.FunctionsHttpError(response);\n                }\n                let responseType = ((_a = response.headers.get('Content-Type')) !== null && _a !== void 0 ? _a : 'text/plain').split(';')[0].trim();\n                let data;\n                if (responseType === 'application/json') {\n                    data = yield response.json();\n                }\n                else if (responseType === 'application/octet-stream') {\n                    data = yield response.blob();\n                }\n                else if (responseType === 'text/event-stream') {\n                    data = response;\n                }\n                else if (responseType === 'multipart/form-data') {\n                    data = yield response.formData();\n                }\n                else {\n                    // default to text\n                    data = yield response.text();\n                }\n                return { data, error: null };\n            }\n            catch (error) {\n                return { data: null, error };\n            }\n        });\n    }\n}\n//# sourceMappingURL=FunctionsClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/functions-js/dist/module/FunctionsClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/functions-js/dist/module/helper.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@supabase/functions-js/dist/module/helper.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   resolveFetch: () => (/* binding */ resolveFetch)\n/* harmony export */ });\nconst resolveFetch = (customFetch) => {\n    let _fetch;\n    if (customFetch) {\n        _fetch = customFetch;\n    }\n    else if (typeof fetch === 'undefined') {\n        _fetch = (...args) => Promise.resolve(/*! import() */).then(__webpack_require__.bind(__webpack_require__, /*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\")).then(({ default: fetch }) => fetch(...args));\n    }\n    else {\n        _fetch = fetch;\n    }\n    return (...args) => _fetch(...args);\n};\n//# sourceMappingURL=helper.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/functions-js/dist/module/helper.js?");

/***/ }),

/***/ "./node_modules/@supabase/functions-js/dist/module/types.js":
/*!******************************************************************!*\
  !*** ./node_modules/@supabase/functions-js/dist/module/types.js ***!
  \******************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   FunctionRegion: () => (/* binding */ FunctionRegion),\n/* harmony export */   FunctionsError: () => (/* binding */ FunctionsError),\n/* harmony export */   FunctionsFetchError: () => (/* binding */ FunctionsFetchError),\n/* harmony export */   FunctionsHttpError: () => (/* binding */ FunctionsHttpError),\n/* harmony export */   FunctionsRelayError: () => (/* binding */ FunctionsRelayError)\n/* harmony export */ });\nclass FunctionsError extends Error {\n    constructor(message, name = 'FunctionsError', context) {\n        super(message);\n        this.name = name;\n        this.context = context;\n    }\n}\nclass FunctionsFetchError extends FunctionsError {\n    constructor(context) {\n        super('Failed to send a request to the Edge Function', 'FunctionsFetchError', context);\n    }\n}\nclass FunctionsRelayError extends FunctionsError {\n    constructor(context) {\n        super('Relay Error invoking the Edge Function', 'FunctionsRelayError', context);\n    }\n}\nclass FunctionsHttpError extends FunctionsError {\n    constructor(context) {\n        super('Edge Function returned a non-2xx status code', 'FunctionsHttpError', context);\n    }\n}\n// Define the enum for the 'region' property\nvar FunctionRegion;\n(function (FunctionRegion) {\n    FunctionRegion[\"Any\"] = \"any\";\n    FunctionRegion[\"ApNortheast1\"] = \"ap-northeast-1\";\n    FunctionRegion[\"ApNortheast2\"] = \"ap-northeast-2\";\n    FunctionRegion[\"ApSouth1\"] = \"ap-south-1\";\n    FunctionRegion[\"ApSoutheast1\"] = \"ap-southeast-1\";\n    FunctionRegion[\"ApSoutheast2\"] = \"ap-southeast-2\";\n    FunctionRegion[\"CaCentral1\"] = \"ca-central-1\";\n    FunctionRegion[\"EuCentral1\"] = \"eu-central-1\";\n    FunctionRegion[\"EuWest1\"] = \"eu-west-1\";\n    FunctionRegion[\"EuWest2\"] = \"eu-west-2\";\n    FunctionRegion[\"EuWest3\"] = \"eu-west-3\";\n    FunctionRegion[\"SaEast1\"] = \"sa-east-1\";\n    FunctionRegion[\"UsEast1\"] = \"us-east-1\";\n    FunctionRegion[\"UsWest1\"] = \"us-west-1\";\n    FunctionRegion[\"UsWest2\"] = \"us-west-2\";\n})(FunctionRegion || (FunctionRegion = {}));\n//# sourceMappingURL=types.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/functions-js/dist/module/types.js?");

/***/ }),

/***/ "./node_modules/@supabase/node-fetch/browser.js":
/*!******************************************************!*\
  !*** ./node_modules/@supabase/node-fetch/browser.js ***!
  \******************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   Headers: () => (/* binding */ Headers),\n/* harmony export */   Request: () => (/* binding */ Request),\n/* harmony export */   Response: () => (/* binding */ Response),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__),\n/* harmony export */   fetch: () => (/* binding */ fetch)\n/* harmony export */ });\n\n\n// ref: https://github.com/tc39/proposal-global\nvar getGlobal = function() {\n    // the only reliable means to get the global object is\n    // `Function('return this')()`\n    // However, this causes CSP violations in Chrome apps.\n    if (typeof self !== 'undefined') { return self; }\n    if (typeof window !== 'undefined') { return window; }\n    if (typeof __webpack_require__.g !== 'undefined') { return __webpack_require__.g; }\n    throw new Error('unable to locate global object');\n}\n\nvar globalObject = getGlobal();\n\nconst fetch = globalObject.fetch;\n\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = (globalObject.fetch.bind(globalObject));\n\nconst Headers = globalObject.Headers;\nconst Request = globalObject.Request;\nconst Response = globalObject.Response;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/node-fetch/browser.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestBuilder.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestBuilder.js ***!
  \**************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\n// @ts-ignore\nconst node_fetch_1 = __importDefault(__webpack_require__(/*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\"));\nconst PostgrestError_1 = __importDefault(__webpack_require__(/*! ./PostgrestError */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestError.js\"));\nclass PostgrestBuilder {\n    constructor(builder) {\n        this.shouldThrowOnError = false;\n        this.method = builder.method;\n        this.url = builder.url;\n        this.headers = builder.headers;\n        this.schema = builder.schema;\n        this.body = builder.body;\n        this.shouldThrowOnError = builder.shouldThrowOnError;\n        this.signal = builder.signal;\n        this.isMaybeSingle = builder.isMaybeSingle;\n        if (builder.fetch) {\n            this.fetch = builder.fetch;\n        }\n        else if (typeof fetch === 'undefined') {\n            this.fetch = node_fetch_1.default;\n        }\n        else {\n            this.fetch = fetch;\n        }\n    }\n    /**\n     * If there's an error with the query, throwOnError will reject the promise by\n     * throwing the error instead of returning it as part of a successful response.\n     *\n     * {@link https://github.com/supabase/supabase-js/issues/92}\n     */\n    throwOnError() {\n        this.shouldThrowOnError = true;\n        return this;\n    }\n    then(onfulfilled, onrejected) {\n        // https://postgrest.org/en/stable/api.html#switching-schemas\n        if (this.schema === undefined) {\n            // skip\n        }\n        else if (['GET', 'HEAD'].includes(this.method)) {\n            this.headers['Accept-Profile'] = this.schema;\n        }\n        else {\n            this.headers['Content-Profile'] = this.schema;\n        }\n        if (this.method !== 'GET' && this.method !== 'HEAD') {\n            this.headers['Content-Type'] = 'application/json';\n        }\n        // NOTE: Invoke w/o `this` to avoid illegal invocation error.\n        // https://github.com/supabase/postgrest-js/pull/247\n        const _fetch = this.fetch;\n        let res = _fetch(this.url.toString(), {\n            method: this.method,\n            headers: this.headers,\n            body: JSON.stringify(this.body),\n            signal: this.signal,\n        }).then(async (res) => {\n            var _a, _b, _c;\n            let error = null;\n            let data = null;\n            let count = null;\n            let status = res.status;\n            let statusText = res.statusText;\n            if (res.ok) {\n                if (this.method !== 'HEAD') {\n                    const body = await res.text();\n                    if (body === '') {\n                        // Prefer: return=minimal\n                    }\n                    else if (this.headers['Accept'] === 'text/csv') {\n                        data = body;\n                    }\n                    else if (this.headers['Accept'] &&\n                        this.headers['Accept'].includes('application/vnd.pgrst.plan+text')) {\n                        data = body;\n                    }\n                    else {\n                        data = JSON.parse(body);\n                    }\n                }\n                const countHeader = (_a = this.headers['Prefer']) === null || _a === void 0 ? void 0 : _a.match(/count=(exact|planned|estimated)/);\n                const contentRange = (_b = res.headers.get('content-range')) === null || _b === void 0 ? void 0 : _b.split('/');\n                if (countHeader && contentRange && contentRange.length > 1) {\n                    count = parseInt(contentRange[1]);\n                }\n                // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n                // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n                if (this.isMaybeSingle && this.method === 'GET' && Array.isArray(data)) {\n                    if (data.length > 1) {\n                        error = {\n                            // https://github.com/PostgREST/postgrest/blob/a867d79c42419af16c18c3fb019eba8df992626f/src/PostgREST/Error.hs#L553\n                            code: 'PGRST116',\n                            details: `Results contain ${data.length} rows, application/vnd.pgrst.object+json requires 1 row`,\n                            hint: null,\n                            message: 'JSON object requested, multiple (or no) rows returned',\n                        };\n                        data = null;\n                        count = null;\n                        status = 406;\n                        statusText = 'Not Acceptable';\n                    }\n                    else if (data.length === 1) {\n                        data = data[0];\n                    }\n                    else {\n                        data = null;\n                    }\n                }\n            }\n            else {\n                const body = await res.text();\n                try {\n                    error = JSON.parse(body);\n                    // Workaround for https://github.com/supabase/postgrest-js/issues/295\n                    if (Array.isArray(error) && res.status === 404) {\n                        data = [];\n                        error = null;\n                        status = 200;\n                        statusText = 'OK';\n                    }\n                }\n                catch (_d) {\n                    // Workaround for https://github.com/supabase/postgrest-js/issues/295\n                    if (res.status === 404 && body === '') {\n                        status = 204;\n                        statusText = 'No Content';\n                    }\n                    else {\n                        error = {\n                            message: body,\n                        };\n                    }\n                }\n                if (error && this.isMaybeSingle && ((_c = error === null || error === void 0 ? void 0 : error.details) === null || _c === void 0 ? void 0 : _c.includes('0 rows'))) {\n                    error = null;\n                    status = 200;\n                    statusText = 'OK';\n                }\n                if (error && this.shouldThrowOnError) {\n                    throw new PostgrestError_1.default(error);\n                }\n            }\n            const postgrestResponse = {\n                error,\n                data,\n                count,\n                status,\n                statusText,\n            };\n            return postgrestResponse;\n        });\n        if (!this.shouldThrowOnError) {\n            res = res.catch((fetchError) => {\n                var _a, _b, _c;\n                return ({\n                    error: {\n                        message: `${(_a = fetchError === null || fetchError === void 0 ? void 0 : fetchError.name) !== null && _a !== void 0 ? _a : 'FetchError'}: ${fetchError === null || fetchError === void 0 ? void 0 : fetchError.message}`,\n                        details: `${(_b = fetchError === null || fetchError === void 0 ? void 0 : fetchError.stack) !== null && _b !== void 0 ? _b : ''}`,\n                        hint: '',\n                        code: `${(_c = fetchError === null || fetchError === void 0 ? void 0 : fetchError.code) !== null && _c !== void 0 ? _c : ''}`,\n                    },\n                    data: null,\n                    count: null,\n                    status: 0,\n                    statusText: '',\n                });\n            });\n        }\n        return res.then(onfulfilled, onrejected);\n    }\n}\nexports[\"default\"] = PostgrestBuilder;\n//# sourceMappingURL=PostgrestBuilder.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestBuilder.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestClient.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestClient.js ***!
  \*************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst PostgrestQueryBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestQueryBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestQueryBuilder.js\"));\nconst PostgrestFilterBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestFilterBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js\"));\nconst constants_1 = __webpack_require__(/*! ./constants */ \"./node_modules/@supabase/postgrest-js/dist/cjs/constants.js\");\n/**\n * PostgREST client.\n *\n * @typeParam Database - Types for the schema from the [type\n * generator](https://supabase.com/docs/reference/javascript/next/typescript-support)\n *\n * @typeParam SchemaName - Postgres schema to switch to. Must be a string\n * literal, the same one passed to the constructor. If the schema is not\n * `\"public\"`, this must be supplied manually.\n */\nclass PostgrestClient {\n    // TODO: Add back shouldThrowOnError once we figure out the typings\n    /**\n     * Creates a PostgREST client.\n     *\n     * @param url - URL of the PostgREST endpoint\n     * @param options - Named parameters\n     * @param options.headers - Custom headers\n     * @param options.schema - Postgres schema to switch to\n     * @param options.fetch - Custom fetch\n     */\n    constructor(url, { headers = {}, schema, fetch, } = {}) {\n        this.url = url;\n        this.headers = Object.assign(Object.assign({}, constants_1.DEFAULT_HEADERS), headers);\n        this.schemaName = schema;\n        this.fetch = fetch;\n    }\n    /**\n     * Perform a query on a table or a view.\n     *\n     * @param relation - The table or view name to query\n     */\n    from(relation) {\n        const url = new URL(`${this.url}/${relation}`);\n        return new PostgrestQueryBuilder_1.default(url, {\n            headers: Object.assign({}, this.headers),\n            schema: this.schemaName,\n            fetch: this.fetch,\n        });\n    }\n    /**\n     * Select a schema to query or perform an function (rpc) call.\n     *\n     * The schema needs to be on the list of exposed schemas inside Supabase.\n     *\n     * @param schema - The schema to query\n     */\n    schema(schema) {\n        return new PostgrestClient(this.url, {\n            headers: this.headers,\n            schema,\n            fetch: this.fetch,\n        });\n    }\n    /**\n     * Perform a function call.\n     *\n     * @param fn - The function name to call\n     * @param args - The arguments to pass to the function call\n     * @param options - Named parameters\n     * @param options.head - When set to `true`, `data` will not be returned.\n     * Useful if you only need the count.\n     * @param options.get - When set to `true`, the function will be called with\n     * read-only access mode.\n     * @param options.count - Count algorithm to use to count rows returned by the\n     * function. Only applicable for [set-returning\n     * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     */\n    rpc(fn, args = {}, { head = false, get = false, count, } = {}) {\n        let method;\n        const url = new URL(`${this.url}/rpc/${fn}`);\n        let body;\n        if (head || get) {\n            method = head ? 'HEAD' : 'GET';\n            Object.entries(args)\n                // params with undefined value needs to be filtered out, otherwise it'll\n                // show up as `?param=undefined`\n                .filter(([_, value]) => value !== undefined)\n                // array values need special syntax\n                .map(([name, value]) => [name, Array.isArray(value) ? `{${value.join(',')}}` : `${value}`])\n                .forEach(([name, value]) => {\n                url.searchParams.append(name, value);\n            });\n        }\n        else {\n            method = 'POST';\n            body = args;\n        }\n        const headers = Object.assign({}, this.headers);\n        if (count) {\n            headers['Prefer'] = `count=${count}`;\n        }\n        return new PostgrestFilterBuilder_1.default({\n            method,\n            url,\n            headers,\n            schema: this.schemaName,\n            body,\n            fetch: this.fetch,\n            allowEmpty: false,\n        });\n    }\n}\nexports[\"default\"] = PostgrestClient;\n//# sourceMappingURL=PostgrestClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestError.js":
/*!************************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestError.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nclass PostgrestError extends Error {\n    constructor(context) {\n        super(context.message);\n        this.name = 'PostgrestError';\n        this.details = context.details;\n        this.hint = context.hint;\n        this.code = context.code;\n    }\n}\nexports[\"default\"] = PostgrestError;\n//# sourceMappingURL=PostgrestError.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestError.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js":
/*!********************************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js ***!
  \********************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst PostgrestTransformBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestTransformBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestTransformBuilder.js\"));\nclass PostgrestFilterBuilder extends PostgrestTransformBuilder_1.default {\n    /**\n     * Match only rows where `column` is equal to `value`.\n     *\n     * To check if the value of `column` is NULL, you should use `.is()` instead.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    eq(column, value) {\n        this.url.searchParams.append(column, `eq.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` is not equal to `value`.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    neq(column, value) {\n        this.url.searchParams.append(column, `neq.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` is greater than `value`.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    gt(column, value) {\n        this.url.searchParams.append(column, `gt.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` is greater than or equal to `value`.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    gte(column, value) {\n        this.url.searchParams.append(column, `gte.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` is less than `value`.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    lt(column, value) {\n        this.url.searchParams.append(column, `lt.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` is less than or equal to `value`.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    lte(column, value) {\n        this.url.searchParams.append(column, `lte.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` matches `pattern` case-sensitively.\n     *\n     * @param column - The column to filter on\n     * @param pattern - The pattern to match with\n     */\n    like(column, pattern) {\n        this.url.searchParams.append(column, `like.${pattern}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` matches all of `patterns` case-sensitively.\n     *\n     * @param column - The column to filter on\n     * @param patterns - The patterns to match with\n     */\n    likeAllOf(column, patterns) {\n        this.url.searchParams.append(column, `like(all).{${patterns.join(',')}}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` matches any of `patterns` case-sensitively.\n     *\n     * @param column - The column to filter on\n     * @param patterns - The patterns to match with\n     */\n    likeAnyOf(column, patterns) {\n        this.url.searchParams.append(column, `like(any).{${patterns.join(',')}}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` matches `pattern` case-insensitively.\n     *\n     * @param column - The column to filter on\n     * @param pattern - The pattern to match with\n     */\n    ilike(column, pattern) {\n        this.url.searchParams.append(column, `ilike.${pattern}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` matches all of `patterns` case-insensitively.\n     *\n     * @param column - The column to filter on\n     * @param patterns - The patterns to match with\n     */\n    ilikeAllOf(column, patterns) {\n        this.url.searchParams.append(column, `ilike(all).{${patterns.join(',')}}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` matches any of `patterns` case-insensitively.\n     *\n     * @param column - The column to filter on\n     * @param patterns - The patterns to match with\n     */\n    ilikeAnyOf(column, patterns) {\n        this.url.searchParams.append(column, `ilike(any).{${patterns.join(',')}}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` IS `value`.\n     *\n     * For non-boolean columns, this is only relevant for checking if the value of\n     * `column` is NULL by setting `value` to `null`.\n     *\n     * For boolean columns, you can also set `value` to `true` or `false` and it\n     * will behave the same way as `.eq()`.\n     *\n     * @param column - The column to filter on\n     * @param value - The value to filter with\n     */\n    is(column, value) {\n        this.url.searchParams.append(column, `is.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows where `column` is included in the `values` array.\n     *\n     * @param column - The column to filter on\n     * @param values - The values array to filter with\n     */\n    in(column, values) {\n        const cleanedValues = Array.from(new Set(values))\n            .map((s) => {\n            // handle postgrest reserved characters\n            // https://postgrest.org/en/v7.0.0/api.html#reserved-characters\n            if (typeof s === 'string' && new RegExp('[,()]').test(s))\n                return `\"${s}\"`;\n            else\n                return `${s}`;\n        })\n            .join(',');\n        this.url.searchParams.append(column, `in.(${cleanedValues})`);\n        return this;\n    }\n    /**\n     * Only relevant for jsonb, array, and range columns. Match only rows where\n     * `column` contains every element appearing in `value`.\n     *\n     * @param column - The jsonb, array, or range column to filter on\n     * @param value - The jsonb, array, or range value to filter with\n     */\n    contains(column, value) {\n        if (typeof value === 'string') {\n            // range types can be inclusive '[', ']' or exclusive '(', ')' so just\n            // keep it simple and accept a string\n            this.url.searchParams.append(column, `cs.${value}`);\n        }\n        else if (Array.isArray(value)) {\n            // array\n            this.url.searchParams.append(column, `cs.{${value.join(',')}}`);\n        }\n        else {\n            // json\n            this.url.searchParams.append(column, `cs.${JSON.stringify(value)}`);\n        }\n        return this;\n    }\n    /**\n     * Only relevant for jsonb, array, and range columns. Match only rows where\n     * every element appearing in `column` is contained by `value`.\n     *\n     * @param column - The jsonb, array, or range column to filter on\n     * @param value - The jsonb, array, or range value to filter with\n     */\n    containedBy(column, value) {\n        if (typeof value === 'string') {\n            // range\n            this.url.searchParams.append(column, `cd.${value}`);\n        }\n        else if (Array.isArray(value)) {\n            // array\n            this.url.searchParams.append(column, `cd.{${value.join(',')}}`);\n        }\n        else {\n            // json\n            this.url.searchParams.append(column, `cd.${JSON.stringify(value)}`);\n        }\n        return this;\n    }\n    /**\n     * Only relevant for range columns. Match only rows where every element in\n     * `column` is greater than any element in `range`.\n     *\n     * @param column - The range column to filter on\n     * @param range - The range to filter with\n     */\n    rangeGt(column, range) {\n        this.url.searchParams.append(column, `sr.${range}`);\n        return this;\n    }\n    /**\n     * Only relevant for range columns. Match only rows where every element in\n     * `column` is either contained in `range` or greater than any element in\n     * `range`.\n     *\n     * @param column - The range column to filter on\n     * @param range - The range to filter with\n     */\n    rangeGte(column, range) {\n        this.url.searchParams.append(column, `nxl.${range}`);\n        return this;\n    }\n    /**\n     * Only relevant for range columns. Match only rows where every element in\n     * `column` is less than any element in `range`.\n     *\n     * @param column - The range column to filter on\n     * @param range - The range to filter with\n     */\n    rangeLt(column, range) {\n        this.url.searchParams.append(column, `sl.${range}`);\n        return this;\n    }\n    /**\n     * Only relevant for range columns. Match only rows where every element in\n     * `column` is either contained in `range` or less than any element in\n     * `range`.\n     *\n     * @param column - The range column to filter on\n     * @param range - The range to filter with\n     */\n    rangeLte(column, range) {\n        this.url.searchParams.append(column, `nxr.${range}`);\n        return this;\n    }\n    /**\n     * Only relevant for range columns. Match only rows where `column` is\n     * mutually exclusive to `range` and there can be no element between the two\n     * ranges.\n     *\n     * @param column - The range column to filter on\n     * @param range - The range to filter with\n     */\n    rangeAdjacent(column, range) {\n        this.url.searchParams.append(column, `adj.${range}`);\n        return this;\n    }\n    /**\n     * Only relevant for array and range columns. Match only rows where\n     * `column` and `value` have an element in common.\n     *\n     * @param column - The array or range column to filter on\n     * @param value - The array or range value to filter with\n     */\n    overlaps(column, value) {\n        if (typeof value === 'string') {\n            // range\n            this.url.searchParams.append(column, `ov.${value}`);\n        }\n        else {\n            // array\n            this.url.searchParams.append(column, `ov.{${value.join(',')}}`);\n        }\n        return this;\n    }\n    /**\n     * Only relevant for text and tsvector columns. Match only rows where\n     * `column` matches the query string in `query`.\n     *\n     * @param column - The text or tsvector column to filter on\n     * @param query - The query text to match with\n     * @param options - Named parameters\n     * @param options.config - The text search configuration to use\n     * @param options.type - Change how the `query` text is interpreted\n     */\n    textSearch(column, query, { config, type } = {}) {\n        let typePart = '';\n        if (type === 'plain') {\n            typePart = 'pl';\n        }\n        else if (type === 'phrase') {\n            typePart = 'ph';\n        }\n        else if (type === 'websearch') {\n            typePart = 'w';\n        }\n        const configPart = config === undefined ? '' : `(${config})`;\n        this.url.searchParams.append(column, `${typePart}fts${configPart}.${query}`);\n        return this;\n    }\n    /**\n     * Match only rows where each column in `query` keys is equal to its\n     * associated value. Shorthand for multiple `.eq()`s.\n     *\n     * @param query - The object to filter with, with column names as keys mapped\n     * to their filter values\n     */\n    match(query) {\n        Object.entries(query).forEach(([column, value]) => {\n            this.url.searchParams.append(column, `eq.${value}`);\n        });\n        return this;\n    }\n    /**\n     * Match only rows which doesn't satisfy the filter.\n     *\n     * Unlike most filters, `opearator` and `value` are used as-is and need to\n     * follow [PostgREST\n     * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n     * to make sure they are properly sanitized.\n     *\n     * @param column - The column to filter on\n     * @param operator - The operator to be negated to filter with, following\n     * PostgREST syntax\n     * @param value - The value to filter with, following PostgREST syntax\n     */\n    not(column, operator, value) {\n        this.url.searchParams.append(column, `not.${operator}.${value}`);\n        return this;\n    }\n    /**\n     * Match only rows which satisfy at least one of the filters.\n     *\n     * Unlike most filters, `filters` is used as-is and needs to follow [PostgREST\n     * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n     * to make sure it's properly sanitized.\n     *\n     * It's currently not possible to do an `.or()` filter across multiple tables.\n     *\n     * @param filters - The filters to use, following PostgREST syntax\n     * @param options - Named parameters\n     * @param options.referencedTable - Set this to filter on referenced tables\n     * instead of the parent table\n     * @param options.foreignTable - Deprecated, use `referencedTable` instead\n     */\n    or(filters, { foreignTable, referencedTable = foreignTable, } = {}) {\n        const key = referencedTable ? `${referencedTable}.or` : 'or';\n        this.url.searchParams.append(key, `(${filters})`);\n        return this;\n    }\n    /**\n     * Match only rows which satisfy the filter. This is an escape hatch - you\n     * should use the specific filter methods wherever possible.\n     *\n     * Unlike most filters, `opearator` and `value` are used as-is and need to\n     * follow [PostgREST\n     * syntax](https://postgrest.org/en/stable/api.html#operators). You also need\n     * to make sure they are properly sanitized.\n     *\n     * @param column - The column to filter on\n     * @param operator - The operator to filter with, following PostgREST syntax\n     * @param value - The value to filter with, following PostgREST syntax\n     */\n    filter(column, operator, value) {\n        this.url.searchParams.append(column, `${operator}.${value}`);\n        return this;\n    }\n}\nexports[\"default\"] = PostgrestFilterBuilder;\n//# sourceMappingURL=PostgrestFilterBuilder.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestQueryBuilder.js":
/*!*******************************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestQueryBuilder.js ***!
  \*******************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst PostgrestFilterBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestFilterBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js\"));\nclass PostgrestQueryBuilder {\n    constructor(url, { headers = {}, schema, fetch, }) {\n        this.url = url;\n        this.headers = headers;\n        this.schema = schema;\n        this.fetch = fetch;\n    }\n    /**\n     * Perform a SELECT query on the table or view.\n     *\n     * @param columns - The columns to retrieve, separated by commas. Columns can be renamed when returned with `customName:columnName`\n     *\n     * @param options - Named parameters\n     *\n     * @param options.head - When set to `true`, `data` will not be returned.\n     * Useful if you only need the count.\n     *\n     * @param options.count - Count algorithm to use to count rows in the table or view.\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     */\n    select(columns, { head = false, count, } = {}) {\n        const method = head ? 'HEAD' : 'GET';\n        // Remove whitespaces except when quoted\n        let quoted = false;\n        const cleanedColumns = (columns !== null && columns !== void 0 ? columns : '*')\n            .split('')\n            .map((c) => {\n            if (/\\s/.test(c) && !quoted) {\n                return '';\n            }\n            if (c === '\"') {\n                quoted = !quoted;\n            }\n            return c;\n        })\n            .join('');\n        this.url.searchParams.set('select', cleanedColumns);\n        if (count) {\n            this.headers['Prefer'] = `count=${count}`;\n        }\n        return new PostgrestFilterBuilder_1.default({\n            method,\n            url: this.url,\n            headers: this.headers,\n            schema: this.schema,\n            fetch: this.fetch,\n            allowEmpty: false,\n        });\n    }\n    /**\n     * Perform an INSERT into the table or view.\n     *\n     * By default, inserted rows are not returned. To return it, chain the call\n     * with `.select()`.\n     *\n     * @param values - The values to insert. Pass an object to insert a single row\n     * or an array to insert multiple rows.\n     *\n     * @param options - Named parameters\n     *\n     * @param options.count - Count algorithm to use to count inserted rows.\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     *\n     * @param options.defaultToNull - Make missing fields default to `null`.\n     * Otherwise, use the default value for the column. Only applies for bulk\n     * inserts.\n     */\n    insert(values, { count, defaultToNull = true, } = {}) {\n        const method = 'POST';\n        const prefersHeaders = [];\n        if (this.headers['Prefer']) {\n            prefersHeaders.push(this.headers['Prefer']);\n        }\n        if (count) {\n            prefersHeaders.push(`count=${count}`);\n        }\n        if (!defaultToNull) {\n            prefersHeaders.push('missing=default');\n        }\n        this.headers['Prefer'] = prefersHeaders.join(',');\n        if (Array.isArray(values)) {\n            const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), []);\n            if (columns.length > 0) {\n                const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`);\n                this.url.searchParams.set('columns', uniqueColumns.join(','));\n            }\n        }\n        return new PostgrestFilterBuilder_1.default({\n            method,\n            url: this.url,\n            headers: this.headers,\n            schema: this.schema,\n            body: values,\n            fetch: this.fetch,\n            allowEmpty: false,\n        });\n    }\n    /**\n     * Perform an UPSERT on the table or view. Depending on the column(s) passed\n     * to `onConflict`, `.upsert()` allows you to perform the equivalent of\n     * `.insert()` if a row with the corresponding `onConflict` columns doesn't\n     * exist, or if it does exist, perform an alternative action depending on\n     * `ignoreDuplicates`.\n     *\n     * By default, upserted rows are not returned. To return it, chain the call\n     * with `.select()`.\n     *\n     * @param values - The values to upsert with. Pass an object to upsert a\n     * single row or an array to upsert multiple rows.\n     *\n     * @param options - Named parameters\n     *\n     * @param options.onConflict - Comma-separated UNIQUE column(s) to specify how\n     * duplicate rows are determined. Two rows are duplicates if all the\n     * `onConflict` columns are equal.\n     *\n     * @param options.ignoreDuplicates - If `true`, duplicate rows are ignored. If\n     * `false`, duplicate rows are merged with existing rows.\n     *\n     * @param options.count - Count algorithm to use to count upserted rows.\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     *\n     * @param options.defaultToNull - Make missing fields default to `null`.\n     * Otherwise, use the default value for the column. This only applies when\n     * inserting new rows, not when merging with existing rows under\n     * `ignoreDuplicates: false`. This also only applies when doing bulk upserts.\n     */\n    upsert(values, { onConflict, ignoreDuplicates = false, count, defaultToNull = true, } = {}) {\n        const method = 'POST';\n        const prefersHeaders = [`resolution=${ignoreDuplicates ? 'ignore' : 'merge'}-duplicates`];\n        if (onConflict !== undefined)\n            this.url.searchParams.set('on_conflict', onConflict);\n        if (this.headers['Prefer']) {\n            prefersHeaders.push(this.headers['Prefer']);\n        }\n        if (count) {\n            prefersHeaders.push(`count=${count}`);\n        }\n        if (!defaultToNull) {\n            prefersHeaders.push('missing=default');\n        }\n        this.headers['Prefer'] = prefersHeaders.join(',');\n        if (Array.isArray(values)) {\n            const columns = values.reduce((acc, x) => acc.concat(Object.keys(x)), []);\n            if (columns.length > 0) {\n                const uniqueColumns = [...new Set(columns)].map((column) => `\"${column}\"`);\n                this.url.searchParams.set('columns', uniqueColumns.join(','));\n            }\n        }\n        return new PostgrestFilterBuilder_1.default({\n            method,\n            url: this.url,\n            headers: this.headers,\n            schema: this.schema,\n            body: values,\n            fetch: this.fetch,\n            allowEmpty: false,\n        });\n    }\n    /**\n     * Perform an UPDATE on the table or view.\n     *\n     * By default, updated rows are not returned. To return it, chain the call\n     * with `.select()` after filters.\n     *\n     * @param values - The values to update with\n     *\n     * @param options - Named parameters\n     *\n     * @param options.count - Count algorithm to use to count updated rows.\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     */\n    update(values, { count, } = {}) {\n        const method = 'PATCH';\n        const prefersHeaders = [];\n        if (this.headers['Prefer']) {\n            prefersHeaders.push(this.headers['Prefer']);\n        }\n        if (count) {\n            prefersHeaders.push(`count=${count}`);\n        }\n        this.headers['Prefer'] = prefersHeaders.join(',');\n        return new PostgrestFilterBuilder_1.default({\n            method,\n            url: this.url,\n            headers: this.headers,\n            schema: this.schema,\n            body: values,\n            fetch: this.fetch,\n            allowEmpty: false,\n        });\n    }\n    /**\n     * Perform a DELETE on the table or view.\n     *\n     * By default, deleted rows are not returned. To return it, chain the call\n     * with `.select()` after filters.\n     *\n     * @param options - Named parameters\n     *\n     * @param options.count - Count algorithm to use to count deleted rows.\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     */\n    delete({ count, } = {}) {\n        const method = 'DELETE';\n        const prefersHeaders = [];\n        if (count) {\n            prefersHeaders.push(`count=${count}`);\n        }\n        if (this.headers['Prefer']) {\n            prefersHeaders.unshift(this.headers['Prefer']);\n        }\n        this.headers['Prefer'] = prefersHeaders.join(',');\n        return new PostgrestFilterBuilder_1.default({\n            method,\n            url: this.url,\n            headers: this.headers,\n            schema: this.schema,\n            fetch: this.fetch,\n            allowEmpty: false,\n        });\n    }\n}\nexports[\"default\"] = PostgrestQueryBuilder;\n//# sourceMappingURL=PostgrestQueryBuilder.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestQueryBuilder.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestTransformBuilder.js":
/*!***********************************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestTransformBuilder.js ***!
  \***********************************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst PostgrestBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestBuilder.js\"));\nclass PostgrestTransformBuilder extends PostgrestBuilder_1.default {\n    /**\n     * Perform a SELECT on the query result.\n     *\n     * By default, `.insert()`, `.update()`, `.upsert()`, and `.delete()` do not\n     * return modified rows. By calling this method, modified rows are returned in\n     * `data`.\n     *\n     * @param columns - The columns to retrieve, separated by commas\n     */\n    select(columns) {\n        // Remove whitespaces except when quoted\n        let quoted = false;\n        const cleanedColumns = (columns !== null && columns !== void 0 ? columns : '*')\n            .split('')\n            .map((c) => {\n            if (/\\s/.test(c) && !quoted) {\n                return '';\n            }\n            if (c === '\"') {\n                quoted = !quoted;\n            }\n            return c;\n        })\n            .join('');\n        this.url.searchParams.set('select', cleanedColumns);\n        if (this.headers['Prefer']) {\n            this.headers['Prefer'] += ',';\n        }\n        this.headers['Prefer'] += 'return=representation';\n        return this;\n    }\n    /**\n     * Order the query result by `column`.\n     *\n     * You can call this method multiple times to order by multiple columns.\n     *\n     * You can order referenced tables, but it only affects the ordering of the\n     * parent table if you use `!inner` in the query.\n     *\n     * @param column - The column to order by\n     * @param options - Named parameters\n     * @param options.ascending - If `true`, the result will be in ascending order\n     * @param options.nullsFirst - If `true`, `null`s appear first. If `false`,\n     * `null`s appear last.\n     * @param options.referencedTable - Set this to order a referenced table by\n     * its columns\n     * @param options.foreignTable - Deprecated, use `options.referencedTable`\n     * instead\n     */\n    order(column, { ascending = true, nullsFirst, foreignTable, referencedTable = foreignTable, } = {}) {\n        const key = referencedTable ? `${referencedTable}.order` : 'order';\n        const existingOrder = this.url.searchParams.get(key);\n        this.url.searchParams.set(key, `${existingOrder ? `${existingOrder},` : ''}${column}.${ascending ? 'asc' : 'desc'}${nullsFirst === undefined ? '' : nullsFirst ? '.nullsfirst' : '.nullslast'}`);\n        return this;\n    }\n    /**\n     * Limit the query result by `count`.\n     *\n     * @param count - The maximum number of rows to return\n     * @param options - Named parameters\n     * @param options.referencedTable - Set this to limit rows of referenced\n     * tables instead of the parent table\n     * @param options.foreignTable - Deprecated, use `options.referencedTable`\n     * instead\n     */\n    limit(count, { foreignTable, referencedTable = foreignTable, } = {}) {\n        const key = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`;\n        this.url.searchParams.set(key, `${count}`);\n        return this;\n    }\n    /**\n     * Limit the query result by starting at an offset `from` and ending at the offset `to`.\n     * Only records within this range are returned.\n     * This respects the query order and if there is no order clause the range could behave unexpectedly.\n     * The `from` and `to` values are 0-based and inclusive: `range(1, 3)` will include the second, third\n     * and fourth rows of the query.\n     *\n     * @param from - The starting index from which to limit the result\n     * @param to - The last index to which to limit the result\n     * @param options - Named parameters\n     * @param options.referencedTable - Set this to limit rows of referenced\n     * tables instead of the parent table\n     * @param options.foreignTable - Deprecated, use `options.referencedTable`\n     * instead\n     */\n    range(from, to, { foreignTable, referencedTable = foreignTable, } = {}) {\n        const keyOffset = typeof referencedTable === 'undefined' ? 'offset' : `${referencedTable}.offset`;\n        const keyLimit = typeof referencedTable === 'undefined' ? 'limit' : `${referencedTable}.limit`;\n        this.url.searchParams.set(keyOffset, `${from}`);\n        // Range is inclusive, so add 1\n        this.url.searchParams.set(keyLimit, `${to - from + 1}`);\n        return this;\n    }\n    /**\n     * Set the AbortSignal for the fetch request.\n     *\n     * @param signal - The AbortSignal to use for the fetch request\n     */\n    abortSignal(signal) {\n        this.signal = signal;\n        return this;\n    }\n    /**\n     * Return `data` as a single object instead of an array of objects.\n     *\n     * Query result must be one row (e.g. using `.limit(1)`), otherwise this\n     * returns an error.\n     */\n    single() {\n        this.headers['Accept'] = 'application/vnd.pgrst.object+json';\n        return this;\n    }\n    /**\n     * Return `data` as a single object instead of an array of objects.\n     *\n     * Query result must be zero or one row (e.g. using `.limit(1)`), otherwise\n     * this returns an error.\n     */\n    maybeSingle() {\n        // Temporary partial fix for https://github.com/supabase/postgrest-js/issues/361\n        // Issue persists e.g. for `.insert([...]).select().maybeSingle()`\n        if (this.method === 'GET') {\n            this.headers['Accept'] = 'application/json';\n        }\n        else {\n            this.headers['Accept'] = 'application/vnd.pgrst.object+json';\n        }\n        this.isMaybeSingle = true;\n        return this;\n    }\n    /**\n     * Return `data` as a string in CSV format.\n     */\n    csv() {\n        this.headers['Accept'] = 'text/csv';\n        return this;\n    }\n    /**\n     * Return `data` as an object in [GeoJSON](https://geojson.org) format.\n     */\n    geojson() {\n        this.headers['Accept'] = 'application/geo+json';\n        return this;\n    }\n    /**\n     * Return `data` as the EXPLAIN plan for the query.\n     *\n     * You need to enable the\n     * [db_plan_enabled](https://supabase.com/docs/guides/database/debugging-performance#enabling-explain)\n     * setting before using this method.\n     *\n     * @param options - Named parameters\n     *\n     * @param options.analyze - If `true`, the query will be executed and the\n     * actual run time will be returned\n     *\n     * @param options.verbose - If `true`, the query identifier will be returned\n     * and `data` will include the output columns of the query\n     *\n     * @param options.settings - If `true`, include information on configuration\n     * parameters that affect query planning\n     *\n     * @param options.buffers - If `true`, include information on buffer usage\n     *\n     * @param options.wal - If `true`, include information on WAL record generation\n     *\n     * @param options.format - The format of the output, can be `\"text\"` (default)\n     * or `\"json\"`\n     */\n    explain({ analyze = false, verbose = false, settings = false, buffers = false, wal = false, format = 'text', } = {}) {\n        var _a;\n        const options = [\n            analyze ? 'analyze' : null,\n            verbose ? 'verbose' : null,\n            settings ? 'settings' : null,\n            buffers ? 'buffers' : null,\n            wal ? 'wal' : null,\n        ]\n            .filter(Boolean)\n            .join('|');\n        // An Accept header can carry multiple media types but postgrest-js always sends one\n        const forMediatype = (_a = this.headers['Accept']) !== null && _a !== void 0 ? _a : 'application/json';\n        this.headers['Accept'] = `application/vnd.pgrst.plan+${format}; for=\"${forMediatype}\"; options=${options};`;\n        if (format === 'json')\n            return this;\n        else\n            return this;\n    }\n    /**\n     * Rollback the query.\n     *\n     * `data` will still be returned, but the query is not committed.\n     */\n    rollback() {\n        var _a;\n        if (((_a = this.headers['Prefer']) !== null && _a !== void 0 ? _a : '').trim().length > 0) {\n            this.headers['Prefer'] += ',tx=rollback';\n        }\n        else {\n            this.headers['Prefer'] = 'tx=rollback';\n        }\n        return this;\n    }\n    /**\n     * Override the type of the returned `data`.\n     *\n     * @typeParam NewResult - The new result type to override with\n     */\n    returns() {\n        return this;\n    }\n}\nexports[\"default\"] = PostgrestTransformBuilder;\n//# sourceMappingURL=PostgrestTransformBuilder.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestTransformBuilder.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/constants.js":
/*!*******************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/constants.js ***!
  \*******************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.DEFAULT_HEADERS = void 0;\nconst version_1 = __webpack_require__(/*! ./version */ \"./node_modules/@supabase/postgrest-js/dist/cjs/version.js\");\nexports.DEFAULT_HEADERS = { 'X-Client-Info': `postgrest-js/${version_1.version}` };\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/constants.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/index.js ***!
  \***************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.PostgrestBuilder = exports.PostgrestTransformBuilder = exports.PostgrestFilterBuilder = exports.PostgrestQueryBuilder = exports.PostgrestClient = void 0;\n// Always update wrapper.mjs when updating this file.\nconst PostgrestClient_1 = __importDefault(__webpack_require__(/*! ./PostgrestClient */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestClient.js\"));\nexports.PostgrestClient = PostgrestClient_1.default;\nconst PostgrestQueryBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestQueryBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestQueryBuilder.js\"));\nexports.PostgrestQueryBuilder = PostgrestQueryBuilder_1.default;\nconst PostgrestFilterBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestFilterBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestFilterBuilder.js\"));\nexports.PostgrestFilterBuilder = PostgrestFilterBuilder_1.default;\nconst PostgrestTransformBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestTransformBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestTransformBuilder.js\"));\nexports.PostgrestTransformBuilder = PostgrestTransformBuilder_1.default;\nconst PostgrestBuilder_1 = __importDefault(__webpack_require__(/*! ./PostgrestBuilder */ \"./node_modules/@supabase/postgrest-js/dist/cjs/PostgrestBuilder.js\"));\nexports.PostgrestBuilder = PostgrestBuilder_1.default;\nexports[\"default\"] = {\n    PostgrestClient: PostgrestClient_1.default,\n    PostgrestQueryBuilder: PostgrestQueryBuilder_1.default,\n    PostgrestFilterBuilder: PostgrestFilterBuilder_1.default,\n    PostgrestTransformBuilder: PostgrestTransformBuilder_1.default,\n    PostgrestBuilder: PostgrestBuilder_1.default,\n};\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/index.js?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/cjs/version.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/cjs/version.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.version = void 0;\nexports.version = '0.0.0-automated';\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/cjs/version.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/RealtimeChannel.js":
/*!***************************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/RealtimeChannel.js ***!
  \***************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   REALTIME_CHANNEL_STATES: () => (/* binding */ REALTIME_CHANNEL_STATES),\n/* harmony export */   REALTIME_LISTEN_TYPES: () => (/* binding */ REALTIME_LISTEN_TYPES),\n/* harmony export */   REALTIME_POSTGRES_CHANGES_LISTEN_EVENT: () => (/* binding */ REALTIME_POSTGRES_CHANGES_LISTEN_EVENT),\n/* harmony export */   REALTIME_SUBSCRIBE_STATES: () => (/* binding */ REALTIME_SUBSCRIBE_STATES),\n/* harmony export */   \"default\": () => (/* binding */ RealtimeChannel)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/constants */ \"./node_modules/@supabase/realtime-js/dist/module/lib/constants.js\");\n/* harmony import */ var _lib_push__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/push */ \"./node_modules/@supabase/realtime-js/dist/module/lib/push.js\");\n/* harmony import */ var _lib_timer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/timer */ \"./node_modules/@supabase/realtime-js/dist/module/lib/timer.js\");\n/* harmony import */ var _RealtimePresence__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./RealtimePresence */ \"./node_modules/@supabase/realtime-js/dist/module/RealtimePresence.js\");\n/* harmony import */ var _lib_transformers__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/transformers */ \"./node_modules/@supabase/realtime-js/dist/module/lib/transformers.js\");\n\n\n\n\n\n\nvar REALTIME_POSTGRES_CHANGES_LISTEN_EVENT;\n(function (REALTIME_POSTGRES_CHANGES_LISTEN_EVENT) {\n    REALTIME_POSTGRES_CHANGES_LISTEN_EVENT[\"ALL\"] = \"*\";\n    REALTIME_POSTGRES_CHANGES_LISTEN_EVENT[\"INSERT\"] = \"INSERT\";\n    REALTIME_POSTGRES_CHANGES_LISTEN_EVENT[\"UPDATE\"] = \"UPDATE\";\n    REALTIME_POSTGRES_CHANGES_LISTEN_EVENT[\"DELETE\"] = \"DELETE\";\n})(REALTIME_POSTGRES_CHANGES_LISTEN_EVENT || (REALTIME_POSTGRES_CHANGES_LISTEN_EVENT = {}));\nvar REALTIME_LISTEN_TYPES;\n(function (REALTIME_LISTEN_TYPES) {\n    REALTIME_LISTEN_TYPES[\"BROADCAST\"] = \"broadcast\";\n    REALTIME_LISTEN_TYPES[\"PRESENCE\"] = \"presence\";\n    /**\n     * listen to Postgres changes.\n     */\n    REALTIME_LISTEN_TYPES[\"POSTGRES_CHANGES\"] = \"postgres_changes\";\n})(REALTIME_LISTEN_TYPES || (REALTIME_LISTEN_TYPES = {}));\nvar REALTIME_SUBSCRIBE_STATES;\n(function (REALTIME_SUBSCRIBE_STATES) {\n    REALTIME_SUBSCRIBE_STATES[\"SUBSCRIBED\"] = \"SUBSCRIBED\";\n    REALTIME_SUBSCRIBE_STATES[\"TIMED_OUT\"] = \"TIMED_OUT\";\n    REALTIME_SUBSCRIBE_STATES[\"CLOSED\"] = \"CLOSED\";\n    REALTIME_SUBSCRIBE_STATES[\"CHANNEL_ERROR\"] = \"CHANNEL_ERROR\";\n})(REALTIME_SUBSCRIBE_STATES || (REALTIME_SUBSCRIBE_STATES = {}));\nconst REALTIME_CHANNEL_STATES = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES;\n/** A channel is the basic building block of Realtime\n * and narrows the scope of data flow to subscribed clients.\n * You can think of a channel as a chatroom where participants are able to see who's online\n * and send and receive messages.\n */\nclass RealtimeChannel {\n    constructor(\n    /** Topic name can be any string. */\n    topic, params = { config: {} }, socket) {\n        this.topic = topic;\n        this.params = params;\n        this.socket = socket;\n        this.bindings = {};\n        this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.closed;\n        this.joinedOnce = false;\n        this.pushBuffer = [];\n        this.subTopic = topic.replace(/^realtime:/i, '');\n        this.params.config = Object.assign({\n            broadcast: { ack: false, self: false },\n            presence: { key: '' },\n            private: false,\n        }, params.config);\n        this.timeout = this.socket.timeout;\n        this.joinPush = new _lib_push__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this, _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.join, this.params, this.timeout);\n        this.rejoinTimer = new _lib_timer__WEBPACK_IMPORTED_MODULE_2__[\"default\"](() => this._rejoinUntilConnected(), this.socket.reconnectAfterMs);\n        this.joinPush.receive('ok', () => {\n            this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.joined;\n            this.rejoinTimer.reset();\n            this.pushBuffer.forEach((pushEvent) => pushEvent.send());\n            this.pushBuffer = [];\n        });\n        this._onClose(() => {\n            this.rejoinTimer.reset();\n            this.socket.log('channel', `close ${this.topic} ${this._joinRef()}`);\n            this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.closed;\n            this.socket._remove(this);\n        });\n        this._onError((reason) => {\n            if (this._isLeaving() || this._isClosed()) {\n                return;\n            }\n            this.socket.log('channel', `error ${this.topic}`, reason);\n            this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.errored;\n            this.rejoinTimer.scheduleTimeout();\n        });\n        this.joinPush.receive('timeout', () => {\n            if (!this._isJoining()) {\n                return;\n            }\n            this.socket.log('channel', `timeout ${this.topic}`, this.joinPush.timeout);\n            this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.errored;\n            this.rejoinTimer.scheduleTimeout();\n        });\n        this._on(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.reply, {}, (payload, ref) => {\n            this._trigger(this._replyEventName(ref), payload);\n        });\n        this.presence = new _RealtimePresence__WEBPACK_IMPORTED_MODULE_3__[\"default\"](this);\n        this.broadcastEndpointURL =\n            (0,_lib_transformers__WEBPACK_IMPORTED_MODULE_4__.httpEndpointURL)(this.socket.endPoint) + '/api/broadcast';\n    }\n    /** Subscribe registers your client with the server */\n    subscribe(callback, timeout = this.timeout) {\n        var _a, _b;\n        if (!this.socket.isConnected()) {\n            this.socket.connect();\n        }\n        if (this.joinedOnce) {\n            throw `tried to subscribe multiple times. 'subscribe' can only be called a single time per channel instance`;\n        }\n        else {\n            const { config: { broadcast, presence, private: isPrivate }, } = this.params;\n            this._onError((e) => callback && callback('CHANNEL_ERROR', e));\n            this._onClose(() => callback && callback('CLOSED'));\n            const accessTokenPayload = {};\n            const config = {\n                broadcast,\n                presence,\n                postgres_changes: (_b = (_a = this.bindings.postgres_changes) === null || _a === void 0 ? void 0 : _a.map((r) => r.filter)) !== null && _b !== void 0 ? _b : [],\n                private: isPrivate,\n            };\n            if (this.socket.accessToken) {\n                accessTokenPayload.access_token = this.socket.accessToken;\n            }\n            this.updateJoinPayload(Object.assign({ config }, accessTokenPayload));\n            this.joinedOnce = true;\n            this._rejoin(timeout);\n            this.joinPush\n                .receive('ok', ({ postgres_changes: serverPostgresFilters, }) => {\n                var _a;\n                this.socket.accessToken &&\n                    this.socket.setAuth(this.socket.accessToken);\n                if (serverPostgresFilters === undefined) {\n                    callback && callback('SUBSCRIBED');\n                    return;\n                }\n                else {\n                    const clientPostgresBindings = this.bindings.postgres_changes;\n                    const bindingsLen = (_a = clientPostgresBindings === null || clientPostgresBindings === void 0 ? void 0 : clientPostgresBindings.length) !== null && _a !== void 0 ? _a : 0;\n                    const newPostgresBindings = [];\n                    for (let i = 0; i < bindingsLen; i++) {\n                        const clientPostgresBinding = clientPostgresBindings[i];\n                        const { filter: { event, schema, table, filter }, } = clientPostgresBinding;\n                        const serverPostgresFilter = serverPostgresFilters && serverPostgresFilters[i];\n                        if (serverPostgresFilter &&\n                            serverPostgresFilter.event === event &&\n                            serverPostgresFilter.schema === schema &&\n                            serverPostgresFilter.table === table &&\n                            serverPostgresFilter.filter === filter) {\n                            newPostgresBindings.push(Object.assign(Object.assign({}, clientPostgresBinding), { id: serverPostgresFilter.id }));\n                        }\n                        else {\n                            this.unsubscribe();\n                            callback &&\n                                callback('CHANNEL_ERROR', new Error('mismatch between server and client bindings for postgres changes'));\n                            return;\n                        }\n                    }\n                    this.bindings.postgres_changes = newPostgresBindings;\n                    callback && callback('SUBSCRIBED');\n                    return;\n                }\n            })\n                .receive('error', (error) => {\n                callback &&\n                    callback('CHANNEL_ERROR', new Error(JSON.stringify(Object.values(error).join(', ') || 'error')));\n                return;\n            })\n                .receive('timeout', () => {\n                callback && callback('TIMED_OUT');\n                return;\n            });\n        }\n        return this;\n    }\n    presenceState() {\n        return this.presence.state;\n    }\n    async track(payload, opts = {}) {\n        return await this.send({\n            type: 'presence',\n            event: 'track',\n            payload,\n        }, opts.timeout || this.timeout);\n    }\n    async untrack(opts = {}) {\n        return await this.send({\n            type: 'presence',\n            event: 'untrack',\n        }, opts);\n    }\n    on(type, filter, callback) {\n        return this._on(type, filter, callback);\n    }\n    /**\n     * Sends a message into the channel.\n     *\n     * @param args Arguments to send to channel\n     * @param args.type The type of event to send\n     * @param args.event The name of the event being sent\n     * @param args.payload Payload to be sent\n     * @param opts Options to be used during the send process\n     */\n    async send(args, opts = {}) {\n        var _a, _b;\n        if (!this._canPush() && args.type === 'broadcast') {\n            const { event, payload: endpoint_payload } = args;\n            const options = {\n                method: 'POST',\n                headers: {\n                    Authorization: this.socket.accessToken\n                        ? `Bearer ${this.socket.accessToken}`\n                        : '',\n                    apikey: this.socket.apiKey ? this.socket.apiKey : '',\n                    'Content-Type': 'application/json',\n                },\n                body: JSON.stringify({\n                    messages: [\n                        { topic: this.subTopic, event, payload: endpoint_payload },\n                    ],\n                }),\n            };\n            try {\n                const response = await this._fetchWithTimeout(this.broadcastEndpointURL, options, (_a = opts.timeout) !== null && _a !== void 0 ? _a : this.timeout);\n                await ((_b = response.body) === null || _b === void 0 ? void 0 : _b.cancel());\n                return response.ok ? 'ok' : 'error';\n            }\n            catch (error) {\n                if (error.name === 'AbortError') {\n                    return 'timed out';\n                }\n                else {\n                    return 'error';\n                }\n            }\n        }\n        else {\n            return new Promise((resolve) => {\n                var _a, _b, _c;\n                const push = this._push(args.type, args, opts.timeout || this.timeout);\n                if (args.type === 'broadcast' && !((_c = (_b = (_a = this.params) === null || _a === void 0 ? void 0 : _a.config) === null || _b === void 0 ? void 0 : _b.broadcast) === null || _c === void 0 ? void 0 : _c.ack)) {\n                    resolve('ok');\n                }\n                push.receive('ok', () => resolve('ok'));\n                push.receive('error', () => resolve('error'));\n                push.receive('timeout', () => resolve('timed out'));\n            });\n        }\n    }\n    updateJoinPayload(payload) {\n        this.joinPush.updatePayload(payload);\n    }\n    /**\n     * Leaves the channel.\n     *\n     * Unsubscribes from server events, and instructs channel to terminate on server.\n     * Triggers onClose() hooks.\n     *\n     * To receive leave acknowledgements, use the a `receive` hook to bind to the server ack, ie:\n     * channel.unsubscribe().receive(\"ok\", () => alert(\"left!\") )\n     */\n    unsubscribe(timeout = this.timeout) {\n        this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.leaving;\n        const onClose = () => {\n            this.socket.log('channel', `leave ${this.topic}`);\n            this._trigger(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.close, 'leave', this._joinRef());\n        };\n        this.rejoinTimer.reset();\n        // Destroy joinPush to avoid connection timeouts during unscription phase\n        this.joinPush.destroy();\n        return new Promise((resolve) => {\n            const leavePush = new _lib_push__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this, _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.leave, {}, timeout);\n            leavePush\n                .receive('ok', () => {\n                onClose();\n                resolve('ok');\n            })\n                .receive('timeout', () => {\n                onClose();\n                resolve('timed out');\n            })\n                .receive('error', () => {\n                resolve('error');\n            });\n            leavePush.send();\n            if (!this._canPush()) {\n                leavePush.trigger('ok', {});\n            }\n        });\n    }\n    /** @internal */\n    async _fetchWithTimeout(url, options, timeout) {\n        const controller = new AbortController();\n        const id = setTimeout(() => controller.abort(), timeout);\n        const response = await this.socket.fetch(url, Object.assign(Object.assign({}, options), { signal: controller.signal }));\n        clearTimeout(id);\n        return response;\n    }\n    /** @internal */\n    _push(event, payload, timeout = this.timeout) {\n        if (!this.joinedOnce) {\n            throw `tried to push '${event}' to '${this.topic}' before joining. Use channel.subscribe() before pushing events`;\n        }\n        let pushEvent = new _lib_push__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this, event, payload, timeout);\n        if (this._canPush()) {\n            pushEvent.send();\n        }\n        else {\n            pushEvent.startTimeout();\n            this.pushBuffer.push(pushEvent);\n        }\n        return pushEvent;\n    }\n    /**\n     * Overridable message hook\n     *\n     * Receives all events for specialized message handling before dispatching to the channel callbacks.\n     * Must return the payload, modified or unmodified.\n     *\n     * @internal\n     */\n    _onMessage(_event, payload, _ref) {\n        return payload;\n    }\n    /** @internal */\n    _isMember(topic) {\n        return this.topic === topic;\n    }\n    /** @internal */\n    _joinRef() {\n        return this.joinPush.ref;\n    }\n    /** @internal */\n    _trigger(type, payload, ref) {\n        var _a, _b;\n        const typeLower = type.toLocaleLowerCase();\n        const { close, error, leave, join } = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS;\n        const events = [close, error, leave, join];\n        if (ref && events.indexOf(typeLower) >= 0 && ref !== this._joinRef()) {\n            return;\n        }\n        let handledPayload = this._onMessage(typeLower, payload, ref);\n        if (payload && !handledPayload) {\n            throw 'channel onMessage callbacks must return the payload, modified or unmodified';\n        }\n        if (['insert', 'update', 'delete'].includes(typeLower)) {\n            (_a = this.bindings.postgres_changes) === null || _a === void 0 ? void 0 : _a.filter((bind) => {\n                var _a, _b, _c;\n                return (((_a = bind.filter) === null || _a === void 0 ? void 0 : _a.event) === '*' ||\n                    ((_c = (_b = bind.filter) === null || _b === void 0 ? void 0 : _b.event) === null || _c === void 0 ? void 0 : _c.toLocaleLowerCase()) === typeLower);\n            }).map((bind) => bind.callback(handledPayload, ref));\n        }\n        else {\n            (_b = this.bindings[typeLower]) === null || _b === void 0 ? void 0 : _b.filter((bind) => {\n                var _a, _b, _c, _d, _e, _f;\n                if (['broadcast', 'presence', 'postgres_changes'].includes(typeLower)) {\n                    if ('id' in bind) {\n                        const bindId = bind.id;\n                        const bindEvent = (_a = bind.filter) === null || _a === void 0 ? void 0 : _a.event;\n                        return (bindId &&\n                            ((_b = payload.ids) === null || _b === void 0 ? void 0 : _b.includes(bindId)) &&\n                            (bindEvent === '*' ||\n                                (bindEvent === null || bindEvent === void 0 ? void 0 : bindEvent.toLocaleLowerCase()) ===\n                                    ((_c = payload.data) === null || _c === void 0 ? void 0 : _c.type.toLocaleLowerCase())));\n                    }\n                    else {\n                        const bindEvent = (_e = (_d = bind === null || bind === void 0 ? void 0 : bind.filter) === null || _d === void 0 ? void 0 : _d.event) === null || _e === void 0 ? void 0 : _e.toLocaleLowerCase();\n                        return (bindEvent === '*' ||\n                            bindEvent === ((_f = payload === null || payload === void 0 ? void 0 : payload.event) === null || _f === void 0 ? void 0 : _f.toLocaleLowerCase()));\n                    }\n                }\n                else {\n                    return bind.type.toLocaleLowerCase() === typeLower;\n                }\n            }).map((bind) => {\n                if (typeof handledPayload === 'object' && 'ids' in handledPayload) {\n                    const postgresChanges = handledPayload.data;\n                    const { schema, table, commit_timestamp, type, errors } = postgresChanges;\n                    const enrichedPayload = {\n                        schema: schema,\n                        table: table,\n                        commit_timestamp: commit_timestamp,\n                        eventType: type,\n                        new: {},\n                        old: {},\n                        errors: errors,\n                    };\n                    handledPayload = Object.assign(Object.assign({}, enrichedPayload), this._getPayloadRecords(postgresChanges));\n                }\n                bind.callback(handledPayload, ref);\n            });\n        }\n    }\n    /** @internal */\n    _isClosed() {\n        return this.state === _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.closed;\n    }\n    /** @internal */\n    _isJoined() {\n        return this.state === _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.joined;\n    }\n    /** @internal */\n    _isJoining() {\n        return this.state === _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.joining;\n    }\n    /** @internal */\n    _isLeaving() {\n        return this.state === _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.leaving;\n    }\n    /** @internal */\n    _replyEventName(ref) {\n        return `chan_reply_${ref}`;\n    }\n    /** @internal */\n    _on(type, filter, callback) {\n        const typeLower = type.toLocaleLowerCase();\n        const binding = {\n            type: typeLower,\n            filter: filter,\n            callback: callback,\n        };\n        if (this.bindings[typeLower]) {\n            this.bindings[typeLower].push(binding);\n        }\n        else {\n            this.bindings[typeLower] = [binding];\n        }\n        return this;\n    }\n    /** @internal */\n    _off(type, filter) {\n        const typeLower = type.toLocaleLowerCase();\n        this.bindings[typeLower] = this.bindings[typeLower].filter((bind) => {\n            var _a;\n            return !(((_a = bind.type) === null || _a === void 0 ? void 0 : _a.toLocaleLowerCase()) === typeLower &&\n                RealtimeChannel.isEqual(bind.filter, filter));\n        });\n        return this;\n    }\n    /** @internal */\n    static isEqual(obj1, obj2) {\n        if (Object.keys(obj1).length !== Object.keys(obj2).length) {\n            return false;\n        }\n        for (const k in obj1) {\n            if (obj1[k] !== obj2[k]) {\n                return false;\n            }\n        }\n        return true;\n    }\n    /** @internal */\n    _rejoinUntilConnected() {\n        this.rejoinTimer.scheduleTimeout();\n        if (this.socket.isConnected()) {\n            this._rejoin();\n        }\n    }\n    /**\n     * Registers a callback that will be executed when the channel closes.\n     *\n     * @internal\n     */\n    _onClose(callback) {\n        this._on(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.close, {}, callback);\n    }\n    /**\n     * Registers a callback that will be executed when the channel encounteres an error.\n     *\n     * @internal\n     */\n    _onError(callback) {\n        this._on(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.error, {}, (reason) => callback(reason));\n    }\n    /**\n     * Returns `true` if the socket is connected and the channel has been joined.\n     *\n     * @internal\n     */\n    _canPush() {\n        return this.socket.isConnected() && this._isJoined();\n    }\n    /** @internal */\n    _rejoin(timeout = this.timeout) {\n        if (this._isLeaving()) {\n            return;\n        }\n        this.socket._leaveOpenTopic(this.topic);\n        this.state = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_STATES.joining;\n        this.joinPush.resend(timeout);\n    }\n    /** @internal */\n    _getPayloadRecords(payload) {\n        const records = {\n            new: {},\n            old: {},\n        };\n        if (payload.type === 'INSERT' || payload.type === 'UPDATE') {\n            records.new = _lib_transformers__WEBPACK_IMPORTED_MODULE_4__.convertChangeData(payload.columns, payload.record);\n        }\n        if (payload.type === 'UPDATE' || payload.type === 'DELETE') {\n            records.old = _lib_transformers__WEBPACK_IMPORTED_MODULE_4__.convertChangeData(payload.columns, payload.old_record);\n        }\n        return records;\n    }\n}\n//# sourceMappingURL=RealtimeChannel.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/RealtimeChannel.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/RealtimeClient.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/RealtimeClient.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ RealtimeClient)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./lib/constants */ \"./node_modules/@supabase/realtime-js/dist/module/lib/constants.js\");\n/* harmony import */ var _lib_serializer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./lib/serializer */ \"./node_modules/@supabase/realtime-js/dist/module/lib/serializer.js\");\n/* harmony import */ var _lib_timer__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/timer */ \"./node_modules/@supabase/realtime-js/dist/module/lib/timer.js\");\n/* harmony import */ var _lib_transformers__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/transformers */ \"./node_modules/@supabase/realtime-js/dist/module/lib/transformers.js\");\n/* harmony import */ var _RealtimeChannel__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./RealtimeChannel */ \"./node_modules/@supabase/realtime-js/dist/module/RealtimeChannel.js\");\n\n\n\n\n\nconst noop = () => { };\nconst NATIVE_WEBSOCKET_AVAILABLE = typeof WebSocket !== 'undefined';\nclass RealtimeClient {\n    /**\n     * Initializes the Socket.\n     *\n     * @param endPoint The string WebSocket endpoint, ie, \"ws://example.com/socket\", \"wss://example.com\", \"/socket\" (inherited host & protocol)\n     * @param httpEndpoint The string HTTP endpoint, ie, \"https://example.com\", \"/\" (inherited host & protocol)\n     * @param options.transport The Websocket Transport, for example WebSocket.\n     * @param options.timeout The default timeout in milliseconds to trigger push timeouts.\n     * @param options.params The optional params to pass when connecting.\n     * @param options.headers The optional headers to pass when connecting.\n     * @param options.heartbeatIntervalMs The millisec interval to send a heartbeat message.\n     * @param options.logger The optional function for specialized logging, ie: logger: (kind, msg, data) => { console.log(`${kind}: ${msg}`, data) }\n     * @param options.encode The function to encode outgoing messages. Defaults to JSON: (payload, callback) => callback(JSON.stringify(payload))\n     * @param options.decode The function to decode incoming messages. Defaults to Serializer's decode.\n     * @param options.reconnectAfterMs he optional function that returns the millsec reconnect interval. Defaults to stepped backoff off.\n     */\n    constructor(endPoint, options) {\n        var _a;\n        this.accessToken = null;\n        this.apiKey = null;\n        this.channels = [];\n        this.endPoint = '';\n        this.httpEndpoint = '';\n        this.headers = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.DEFAULT_HEADERS;\n        this.params = {};\n        this.timeout = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.DEFAULT_TIMEOUT;\n        this.heartbeatIntervalMs = 30000;\n        this.heartbeatTimer = undefined;\n        this.pendingHeartbeatRef = null;\n        this.ref = 0;\n        this.logger = noop;\n        this.conn = null;\n        this.sendBuffer = [];\n        this.serializer = new _lib_serializer__WEBPACK_IMPORTED_MODULE_1__[\"default\"]();\n        this.stateChangeCallbacks = {\n            open: [],\n            close: [],\n            error: [],\n            message: [],\n        };\n        /**\n         * Use either custom fetch, if provided, or default fetch to make HTTP requests\n         *\n         * @internal\n         */\n        this._resolveFetch = (customFetch) => {\n            let _fetch;\n            if (customFetch) {\n                _fetch = customFetch;\n            }\n            else if (typeof fetch === 'undefined') {\n                _fetch = (...args) => Promise.resolve(/*! import() */).then(__webpack_require__.bind(__webpack_require__, /*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\")).then(({ default: fetch }) => fetch(...args));\n            }\n            else {\n                _fetch = fetch;\n            }\n            return (...args) => _fetch(...args);\n        };\n        this.endPoint = `${endPoint}/${_lib_constants__WEBPACK_IMPORTED_MODULE_0__.TRANSPORTS.websocket}`;\n        this.httpEndpoint = (0,_lib_transformers__WEBPACK_IMPORTED_MODULE_3__.httpEndpointURL)(endPoint);\n        if (options === null || options === void 0 ? void 0 : options.transport) {\n            this.transport = options.transport;\n        }\n        else {\n            this.transport = null;\n        }\n        if (options === null || options === void 0 ? void 0 : options.params)\n            this.params = options.params;\n        if (options === null || options === void 0 ? void 0 : options.headers)\n            this.headers = Object.assign(Object.assign({}, this.headers), options.headers);\n        if (options === null || options === void 0 ? void 0 : options.timeout)\n            this.timeout = options.timeout;\n        if (options === null || options === void 0 ? void 0 : options.logger)\n            this.logger = options.logger;\n        if (options === null || options === void 0 ? void 0 : options.heartbeatIntervalMs)\n            this.heartbeatIntervalMs = options.heartbeatIntervalMs;\n        const accessToken = (_a = options === null || options === void 0 ? void 0 : options.params) === null || _a === void 0 ? void 0 : _a.apikey;\n        if (accessToken) {\n            this.accessToken = accessToken;\n            this.apiKey = accessToken;\n        }\n        this.reconnectAfterMs = (options === null || options === void 0 ? void 0 : options.reconnectAfterMs)\n            ? options.reconnectAfterMs\n            : (tries) => {\n                return [1000, 2000, 5000, 10000][tries - 1] || 10000;\n            };\n        this.encode = (options === null || options === void 0 ? void 0 : options.encode)\n            ? options.encode\n            : (payload, callback) => {\n                return callback(JSON.stringify(payload));\n            };\n        this.decode = (options === null || options === void 0 ? void 0 : options.decode)\n            ? options.decode\n            : this.serializer.decode.bind(this.serializer);\n        this.reconnectTimer = new _lib_timer__WEBPACK_IMPORTED_MODULE_2__[\"default\"](async () => {\n            this.disconnect();\n            this.connect();\n        }, this.reconnectAfterMs);\n        this.fetch = this._resolveFetch(options === null || options === void 0 ? void 0 : options.fetch);\n    }\n    /**\n     * Connects the socket, unless already connected.\n     */\n    connect() {\n        if (this.conn) {\n            return;\n        }\n        if (this.transport) {\n            this.conn = new this.transport(this._endPointURL(), undefined, {\n                headers: this.headers,\n            });\n            return;\n        }\n        if (NATIVE_WEBSOCKET_AVAILABLE) {\n            this.conn = new WebSocket(this._endPointURL());\n            this.setupConnection();\n            return;\n        }\n        this.conn = new WSWebSocketDummy(this._endPointURL(), undefined, {\n            close: () => {\n                this.conn = null;\n            },\n        });\n        __webpack_require__.e(/*! import() */ \"node_modules_ws_browser_js\").then(__webpack_require__.t.bind(__webpack_require__, /*! ws */ \"./node_modules/ws/browser.js\", 23)).then(({ default: WS }) => {\n            this.conn = new WS(this._endPointURL(), undefined, {\n                headers: this.headers,\n            });\n            this.setupConnection();\n        });\n    }\n    /**\n     * Disconnects the socket.\n     *\n     * @param code A numeric status code to send on disconnect.\n     * @param reason A custom reason for the disconnect.\n     */\n    disconnect(code, reason) {\n        if (this.conn) {\n            this.conn.onclose = function () { }; // noop\n            if (code) {\n                this.conn.close(code, reason !== null && reason !== void 0 ? reason : '');\n            }\n            else {\n                this.conn.close();\n            }\n            this.conn = null;\n            // remove open handles\n            this.heartbeatTimer && clearInterval(this.heartbeatTimer);\n            this.reconnectTimer.reset();\n        }\n    }\n    /**\n     * Returns all created channels\n     */\n    getChannels() {\n        return this.channels;\n    }\n    /**\n     * Unsubscribes and removes a single channel\n     * @param channel A RealtimeChannel instance\n     */\n    async removeChannel(channel) {\n        const status = await channel.unsubscribe();\n        if (this.channels.length === 0) {\n            this.disconnect();\n        }\n        return status;\n    }\n    /**\n     * Unsubscribes and removes all channels\n     */\n    async removeAllChannels() {\n        const values_1 = await Promise.all(this.channels.map((channel) => channel.unsubscribe()));\n        this.disconnect();\n        return values_1;\n    }\n    /**\n     * Logs the message.\n     *\n     * For customized logging, `this.logger` can be overridden.\n     */\n    log(kind, msg, data) {\n        this.logger(kind, msg, data);\n    }\n    /**\n     * Returns the current state of the socket.\n     */\n    connectionState() {\n        switch (this.conn && this.conn.readyState) {\n            case _lib_constants__WEBPACK_IMPORTED_MODULE_0__.SOCKET_STATES.connecting:\n                return _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_STATE.Connecting;\n            case _lib_constants__WEBPACK_IMPORTED_MODULE_0__.SOCKET_STATES.open:\n                return _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_STATE.Open;\n            case _lib_constants__WEBPACK_IMPORTED_MODULE_0__.SOCKET_STATES.closing:\n                return _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_STATE.Closing;\n            default:\n                return _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_STATE.Closed;\n        }\n    }\n    /**\n     * Returns `true` is the connection is open.\n     */\n    isConnected() {\n        return this.connectionState() === _lib_constants__WEBPACK_IMPORTED_MODULE_0__.CONNECTION_STATE.Open;\n    }\n    channel(topic, params = { config: {} }) {\n        const chan = new _RealtimeChannel__WEBPACK_IMPORTED_MODULE_4__[\"default\"](`realtime:${topic}`, params, this);\n        this.channels.push(chan);\n        return chan;\n    }\n    /**\n     * Push out a message if the socket is connected.\n     *\n     * If the socket is not connected, the message gets enqueued within a local buffer, and sent out when a connection is next established.\n     */\n    push(data) {\n        const { topic, event, payload, ref } = data;\n        const callback = () => {\n            this.encode(data, (result) => {\n                var _a;\n                (_a = this.conn) === null || _a === void 0 ? void 0 : _a.send(result);\n            });\n        };\n        this.log('push', `${topic} ${event} (${ref})`, payload);\n        if (this.isConnected()) {\n            callback();\n        }\n        else {\n            this.sendBuffer.push(callback);\n        }\n    }\n    /**\n     * Sets the JWT access token used for channel subscription authorization and Realtime RLS.\n     *\n     * @param token A JWT string.\n     */\n    setAuth(token) {\n        this.accessToken = token;\n        this.channels.forEach((channel) => {\n            token && channel.updateJoinPayload({ access_token: token });\n            if (channel.joinedOnce && channel._isJoined()) {\n                channel._push(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.access_token, { access_token: token });\n            }\n        });\n    }\n    /**\n     * Return the next message ref, accounting for overflows\n     *\n     * @internal\n     */\n    _makeRef() {\n        let newRef = this.ref + 1;\n        if (newRef === this.ref) {\n            this.ref = 0;\n        }\n        else {\n            this.ref = newRef;\n        }\n        return this.ref.toString();\n    }\n    /**\n     * Unsubscribe from channels with the specified topic.\n     *\n     * @internal\n     */\n    _leaveOpenTopic(topic) {\n        let dupChannel = this.channels.find((c) => c.topic === topic && (c._isJoined() || c._isJoining()));\n        if (dupChannel) {\n            this.log('transport', `leaving duplicate topic \"${topic}\"`);\n            dupChannel.unsubscribe();\n        }\n    }\n    /**\n     * Removes a subscription from the socket.\n     *\n     * @param channel An open subscription.\n     *\n     * @internal\n     */\n    _remove(channel) {\n        this.channels = this.channels.filter((c) => c._joinRef() !== channel._joinRef());\n    }\n    /**\n     * Sets up connection handlers.\n     *\n     * @internal\n     */\n    setupConnection() {\n        if (this.conn) {\n            this.conn.binaryType = 'arraybuffer';\n            this.conn.onopen = () => this._onConnOpen();\n            this.conn.onerror = (error) => this._onConnError(error);\n            this.conn.onmessage = (event) => this._onConnMessage(event);\n            this.conn.onclose = (event) => this._onConnClose(event);\n        }\n    }\n    /**\n     * Returns the URL of the websocket.\n     *\n     * @internal\n     */\n    _endPointURL() {\n        return this._appendParams(this.endPoint, Object.assign({}, this.params, { vsn: _lib_constants__WEBPACK_IMPORTED_MODULE_0__.VSN }));\n    }\n    /** @internal */\n    _onConnMessage(rawMessage) {\n        this.decode(rawMessage.data, (msg) => {\n            let { topic, event, payload, ref } = msg;\n            if ((ref && ref === this.pendingHeartbeatRef) ||\n                event === (payload === null || payload === void 0 ? void 0 : payload.type)) {\n                this.pendingHeartbeatRef = null;\n            }\n            this.log('receive', `${payload.status || ''} ${topic} ${event} ${(ref && '(' + ref + ')') || ''}`, payload);\n            this.channels\n                .filter((channel) => channel._isMember(topic))\n                .forEach((channel) => channel._trigger(event, payload, ref));\n            this.stateChangeCallbacks.message.forEach((callback) => callback(msg));\n        });\n    }\n    /** @internal */\n    _onConnOpen() {\n        this.log('transport', `connected to ${this._endPointURL()}`);\n        this._flushSendBuffer();\n        this.reconnectTimer.reset();\n        this.heartbeatTimer && clearInterval(this.heartbeatTimer);\n        this.heartbeatTimer = setInterval(() => this._sendHeartbeat(), this.heartbeatIntervalMs);\n        this.stateChangeCallbacks.open.forEach((callback) => callback());\n    }\n    /** @internal */\n    _onConnClose(event) {\n        this.log('transport', 'close', event);\n        this._triggerChanError();\n        this.heartbeatTimer && clearInterval(this.heartbeatTimer);\n        this.reconnectTimer.scheduleTimeout();\n        this.stateChangeCallbacks.close.forEach((callback) => callback(event));\n    }\n    /** @internal */\n    _onConnError(error) {\n        this.log('transport', error.message);\n        this._triggerChanError();\n        this.stateChangeCallbacks.error.forEach((callback) => callback(error));\n    }\n    /** @internal */\n    _triggerChanError() {\n        this.channels.forEach((channel) => channel._trigger(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.CHANNEL_EVENTS.error));\n    }\n    /** @internal */\n    _appendParams(url, params) {\n        if (Object.keys(params).length === 0) {\n            return url;\n        }\n        const prefix = url.match(/\\?/) ? '&' : '?';\n        const query = new URLSearchParams(params);\n        return `${url}${prefix}${query}`;\n    }\n    /** @internal */\n    _flushSendBuffer() {\n        if (this.isConnected() && this.sendBuffer.length > 0) {\n            this.sendBuffer.forEach((callback) => callback());\n            this.sendBuffer = [];\n        }\n    }\n    /** @internal */\n    _sendHeartbeat() {\n        var _a;\n        if (!this.isConnected()) {\n            return;\n        }\n        if (this.pendingHeartbeatRef) {\n            this.pendingHeartbeatRef = null;\n            this.log('transport', 'heartbeat timeout. Attempting to re-establish connection');\n            (_a = this.conn) === null || _a === void 0 ? void 0 : _a.close(_lib_constants__WEBPACK_IMPORTED_MODULE_0__.WS_CLOSE_NORMAL, 'hearbeat timeout');\n            return;\n        }\n        this.pendingHeartbeatRef = this._makeRef();\n        this.push({\n            topic: 'phoenix',\n            event: 'heartbeat',\n            payload: {},\n            ref: this.pendingHeartbeatRef,\n        });\n        this.setAuth(this.accessToken);\n    }\n}\nclass WSWebSocketDummy {\n    constructor(address, _protocols, options) {\n        this.binaryType = 'arraybuffer';\n        this.onclose = () => { };\n        this.onerror = () => { };\n        this.onmessage = () => { };\n        this.onopen = () => { };\n        this.readyState = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.SOCKET_STATES.connecting;\n        this.send = () => { };\n        this.url = null;\n        this.url = address;\n        this.close = options.close;\n    }\n}\n//# sourceMappingURL=RealtimeClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/RealtimeClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/RealtimePresence.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/RealtimePresence.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   REALTIME_PRESENCE_LISTEN_EVENTS: () => (/* binding */ REALTIME_PRESENCE_LISTEN_EVENTS),\n/* harmony export */   \"default\": () => (/* binding */ RealtimePresence)\n/* harmony export */ });\n/*\n  This file draws heavily from https://github.com/phoenixframework/phoenix/blob/d344ec0a732ab4ee204215b31de69cf4be72e3bf/assets/js/phoenix/presence.js\n  License: https://github.com/phoenixframework/phoenix/blob/d344ec0a732ab4ee204215b31de69cf4be72e3bf/LICENSE.md\n*/\nvar REALTIME_PRESENCE_LISTEN_EVENTS;\n(function (REALTIME_PRESENCE_LISTEN_EVENTS) {\n    REALTIME_PRESENCE_LISTEN_EVENTS[\"SYNC\"] = \"sync\";\n    REALTIME_PRESENCE_LISTEN_EVENTS[\"JOIN\"] = \"join\";\n    REALTIME_PRESENCE_LISTEN_EVENTS[\"LEAVE\"] = \"leave\";\n})(REALTIME_PRESENCE_LISTEN_EVENTS || (REALTIME_PRESENCE_LISTEN_EVENTS = {}));\nclass RealtimePresence {\n    /**\n     * Initializes the Presence.\n     *\n     * @param channel - The RealtimeChannel\n     * @param opts - The options,\n     *        for example `{events: {state: 'state', diff: 'diff'}}`\n     */\n    constructor(channel, opts) {\n        this.channel = channel;\n        this.state = {};\n        this.pendingDiffs = [];\n        this.joinRef = null;\n        this.caller = {\n            onJoin: () => { },\n            onLeave: () => { },\n            onSync: () => { },\n        };\n        const events = (opts === null || opts === void 0 ? void 0 : opts.events) || {\n            state: 'presence_state',\n            diff: 'presence_diff',\n        };\n        this.channel._on(events.state, {}, (newState) => {\n            const { onJoin, onLeave, onSync } = this.caller;\n            this.joinRef = this.channel._joinRef();\n            this.state = RealtimePresence.syncState(this.state, newState, onJoin, onLeave);\n            this.pendingDiffs.forEach((diff) => {\n                this.state = RealtimePresence.syncDiff(this.state, diff, onJoin, onLeave);\n            });\n            this.pendingDiffs = [];\n            onSync();\n        });\n        this.channel._on(events.diff, {}, (diff) => {\n            const { onJoin, onLeave, onSync } = this.caller;\n            if (this.inPendingSyncState()) {\n                this.pendingDiffs.push(diff);\n            }\n            else {\n                this.state = RealtimePresence.syncDiff(this.state, diff, onJoin, onLeave);\n                onSync();\n            }\n        });\n        this.onJoin((key, currentPresences, newPresences) => {\n            this.channel._trigger('presence', {\n                event: 'join',\n                key,\n                currentPresences,\n                newPresences,\n            });\n        });\n        this.onLeave((key, currentPresences, leftPresences) => {\n            this.channel._trigger('presence', {\n                event: 'leave',\n                key,\n                currentPresences,\n                leftPresences,\n            });\n        });\n        this.onSync(() => {\n            this.channel._trigger('presence', { event: 'sync' });\n        });\n    }\n    /**\n     * Used to sync the list of presences on the server with the\n     * client's state.\n     *\n     * An optional `onJoin` and `onLeave` callback can be provided to\n     * react to changes in the client's local presences across\n     * disconnects and reconnects with the server.\n     *\n     * @internal\n     */\n    static syncState(currentState, newState, onJoin, onLeave) {\n        const state = this.cloneDeep(currentState);\n        const transformedState = this.transformState(newState);\n        const joins = {};\n        const leaves = {};\n        this.map(state, (key, presences) => {\n            if (!transformedState[key]) {\n                leaves[key] = presences;\n            }\n        });\n        this.map(transformedState, (key, newPresences) => {\n            const currentPresences = state[key];\n            if (currentPresences) {\n                const newPresenceRefs = newPresences.map((m) => m.presence_ref);\n                const curPresenceRefs = currentPresences.map((m) => m.presence_ref);\n                const joinedPresences = newPresences.filter((m) => curPresenceRefs.indexOf(m.presence_ref) < 0);\n                const leftPresences = currentPresences.filter((m) => newPresenceRefs.indexOf(m.presence_ref) < 0);\n                if (joinedPresences.length > 0) {\n                    joins[key] = joinedPresences;\n                }\n                if (leftPresences.length > 0) {\n                    leaves[key] = leftPresences;\n                }\n            }\n            else {\n                joins[key] = newPresences;\n            }\n        });\n        return this.syncDiff(state, { joins, leaves }, onJoin, onLeave);\n    }\n    /**\n     * Used to sync a diff of presence join and leave events from the\n     * server, as they happen.\n     *\n     * Like `syncState`, `syncDiff` accepts optional `onJoin` and\n     * `onLeave` callbacks to react to a user joining or leaving from a\n     * device.\n     *\n     * @internal\n     */\n    static syncDiff(state, diff, onJoin, onLeave) {\n        const { joins, leaves } = {\n            joins: this.transformState(diff.joins),\n            leaves: this.transformState(diff.leaves),\n        };\n        if (!onJoin) {\n            onJoin = () => { };\n        }\n        if (!onLeave) {\n            onLeave = () => { };\n        }\n        this.map(joins, (key, newPresences) => {\n            var _a;\n            const currentPresences = (_a = state[key]) !== null && _a !== void 0 ? _a : [];\n            state[key] = this.cloneDeep(newPresences);\n            if (currentPresences.length > 0) {\n                const joinedPresenceRefs = state[key].map((m) => m.presence_ref);\n                const curPresences = currentPresences.filter((m) => joinedPresenceRefs.indexOf(m.presence_ref) < 0);\n                state[key].unshift(...curPresences);\n            }\n            onJoin(key, currentPresences, newPresences);\n        });\n        this.map(leaves, (key, leftPresences) => {\n            let currentPresences = state[key];\n            if (!currentPresences)\n                return;\n            const presenceRefsToRemove = leftPresences.map((m) => m.presence_ref);\n            currentPresences = currentPresences.filter((m) => presenceRefsToRemove.indexOf(m.presence_ref) < 0);\n            state[key] = currentPresences;\n            onLeave(key, currentPresences, leftPresences);\n            if (currentPresences.length === 0)\n                delete state[key];\n        });\n        return state;\n    }\n    /** @internal */\n    static map(obj, func) {\n        return Object.getOwnPropertyNames(obj).map((key) => func(key, obj[key]));\n    }\n    /**\n     * Remove 'metas' key\n     * Change 'phx_ref' to 'presence_ref'\n     * Remove 'phx_ref' and 'phx_ref_prev'\n     *\n     * @example\n     * // returns {\n     *  abc123: [\n     *    { presence_ref: '2', user_id: 1 },\n     *    { presence_ref: '3', user_id: 2 }\n     *  ]\n     * }\n     * RealtimePresence.transformState({\n     *  abc123: {\n     *    metas: [\n     *      { phx_ref: '2', phx_ref_prev: '1' user_id: 1 },\n     *      { phx_ref: '3', user_id: 2 }\n     *    ]\n     *  }\n     * })\n     *\n     * @internal\n     */\n    static transformState(state) {\n        state = this.cloneDeep(state);\n        return Object.getOwnPropertyNames(state).reduce((newState, key) => {\n            const presences = state[key];\n            if ('metas' in presences) {\n                newState[key] = presences.metas.map((presence) => {\n                    presence['presence_ref'] = presence['phx_ref'];\n                    delete presence['phx_ref'];\n                    delete presence['phx_ref_prev'];\n                    return presence;\n                });\n            }\n            else {\n                newState[key] = presences;\n            }\n            return newState;\n        }, {});\n    }\n    /** @internal */\n    static cloneDeep(obj) {\n        return JSON.parse(JSON.stringify(obj));\n    }\n    /** @internal */\n    onJoin(callback) {\n        this.caller.onJoin = callback;\n    }\n    /** @internal */\n    onLeave(callback) {\n        this.caller.onLeave = callback;\n    }\n    /** @internal */\n    onSync(callback) {\n        this.caller.onSync = callback;\n    }\n    /** @internal */\n    inPendingSyncState() {\n        return !this.joinRef || this.joinRef !== this.channel._joinRef();\n    }\n}\n//# sourceMappingURL=RealtimePresence.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/RealtimePresence.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/index.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   REALTIME_CHANNEL_STATES: () => (/* reexport safe */ _RealtimeChannel__WEBPACK_IMPORTED_MODULE_1__.REALTIME_CHANNEL_STATES),\n/* harmony export */   REALTIME_LISTEN_TYPES: () => (/* reexport safe */ _RealtimeChannel__WEBPACK_IMPORTED_MODULE_1__.REALTIME_LISTEN_TYPES),\n/* harmony export */   REALTIME_POSTGRES_CHANGES_LISTEN_EVENT: () => (/* reexport safe */ _RealtimeChannel__WEBPACK_IMPORTED_MODULE_1__.REALTIME_POSTGRES_CHANGES_LISTEN_EVENT),\n/* harmony export */   REALTIME_PRESENCE_LISTEN_EVENTS: () => (/* reexport safe */ _RealtimePresence__WEBPACK_IMPORTED_MODULE_2__.REALTIME_PRESENCE_LISTEN_EVENTS),\n/* harmony export */   REALTIME_SUBSCRIBE_STATES: () => (/* reexport safe */ _RealtimeChannel__WEBPACK_IMPORTED_MODULE_1__.REALTIME_SUBSCRIBE_STATES),\n/* harmony export */   RealtimeChannel: () => (/* reexport safe */ _RealtimeChannel__WEBPACK_IMPORTED_MODULE_1__[\"default\"]),\n/* harmony export */   RealtimeClient: () => (/* reexport safe */ _RealtimeClient__WEBPACK_IMPORTED_MODULE_0__[\"default\"]),\n/* harmony export */   RealtimePresence: () => (/* reexport safe */ _RealtimePresence__WEBPACK_IMPORTED_MODULE_2__[\"default\"])\n/* harmony export */ });\n/* harmony import */ var _RealtimeClient__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./RealtimeClient */ \"./node_modules/@supabase/realtime-js/dist/module/RealtimeClient.js\");\n/* harmony import */ var _RealtimeChannel__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./RealtimeChannel */ \"./node_modules/@supabase/realtime-js/dist/module/RealtimeChannel.js\");\n/* harmony import */ var _RealtimePresence__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./RealtimePresence */ \"./node_modules/@supabase/realtime-js/dist/module/RealtimePresence.js\");\n\n\n\n\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/index.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/lib/constants.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/lib/constants.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   CHANNEL_EVENTS: () => (/* binding */ CHANNEL_EVENTS),\n/* harmony export */   CHANNEL_STATES: () => (/* binding */ CHANNEL_STATES),\n/* harmony export */   CONNECTION_STATE: () => (/* binding */ CONNECTION_STATE),\n/* harmony export */   DEFAULT_HEADERS: () => (/* binding */ DEFAULT_HEADERS),\n/* harmony export */   DEFAULT_TIMEOUT: () => (/* binding */ DEFAULT_TIMEOUT),\n/* harmony export */   SOCKET_STATES: () => (/* binding */ SOCKET_STATES),\n/* harmony export */   TRANSPORTS: () => (/* binding */ TRANSPORTS),\n/* harmony export */   VSN: () => (/* binding */ VSN),\n/* harmony export */   WS_CLOSE_NORMAL: () => (/* binding */ WS_CLOSE_NORMAL)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./version */ \"./node_modules/@supabase/realtime-js/dist/module/lib/version.js\");\n\nconst DEFAULT_HEADERS = { 'X-Client-Info': `realtime-js/${_version__WEBPACK_IMPORTED_MODULE_0__.version}` };\nconst VSN = '1.0.0';\nconst DEFAULT_TIMEOUT = 10000;\nconst WS_CLOSE_NORMAL = 1000;\nvar SOCKET_STATES;\n(function (SOCKET_STATES) {\n    SOCKET_STATES[SOCKET_STATES[\"connecting\"] = 0] = \"connecting\";\n    SOCKET_STATES[SOCKET_STATES[\"open\"] = 1] = \"open\";\n    SOCKET_STATES[SOCKET_STATES[\"closing\"] = 2] = \"closing\";\n    SOCKET_STATES[SOCKET_STATES[\"closed\"] = 3] = \"closed\";\n})(SOCKET_STATES || (SOCKET_STATES = {}));\nvar CHANNEL_STATES;\n(function (CHANNEL_STATES) {\n    CHANNEL_STATES[\"closed\"] = \"closed\";\n    CHANNEL_STATES[\"errored\"] = \"errored\";\n    CHANNEL_STATES[\"joined\"] = \"joined\";\n    CHANNEL_STATES[\"joining\"] = \"joining\";\n    CHANNEL_STATES[\"leaving\"] = \"leaving\";\n})(CHANNEL_STATES || (CHANNEL_STATES = {}));\nvar CHANNEL_EVENTS;\n(function (CHANNEL_EVENTS) {\n    CHANNEL_EVENTS[\"close\"] = \"phx_close\";\n    CHANNEL_EVENTS[\"error\"] = \"phx_error\";\n    CHANNEL_EVENTS[\"join\"] = \"phx_join\";\n    CHANNEL_EVENTS[\"reply\"] = \"phx_reply\";\n    CHANNEL_EVENTS[\"leave\"] = \"phx_leave\";\n    CHANNEL_EVENTS[\"access_token\"] = \"access_token\";\n})(CHANNEL_EVENTS || (CHANNEL_EVENTS = {}));\nvar TRANSPORTS;\n(function (TRANSPORTS) {\n    TRANSPORTS[\"websocket\"] = \"websocket\";\n})(TRANSPORTS || (TRANSPORTS = {}));\nvar CONNECTION_STATE;\n(function (CONNECTION_STATE) {\n    CONNECTION_STATE[\"Connecting\"] = \"connecting\";\n    CONNECTION_STATE[\"Open\"] = \"open\";\n    CONNECTION_STATE[\"Closing\"] = \"closing\";\n    CONNECTION_STATE[\"Closed\"] = \"closed\";\n})(CONNECTION_STATE || (CONNECTION_STATE = {}));\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/lib/constants.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/lib/push.js":
/*!********************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/lib/push.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Push)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lib/constants */ \"./node_modules/@supabase/realtime-js/dist/module/lib/constants.js\");\n\nclass Push {\n    /**\n     * Initializes the Push\n     *\n     * @param channel The Channel\n     * @param event The event, for example `\"phx_join\"`\n     * @param payload The payload, for example `{user_id: 123}`\n     * @param timeout The push timeout in milliseconds\n     */\n    constructor(channel, event, payload = {}, timeout = _lib_constants__WEBPACK_IMPORTED_MODULE_0__.DEFAULT_TIMEOUT) {\n        this.channel = channel;\n        this.event = event;\n        this.payload = payload;\n        this.timeout = timeout;\n        this.sent = false;\n        this.timeoutTimer = undefined;\n        this.ref = '';\n        this.receivedResp = null;\n        this.recHooks = [];\n        this.refEvent = null;\n    }\n    resend(timeout) {\n        this.timeout = timeout;\n        this._cancelRefEvent();\n        this.ref = '';\n        this.refEvent = null;\n        this.receivedResp = null;\n        this.sent = false;\n        this.send();\n    }\n    send() {\n        if (this._hasReceived('timeout')) {\n            return;\n        }\n        this.startTimeout();\n        this.sent = true;\n        this.channel.socket.push({\n            topic: this.channel.topic,\n            event: this.event,\n            payload: this.payload,\n            ref: this.ref,\n            join_ref: this.channel._joinRef(),\n        });\n    }\n    updatePayload(payload) {\n        this.payload = Object.assign(Object.assign({}, this.payload), payload);\n    }\n    receive(status, callback) {\n        var _a;\n        if (this._hasReceived(status)) {\n            callback((_a = this.receivedResp) === null || _a === void 0 ? void 0 : _a.response);\n        }\n        this.recHooks.push({ status, callback });\n        return this;\n    }\n    startTimeout() {\n        if (this.timeoutTimer) {\n            return;\n        }\n        this.ref = this.channel.socket._makeRef();\n        this.refEvent = this.channel._replyEventName(this.ref);\n        const callback = (payload) => {\n            this._cancelRefEvent();\n            this._cancelTimeout();\n            this.receivedResp = payload;\n            this._matchReceive(payload);\n        };\n        this.channel._on(this.refEvent, {}, callback);\n        this.timeoutTimer = setTimeout(() => {\n            this.trigger('timeout', {});\n        }, this.timeout);\n    }\n    trigger(status, response) {\n        if (this.refEvent)\n            this.channel._trigger(this.refEvent, { status, response });\n    }\n    destroy() {\n        this._cancelRefEvent();\n        this._cancelTimeout();\n    }\n    _cancelRefEvent() {\n        if (!this.refEvent) {\n            return;\n        }\n        this.channel._off(this.refEvent, {});\n    }\n    _cancelTimeout() {\n        clearTimeout(this.timeoutTimer);\n        this.timeoutTimer = undefined;\n    }\n    _matchReceive({ status, response, }) {\n        this.recHooks\n            .filter((h) => h.status === status)\n            .forEach((h) => h.callback(response));\n    }\n    _hasReceived(status) {\n        return this.receivedResp && this.receivedResp.status === status;\n    }\n}\n//# sourceMappingURL=push.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/lib/push.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/lib/serializer.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/lib/serializer.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Serializer)\n/* harmony export */ });\n// This file draws heavily from https://github.com/phoenixframework/phoenix/commit/cf098e9cf7a44ee6479d31d911a97d3c7430c6fe\n// License: https://github.com/phoenixframework/phoenix/blob/master/LICENSE.md\nclass Serializer {\n    constructor() {\n        this.HEADER_LENGTH = 1;\n    }\n    decode(rawPayload, callback) {\n        if (rawPayload.constructor === ArrayBuffer) {\n            return callback(this._binaryDecode(rawPayload));\n        }\n        if (typeof rawPayload === 'string') {\n            return callback(JSON.parse(rawPayload));\n        }\n        return callback({});\n    }\n    _binaryDecode(buffer) {\n        const view = new DataView(buffer);\n        const decoder = new TextDecoder();\n        return this._decodeBroadcast(buffer, view, decoder);\n    }\n    _decodeBroadcast(buffer, view, decoder) {\n        const topicSize = view.getUint8(1);\n        const eventSize = view.getUint8(2);\n        let offset = this.HEADER_LENGTH + 2;\n        const topic = decoder.decode(buffer.slice(offset, offset + topicSize));\n        offset = offset + topicSize;\n        const event = decoder.decode(buffer.slice(offset, offset + eventSize));\n        offset = offset + eventSize;\n        const data = JSON.parse(decoder.decode(buffer.slice(offset, buffer.byteLength)));\n        return { ref: null, topic: topic, event: event, payload: data };\n    }\n}\n//# sourceMappingURL=serializer.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/lib/serializer.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/lib/timer.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/lib/timer.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Timer)\n/* harmony export */ });\n/**\n * Creates a timer that accepts a `timerCalc` function to perform calculated timeout retries, such as exponential backoff.\n *\n * @example\n *    let reconnectTimer = new Timer(() => this.connect(), function(tries){\n *      return [1000, 5000, 10000][tries - 1] || 10000\n *    })\n *    reconnectTimer.scheduleTimeout() // fires after 1000\n *    reconnectTimer.scheduleTimeout() // fires after 5000\n *    reconnectTimer.reset()\n *    reconnectTimer.scheduleTimeout() // fires after 1000\n */\nclass Timer {\n    constructor(callback, timerCalc) {\n        this.callback = callback;\n        this.timerCalc = timerCalc;\n        this.timer = undefined;\n        this.tries = 0;\n        this.callback = callback;\n        this.timerCalc = timerCalc;\n    }\n    reset() {\n        this.tries = 0;\n        clearTimeout(this.timer);\n    }\n    // Cancels any previous scheduleTimeout and schedules callback\n    scheduleTimeout() {\n        clearTimeout(this.timer);\n        this.timer = setTimeout(() => {\n            this.tries = this.tries + 1;\n            this.callback();\n        }, this.timerCalc(this.tries + 1));\n    }\n}\n//# sourceMappingURL=timer.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/lib/timer.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/lib/transformers.js":
/*!****************************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/lib/transformers.js ***!
  \****************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   PostgresTypes: () => (/* binding */ PostgresTypes),\n/* harmony export */   convertCell: () => (/* binding */ convertCell),\n/* harmony export */   convertChangeData: () => (/* binding */ convertChangeData),\n/* harmony export */   convertColumn: () => (/* binding */ convertColumn),\n/* harmony export */   httpEndpointURL: () => (/* binding */ httpEndpointURL),\n/* harmony export */   toArray: () => (/* binding */ toArray),\n/* harmony export */   toBoolean: () => (/* binding */ toBoolean),\n/* harmony export */   toJson: () => (/* binding */ toJson),\n/* harmony export */   toNumber: () => (/* binding */ toNumber),\n/* harmony export */   toTimestampString: () => (/* binding */ toTimestampString)\n/* harmony export */ });\n/**\n * Helpers to convert the change Payload into native JS types.\n */\n// Adapted from epgsql (src/epgsql_binary.erl), this module licensed under\n// 3-clause BSD found here: https://raw.githubusercontent.com/epgsql/epgsql/devel/LICENSE\nvar PostgresTypes;\n(function (PostgresTypes) {\n    PostgresTypes[\"abstime\"] = \"abstime\";\n    PostgresTypes[\"bool\"] = \"bool\";\n    PostgresTypes[\"date\"] = \"date\";\n    PostgresTypes[\"daterange\"] = \"daterange\";\n    PostgresTypes[\"float4\"] = \"float4\";\n    PostgresTypes[\"float8\"] = \"float8\";\n    PostgresTypes[\"int2\"] = \"int2\";\n    PostgresTypes[\"int4\"] = \"int4\";\n    PostgresTypes[\"int4range\"] = \"int4range\";\n    PostgresTypes[\"int8\"] = \"int8\";\n    PostgresTypes[\"int8range\"] = \"int8range\";\n    PostgresTypes[\"json\"] = \"json\";\n    PostgresTypes[\"jsonb\"] = \"jsonb\";\n    PostgresTypes[\"money\"] = \"money\";\n    PostgresTypes[\"numeric\"] = \"numeric\";\n    PostgresTypes[\"oid\"] = \"oid\";\n    PostgresTypes[\"reltime\"] = \"reltime\";\n    PostgresTypes[\"text\"] = \"text\";\n    PostgresTypes[\"time\"] = \"time\";\n    PostgresTypes[\"timestamp\"] = \"timestamp\";\n    PostgresTypes[\"timestamptz\"] = \"timestamptz\";\n    PostgresTypes[\"timetz\"] = \"timetz\";\n    PostgresTypes[\"tsrange\"] = \"tsrange\";\n    PostgresTypes[\"tstzrange\"] = \"tstzrange\";\n})(PostgresTypes || (PostgresTypes = {}));\n/**\n * Takes an array of columns and an object of string values then converts each string value\n * to its mapped type.\n *\n * @param {{name: String, type: String}[]} columns\n * @param {Object} record\n * @param {Object} options The map of various options that can be applied to the mapper\n * @param {Array} options.skipTypes The array of types that should not be converted\n *\n * @example convertChangeData([{name: 'first_name', type: 'text'}, {name: 'age', type: 'int4'}], {first_name: 'Paul', age:'33'}, {})\n * //=>{ first_name: 'Paul', age: 33 }\n */\nconst convertChangeData = (columns, record, options = {}) => {\n    var _a;\n    const skipTypes = (_a = options.skipTypes) !== null && _a !== void 0 ? _a : [];\n    return Object.keys(record).reduce((acc, rec_key) => {\n        acc[rec_key] = convertColumn(rec_key, columns, record, skipTypes);\n        return acc;\n    }, {});\n};\n/**\n * Converts the value of an individual column.\n *\n * @param {String} columnName The column that you want to convert\n * @param {{name: String, type: String}[]} columns All of the columns\n * @param {Object} record The map of string values\n * @param {Array} skipTypes An array of types that should not be converted\n * @return {object} Useless information\n *\n * @example convertColumn('age', [{name: 'first_name', type: 'text'}, {name: 'age', type: 'int4'}], {first_name: 'Paul', age: '33'}, [])\n * //=> 33\n * @example convertColumn('age', [{name: 'first_name', type: 'text'}, {name: 'age', type: 'int4'}], {first_name: 'Paul', age: '33'}, ['int4'])\n * //=> \"33\"\n */\nconst convertColumn = (columnName, columns, record, skipTypes) => {\n    const column = columns.find((x) => x.name === columnName);\n    const colType = column === null || column === void 0 ? void 0 : column.type;\n    const value = record[columnName];\n    if (colType && !skipTypes.includes(colType)) {\n        return convertCell(colType, value);\n    }\n    return noop(value);\n};\n/**\n * If the value of the cell is `null`, returns null.\n * Otherwise converts the string value to the correct type.\n * @param {String} type A postgres column type\n * @param {String} value The cell value\n *\n * @example convertCell('bool', 't')\n * //=> true\n * @example convertCell('int8', '10')\n * //=> 10\n * @example convertCell('_int4', '{1,2,3,4}')\n * //=> [1,2,3,4]\n */\nconst convertCell = (type, value) => {\n    // if data type is an array\n    if (type.charAt(0) === '_') {\n        const dataType = type.slice(1, type.length);\n        return toArray(value, dataType);\n    }\n    // If not null, convert to correct type.\n    switch (type) {\n        case PostgresTypes.bool:\n            return toBoolean(value);\n        case PostgresTypes.float4:\n        case PostgresTypes.float8:\n        case PostgresTypes.int2:\n        case PostgresTypes.int4:\n        case PostgresTypes.int8:\n        case PostgresTypes.numeric:\n        case PostgresTypes.oid:\n            return toNumber(value);\n        case PostgresTypes.json:\n        case PostgresTypes.jsonb:\n            return toJson(value);\n        case PostgresTypes.timestamp:\n            return toTimestampString(value); // Format to be consistent with PostgREST\n        case PostgresTypes.abstime: // To allow users to cast it based on Timezone\n        case PostgresTypes.date: // To allow users to cast it based on Timezone\n        case PostgresTypes.daterange:\n        case PostgresTypes.int4range:\n        case PostgresTypes.int8range:\n        case PostgresTypes.money:\n        case PostgresTypes.reltime: // To allow users to cast it based on Timezone\n        case PostgresTypes.text:\n        case PostgresTypes.time: // To allow users to cast it based on Timezone\n        case PostgresTypes.timestamptz: // To allow users to cast it based on Timezone\n        case PostgresTypes.timetz: // To allow users to cast it based on Timezone\n        case PostgresTypes.tsrange:\n        case PostgresTypes.tstzrange:\n            return noop(value);\n        default:\n            // Return the value for remaining types\n            return noop(value);\n    }\n};\nconst noop = (value) => {\n    return value;\n};\nconst toBoolean = (value) => {\n    switch (value) {\n        case 't':\n            return true;\n        case 'f':\n            return false;\n        default:\n            return value;\n    }\n};\nconst toNumber = (value) => {\n    if (typeof value === 'string') {\n        const parsedValue = parseFloat(value);\n        if (!Number.isNaN(parsedValue)) {\n            return parsedValue;\n        }\n    }\n    return value;\n};\nconst toJson = (value) => {\n    if (typeof value === 'string') {\n        try {\n            return JSON.parse(value);\n        }\n        catch (error) {\n            console.log(`JSON parse error: ${error}`);\n            return value;\n        }\n    }\n    return value;\n};\n/**\n * Converts a Postgres Array into a native JS array\n *\n * @example toArray('{}', 'int4')\n * //=> []\n * @example toArray('{\"[2021-01-01,2021-12-31)\",\"(2021-01-01,2021-12-32]\"}', 'daterange')\n * //=> ['[2021-01-01,2021-12-31)', '(2021-01-01,2021-12-32]']\n * @example toArray([1,2,3,4], 'int4')\n * //=> [1,2,3,4]\n */\nconst toArray = (value, type) => {\n    if (typeof value !== 'string') {\n        return value;\n    }\n    const lastIdx = value.length - 1;\n    const closeBrace = value[lastIdx];\n    const openBrace = value[0];\n    // Confirm value is a Postgres array by checking curly brackets\n    if (openBrace === '{' && closeBrace === '}') {\n        let arr;\n        const valTrim = value.slice(1, lastIdx);\n        // TODO: find a better solution to separate Postgres array data\n        try {\n            arr = JSON.parse('[' + valTrim + ']');\n        }\n        catch (_) {\n            // WARNING: splitting on comma does not cover all edge cases\n            arr = valTrim ? valTrim.split(',') : [];\n        }\n        return arr.map((val) => convertCell(type, val));\n    }\n    return value;\n};\n/**\n * Fixes timestamp to be ISO-8601. Swaps the space between the date and time for a 'T'\n * See https://github.com/supabase/supabase/issues/18\n *\n * @example toTimestampString('2019-09-10 00:00:00')\n * //=> '2019-09-10T00:00:00'\n */\nconst toTimestampString = (value) => {\n    if (typeof value === 'string') {\n        return value.replace(' ', 'T');\n    }\n    return value;\n};\nconst httpEndpointURL = (socketUrl) => {\n    let url = socketUrl;\n    url = url.replace(/^ws/i, 'http');\n    url = url.replace(/(\\/socket\\/websocket|\\/socket|\\/websocket)\\/?$/i, '');\n    return url.replace(/\\/+$/, '');\n};\n//# sourceMappingURL=transformers.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/lib/transformers.js?");

/***/ }),

/***/ "./node_modules/@supabase/realtime-js/dist/module/lib/version.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@supabase/realtime-js/dist/module/lib/version.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   version: () => (/* binding */ version)\n/* harmony export */ });\nconst version = '2.10.2';\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/realtime-js/dist/module/lib/version.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/StorageClient.js":
/*!************************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/StorageClient.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   StorageClient: () => (/* binding */ StorageClient)\n/* harmony export */ });\n/* harmony import */ var _packages_StorageFileApi__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./packages/StorageFileApi */ \"./node_modules/@supabase/storage-js/dist/module/packages/StorageFileApi.js\");\n/* harmony import */ var _packages_StorageBucketApi__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./packages/StorageBucketApi */ \"./node_modules/@supabase/storage-js/dist/module/packages/StorageBucketApi.js\");\n\n\nclass StorageClient extends _packages_StorageBucketApi__WEBPACK_IMPORTED_MODULE_0__[\"default\"] {\n    constructor(url, headers = {}, fetch) {\n        super(url, headers, fetch);\n    }\n    /**\n     * Perform file operation in a bucket.\n     *\n     * @param id The bucket id to operate on.\n     */\n    from(id) {\n        return new _packages_StorageFileApi__WEBPACK_IMPORTED_MODULE_1__[\"default\"](this.url, this.headers, id, this.fetch);\n    }\n}\n//# sourceMappingURL=StorageClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/StorageClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/lib/constants.js":
/*!************************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/lib/constants.js ***!
  \************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DEFAULT_HEADERS: () => (/* binding */ DEFAULT_HEADERS)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./version */ \"./node_modules/@supabase/storage-js/dist/module/lib/version.js\");\n\nconst DEFAULT_HEADERS = { 'X-Client-Info': `storage-js/${_version__WEBPACK_IMPORTED_MODULE_0__.version}` };\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/lib/constants.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/lib/errors.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/lib/errors.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   StorageApiError: () => (/* binding */ StorageApiError),\n/* harmony export */   StorageError: () => (/* binding */ StorageError),\n/* harmony export */   StorageUnknownError: () => (/* binding */ StorageUnknownError),\n/* harmony export */   isStorageError: () => (/* binding */ isStorageError)\n/* harmony export */ });\nclass StorageError extends Error {\n    constructor(message) {\n        super(message);\n        this.__isStorageError = true;\n        this.name = 'StorageError';\n    }\n}\nfunction isStorageError(error) {\n    return typeof error === 'object' && error !== null && '__isStorageError' in error;\n}\nclass StorageApiError extends StorageError {\n    constructor(message, status) {\n        super(message);\n        this.name = 'StorageApiError';\n        this.status = status;\n    }\n    toJSON() {\n        return {\n            name: this.name,\n            message: this.message,\n            status: this.status,\n        };\n    }\n}\nclass StorageUnknownError extends StorageError {\n    constructor(message, originalError) {\n        super(message);\n        this.name = 'StorageUnknownError';\n        this.originalError = originalError;\n    }\n}\n//# sourceMappingURL=errors.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/lib/errors.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/lib/fetch.js":
/*!********************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/lib/fetch.js ***!
  \********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   get: () => (/* binding */ get),\n/* harmony export */   head: () => (/* binding */ head),\n/* harmony export */   post: () => (/* binding */ post),\n/* harmony export */   put: () => (/* binding */ put),\n/* harmony export */   remove: () => (/* binding */ remove)\n/* harmony export */ });\n/* harmony import */ var _errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./errors */ \"./node_modules/@supabase/storage-js/dist/module/lib/errors.js\");\n/* harmony import */ var _helpers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./helpers */ \"./node_modules/@supabase/storage-js/dist/module/lib/helpers.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\nconst _getErrorMessage = (err) => err.msg || err.message || err.error_description || err.error || JSON.stringify(err);\nconst handleError = (error, reject, options) => __awaiter(void 0, void 0, void 0, function* () {\n    const Res = yield (0,_helpers__WEBPACK_IMPORTED_MODULE_0__.resolveResponse)();\n    if (error instanceof Res && !(options === null || options === void 0 ? void 0 : options.noResolveJson)) {\n        error\n            .json()\n            .then((err) => {\n            reject(new _errors__WEBPACK_IMPORTED_MODULE_1__.StorageApiError(_getErrorMessage(err), error.status || 500));\n        })\n            .catch((err) => {\n            reject(new _errors__WEBPACK_IMPORTED_MODULE_1__.StorageUnknownError(_getErrorMessage(err), err));\n        });\n    }\n    else {\n        reject(new _errors__WEBPACK_IMPORTED_MODULE_1__.StorageUnknownError(_getErrorMessage(error), error));\n    }\n});\nconst _getRequestParams = (method, options, parameters, body) => {\n    const params = { method, headers: (options === null || options === void 0 ? void 0 : options.headers) || {} };\n    if (method === 'GET') {\n        return params;\n    }\n    params.headers = Object.assign({ 'Content-Type': 'application/json' }, options === null || options === void 0 ? void 0 : options.headers);\n    if (body) {\n        params.body = JSON.stringify(body);\n    }\n    return Object.assign(Object.assign({}, params), parameters);\n};\nfunction _handleRequest(fetcher, method, url, options, parameters, body) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return new Promise((resolve, reject) => {\n            fetcher(url, _getRequestParams(method, options, parameters, body))\n                .then((result) => {\n                if (!result.ok)\n                    throw result;\n                if (options === null || options === void 0 ? void 0 : options.noResolveJson)\n                    return result;\n                return result.json();\n            })\n                .then((data) => resolve(data))\n                .catch((error) => handleError(error, reject, options));\n        });\n    });\n}\nfunction get(fetcher, url, options, parameters) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return _handleRequest(fetcher, 'GET', url, options, parameters);\n    });\n}\nfunction post(fetcher, url, body, options, parameters) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return _handleRequest(fetcher, 'POST', url, options, parameters, body);\n    });\n}\nfunction put(fetcher, url, body, options, parameters) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return _handleRequest(fetcher, 'PUT', url, options, parameters, body);\n    });\n}\nfunction head(fetcher, url, options, parameters) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return _handleRequest(fetcher, 'HEAD', url, Object.assign(Object.assign({}, options), { noResolveJson: true }), parameters);\n    });\n}\nfunction remove(fetcher, url, body, options, parameters) {\n    return __awaiter(this, void 0, void 0, function* () {\n        return _handleRequest(fetcher, 'DELETE', url, options, parameters, body);\n    });\n}\n//# sourceMappingURL=fetch.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/lib/fetch.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/lib/helpers.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/lib/helpers.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   recursiveToCamel: () => (/* binding */ recursiveToCamel),\n/* harmony export */   resolveFetch: () => (/* binding */ resolveFetch),\n/* harmony export */   resolveResponse: () => (/* binding */ resolveResponse)\n/* harmony export */ });\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nconst resolveFetch = (customFetch) => {\n    let _fetch;\n    if (customFetch) {\n        _fetch = customFetch;\n    }\n    else if (typeof fetch === 'undefined') {\n        _fetch = (...args) => Promise.resolve(/*! import() */).then(__webpack_require__.bind(__webpack_require__, /*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\")).then(({ default: fetch }) => fetch(...args));\n    }\n    else {\n        _fetch = fetch;\n    }\n    return (...args) => _fetch(...args);\n};\nconst resolveResponse = () => __awaiter(void 0, void 0, void 0, function* () {\n    if (typeof Response === 'undefined') {\n        // @ts-ignore\n        return (yield Promise.resolve(/*! import() */).then(__webpack_require__.bind(__webpack_require__, /*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\"))).Response;\n    }\n    return Response;\n});\nconst recursiveToCamel = (item) => {\n    if (Array.isArray(item)) {\n        return item.map((el) => recursiveToCamel(el));\n    }\n    else if (typeof item === 'function' || item !== Object(item)) {\n        return item;\n    }\n    const result = {};\n    Object.entries(item).forEach(([key, value]) => {\n        const newKey = key.replace(/([-_][a-z])/gi, (c) => c.toUpperCase().replace(/[-_]/g, ''));\n        result[newKey] = recursiveToCamel(value);\n    });\n    return result;\n};\n//# sourceMappingURL=helpers.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/lib/helpers.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/lib/version.js":
/*!**********************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/lib/version.js ***!
  \**********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   version: () => (/* binding */ version)\n/* harmony export */ });\n// generated by genversion\nconst version = '2.7.0';\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/lib/version.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/packages/StorageBucketApi.js":
/*!************************************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/packages/StorageBucketApi.js ***!
  \************************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ StorageBucketApi)\n/* harmony export */ });\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lib/constants */ \"./node_modules/@supabase/storage-js/dist/module/lib/constants.js\");\n/* harmony import */ var _lib_errors__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ../lib/errors */ \"./node_modules/@supabase/storage-js/dist/module/lib/errors.js\");\n/* harmony import */ var _lib_fetch__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lib/fetch */ \"./node_modules/@supabase/storage-js/dist/module/lib/fetch.js\");\n/* harmony import */ var _lib_helpers__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lib/helpers */ \"./node_modules/@supabase/storage-js/dist/module/lib/helpers.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\nclass StorageBucketApi {\n    constructor(url, headers = {}, fetch) {\n        this.url = url;\n        this.headers = Object.assign(Object.assign({}, _lib_constants__WEBPACK_IMPORTED_MODULE_0__.DEFAULT_HEADERS), headers);\n        this.fetch = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_1__.resolveFetch)(fetch);\n    }\n    /**\n     * Retrieves the details of all Storage buckets within an existing project.\n     */\n    listBuckets() {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.get)(this.fetch, `${this.url}/bucket`, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_3__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Retrieves the details of an existing Storage bucket.\n     *\n     * @param id The unique identifier of the bucket you would like to retrieve.\n     */\n    getBucket(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.get)(this.fetch, `${this.url}/bucket/${id}`, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_3__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Creates a new Storage bucket\n     *\n     * @param id A unique identifier for the bucket you are creating.\n     * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations. By default, buckets are private.\n     * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n     * The global file size limit takes precedence over this value.\n     * The default value is null, which doesn't set a per bucket file size limit.\n     * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n     * The default value is null, which allows files with all mime types to be uploaded.\n     * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n     * @returns newly created bucket id\n     */\n    createBucket(id, options = {\n        public: false,\n    }) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/bucket`, {\n                    id,\n                    name: id,\n                    public: options.public,\n                    file_size_limit: options.fileSizeLimit,\n                    allowed_mime_types: options.allowedMimeTypes,\n                }, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_3__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Updates a Storage bucket\n     *\n     * @param id A unique identifier for the bucket you are updating.\n     * @param options.public The visibility of the bucket. Public buckets don't require an authorization token to download objects, but still require a valid token for all other operations.\n     * @param options.fileSizeLimit specifies the max file size in bytes that can be uploaded to this bucket.\n     * The global file size limit takes precedence over this value.\n     * The default value is null, which doesn't set a per bucket file size limit.\n     * @param options.allowedMimeTypes specifies the allowed mime types that this bucket can accept during upload.\n     * The default value is null, which allows files with all mime types to be uploaded.\n     * Each mime type specified can be a wildcard, e.g. image/*, or a specific mime type, e.g. image/png.\n     */\n    updateBucket(id, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.put)(this.fetch, `${this.url}/bucket/${id}`, {\n                    id,\n                    name: id,\n                    public: options.public,\n                    file_size_limit: options.fileSizeLimit,\n                    allowed_mime_types: options.allowedMimeTypes,\n                }, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_3__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Removes all objects inside a single bucket.\n     *\n     * @param id The unique identifier of the bucket you would like to empty.\n     */\n    emptyBucket(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/bucket/${id}/empty`, {}, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_3__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Deletes an existing bucket. A bucket can't be deleted with existing objects inside it.\n     * You must first `empty()` the bucket.\n     *\n     * @param id The unique identifier of the bucket you would like to delete.\n     */\n    deleteBucket(id) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.remove)(this.fetch, `${this.url}/bucket/${id}`, {}, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_3__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n}\n//# sourceMappingURL=StorageBucketApi.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/packages/StorageBucketApi.js?");

/***/ }),

/***/ "./node_modules/@supabase/storage-js/dist/module/packages/StorageFileApi.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@supabase/storage-js/dist/module/packages/StorageFileApi.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ StorageFileApi)\n/* harmony export */ });\n/* harmony import */ var _lib_errors__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../lib/errors */ \"./node_modules/@supabase/storage-js/dist/module/lib/errors.js\");\n/* harmony import */ var _lib_fetch__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../lib/fetch */ \"./node_modules/@supabase/storage-js/dist/module/lib/fetch.js\");\n/* harmony import */ var _lib_helpers__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../lib/helpers */ \"./node_modules/@supabase/storage-js/dist/module/lib/helpers.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\nconst DEFAULT_SEARCH_OPTIONS = {\n    limit: 100,\n    offset: 0,\n    sortBy: {\n        column: 'name',\n        order: 'asc',\n    },\n};\nconst DEFAULT_FILE_OPTIONS = {\n    cacheControl: '3600',\n    contentType: 'text/plain;charset=UTF-8',\n    upsert: false,\n};\nclass StorageFileApi {\n    constructor(url, headers = {}, bucketId, fetch) {\n        this.url = url;\n        this.headers = headers;\n        this.bucketId = bucketId;\n        this.fetch = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_0__.resolveFetch)(fetch);\n    }\n    /**\n     * Uploads a file to an existing bucket or replaces an existing file at the specified path with a new one.\n     *\n     * @param method HTTP method.\n     * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n     * @param fileBody The body of the file to be stored in the bucket.\n     */\n    uploadOrUpdate(method, path, fileBody, fileOptions) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                let body;\n                const options = Object.assign(Object.assign({}, DEFAULT_FILE_OPTIONS), fileOptions);\n                let headers = Object.assign(Object.assign({}, this.headers), (method === 'POST' && { 'x-upsert': String(options.upsert) }));\n                const metadata = options.metadata;\n                if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n                    body = new FormData();\n                    body.append('cacheControl', options.cacheControl);\n                    body.append('', fileBody);\n                    if (metadata) {\n                        body.append('metadata', this.encodeMetadata(metadata));\n                    }\n                }\n                else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n                    body = fileBody;\n                    body.append('cacheControl', options.cacheControl);\n                    if (metadata) {\n                        body.append('metadata', this.encodeMetadata(metadata));\n                    }\n                }\n                else {\n                    body = fileBody;\n                    headers['cache-control'] = `max-age=${options.cacheControl}`;\n                    headers['content-type'] = options.contentType;\n                    if (metadata) {\n                        headers['x-metadata'] = this.toBase64(this.encodeMetadata(metadata));\n                    }\n                }\n                if (fileOptions === null || fileOptions === void 0 ? void 0 : fileOptions.headers) {\n                    headers = Object.assign(Object.assign({}, headers), fileOptions.headers);\n                }\n                const cleanPath = this._removeEmptyFolders(path);\n                const _path = this._getFinalPath(cleanPath);\n                const res = yield this.fetch(`${this.url}/object/${_path}`, Object.assign({ method, body: body, headers }, ((options === null || options === void 0 ? void 0 : options.duplex) ? { duplex: options.duplex } : {})));\n                const data = yield res.json();\n                if (res.ok) {\n                    return {\n                        data: { path: cleanPath, id: data.Id, fullPath: data.Key },\n                        error: null,\n                    };\n                }\n                else {\n                    const error = data;\n                    return { data: null, error };\n                }\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Uploads a file to an existing bucket.\n     *\n     * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n     * @param fileBody The body of the file to be stored in the bucket.\n     */\n    upload(path, fileBody, fileOptions) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.uploadOrUpdate('POST', path, fileBody, fileOptions);\n        });\n    }\n    /**\n     * Upload a file with a token generated from `createSignedUploadUrl`.\n     * @param path The file path, including the file name. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to upload.\n     * @param token The token generated from `createSignedUploadUrl`\n     * @param fileBody The body of the file to be stored in the bucket.\n     */\n    uploadToSignedUrl(path, token, fileBody, fileOptions) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const cleanPath = this._removeEmptyFolders(path);\n            const _path = this._getFinalPath(cleanPath);\n            const url = new URL(this.url + `/object/upload/sign/${_path}`);\n            url.searchParams.set('token', token);\n            try {\n                let body;\n                const options = Object.assign({ upsert: DEFAULT_FILE_OPTIONS.upsert }, fileOptions);\n                const headers = Object.assign(Object.assign({}, this.headers), { 'x-upsert': String(options.upsert) });\n                if (typeof Blob !== 'undefined' && fileBody instanceof Blob) {\n                    body = new FormData();\n                    body.append('cacheControl', options.cacheControl);\n                    body.append('', fileBody);\n                }\n                else if (typeof FormData !== 'undefined' && fileBody instanceof FormData) {\n                    body = fileBody;\n                    body.append('cacheControl', options.cacheControl);\n                }\n                else {\n                    body = fileBody;\n                    headers['cache-control'] = `max-age=${options.cacheControl}`;\n                    headers['content-type'] = options.contentType;\n                }\n                const res = yield this.fetch(url.toString(), {\n                    method: 'PUT',\n                    body: body,\n                    headers,\n                });\n                const data = yield res.json();\n                if (res.ok) {\n                    return {\n                        data: { path: cleanPath, fullPath: data.Key },\n                        error: null,\n                    };\n                }\n                else {\n                    const error = data;\n                    return { data: null, error };\n                }\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Creates a signed upload URL.\n     * Signed upload URLs can be used to upload files to the bucket without further authentication.\n     * They are valid for 2 hours.\n     * @param path The file path, including the current file name. For example `folder/image.png`.\n     * @param options.upsert If set to true, allows the file to be overwritten if it already exists.\n     */\n    createSignedUploadUrl(path, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                let _path = this._getFinalPath(path);\n                const headers = Object.assign({}, this.headers);\n                if (options === null || options === void 0 ? void 0 : options.upsert) {\n                    headers['x-upsert'] = 'true';\n                }\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/object/upload/sign/${_path}`, {}, { headers });\n                const url = new URL(this.url + data.url);\n                const token = url.searchParams.get('token');\n                if (!token) {\n                    throw new _lib_errors__WEBPACK_IMPORTED_MODULE_1__.StorageError('No token returned by API');\n                }\n                return { data: { signedUrl: url.toString(), path, token }, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Replaces an existing file at the specified path with a new one.\n     *\n     * @param path The relative file path. Should be of the format `folder/subfolder/filename.png`. The bucket must already exist before attempting to update.\n     * @param fileBody The body of the file to be stored in the bucket.\n     */\n    update(path, fileBody, fileOptions) {\n        return __awaiter(this, void 0, void 0, function* () {\n            return this.uploadOrUpdate('PUT', path, fileBody, fileOptions);\n        });\n    }\n    /**\n     * Moves an existing file to a new path in the same bucket.\n     *\n     * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n     * @param toPath The new file path, including the new file name. For example `folder/image-new.png`.\n     * @param options The destination options.\n     */\n    move(fromPath, toPath, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/object/move`, {\n                    bucketId: this.bucketId,\n                    sourceKey: fromPath,\n                    destinationKey: toPath,\n                    destinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket,\n                }, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Copies an existing file to a new path in the same bucket.\n     *\n     * @param fromPath The original file path, including the current file name. For example `folder/image.png`.\n     * @param toPath The new file path, including the new file name. For example `folder/image-copy.png`.\n     * @param options The destination options.\n     */\n    copy(fromPath, toPath, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/object/copy`, {\n                    bucketId: this.bucketId,\n                    sourceKey: fromPath,\n                    destinationKey: toPath,\n                    destinationBucket: options === null || options === void 0 ? void 0 : options.destinationBucket,\n                }, { headers: this.headers });\n                return { data: { path: data.Key }, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Creates a signed URL. Use a signed URL to share a file for a fixed amount of time.\n     *\n     * @param path The file path, including the current file name. For example `folder/image.png`.\n     * @param expiresIn The number of seconds until the signed URL expires. For example, `60` for a URL which is valid for one minute.\n     * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n     * @param options.transform Transform the asset before serving it to the client.\n     */\n    createSignedUrl(path, expiresIn, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                let _path = this._getFinalPath(path);\n                let data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/object/sign/${_path}`, Object.assign({ expiresIn }, ((options === null || options === void 0 ? void 0 : options.transform) ? { transform: options.transform } : {})), { headers: this.headers });\n                const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download)\n                    ? `&download=${options.download === true ? '' : options.download}`\n                    : '';\n                const signedUrl = encodeURI(`${this.url}${data.signedURL}${downloadQueryParam}`);\n                data = { signedUrl };\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Creates multiple signed URLs. Use a signed URL to share a file for a fixed amount of time.\n     *\n     * @param paths The file paths to be downloaded, including the current file names. For example `['folder/image.png', 'folder2/image2.png']`.\n     * @param expiresIn The number of seconds until the signed URLs expire. For example, `60` for URLs which are valid for one minute.\n     * @param options.download triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n     */\n    createSignedUrls(paths, expiresIn, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/object/sign/${this.bucketId}`, { expiresIn, paths }, { headers: this.headers });\n                const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download)\n                    ? `&download=${options.download === true ? '' : options.download}`\n                    : '';\n                return {\n                    data: data.map((datum) => (Object.assign(Object.assign({}, datum), { signedUrl: datum.signedURL\n                            ? encodeURI(`${this.url}${datum.signedURL}${downloadQueryParam}`)\n                            : null }))),\n                    error: null,\n                };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Downloads a file from a private bucket. For public buckets, make a request to the URL returned from `getPublicUrl` instead.\n     *\n     * @param path The full path and file name of the file to be downloaded. For example `folder/image.png`.\n     * @param options.transform Transform the asset before serving it to the client.\n     */\n    download(path, options) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const wantsTransformation = typeof (options === null || options === void 0 ? void 0 : options.transform) !== 'undefined';\n            const renderPath = wantsTransformation ? 'render/image/authenticated' : 'object';\n            const transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n            const queryString = transformationQuery ? `?${transformationQuery}` : '';\n            try {\n                const _path = this._getFinalPath(path);\n                const res = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.get)(this.fetch, `${this.url}/${renderPath}/${_path}${queryString}`, {\n                    headers: this.headers,\n                    noResolveJson: true,\n                });\n                const data = yield res.blob();\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Retrieves the details of an existing file.\n     * @param path\n     */\n    info(path) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const _path = this._getFinalPath(path);\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.get)(this.fetch, `${this.url}/object/info/${_path}`, {\n                    headers: this.headers,\n                });\n                return { data: (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_0__.recursiveToCamel)(data), error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Checks the existence of a file.\n     * @param path\n     */\n    exists(path) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const _path = this._getFinalPath(path);\n            try {\n                yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.head)(this.fetch, `${this.url}/object/${_path}`, {\n                    headers: this.headers,\n                });\n                return { data: true, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error) && error instanceof _lib_errors__WEBPACK_IMPORTED_MODULE_1__.StorageUnknownError) {\n                    const originalError = error.originalError;\n                    if ([400, 404].includes(originalError === null || originalError === void 0 ? void 0 : originalError.status)) {\n                        return { data: false, error };\n                    }\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * A simple convenience function to get the URL for an asset in a public bucket. If you do not want to use this function, you can construct the public URL by concatenating the bucket URL with the path to the asset.\n     * This function does not verify if the bucket is public. If a public URL is created for a bucket which is not public, you will not be able to download the asset.\n     *\n     * @param path The path and name of the file to generate the public URL for. For example `folder/image.png`.\n     * @param options.download Triggers the file as a download if set to true. Set this parameter as the name of the file if you want to trigger the download with a different filename.\n     * @param options.transform Transform the asset before serving it to the client.\n     */\n    getPublicUrl(path, options) {\n        const _path = this._getFinalPath(path);\n        const _queryString = [];\n        const downloadQueryParam = (options === null || options === void 0 ? void 0 : options.download)\n            ? `download=${options.download === true ? '' : options.download}`\n            : '';\n        if (downloadQueryParam !== '') {\n            _queryString.push(downloadQueryParam);\n        }\n        const wantsTransformation = typeof (options === null || options === void 0 ? void 0 : options.transform) !== 'undefined';\n        const renderPath = wantsTransformation ? 'render/image' : 'object';\n        const transformationQuery = this.transformOptsToQueryString((options === null || options === void 0 ? void 0 : options.transform) || {});\n        if (transformationQuery !== '') {\n            _queryString.push(transformationQuery);\n        }\n        let queryString = _queryString.join('&');\n        if (queryString !== '') {\n            queryString = `?${queryString}`;\n        }\n        return {\n            data: { publicUrl: encodeURI(`${this.url}/${renderPath}/public/${_path}${queryString}`) },\n        };\n    }\n    /**\n     * Deletes files within the same bucket\n     *\n     * @param paths An array of files to delete, including the path and file name. For example [`'folder/image.png'`].\n     */\n    remove(paths) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.remove)(this.fetch, `${this.url}/object/${this.bucketId}`, { prefixes: paths }, { headers: this.headers });\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    /**\n     * Get file metadata\n     * @param id the file id to retrieve metadata\n     */\n    // async getMetadata(\n    //   id: string\n    // ): Promise<\n    //   | {\n    //       data: Metadata\n    //       error: null\n    //     }\n    //   | {\n    //       data: null\n    //       error: StorageError\n    //     }\n    // > {\n    //   try {\n    //     const data = await get(this.fetch, `${this.url}/metadata/${id}`, { headers: this.headers })\n    //     return { data, error: null }\n    //   } catch (error) {\n    //     if (isStorageError(error)) {\n    //       return { data: null, error }\n    //     }\n    //     throw error\n    //   }\n    // }\n    /**\n     * Update file metadata\n     * @param id the file id to update metadata\n     * @param meta the new file metadata\n     */\n    // async updateMetadata(\n    //   id: string,\n    //   meta: Metadata\n    // ): Promise<\n    //   | {\n    //       data: Metadata\n    //       error: null\n    //     }\n    //   | {\n    //       data: null\n    //       error: StorageError\n    //     }\n    // > {\n    //   try {\n    //     const data = await post(\n    //       this.fetch,\n    //       `${this.url}/metadata/${id}`,\n    //       { ...meta },\n    //       { headers: this.headers }\n    //     )\n    //     return { data, error: null }\n    //   } catch (error) {\n    //     if (isStorageError(error)) {\n    //       return { data: null, error }\n    //     }\n    //     throw error\n    //   }\n    // }\n    /**\n     * Lists all the files within a bucket.\n     * @param path The folder path.\n     */\n    list(path, options, parameters) {\n        return __awaiter(this, void 0, void 0, function* () {\n            try {\n                const body = Object.assign(Object.assign(Object.assign({}, DEFAULT_SEARCH_OPTIONS), options), { prefix: path || '' });\n                const data = yield (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_2__.post)(this.fetch, `${this.url}/object/list/${this.bucketId}`, body, { headers: this.headers }, parameters);\n                return { data, error: null };\n            }\n            catch (error) {\n                if ((0,_lib_errors__WEBPACK_IMPORTED_MODULE_1__.isStorageError)(error)) {\n                    return { data: null, error };\n                }\n                throw error;\n            }\n        });\n    }\n    encodeMetadata(metadata) {\n        return JSON.stringify(metadata);\n    }\n    toBase64(data) {\n        if (typeof Buffer !== 'undefined') {\n            return Buffer.from(data).toString('base64');\n        }\n        return btoa(data);\n    }\n    _getFinalPath(path) {\n        return `${this.bucketId}/${path}`;\n    }\n    _removeEmptyFolders(path) {\n        return path.replace(/^\\/|\\/$/g, '').replace(/\\/+/g, '/');\n    }\n    transformOptsToQueryString(transform) {\n        const params = [];\n        if (transform.width) {\n            params.push(`width=${transform.width}`);\n        }\n        if (transform.height) {\n            params.push(`height=${transform.height}`);\n        }\n        if (transform.resize) {\n            params.push(`resize=${transform.resize}`);\n        }\n        if (transform.format) {\n            params.push(`format=${transform.format}`);\n        }\n        if (transform.quality) {\n            params.push(`quality=${transform.quality}`);\n        }\n        return params.join('&');\n    }\n}\n//# sourceMappingURL=StorageFileApi.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/storage-js/dist/module/packages/StorageFileApi.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/SupabaseClient.js":
/*!**************************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/SupabaseClient.js ***!
  \**************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ SupabaseClient)\n/* harmony export */ });\n/* harmony import */ var _supabase_functions_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! @supabase/functions-js */ \"./node_modules/@supabase/functions-js/dist/module/FunctionsClient.js\");\n/* harmony import */ var _supabase_postgrest_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @supabase/postgrest-js */ \"./node_modules/@supabase/postgrest-js/dist/esm/wrapper.mjs\");\n/* harmony import */ var _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @supabase/realtime-js */ \"./node_modules/@supabase/realtime-js/dist/module/index.js\");\n/* harmony import */ var _supabase_storage_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! @supabase/storage-js */ \"./node_modules/@supabase/storage-js/dist/module/StorageClient.js\");\n/* harmony import */ var _lib_constants__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./lib/constants */ \"./node_modules/@supabase/supabase-js/dist/module/lib/constants.js\");\n/* harmony import */ var _lib_fetch__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./lib/fetch */ \"./node_modules/@supabase/supabase-js/dist/module/lib/fetch.js\");\n/* harmony import */ var _lib_helpers__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./lib/helpers */ \"./node_modules/@supabase/supabase-js/dist/module/lib/helpers.js\");\n/* harmony import */ var _lib_SupabaseAuthClient__WEBPACK_IMPORTED_MODULE_7__ = __webpack_require__(/*! ./lib/SupabaseAuthClient */ \"./node_modules/@supabase/supabase-js/dist/module/lib/SupabaseAuthClient.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n\n\n\n\n\n\n\n\n/**\n * Supabase Client.\n *\n * An isomorphic Javascript client for interacting with Postgres.\n */\nclass SupabaseClient {\n    /**\n     * Create a new client for use in the browser.\n     * @param supabaseUrl The unique Supabase URL which is supplied when you create a new project in your project dashboard.\n     * @param supabaseKey The unique Supabase Key which is supplied when you create a new project in your project dashboard.\n     * @param options.db.schema You can switch in between schemas. The schema needs to be on the list of exposed schemas inside Supabase.\n     * @param options.auth.autoRefreshToken Set to \"true\" if you want to automatically refresh the token before expiring.\n     * @param options.auth.persistSession Set to \"true\" if you want to automatically save the user session into local storage.\n     * @param options.auth.detectSessionInUrl Set to \"true\" if you want to automatically detects OAuth grants in the URL and signs in the user.\n     * @param options.realtime Options passed along to realtime-js constructor.\n     * @param options.global.fetch A custom fetch implementation.\n     * @param options.global.headers Any additional headers to send with each network request.\n     */\n    constructor(supabaseUrl, supabaseKey, options) {\n        var _a, _b, _c;\n        this.supabaseUrl = supabaseUrl;\n        this.supabaseKey = supabaseKey;\n        if (!supabaseUrl)\n            throw new Error('supabaseUrl is required.');\n        if (!supabaseKey)\n            throw new Error('supabaseKey is required.');\n        const _supabaseUrl = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_2__.stripTrailingSlash)(supabaseUrl);\n        this.realtimeUrl = `${_supabaseUrl}/realtime/v1`.replace(/^http/i, 'ws');\n        this.authUrl = `${_supabaseUrl}/auth/v1`;\n        this.storageUrl = `${_supabaseUrl}/storage/v1`;\n        this.functionsUrl = `${_supabaseUrl}/functions/v1`;\n        // default storage key uses the supabase project ref as a namespace\n        const defaultStorageKey = `sb-${new URL(this.authUrl).hostname.split('.')[0]}-auth-token`;\n        const DEFAULTS = {\n            db: _lib_constants__WEBPACK_IMPORTED_MODULE_3__.DEFAULT_DB_OPTIONS,\n            realtime: _lib_constants__WEBPACK_IMPORTED_MODULE_3__.DEFAULT_REALTIME_OPTIONS,\n            auth: Object.assign(Object.assign({}, _lib_constants__WEBPACK_IMPORTED_MODULE_3__.DEFAULT_AUTH_OPTIONS), { storageKey: defaultStorageKey }),\n            global: _lib_constants__WEBPACK_IMPORTED_MODULE_3__.DEFAULT_GLOBAL_OPTIONS,\n        };\n        const settings = (0,_lib_helpers__WEBPACK_IMPORTED_MODULE_2__.applySettingDefaults)(options !== null && options !== void 0 ? options : {}, DEFAULTS);\n        this.storageKey = (_a = settings.auth.storageKey) !== null && _a !== void 0 ? _a : '';\n        this.headers = (_b = settings.global.headers) !== null && _b !== void 0 ? _b : {};\n        if (!settings.accessToken) {\n            this.auth = this._initSupabaseAuthClient((_c = settings.auth) !== null && _c !== void 0 ? _c : {}, this.headers, settings.global.fetch);\n        }\n        else {\n            this.accessToken = settings.accessToken;\n            this.auth = new Proxy({}, {\n                get: (_, prop) => {\n                    throw new Error(`@supabase/supabase-js: Supabase Client is configured with the accessToken option, accessing supabase.auth.${String(prop)} is not possible`);\n                },\n            });\n        }\n        this.fetch = (0,_lib_fetch__WEBPACK_IMPORTED_MODULE_4__.fetchWithAuth)(supabaseKey, this._getAccessToken.bind(this), settings.global.fetch);\n        this.realtime = this._initRealtimeClient(Object.assign({ headers: this.headers }, settings.realtime));\n        this.rest = new _supabase_postgrest_js__WEBPACK_IMPORTED_MODULE_0__.PostgrestClient(`${_supabaseUrl}/rest/v1`, {\n            headers: this.headers,\n            schema: settings.db.schema,\n            fetch: this.fetch,\n        });\n        if (!settings.accessToken) {\n            this._listenForAuthEvents();\n        }\n    }\n    /**\n     * Supabase Functions allows you to deploy and invoke edge functions.\n     */\n    get functions() {\n        return new _supabase_functions_js__WEBPACK_IMPORTED_MODULE_5__.FunctionsClient(this.functionsUrl, {\n            headers: this.headers,\n            customFetch: this.fetch,\n        });\n    }\n    /**\n     * Supabase Storage allows you to manage user-generated content, such as photos or videos.\n     */\n    get storage() {\n        return new _supabase_storage_js__WEBPACK_IMPORTED_MODULE_6__.StorageClient(this.storageUrl, this.headers, this.fetch);\n    }\n    /**\n     * Perform a query on a table or a view.\n     *\n     * @param relation - The table or view name to query\n     */\n    from(relation) {\n        return this.rest.from(relation);\n    }\n    // NOTE: signatures must be kept in sync with PostgrestClient.schema\n    /**\n     * Select a schema to query or perform an function (rpc) call.\n     *\n     * The schema needs to be on the list of exposed schemas inside Supabase.\n     *\n     * @param schema - The schema to query\n     */\n    schema(schema) {\n        return this.rest.schema(schema);\n    }\n    // NOTE: signatures must be kept in sync with PostgrestClient.rpc\n    /**\n     * Perform a function call.\n     *\n     * @param fn - The function name to call\n     * @param args - The arguments to pass to the function call\n     * @param options - Named parameters\n     * @param options.head - When set to `true`, `data` will not be returned.\n     * Useful if you only need the count.\n     * @param options.get - When set to `true`, the function will be called with\n     * read-only access mode.\n     * @param options.count - Count algorithm to use to count rows returned by the\n     * function. Only applicable for [set-returning\n     * functions](https://www.postgresql.org/docs/current/functions-srf.html).\n     *\n     * `\"exact\"`: Exact but slow count algorithm. Performs a `COUNT(*)` under the\n     * hood.\n     *\n     * `\"planned\"`: Approximated but fast count algorithm. Uses the Postgres\n     * statistics under the hood.\n     *\n     * `\"estimated\"`: Uses exact count for low numbers and planned count for high\n     * numbers.\n     */\n    rpc(fn, args = {}, options = {}) {\n        return this.rest.rpc(fn, args, options);\n    }\n    /**\n     * Creates a Realtime channel with Broadcast, Presence, and Postgres Changes.\n     *\n     * @param {string} name - The name of the Realtime channel.\n     * @param {Object} opts - The options to pass to the Realtime channel.\n     *\n     */\n    channel(name, opts = { config: {} }) {\n        return this.realtime.channel(name, opts);\n    }\n    /**\n     * Returns all Realtime channels.\n     */\n    getChannels() {\n        return this.realtime.getChannels();\n    }\n    /**\n     * Unsubscribes and removes Realtime channel from Realtime client.\n     *\n     * @param {RealtimeChannel} channel - The name of the Realtime channel.\n     *\n     */\n    removeChannel(channel) {\n        return this.realtime.removeChannel(channel);\n    }\n    /**\n     * Unsubscribes and removes all Realtime channels from Realtime client.\n     */\n    removeAllChannels() {\n        return this.realtime.removeAllChannels();\n    }\n    _getAccessToken() {\n        var _a, _b;\n        return __awaiter(this, void 0, void 0, function* () {\n            if (this.accessToken) {\n                return yield this.accessToken();\n            }\n            const { data } = yield this.auth.getSession();\n            return (_b = (_a = data.session) === null || _a === void 0 ? void 0 : _a.access_token) !== null && _b !== void 0 ? _b : null;\n        });\n    }\n    _initSupabaseAuthClient({ autoRefreshToken, persistSession, detectSessionInUrl, storage, storageKey, flowType, lock, debug, }, headers, fetch) {\n        var _a;\n        const authHeaders = {\n            Authorization: `Bearer ${this.supabaseKey}`,\n            apikey: `${this.supabaseKey}`,\n        };\n        return new _lib_SupabaseAuthClient__WEBPACK_IMPORTED_MODULE_7__.SupabaseAuthClient({\n            url: this.authUrl,\n            headers: Object.assign(Object.assign({}, authHeaders), headers),\n            storageKey: storageKey,\n            autoRefreshToken,\n            persistSession,\n            detectSessionInUrl,\n            storage,\n            flowType,\n            lock,\n            debug,\n            fetch,\n            // auth checks if there is a custom authorizaiton header using this flag\n            // so it knows whether to return an error when getUser is called with no session\n            hasCustomAuthorizationHeader: (_a = 'Authorization' in this.headers) !== null && _a !== void 0 ? _a : false,\n        });\n    }\n    _initRealtimeClient(options) {\n        return new _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_1__.RealtimeClient(this.realtimeUrl, Object.assign(Object.assign({}, options), { params: Object.assign({ apikey: this.supabaseKey }, options === null || options === void 0 ? void 0 : options.params) }));\n    }\n    _listenForAuthEvents() {\n        let data = this.auth.onAuthStateChange((event, session) => {\n            this._handleTokenChanged(event, 'CLIENT', session === null || session === void 0 ? void 0 : session.access_token);\n        });\n        return data;\n    }\n    _handleTokenChanged(event, source, token) {\n        if ((event === 'TOKEN_REFRESHED' || event === 'SIGNED_IN') &&\n            this.changedAccessToken !== token) {\n            // Token has changed\n            this.realtime.setAuth(token !== null && token !== void 0 ? token : null);\n            this.changedAccessToken = token;\n        }\n        else if (event === 'SIGNED_OUT') {\n            // Token is removed\n            this.realtime.setAuth(this.supabaseKey);\n            if (source == 'STORAGE')\n                this.auth.signOut();\n            this.changedAccessToken = undefined;\n        }\n    }\n}\n//# sourceMappingURL=SupabaseClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/SupabaseClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/index.js ***!
  \*****************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   AuthAdminApi: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthAdminApi),\n/* harmony export */   AuthApiError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthApiError),\n/* harmony export */   AuthClient: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthClient),\n/* harmony export */   AuthError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthError),\n/* harmony export */   AuthImplicitGrantRedirectError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthImplicitGrantRedirectError),\n/* harmony export */   AuthInvalidCredentialsError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthInvalidCredentialsError),\n/* harmony export */   AuthInvalidTokenResponseError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthInvalidTokenResponseError),\n/* harmony export */   AuthPKCEGrantCodeExchangeError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthPKCEGrantCodeExchangeError),\n/* harmony export */   AuthRetryableFetchError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthRetryableFetchError),\n/* harmony export */   AuthSessionMissingError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthSessionMissingError),\n/* harmony export */   AuthUnknownError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthUnknownError),\n/* harmony export */   AuthWeakPasswordError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthWeakPasswordError),\n/* harmony export */   CustomAuthError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.CustomAuthError),\n/* harmony export */   FunctionRegion: () => (/* reexport safe */ _supabase_functions_js__WEBPACK_IMPORTED_MODULE_1__.FunctionRegion),\n/* harmony export */   FunctionsError: () => (/* reexport safe */ _supabase_functions_js__WEBPACK_IMPORTED_MODULE_1__.FunctionsError),\n/* harmony export */   FunctionsFetchError: () => (/* reexport safe */ _supabase_functions_js__WEBPACK_IMPORTED_MODULE_1__.FunctionsFetchError),\n/* harmony export */   FunctionsHttpError: () => (/* reexport safe */ _supabase_functions_js__WEBPACK_IMPORTED_MODULE_1__.FunctionsHttpError),\n/* harmony export */   FunctionsRelayError: () => (/* reexport safe */ _supabase_functions_js__WEBPACK_IMPORTED_MODULE_1__.FunctionsRelayError),\n/* harmony export */   GoTrueAdminApi: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.GoTrueAdminApi),\n/* harmony export */   GoTrueClient: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.GoTrueClient),\n/* harmony export */   NavigatorLockAcquireTimeoutError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.NavigatorLockAcquireTimeoutError),\n/* harmony export */   REALTIME_CHANNEL_STATES: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.REALTIME_CHANNEL_STATES),\n/* harmony export */   REALTIME_LISTEN_TYPES: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.REALTIME_LISTEN_TYPES),\n/* harmony export */   REALTIME_POSTGRES_CHANGES_LISTEN_EVENT: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.REALTIME_POSTGRES_CHANGES_LISTEN_EVENT),\n/* harmony export */   REALTIME_PRESENCE_LISTEN_EVENTS: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.REALTIME_PRESENCE_LISTEN_EVENTS),\n/* harmony export */   REALTIME_SUBSCRIBE_STATES: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.REALTIME_SUBSCRIBE_STATES),\n/* harmony export */   RealtimeChannel: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.RealtimeChannel),\n/* harmony export */   RealtimeClient: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.RealtimeClient),\n/* harmony export */   RealtimePresence: () => (/* reexport safe */ _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__.RealtimePresence),\n/* harmony export */   SupabaseClient: () => (/* reexport safe */ _SupabaseClient__WEBPACK_IMPORTED_MODULE_3__[\"default\"]),\n/* harmony export */   createClient: () => (/* binding */ createClient),\n/* harmony export */   isAuthApiError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.isAuthApiError),\n/* harmony export */   isAuthError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.isAuthError),\n/* harmony export */   isAuthRetryableFetchError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.isAuthRetryableFetchError),\n/* harmony export */   isAuthWeakPasswordError: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.isAuthWeakPasswordError),\n/* harmony export */   lockInternals: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.lockInternals),\n/* harmony export */   navigatorLock: () => (/* reexport safe */ _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.navigatorLock)\n/* harmony export */ });\n/* harmony import */ var _SupabaseClient__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./SupabaseClient */ \"./node_modules/@supabase/supabase-js/dist/module/SupabaseClient.js\");\n/* harmony import */ var _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @supabase/auth-js */ \"./node_modules/@supabase/auth-js/dist/module/index.js\");\n/* harmony import */ var _supabase_functions_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @supabase/functions-js */ \"./node_modules/@supabase/functions-js/dist/module/types.js\");\n/* harmony import */ var _supabase_realtime_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! @supabase/realtime-js */ \"./node_modules/@supabase/realtime-js/dist/module/index.js\");\n\n\n\n\n\n/**\n * Creates a new Supabase Client.\n */\nconst createClient = (supabaseUrl, supabaseKey, options) => {\n    return new _SupabaseClient__WEBPACK_IMPORTED_MODULE_3__[\"default\"](supabaseUrl, supabaseKey, options);\n};\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/index.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/lib/SupabaseAuthClient.js":
/*!**********************************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/lib/SupabaseAuthClient.js ***!
  \**********************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   SupabaseAuthClient: () => (/* binding */ SupabaseAuthClient)\n/* harmony export */ });\n/* harmony import */ var _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @supabase/auth-js */ \"./node_modules/@supabase/auth-js/dist/module/index.js\");\n\nclass SupabaseAuthClient extends _supabase_auth_js__WEBPACK_IMPORTED_MODULE_0__.AuthClient {\n    constructor(options) {\n        super(options);\n    }\n}\n//# sourceMappingURL=SupabaseAuthClient.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/lib/SupabaseAuthClient.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/lib/constants.js":
/*!*************************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/lib/constants.js ***!
  \*************************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   DEFAULT_AUTH_OPTIONS: () => (/* binding */ DEFAULT_AUTH_OPTIONS),\n/* harmony export */   DEFAULT_DB_OPTIONS: () => (/* binding */ DEFAULT_DB_OPTIONS),\n/* harmony export */   DEFAULT_GLOBAL_OPTIONS: () => (/* binding */ DEFAULT_GLOBAL_OPTIONS),\n/* harmony export */   DEFAULT_HEADERS: () => (/* binding */ DEFAULT_HEADERS),\n/* harmony export */   DEFAULT_REALTIME_OPTIONS: () => (/* binding */ DEFAULT_REALTIME_OPTIONS)\n/* harmony export */ });\n/* harmony import */ var _version__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./version */ \"./node_modules/@supabase/supabase-js/dist/module/lib/version.js\");\n\nlet JS_ENV = '';\n// @ts-ignore\nif (typeof Deno !== 'undefined') {\n    JS_ENV = 'deno';\n}\nelse if (typeof document !== 'undefined') {\n    JS_ENV = 'web';\n}\nelse if (typeof navigator !== 'undefined' && navigator.product === 'ReactNative') {\n    JS_ENV = 'react-native';\n}\nelse {\n    JS_ENV = 'node';\n}\nconst DEFAULT_HEADERS = { 'X-Client-Info': `supabase-js-${JS_ENV}/${_version__WEBPACK_IMPORTED_MODULE_0__.version}` };\nconst DEFAULT_GLOBAL_OPTIONS = {\n    headers: DEFAULT_HEADERS,\n};\nconst DEFAULT_DB_OPTIONS = {\n    schema: 'public',\n};\nconst DEFAULT_AUTH_OPTIONS = {\n    autoRefreshToken: true,\n    persistSession: true,\n    detectSessionInUrl: true,\n    flowType: 'implicit',\n};\nconst DEFAULT_REALTIME_OPTIONS = {};\n//# sourceMappingURL=constants.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/lib/constants.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/lib/fetch.js":
/*!*********************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/lib/fetch.js ***!
  \*********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   fetchWithAuth: () => (/* binding */ fetchWithAuth),\n/* harmony export */   resolveFetch: () => (/* binding */ resolveFetch),\n/* harmony export */   resolveHeadersConstructor: () => (/* binding */ resolveHeadersConstructor)\n/* harmony export */ });\n/* harmony import */ var _supabase_node_fetch__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! @supabase/node-fetch */ \"./node_modules/@supabase/node-fetch/browser.js\");\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\n// @ts-ignore\n\nconst resolveFetch = (customFetch) => {\n    let _fetch;\n    if (customFetch) {\n        _fetch = customFetch;\n    }\n    else if (typeof fetch === 'undefined') {\n        _fetch = _supabase_node_fetch__WEBPACK_IMPORTED_MODULE_0__[\"default\"];\n    }\n    else {\n        _fetch = fetch;\n    }\n    return (...args) => _fetch(...args);\n};\nconst resolveHeadersConstructor = () => {\n    if (typeof Headers === 'undefined') {\n        return _supabase_node_fetch__WEBPACK_IMPORTED_MODULE_0__.Headers;\n    }\n    return Headers;\n};\nconst fetchWithAuth = (supabaseKey, getAccessToken, customFetch) => {\n    const fetch = resolveFetch(customFetch);\n    const HeadersConstructor = resolveHeadersConstructor();\n    return (input, init) => __awaiter(void 0, void 0, void 0, function* () {\n        var _a;\n        const accessToken = (_a = (yield getAccessToken())) !== null && _a !== void 0 ? _a : supabaseKey;\n        let headers = new HeadersConstructor(init === null || init === void 0 ? void 0 : init.headers);\n        if (!headers.has('apikey')) {\n            headers.set('apikey', supabaseKey);\n        }\n        if (!headers.has('Authorization')) {\n            headers.set('Authorization', `Bearer ${accessToken}`);\n        }\n        return fetch(input, Object.assign(Object.assign({}, init), { headers }));\n    });\n};\n//# sourceMappingURL=fetch.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/lib/fetch.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/lib/helpers.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/lib/helpers.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   applySettingDefaults: () => (/* binding */ applySettingDefaults),\n/* harmony export */   isBrowser: () => (/* binding */ isBrowser),\n/* harmony export */   stripTrailingSlash: () => (/* binding */ stripTrailingSlash),\n/* harmony export */   uuid: () => (/* binding */ uuid)\n/* harmony export */ });\nvar __awaiter = (undefined && undefined.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nfunction uuid() {\n    return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function (c) {\n        var r = (Math.random() * 16) | 0, v = c == 'x' ? r : (r & 0x3) | 0x8;\n        return v.toString(16);\n    });\n}\nfunction stripTrailingSlash(url) {\n    return url.replace(/\\/$/, '');\n}\nconst isBrowser = () => typeof window !== 'undefined';\nfunction applySettingDefaults(options, defaults) {\n    const { db: dbOptions, auth: authOptions, realtime: realtimeOptions, global: globalOptions, } = options;\n    const { db: DEFAULT_DB_OPTIONS, auth: DEFAULT_AUTH_OPTIONS, realtime: DEFAULT_REALTIME_OPTIONS, global: DEFAULT_GLOBAL_OPTIONS, } = defaults;\n    const result = {\n        db: Object.assign(Object.assign({}, DEFAULT_DB_OPTIONS), dbOptions),\n        auth: Object.assign(Object.assign({}, DEFAULT_AUTH_OPTIONS), authOptions),\n        realtime: Object.assign(Object.assign({}, DEFAULT_REALTIME_OPTIONS), realtimeOptions),\n        global: Object.assign(Object.assign({}, DEFAULT_GLOBAL_OPTIONS), globalOptions),\n        accessToken: () => __awaiter(this, void 0, void 0, function* () { return ''; }),\n    };\n    if (options.accessToken) {\n        result.accessToken = options.accessToken;\n    }\n    else {\n        // hack around Required<>\n        delete result.accessToken;\n    }\n    return result;\n}\n//# sourceMappingURL=helpers.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/lib/helpers.js?");

/***/ }),

/***/ "./node_modules/@supabase/supabase-js/dist/module/lib/version.js":
/*!***********************************************************************!*\
  !*** ./node_modules/@supabase/supabase-js/dist/module/lib/version.js ***!
  \***********************************************************************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   version: () => (/* binding */ version)\n/* harmony export */ });\nconst version = '2.45.2';\n//# sourceMappingURL=version.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/supabase-js/dist/module/lib/version.js?");

/***/ }),

/***/ "./node_modules/abbrev/abbrev.js":
/*!***************************************!*\
  !*** ./node_modules/abbrev/abbrev.js ***!
  \***************************************/
/***/ ((module, exports) => {

eval("module.exports = exports = abbrev.abbrev = abbrev\n\nabbrev.monkeyPatch = monkeyPatch\n\nfunction monkeyPatch () {\n  Object.defineProperty(Array.prototype, 'abbrev', {\n    value: function () { return abbrev(this) },\n    enumerable: false, configurable: true, writable: true\n  })\n\n  Object.defineProperty(Object.prototype, 'abbrev', {\n    value: function () { return abbrev(Object.keys(this)) },\n    enumerable: false, configurable: true, writable: true\n  })\n}\n\nfunction abbrev (list) {\n  if (arguments.length !== 1 || !Array.isArray(list)) {\n    list = Array.prototype.slice.call(arguments, 0)\n  }\n  for (var i = 0, l = list.length, args = [] ; i < l ; i ++) {\n    args[i] = typeof list[i] === \"string\" ? list[i] : String(list[i])\n  }\n\n  // sort them lexicographically, so that they're next to their nearest kin\n  args = args.sort(lexSort)\n\n  // walk through each, seeing how much it has in common with the next and previous\n  var abbrevs = {}\n    , prev = \"\"\n  for (var i = 0, l = args.length ; i < l ; i ++) {\n    var current = args[i]\n      , next = args[i + 1] || \"\"\n      , nextMatches = true\n      , prevMatches = true\n    if (current === next) continue\n    for (var j = 0, cl = current.length ; j < cl ; j ++) {\n      var curChar = current.charAt(j)\n      nextMatches = nextMatches && curChar === next.charAt(j)\n      prevMatches = prevMatches && curChar === prev.charAt(j)\n      if (!nextMatches && !prevMatches) {\n        j ++\n        break\n      }\n    }\n    prev = current\n    if (j === cl) {\n      abbrevs[current] = current\n      continue\n    }\n    for (var a = current.substr(0, j) ; j <= cl ; j ++) {\n      abbrevs[a] = current\n      a += current.charAt(j)\n    }\n  }\n  return abbrevs\n}\n\nfunction lexSort (a, b) {\n  return a === b ? 0 : a > b ? 1 : -1\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/abbrev/abbrev.js?");

/***/ }),

/***/ "./node_modules/agent-base/dist/src/index.js":
/*!***************************************************!*\
  !*** ./node_modules/agent-base/dist/src/index.js ***!
  \***************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nconst events_1 = __webpack_require__(/*! events */ \"./node_modules/events/events.js\");\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\"));\nconst promisify_1 = __importDefault(__webpack_require__(/*! ./promisify */ \"./node_modules/agent-base/dist/src/promisify.js\"));\nconst debug = debug_1.default('agent-base');\nfunction isAgent(v) {\n    return Boolean(v) && typeof v.addRequest === 'function';\n}\nfunction isSecureEndpoint() {\n    const { stack } = new Error();\n    if (typeof stack !== 'string')\n        return false;\n    return stack.split('\\n').some(l => l.indexOf('(https.js:') !== -1 || l.indexOf('node:https:') !== -1);\n}\nfunction createAgent(callback, opts) {\n    return new createAgent.Agent(callback, opts);\n}\n(function (createAgent) {\n    /**\n     * Base `http.Agent` implementation.\n     * No pooling/keep-alive is implemented by default.\n     *\n     * @param {Function} callback\n     * @api public\n     */\n    class Agent extends events_1.EventEmitter {\n        constructor(callback, _opts) {\n            super();\n            let opts = _opts;\n            if (typeof callback === 'function') {\n                this.callback = callback;\n            }\n            else if (callback) {\n                opts = callback;\n            }\n            // Timeout for the socket to be returned from the callback\n            this.timeout = null;\n            if (opts && typeof opts.timeout === 'number') {\n                this.timeout = opts.timeout;\n            }\n            // These aren't actually used by `agent-base`, but are required\n            // for the TypeScript definition files in `@types/node` :/\n            this.maxFreeSockets = 1;\n            this.maxSockets = 1;\n            this.maxTotalSockets = Infinity;\n            this.sockets = {};\n            this.freeSockets = {};\n            this.requests = {};\n            this.options = {};\n        }\n        get defaultPort() {\n            if (typeof this.explicitDefaultPort === 'number') {\n                return this.explicitDefaultPort;\n            }\n            return isSecureEndpoint() ? 443 : 80;\n        }\n        set defaultPort(v) {\n            this.explicitDefaultPort = v;\n        }\n        get protocol() {\n            if (typeof this.explicitProtocol === 'string') {\n                return this.explicitProtocol;\n            }\n            return isSecureEndpoint() ? 'https:' : 'http:';\n        }\n        set protocol(v) {\n            this.explicitProtocol = v;\n        }\n        callback(req, opts, fn) {\n            throw new Error('\"agent-base\" has no default implementation, you must subclass and override `callback()`');\n        }\n        /**\n         * Called by node-core's \"_http_client.js\" module when creating\n         * a new HTTP request with this Agent instance.\n         *\n         * @api public\n         */\n        addRequest(req, _opts) {\n            const opts = Object.assign({}, _opts);\n            if (typeof opts.secureEndpoint !== 'boolean') {\n                opts.secureEndpoint = isSecureEndpoint();\n            }\n            if (opts.host == null) {\n                opts.host = 'localhost';\n            }\n            if (opts.port == null) {\n                opts.port = opts.secureEndpoint ? 443 : 80;\n            }\n            if (opts.protocol == null) {\n                opts.protocol = opts.secureEndpoint ? 'https:' : 'http:';\n            }\n            if (opts.host && opts.path) {\n                // If both a `host` and `path` are specified then it's most\n                // likely the result of a `url.parse()` call... we need to\n                // remove the `path` portion so that `net.connect()` doesn't\n                // attempt to open that as a unix socket file.\n                delete opts.path;\n            }\n            delete opts.agent;\n            delete opts.hostname;\n            delete opts._defaultAgent;\n            delete opts.defaultPort;\n            delete opts.createConnection;\n            // Hint to use \"Connection: close\"\n            // XXX: non-documented `http` module API :(\n            req._last = true;\n            req.shouldKeepAlive = false;\n            let timedOut = false;\n            let timeoutId = null;\n            const timeoutMs = opts.timeout || this.timeout;\n            const onerror = (err) => {\n                if (req._hadError)\n                    return;\n                req.emit('error', err);\n                // For Safety. Some additional errors might fire later on\n                // and we need to make sure we don't double-fire the error event.\n                req._hadError = true;\n            };\n            const ontimeout = () => {\n                timeoutId = null;\n                timedOut = true;\n                const err = new Error(`A \"socket\" was not created for HTTP request before ${timeoutMs}ms`);\n                err.code = 'ETIMEOUT';\n                onerror(err);\n            };\n            const callbackError = (err) => {\n                if (timedOut)\n                    return;\n                if (timeoutId !== null) {\n                    clearTimeout(timeoutId);\n                    timeoutId = null;\n                }\n                onerror(err);\n            };\n            const onsocket = (socket) => {\n                if (timedOut)\n                    return;\n                if (timeoutId != null) {\n                    clearTimeout(timeoutId);\n                    timeoutId = null;\n                }\n                if (isAgent(socket)) {\n                    // `socket` is actually an `http.Agent` instance, so\n                    // relinquish responsibility for this `req` to the Agent\n                    // from here on\n                    debug('Callback returned another Agent instance %o', socket.constructor.name);\n                    socket.addRequest(req, opts);\n                    return;\n                }\n                if (socket) {\n                    socket.once('free', () => {\n                        this.freeSocket(socket, opts);\n                    });\n                    req.onSocket(socket);\n                    return;\n                }\n                const err = new Error(`no Duplex stream was returned to agent-base for \\`${req.method} ${req.path}\\``);\n                onerror(err);\n            };\n            if (typeof this.callback !== 'function') {\n                onerror(new Error('`callback` is not defined'));\n                return;\n            }\n            if (!this.promisifiedCallback) {\n                if (this.callback.length >= 3) {\n                    debug('Converting legacy callback function to promise');\n                    this.promisifiedCallback = promisify_1.default(this.callback);\n                }\n                else {\n                    this.promisifiedCallback = this.callback;\n                }\n            }\n            if (typeof timeoutMs === 'number' && timeoutMs > 0) {\n                timeoutId = setTimeout(ontimeout, timeoutMs);\n            }\n            if ('port' in opts && typeof opts.port !== 'number') {\n                opts.port = Number(opts.port);\n            }\n            try {\n                debug('Resolving socket for %o request: %o', opts.protocol, `${req.method} ${req.path}`);\n                Promise.resolve(this.promisifiedCallback(req, opts)).then(onsocket, callbackError);\n            }\n            catch (err) {\n                Promise.reject(err).catch(callbackError);\n            }\n        }\n        freeSocket(socket, opts) {\n            debug('Freeing socket %o %o', socket.constructor.name, opts);\n            socket.destroy();\n        }\n        destroy() {\n            debug('Destroying agent %o', this.constructor.name);\n        }\n    }\n    createAgent.Agent = Agent;\n    // So that `instanceof` works correctly\n    createAgent.prototype = createAgent.Agent.prototype;\n})(createAgent || (createAgent = {}));\nmodule.exports = createAgent;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/agent-base/dist/src/index.js?");

/***/ }),

/***/ "./node_modules/agent-base/dist/src/promisify.js":
/*!*******************************************************!*\
  !*** ./node_modules/agent-base/dist/src/promisify.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nfunction promisify(fn) {\n    return function (req, opts) {\n        return new Promise((resolve, reject) => {\n            fn.call(this, req, opts, (err, rtn) => {\n                if (err) {\n                    reject(err);\n                }\n                else {\n                    resolve(rtn);\n                }\n            });\n        });\n    };\n}\nexports[\"default\"] = promisify;\n//# sourceMappingURL=promisify.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/agent-base/dist/src/promisify.js?");

/***/ }),

/***/ "./node_modules/ansi-regex/index.js":
/*!******************************************!*\
  !*** ./node_modules/ansi-regex/index.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = ({onlyFirst = false} = {}) => {\n\tconst pattern = [\n\t\t'[\\\\u001B\\\\u009B][[\\\\]()#;?]*(?:(?:(?:(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]+)*|[a-zA-Z\\\\d]+(?:;[-a-zA-Z\\\\d\\\\/#&.:=?%@~_]*)*)?\\\\u0007)',\n\t\t'(?:(?:\\\\d{1,4}(?:;\\\\d{0,4})*)?[\\\\dA-PR-TZcf-ntqry=><~]))'\n\t].join('|');\n\n\treturn new RegExp(pattern, onlyFirst ? undefined : 'g');\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/ansi-regex/index.js?");

/***/ }),

/***/ "./node_modules/aproba/index.js":
/*!**************************************!*\
  !*** ./node_modules/aproba/index.js ***!
  \**************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = validate\n\nfunction isArguments (thingy) {\n  return thingy != null && typeof thingy === 'object' && thingy.hasOwnProperty('callee')\n}\n\nconst types = {\n  '*': {label: 'any', check: () => true},\n  A: {label: 'array', check: _ => Array.isArray(_) || isArguments(_)},\n  S: {label: 'string', check: _ => typeof _ === 'string'},\n  N: {label: 'number', check: _ => typeof _ === 'number'},\n  F: {label: 'function', check: _ => typeof _ === 'function'},\n  O: {label: 'object', check: _ => typeof _ === 'object' && _ != null && !types.A.check(_) && !types.E.check(_)},\n  B: {label: 'boolean', check: _ => typeof _ === 'boolean'},\n  E: {label: 'error', check: _ => _ instanceof Error},\n  Z: {label: 'null', check: _ => _ == null}\n}\n\nfunction addSchema (schema, arity) {\n  const group = arity[schema.length] = arity[schema.length] || []\n  if (group.indexOf(schema) === -1) group.push(schema)\n}\n\nfunction validate (rawSchemas, args) {\n  if (arguments.length !== 2) throw wrongNumberOfArgs(['SA'], arguments.length)\n  if (!rawSchemas) throw missingRequiredArg(0, 'rawSchemas')\n  if (!args) throw missingRequiredArg(1, 'args')\n  if (!types.S.check(rawSchemas)) throw invalidType(0, ['string'], rawSchemas)\n  if (!types.A.check(args)) throw invalidType(1, ['array'], args)\n  const schemas = rawSchemas.split('|')\n  const arity = {}\n\n  schemas.forEach(schema => {\n    for (let ii = 0; ii < schema.length; ++ii) {\n      const type = schema[ii]\n      if (!types[type]) throw unknownType(ii, type)\n    }\n    if (/E.*E/.test(schema)) throw moreThanOneError(schema)\n    addSchema(schema, arity)\n    if (/E/.test(schema)) {\n      addSchema(schema.replace(/E.*$/, 'E'), arity)\n      addSchema(schema.replace(/E/, 'Z'), arity)\n      if (schema.length === 1) addSchema('', arity)\n    }\n  })\n  let matching = arity[args.length]\n  if (!matching) {\n    throw wrongNumberOfArgs(Object.keys(arity), args.length)\n  }\n  for (let ii = 0; ii < args.length; ++ii) {\n    let newMatching = matching.filter(schema => {\n      const type = schema[ii]\n      const typeCheck = types[type].check\n      return typeCheck(args[ii])\n    })\n    if (!newMatching.length) {\n      const labels = matching.map(_ => types[_[ii]].label).filter(_ => _ != null)\n      throw invalidType(ii, labels, args[ii])\n    }\n    matching = newMatching\n  }\n}\n\nfunction missingRequiredArg (num) {\n  return newException('EMISSINGARG', 'Missing required argument #' + (num + 1))\n}\n\nfunction unknownType (num, type) {\n  return newException('EUNKNOWNTYPE', 'Unknown type ' + type + ' in argument #' + (num + 1))\n}\n\nfunction invalidType (num, expectedTypes, value) {\n  let valueType\n  Object.keys(types).forEach(typeCode => {\n    if (types[typeCode].check(value)) valueType = types[typeCode].label\n  })\n  return newException('EINVALIDTYPE', 'Argument #' + (num + 1) + ': Expected ' +\n    englishList(expectedTypes) + ' but got ' + valueType)\n}\n\nfunction englishList (list) {\n  return list.join(', ').replace(/, ([^,]+)$/, ' or $1')\n}\n\nfunction wrongNumberOfArgs (expected, got) {\n  const english = englishList(expected)\n  const args = expected.every(ex => ex.length === 1)\n    ? 'argument'\n    : 'arguments'\n  return newException('EWRONGARGCOUNT', 'Expected ' + english + ' ' + args + ' but got ' + got)\n}\n\nfunction moreThanOneError (schema) {\n  return newException('ETOOMANYERRORTYPES',\n    'Only one error type per argument signature is allowed, more than one found in \"' + schema + '\"')\n}\n\nfunction newException (code, msg) {\n  const err = new Error(msg)\n  err.code = code\n  /* istanbul ignore else */\n  if (Error.captureStackTrace) Error.captureStackTrace(err, validate)\n  return err\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/aproba/index.js?");

/***/ }),

/***/ "./node_modules/are-we-there-yet/lib/index.js":
/*!****************************************************!*\
  !*** ./node_modules/are-we-there-yet/lib/index.js ***!
  \****************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nexports.TrackerGroup = __webpack_require__(/*! ./tracker-group.js */ \"./node_modules/are-we-there-yet/lib/tracker-group.js\")\nexports.Tracker = __webpack_require__(/*! ./tracker.js */ \"./node_modules/are-we-there-yet/lib/tracker.js\")\nexports.TrackerStream = __webpack_require__(/*! ./tracker-stream.js */ \"./node_modules/are-we-there-yet/lib/tracker-stream.js\")\n\n\n//# sourceURL=webpack://thelambda/./node_modules/are-we-there-yet/lib/index.js?");

/***/ }),

/***/ "./node_modules/are-we-there-yet/lib/tracker-base.js":
/*!***********************************************************!*\
  !*** ./node_modules/are-we-there-yet/lib/tracker-base.js ***!
  \***********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar EventEmitter = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter)\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\n\nvar trackerId = 0\nvar TrackerBase = module.exports = function (name) {\n  EventEmitter.call(this)\n  this.id = ++trackerId\n  this.name = name\n}\nutil.inherits(TrackerBase, EventEmitter)\n\n\n//# sourceURL=webpack://thelambda/./node_modules/are-we-there-yet/lib/tracker-base.js?");

/***/ }),

/***/ "./node_modules/are-we-there-yet/lib/tracker-group.js":
/*!************************************************************!*\
  !*** ./node_modules/are-we-there-yet/lib/tracker-group.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\nvar TrackerBase = __webpack_require__(/*! ./tracker-base.js */ \"./node_modules/are-we-there-yet/lib/tracker-base.js\")\nvar Tracker = __webpack_require__(/*! ./tracker.js */ \"./node_modules/are-we-there-yet/lib/tracker.js\")\nvar TrackerStream = __webpack_require__(/*! ./tracker-stream.js */ \"./node_modules/are-we-there-yet/lib/tracker-stream.js\")\n\nvar TrackerGroup = module.exports = function (name) {\n  TrackerBase.call(this, name)\n  this.parentGroup = null\n  this.trackers = []\n  this.completion = {}\n  this.weight = {}\n  this.totalWeight = 0\n  this.finished = false\n  this.bubbleChange = bubbleChange(this)\n}\nutil.inherits(TrackerGroup, TrackerBase)\n\nfunction bubbleChange (trackerGroup) {\n  return function (name, completed, tracker) {\n    trackerGroup.completion[tracker.id] = completed\n    if (trackerGroup.finished) {\n      return\n    }\n    trackerGroup.emit('change', name || trackerGroup.name, trackerGroup.completed(), trackerGroup)\n  }\n}\n\nTrackerGroup.prototype.nameInTree = function () {\n  var names = []\n  var from = this\n  while (from) {\n    names.unshift(from.name)\n    from = from.parentGroup\n  }\n  return names.join('/')\n}\n\nTrackerGroup.prototype.addUnit = function (unit, weight) {\n  if (unit.addUnit) {\n    var toTest = this\n    while (toTest) {\n      if (unit === toTest) {\n        throw new Error(\n          'Attempted to add tracker group ' +\n          unit.name + ' to tree that already includes it ' +\n          this.nameInTree(this))\n      }\n      toTest = toTest.parentGroup\n    }\n    unit.parentGroup = this\n  }\n  this.weight[unit.id] = weight || 1\n  this.totalWeight += this.weight[unit.id]\n  this.trackers.push(unit)\n  this.completion[unit.id] = unit.completed()\n  unit.on('change', this.bubbleChange)\n  if (!this.finished) {\n    this.emit('change', unit.name, this.completion[unit.id], unit)\n  }\n  return unit\n}\n\nTrackerGroup.prototype.completed = function () {\n  if (this.trackers.length === 0) {\n    return 0\n  }\n  var valPerWeight = 1 / this.totalWeight\n  var completed = 0\n  for (var ii = 0; ii < this.trackers.length; ii++) {\n    var trackerId = this.trackers[ii].id\n    completed +=\n      valPerWeight * this.weight[trackerId] * this.completion[trackerId]\n  }\n  return completed\n}\n\nTrackerGroup.prototype.newGroup = function (name, weight) {\n  return this.addUnit(new TrackerGroup(name), weight)\n}\n\nTrackerGroup.prototype.newItem = function (name, todo, weight) {\n  return this.addUnit(new Tracker(name, todo), weight)\n}\n\nTrackerGroup.prototype.newStream = function (name, todo, weight) {\n  return this.addUnit(new TrackerStream(name, todo), weight)\n}\n\nTrackerGroup.prototype.finish = function () {\n  this.finished = true\n  if (!this.trackers.length) {\n    this.addUnit(new Tracker(), 1, true)\n  }\n  for (var ii = 0; ii < this.trackers.length; ii++) {\n    var tracker = this.trackers[ii]\n    tracker.finish()\n    tracker.removeListener('change', this.bubbleChange)\n  }\n  this.emit('change', this.name, 1, this)\n}\n\nvar buffer = '                                  '\nTrackerGroup.prototype.debug = function (depth) {\n  depth = depth || 0\n  var indent = depth ? buffer.substr(0, depth) : ''\n  var output = indent + (this.name || 'top') + ': ' + this.completed() + '\\n'\n  this.trackers.forEach(function (tracker) {\n    if (tracker instanceof TrackerGroup) {\n      output += tracker.debug(depth + 1)\n    } else {\n      output += indent + ' ' + tracker.name + ': ' + tracker.completed() + '\\n'\n    }\n  })\n  return output\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/are-we-there-yet/lib/tracker-group.js?");

/***/ }),

/***/ "./node_modules/are-we-there-yet/lib/tracker-stream.js":
/*!*************************************************************!*\
  !*** ./node_modules/are-we-there-yet/lib/tracker-stream.js ***!
  \*************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\nvar stream = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/readable-browser.js\")\nvar delegate = __webpack_require__(/*! delegates */ \"./node_modules/delegates/index.js\")\nvar Tracker = __webpack_require__(/*! ./tracker.js */ \"./node_modules/are-we-there-yet/lib/tracker.js\")\n\nvar TrackerStream = module.exports = function (name, size, options) {\n  stream.Transform.call(this, options)\n  this.tracker = new Tracker(name, size)\n  this.name = name\n  this.id = this.tracker.id\n  this.tracker.on('change', delegateChange(this))\n}\nutil.inherits(TrackerStream, stream.Transform)\n\nfunction delegateChange (trackerStream) {\n  return function (name, completion, tracker) {\n    trackerStream.emit('change', name, completion, trackerStream)\n  }\n}\n\nTrackerStream.prototype._transform = function (data, encoding, cb) {\n  this.tracker.completeWork(data.length ? data.length : 1)\n  this.push(data)\n  cb()\n}\n\nTrackerStream.prototype._flush = function (cb) {\n  this.tracker.finish()\n  cb()\n}\n\ndelegate(TrackerStream.prototype, 'tracker')\n  .method('completed')\n  .method('addWork')\n  .method('finish')\n\n\n//# sourceURL=webpack://thelambda/./node_modules/are-we-there-yet/lib/tracker-stream.js?");

/***/ }),

/***/ "./node_modules/are-we-there-yet/lib/tracker.js":
/*!******************************************************!*\
  !*** ./node_modules/are-we-there-yet/lib/tracker.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\nvar TrackerBase = __webpack_require__(/*! ./tracker-base.js */ \"./node_modules/are-we-there-yet/lib/tracker-base.js\")\n\nvar Tracker = module.exports = function (name, todo) {\n  TrackerBase.call(this, name)\n  this.workDone = 0\n  this.workTodo = todo || 0\n}\nutil.inherits(Tracker, TrackerBase)\n\nTracker.prototype.completed = function () {\n  return this.workTodo === 0 ? 0 : this.workDone / this.workTodo\n}\n\nTracker.prototype.addWork = function (work) {\n  this.workTodo += work\n  this.emit('change', this.name, this.completed(), this)\n}\n\nTracker.prototype.completeWork = function (work) {\n  this.workDone += work\n  if (this.workDone > this.workTodo) {\n    this.workDone = this.workTodo\n  }\n  this.emit('change', this.name, this.completed(), this)\n}\n\nTracker.prototype.finish = function () {\n  this.workTodo = this.workDone = 1\n  this.emit('change', this.name, 1, this)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/are-we-there-yet/lib/tracker.js?");

/***/ }),

/***/ "./src/auth.js":
/*!*********************!*\
  !*** ./src/auth.js ***!
  \*********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ Auth)\n/* harmony export */ });\n/* harmony import */ var bcrypt__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! bcrypt */ \"./node_modules/bcrypt/bcrypt.js\");\n/* harmony import */ var _db__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./db */ \"./src/db.js\");\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError(\"Cannot call a class as a function\"); }\nfunction _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, \"value\" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }\nfunction _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, \"prototype\", { writable: !1 }), e; }\nfunction _defineProperty(e, r, t) { return (r = _toPropertyKey(r)) in e ? Object.defineProperty(e, r, { value: t, enumerable: !0, configurable: !0, writable: !0 }) : e[r] = t, e; }\nfunction _toPropertyKey(t) { var i = _toPrimitive(t, \"string\"); return \"symbol\" == _typeof(i) ? i : i + \"\"; }\nfunction _toPrimitive(t, r) { if (\"object\" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || \"default\"); if (\"object\" != _typeof(i)) return i; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (\"string\" === r ? String : Number)(t); }\n\n\nvar Auth = /*#__PURE__*/function () {\n  function Auth() {\n    _classCallCheck(this, Auth);\n    _defineProperty(this, \"connection\", (0,_db__WEBPACK_IMPORTED_MODULE_1__[\"default\"])());\n  }\n  return _createClass(Auth, [{\n    key: \"signUp\",\n    value: function signUp(email, password) {\n      var _this = this;\n      bcrypt__WEBPACK_IMPORTED_MODULE_0__.hash(password, 10, function (err, hash) {\n        if (err) {\n          console.error(err.message);\n        }\n        _this.connection.signUp(email, hash);\n      });\n    }\n  }]);\n}(); // bcrypt.compare(psd, '$2b$10$UxWLThzfjT8nYlZH1iHrcuIZ0Xr2V6hKcLYW/F6PXwfTyUMOa15Wy', (err, result) => {\n//     console.log(result);\n// })\n\n\n//# sourceURL=webpack://thelambda/./src/auth.js?");

/***/ }),

/***/ "./src/db.js":
/*!*******************!*\
  !*** ./src/db.js ***!
  \*******************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"default\": () => (/* binding */ DBcomunication)\n/* harmony export */ });\n/* harmony import */ var _supabase_supabase_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! @supabase/supabase-js */ \"./node_modules/@supabase/supabase-js/dist/module/index.js\");\n/* harmony import */ var dotenv__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! dotenv */ \"./node_modules/dotenv/lib/main.js\");\n/* harmony import */ var dotenv__WEBPACK_IMPORTED_MODULE_0___default = /*#__PURE__*/__webpack_require__.n(dotenv__WEBPACK_IMPORTED_MODULE_0__);\nfunction _typeof(o) { \"@babel/helpers - typeof\"; return _typeof = \"function\" == typeof Symbol && \"symbol\" == typeof Symbol.iterator ? function (o) { return typeof o; } : function (o) { return o && \"function\" == typeof Symbol && o.constructor === Symbol && o !== Symbol.prototype ? \"symbol\" : typeof o; }, _typeof(o); }\nfunction _classCallCheck(a, n) { if (!(a instanceof n)) throw new TypeError(\"Cannot call a class as a function\"); }\nfunction _defineProperties(e, r) { for (var t = 0; t < r.length; t++) { var o = r[t]; o.enumerable = o.enumerable || !1, o.configurable = !0, \"value\" in o && (o.writable = !0), Object.defineProperty(e, _toPropertyKey(o.key), o); } }\nfunction _createClass(e, r, t) { return r && _defineProperties(e.prototype, r), t && _defineProperties(e, t), Object.defineProperty(e, \"prototype\", { writable: !1 }), e; }\nfunction _toPropertyKey(t) { var i = _toPrimitive(t, \"string\"); return \"symbol\" == _typeof(i) ? i : i + \"\"; }\nfunction _toPrimitive(t, r) { if (\"object\" != _typeof(t) || !t) return t; var e = t[Symbol.toPrimitive]; if (void 0 !== e) { var i = e.call(t, r || \"default\"); if (\"object\" != _typeof(i)) return i; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (\"string\" === r ? String : Number)(t); }\n\n\n\n// Enable environmental variables\ndotenv__WEBPACK_IMPORTED_MODULE_0___default().config();\nvar DBcomunication = /*#__PURE__*/function () {\n  // Define constructor with database connection\n  function DBcomunication() {\n    var _this = this;\n    _classCallCheck(this, DBcomunication);\n    this.supabase = (0,_supabase_supabase_js__WEBPACK_IMPORTED_MODULE_1__.createClient)(process.env.SUPABASE_URL, process.env.SUPABASE_KEY);\n    // Auth with a database\n    this.supabase.auth.signInWithPassword({\n      email: process.env.EMAIL,\n      password: process.env.PASSWORD\n    }).then(function (response) {\n      _this.token = response.data.session.access_token;\n      _this.refresh_token = response.session.refresh_token;\n    })[\"catch\"](function (err) {\n      if (err) {\n        console.error(\"Error has occured while authorization process: \".concat(err.message));\n      }\n    });\n  }\n  // Define method to insert data into database\n  return _createClass(DBcomunication, [{\n    key: \"signUp\",\n    value: function signUp(pswd, email) {\n      this.supabase.from('users').insert({\n        login: email,\n        password: pswd\n      }).then(function (response) {\n        console.log(response);\n      });\n    }\n  }]);\n}();\n\n\n//# sourceURL=webpack://thelambda/./src/db.js?");

/***/ }),

/***/ "./src/index.js":
/*!**********************!*\
  !*** ./src/index.js ***!
  \**********************/
/***/ ((__unused_webpack_module, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony import */ var _auth__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./auth */ \"./src/auth.js\");\n\nvar form = document.createElement('form');\ndocument.getElementById('root').appendChild(form);\n\n//# sourceURL=webpack://thelambda/./src/index.js?");

/***/ }),

/***/ "./node_modules/balanced-match/index.js":
/*!**********************************************!*\
  !*** ./node_modules/balanced-match/index.js ***!
  \**********************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = balanced;\nfunction balanced(a, b, str) {\n  if (a instanceof RegExp) a = maybeMatch(a, str);\n  if (b instanceof RegExp) b = maybeMatch(b, str);\n\n  var r = range(a, b, str);\n\n  return r && {\n    start: r[0],\n    end: r[1],\n    pre: str.slice(0, r[0]),\n    body: str.slice(r[0] + a.length, r[1]),\n    post: str.slice(r[1] + b.length)\n  };\n}\n\nfunction maybeMatch(reg, str) {\n  var m = str.match(reg);\n  return m ? m[0] : null;\n}\n\nbalanced.range = range;\nfunction range(a, b, str) {\n  var begs, beg, left, right, result;\n  var ai = str.indexOf(a);\n  var bi = str.indexOf(b, ai + 1);\n  var i = ai;\n\n  if (ai >= 0 && bi > 0) {\n    if(a===b) {\n      return [ai, bi];\n    }\n    begs = [];\n    left = str.length;\n\n    while (i >= 0 && !result) {\n      if (i == ai) {\n        begs.push(i);\n        ai = str.indexOf(a, i + 1);\n      } else if (begs.length == 1) {\n        result = [ begs.pop(), bi ];\n      } else {\n        beg = begs.pop();\n        if (beg < left) {\n          left = beg;\n          right = bi;\n        }\n\n        bi = str.indexOf(b, i + 1);\n      }\n\n      i = ai < bi && ai >= 0 ? ai : bi;\n    }\n\n    if (begs.length) {\n      result = [ left, right ];\n    }\n  }\n\n  return result;\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/balanced-match/index.js?");

/***/ }),

/***/ "./node_modules/bcrypt/bcrypt.js":
/*!***************************************!*\
  !*** ./node_modules/bcrypt/bcrypt.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("var __dirname = \"/\";\n\n\nvar nodePreGyp = __webpack_require__(/*! @mapbox/node-pre-gyp */ \"./node_modules/@mapbox/node-pre-gyp/lib/node-pre-gyp.js\");\nvar path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nvar binding_path = nodePreGyp.find(path.resolve(path.join(__dirname, './package.json')));\nvar bindings = __webpack_require__(\"./node_modules/bcrypt sync recursive\")(binding_path);\n\nvar crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\n\nvar promises = __webpack_require__(/*! ./promises */ \"./node_modules/bcrypt/promises.js\");\n\n/// generate a salt (sync)\n/// @param {Number} [rounds] number of rounds (default 10)\n/// @return {String} salt\nmodule.exports.genSaltSync = function genSaltSync(rounds, minor) {\n    // default 10 rounds\n    if (!rounds) {\n        rounds = 10;\n    } else if (typeof rounds !== 'number') {\n        throw new Error('rounds must be a number');\n    }\n\n    if(!minor) {\n        minor = 'b';\n    } else if(minor !== 'b' && minor !== 'a') {\n        throw new Error('minor must be either \"a\" or \"b\"');\n    }\n\n    return bindings.gen_salt_sync(minor, rounds, crypto.randomBytes(16));\n};\n\n/// generate a salt\n/// @param {Number} [rounds] number of rounds (default 10)\n/// @param {Function} cb callback(err, salt)\nmodule.exports.genSalt = function genSalt(rounds, minor, cb) {\n    var error;\n\n    // if callback is first argument, then use defaults for others\n    if (typeof arguments[0] === 'function') {\n        // have to set callback first otherwise arguments are overriden\n        cb = arguments[0];\n        rounds = 10;\n        minor = 'b';\n    // callback is second argument\n    } else if (typeof arguments[1] === 'function') {\n        // have to set callback first otherwise arguments are overriden\n        cb = arguments[1];\n        minor = 'b';\n    }\n\n    if (!cb) {\n        return promises.promise(genSalt, this, [rounds, minor]);\n    }\n\n    // default 10 rounds\n    if (!rounds) {\n        rounds = 10;\n    } else if (typeof rounds !== 'number') {\n        // callback error asynchronously\n        error = new Error('rounds must be a number');\n        return process.nextTick(function() {\n            cb(error);\n        });\n    }\n\n    if(!minor) {\n        minor = 'b'\n    } else if(minor !== 'b' && minor !== 'a') {\n        error = new Error('minor must be either \"a\" or \"b\"');\n        return process.nextTick(function() {\n            cb(error);\n        });\n    }\n\n    crypto.randomBytes(16, function(error, randomBytes) {\n        if (error) {\n            cb(error);\n            return;\n        }\n\n        bindings.gen_salt(minor, rounds, randomBytes, cb);\n    });\n};\n\n/// hash data using a salt\n/// @param {String|Buffer} data the data to encrypt\n/// @param {String} salt the salt to use when hashing\n/// @return {String} hash\nmodule.exports.hashSync = function hashSync(data, salt) {\n    if (data == null || salt == null) {\n        throw new Error('data and salt arguments required');\n    }\n\n    if (!(typeof data === 'string' || data instanceof Buffer) || (typeof salt !== 'string' && typeof salt !== 'number')) {\n        throw new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');\n    }\n\n    if (typeof salt === 'number') {\n        salt = module.exports.genSaltSync(salt);\n    }\n\n    return bindings.encrypt_sync(data, salt);\n};\n\n/// hash data using a salt\n/// @param {String|Buffer} data the data to encrypt\n/// @param {String} salt the salt to use when hashing\n/// @param {Function} cb callback(err, hash)\nmodule.exports.hash = function hash(data, salt, cb) {\n    var error;\n\n    if (typeof data === 'function') {\n        error = new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');\n        return process.nextTick(function() {\n            data(error);\n        });\n    }\n\n    if (typeof salt === 'function') {\n        error = new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');\n        return process.nextTick(function() {\n            salt(error);\n        });\n    }\n\n    // cb exists but is not a function\n    // return a rejecting promise\n    if (cb && typeof cb !== 'function') {\n        return promises.reject(new Error('cb must be a function or null to return a Promise'));\n    }\n\n    if (!cb) {\n        return promises.promise(hash, this, [data, salt]);\n    }\n\n    if (data == null || salt == null) {\n        error = new Error('data and salt arguments required');\n        return process.nextTick(function() {\n            cb(error);\n        });\n    }\n\n    if (!(typeof data === 'string' || data instanceof Buffer) || (typeof salt !== 'string' && typeof salt !== 'number')) {\n        error = new Error('data must be a string or Buffer and salt must either be a salt string or a number of rounds');\n        return process.nextTick(function() {\n            cb(error);\n        });\n    }\n\n\n    if (typeof salt === 'number') {\n        return module.exports.genSalt(salt, function(err, salt) {\n            return bindings.encrypt(data, salt, cb);\n        });\n    }\n\n    return bindings.encrypt(data, salt, cb);\n};\n\n/// compare raw data to hash\n/// @param {String|Buffer} data the data to hash and compare\n/// @param {String} hash expected hash\n/// @return {bool} true if hashed data matches hash\nmodule.exports.compareSync = function compareSync(data, hash) {\n    if (data == null || hash == null) {\n        throw new Error('data and hash arguments required');\n    }\n\n    if (!(typeof data === 'string' || data instanceof Buffer) || typeof hash !== 'string') {\n        throw new Error('data must be a string or Buffer and hash must be a string');\n    }\n\n    return bindings.compare_sync(data, hash);\n};\n\n/// compare raw data to hash\n/// @param {String|Buffer} data the data to hash and compare\n/// @param {String} hash expected hash\n/// @param {Function} cb callback(err, matched) - matched is true if hashed data matches hash\nmodule.exports.compare = function compare(data, hash, cb) {\n    var error;\n\n    if (typeof data === 'function') {\n        error = new Error('data and hash arguments required');\n        return process.nextTick(function() {\n            data(error);\n        });\n    }\n\n    if (typeof hash === 'function') {\n        error = new Error('data and hash arguments required');\n        return process.nextTick(function() {\n            hash(error);\n        });\n    }\n\n    // cb exists but is not a function\n    // return a rejecting promise\n    if (cb && typeof cb !== 'function') {\n        return promises.reject(new Error('cb must be a function or null to return a Promise'));\n    }\n\n    if (!cb) {\n        return promises.promise(compare, this, [data, hash]);\n    }\n\n    if (data == null || hash == null) {\n        error = new Error('data and hash arguments required');\n        return process.nextTick(function() {\n            cb(error);\n        });\n    }\n\n    if (!(typeof data === 'string' || data instanceof Buffer) || typeof hash !== 'string') {\n        error = new Error('data and hash must be strings');\n        return process.nextTick(function() {\n            cb(error);\n        });\n    }\n\n    return bindings.compare(data, hash, cb);\n};\n\n/// @param {String} hash extract rounds from this hash\n/// @return {Number} the number of rounds used to encrypt a given hash\nmodule.exports.getRounds = function getRounds(hash) {\n    if (hash == null) {\n        throw new Error('hash argument required');\n    }\n\n    if (typeof hash !== 'string') {\n        throw new Error('hash must be a string');\n    }\n\n    return bindings.get_rounds(hash);\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/bcrypt/bcrypt.js?");

/***/ }),

/***/ "./node_modules/bcrypt/promises.js":
/*!*****************************************!*\
  !*** ./node_modules/bcrypt/promises.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar Promise = __webpack_require__.g.Promise;\n\n/// encapsulate a method with a node-style callback in a Promise\n/// @param {object} 'this' of the encapsulated function\n/// @param {function} function to be encapsulated\n/// @param {Array-like} args to be passed to the called function\n/// @return {Promise} a Promise encapsulating the function\nmodule.exports.promise = function (fn, context, args) {\n\n    if (!Array.isArray(args)) {\n        args = Array.prototype.slice.call(args);\n    }\n\n    if (typeof fn !== 'function') {\n        return Promise.reject(new Error('fn must be a function'));\n    }\n\n    return new Promise(function(resolve, reject) {\n        args.push(function(err, data) {\n            if (err) {\n                reject(err);\n            } else {\n                resolve(data);\n            }\n        });\n\n        fn.apply(context, args);\n    });\n};\n\n/// @param {err} the error to be thrown\nmodule.exports.reject = function (err) {\n    return Promise.reject(err);\n};\n\n/// changes the promise implementation that bcrypt uses\n/// @param {Promise} the implementation to use\nmodule.exports.use = function(promise) {\n  Promise = promise;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/bcrypt/promises.js?");

/***/ }),

/***/ "./node_modules/bcrypt sync recursive":
/*!***********************************!*\
  !*** ./node_modules/bcrypt/ sync ***!
  \***********************************/
/***/ ((module) => {

eval("function webpackEmptyContext(req) {\n\tvar e = new Error(\"Cannot find module '\" + req + \"'\");\n\te.code = 'MODULE_NOT_FOUND';\n\tthrow e;\n}\nwebpackEmptyContext.keys = () => ([]);\nwebpackEmptyContext.resolve = webpackEmptyContext;\nwebpackEmptyContext.id = \"./node_modules/bcrypt sync recursive\";\nmodule.exports = webpackEmptyContext;\n\n//# sourceURL=webpack://thelambda/./node_modules/bcrypt/_sync?");

/***/ }),

/***/ "./node_modules/brace-expansion/index.js":
/*!***********************************************!*\
  !*** ./node_modules/brace-expansion/index.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var concatMap = __webpack_require__(/*! concat-map */ \"./node_modules/concat-map/index.js\");\nvar balanced = __webpack_require__(/*! balanced-match */ \"./node_modules/balanced-match/index.js\");\n\nmodule.exports = expandTop;\n\nvar escSlash = '\\0SLASH'+Math.random()+'\\0';\nvar escOpen = '\\0OPEN'+Math.random()+'\\0';\nvar escClose = '\\0CLOSE'+Math.random()+'\\0';\nvar escComma = '\\0COMMA'+Math.random()+'\\0';\nvar escPeriod = '\\0PERIOD'+Math.random()+'\\0';\n\nfunction numeric(str) {\n  return parseInt(str, 10) == str\n    ? parseInt(str, 10)\n    : str.charCodeAt(0);\n}\n\nfunction escapeBraces(str) {\n  return str.split('\\\\\\\\').join(escSlash)\n            .split('\\\\{').join(escOpen)\n            .split('\\\\}').join(escClose)\n            .split('\\\\,').join(escComma)\n            .split('\\\\.').join(escPeriod);\n}\n\nfunction unescapeBraces(str) {\n  return str.split(escSlash).join('\\\\')\n            .split(escOpen).join('{')\n            .split(escClose).join('}')\n            .split(escComma).join(',')\n            .split(escPeriod).join('.');\n}\n\n\n// Basically just str.split(\",\"), but handling cases\n// where we have nested braced sections, which should be\n// treated as individual members, like {a,{b,c},d}\nfunction parseCommaParts(str) {\n  if (!str)\n    return [''];\n\n  var parts = [];\n  var m = balanced('{', '}', str);\n\n  if (!m)\n    return str.split(',');\n\n  var pre = m.pre;\n  var body = m.body;\n  var post = m.post;\n  var p = pre.split(',');\n\n  p[p.length-1] += '{' + body + '}';\n  var postParts = parseCommaParts(post);\n  if (post.length) {\n    p[p.length-1] += postParts.shift();\n    p.push.apply(p, postParts);\n  }\n\n  parts.push.apply(parts, p);\n\n  return parts;\n}\n\nfunction expandTop(str) {\n  if (!str)\n    return [];\n\n  // I don't know why Bash 4.3 does this, but it does.\n  // Anything starting with {} will have the first two bytes preserved\n  // but *only* at the top level, so {},a}b will not expand to anything,\n  // but a{},b}c will be expanded to [a}c,abc].\n  // One could argue that this is a bug in Bash, but since the goal of\n  // this module is to match Bash's rules, we escape a leading {}\n  if (str.substr(0, 2) === '{}') {\n    str = '\\\\{\\\\}' + str.substr(2);\n  }\n\n  return expand(escapeBraces(str), true).map(unescapeBraces);\n}\n\nfunction identity(e) {\n  return e;\n}\n\nfunction embrace(str) {\n  return '{' + str + '}';\n}\nfunction isPadded(el) {\n  return /^-?0\\d/.test(el);\n}\n\nfunction lte(i, y) {\n  return i <= y;\n}\nfunction gte(i, y) {\n  return i >= y;\n}\n\nfunction expand(str, isTop) {\n  var expansions = [];\n\n  var m = balanced('{', '}', str);\n  if (!m || /\\$$/.test(m.pre)) return [str];\n\n  var isNumericSequence = /^-?\\d+\\.\\.-?\\d+(?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isAlphaSequence = /^[a-zA-Z]\\.\\.[a-zA-Z](?:\\.\\.-?\\d+)?$/.test(m.body);\n  var isSequence = isNumericSequence || isAlphaSequence;\n  var isOptions = m.body.indexOf(',') >= 0;\n  if (!isSequence && !isOptions) {\n    // {a},b}\n    if (m.post.match(/,.*\\}/)) {\n      str = m.pre + '{' + m.body + escClose + m.post;\n      return expand(str);\n    }\n    return [str];\n  }\n\n  var n;\n  if (isSequence) {\n    n = m.body.split(/\\.\\./);\n  } else {\n    n = parseCommaParts(m.body);\n    if (n.length === 1) {\n      // x{{a,b}}y ==> x{a}y x{b}y\n      n = expand(n[0], false).map(embrace);\n      if (n.length === 1) {\n        var post = m.post.length\n          ? expand(m.post, false)\n          : [''];\n        return post.map(function(p) {\n          return m.pre + n[0] + p;\n        });\n      }\n    }\n  }\n\n  // at this point, n is the parts, and we know it's not a comma set\n  // with a single entry.\n\n  // no need to expand pre, since it is guaranteed to be free of brace-sets\n  var pre = m.pre;\n  var post = m.post.length\n    ? expand(m.post, false)\n    : [''];\n\n  var N;\n\n  if (isSequence) {\n    var x = numeric(n[0]);\n    var y = numeric(n[1]);\n    var width = Math.max(n[0].length, n[1].length)\n    var incr = n.length == 3\n      ? Math.abs(numeric(n[2]))\n      : 1;\n    var test = lte;\n    var reverse = y < x;\n    if (reverse) {\n      incr *= -1;\n      test = gte;\n    }\n    var pad = n.some(isPadded);\n\n    N = [];\n\n    for (var i = x; test(i, y); i += incr) {\n      var c;\n      if (isAlphaSequence) {\n        c = String.fromCharCode(i);\n        if (c === '\\\\')\n          c = '';\n      } else {\n        c = String(i);\n        if (pad) {\n          var need = width - c.length;\n          if (need > 0) {\n            var z = new Array(need + 1).join('0');\n            if (i < 0)\n              c = '-' + z + c.slice(1);\n            else\n              c = z + c;\n          }\n        }\n      }\n      N.push(c);\n    }\n  } else {\n    N = concatMap(n, function(el) { return expand(el, false) });\n  }\n\n  for (var j = 0; j < N.length; j++) {\n    for (var k = 0; k < post.length; k++) {\n      var expansion = pre + N[j] + post[k];\n      if (!isTop || isSequence || expansion)\n        expansions.push(expansion);\n    }\n  }\n\n  return expansions;\n}\n\n\n\n//# sourceURL=webpack://thelambda/./node_modules/brace-expansion/index.js?");

/***/ }),

/***/ "./node_modules/call-bind/callBound.js":
/*!*********************************************!*\
  !*** ./node_modules/call-bind/callBound.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"./node_modules/get-intrinsic/index.js\");\n\nvar callBind = __webpack_require__(/*! ./ */ \"./node_modules/call-bind/index.js\");\n\nvar $indexOf = callBind(GetIntrinsic('String.prototype.indexOf'));\n\nmodule.exports = function callBoundIntrinsic(name, allowMissing) {\n\tvar intrinsic = GetIntrinsic(name, !!allowMissing);\n\tif (typeof intrinsic === 'function' && $indexOf(name, '.prototype.') > -1) {\n\t\treturn callBind(intrinsic);\n\t}\n\treturn intrinsic;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/call-bind/callBound.js?");

/***/ }),

/***/ "./node_modules/call-bind/index.js":
/*!*****************************************!*\
  !*** ./node_modules/call-bind/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar bind = __webpack_require__(/*! function-bind */ \"./node_modules/function-bind/index.js\");\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"./node_modules/get-intrinsic/index.js\");\nvar setFunctionLength = __webpack_require__(/*! set-function-length */ \"./node_modules/set-function-length/index.js\");\n\nvar $TypeError = __webpack_require__(/*! es-errors/type */ \"./node_modules/es-errors/type.js\");\nvar $apply = GetIntrinsic('%Function.prototype.apply%');\nvar $call = GetIntrinsic('%Function.prototype.call%');\nvar $reflectApply = GetIntrinsic('%Reflect.apply%', true) || bind.call($call, $apply);\n\nvar $defineProperty = __webpack_require__(/*! es-define-property */ \"./node_modules/es-define-property/index.js\");\nvar $max = GetIntrinsic('%Math.max%');\n\nmodule.exports = function callBind(originalFunction) {\n\tif (typeof originalFunction !== 'function') {\n\t\tthrow new $TypeError('a function is required');\n\t}\n\tvar func = $reflectApply(bind, $call, arguments);\n\treturn setFunctionLength(\n\t\tfunc,\n\t\t1 + $max(0, originalFunction.length - (arguments.length - 1)),\n\t\ttrue\n\t);\n};\n\nvar applyBind = function applyBind() {\n\treturn $reflectApply(bind, $apply, arguments);\n};\n\nif ($defineProperty) {\n\t$defineProperty(module.exports, 'apply', { value: applyBind });\n} else {\n\tmodule.exports.apply = applyBind;\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/call-bind/index.js?");

/***/ }),

/***/ "./node_modules/chownr/chownr.js":
/*!***************************************!*\
  !*** ./node_modules/chownr/chownr.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fs = __webpack_require__(/*! fs */ \"?6e8d\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\n/* istanbul ignore next */\nconst LCHOWN = fs.lchown ? 'lchown' : 'chown'\n/* istanbul ignore next */\nconst LCHOWNSYNC = fs.lchownSync ? 'lchownSync' : 'chownSync'\n\n/* istanbul ignore next */\nconst needEISDIRHandled = fs.lchown &&\n  !process.version.match(/v1[1-9]+\\./) &&\n  !process.version.match(/v10\\.[6-9]/)\n\nconst lchownSync = (path, uid, gid) => {\n  try {\n    return fs[LCHOWNSYNC](path, uid, gid)\n  } catch (er) {\n    if (er.code !== 'ENOENT')\n      throw er\n  }\n}\n\n/* istanbul ignore next */\nconst chownSync = (path, uid, gid) => {\n  try {\n    return fs.chownSync(path, uid, gid)\n  } catch (er) {\n    if (er.code !== 'ENOENT')\n      throw er\n  }\n}\n\n/* istanbul ignore next */\nconst handleEISDIR =\n  needEISDIRHandled ? (path, uid, gid, cb) => er => {\n    // Node prior to v10 had a very questionable implementation of\n    // fs.lchown, which would always try to call fs.open on a directory\n    // Fall back to fs.chown in those cases.\n    if (!er || er.code !== 'EISDIR')\n      cb(er)\n    else\n      fs.chown(path, uid, gid, cb)\n  }\n  : (_, __, ___, cb) => cb\n\n/* istanbul ignore next */\nconst handleEISDirSync =\n  needEISDIRHandled ? (path, uid, gid) => {\n    try {\n      return lchownSync(path, uid, gid)\n    } catch (er) {\n      if (er.code !== 'EISDIR')\n        throw er\n      chownSync(path, uid, gid)\n    }\n  }\n  : (path, uid, gid) => lchownSync(path, uid, gid)\n\n// fs.readdir could only accept an options object as of node v6\nconst nodeVersion = process.version\nlet readdir = (path, options, cb) => fs.readdir(path, options, cb)\nlet readdirSync = (path, options) => fs.readdirSync(path, options)\n/* istanbul ignore next */\nif (/^v4\\./.test(nodeVersion))\n  readdir = (path, options, cb) => fs.readdir(path, cb)\n\nconst chown = (cpath, uid, gid, cb) => {\n  fs[LCHOWN](cpath, uid, gid, handleEISDIR(cpath, uid, gid, er => {\n    // Skip ENOENT error\n    cb(er && er.code !== 'ENOENT' ? er : null)\n  }))\n}\n\nconst chownrKid = (p, child, uid, gid, cb) => {\n  if (typeof child === 'string')\n    return fs.lstat(path.resolve(p, child), (er, stats) => {\n      // Skip ENOENT error\n      if (er)\n        return cb(er.code !== 'ENOENT' ? er : null)\n      stats.name = child\n      chownrKid(p, stats, uid, gid, cb)\n    })\n\n  if (child.isDirectory()) {\n    chownr(path.resolve(p, child.name), uid, gid, er => {\n      if (er)\n        return cb(er)\n      const cpath = path.resolve(p, child.name)\n      chown(cpath, uid, gid, cb)\n    })\n  } else {\n    const cpath = path.resolve(p, child.name)\n    chown(cpath, uid, gid, cb)\n  }\n}\n\n\nconst chownr = (p, uid, gid, cb) => {\n  readdir(p, { withFileTypes: true }, (er, children) => {\n    // any error other than ENOTDIR or ENOTSUP means it's not readable,\n    // or doesn't exist.  give up.\n    if (er) {\n      if (er.code === 'ENOENT')\n        return cb()\n      else if (er.code !== 'ENOTDIR' && er.code !== 'ENOTSUP')\n        return cb(er)\n    }\n    if (er || !children.length)\n      return chown(p, uid, gid, cb)\n\n    let len = children.length\n    let errState = null\n    const then = er => {\n      if (errState)\n        return\n      if (er)\n        return cb(errState = er)\n      if (-- len === 0)\n        return chown(p, uid, gid, cb)\n    }\n\n    children.forEach(child => chownrKid(p, child, uid, gid, then))\n  })\n}\n\nconst chownrKidSync = (p, child, uid, gid) => {\n  if (typeof child === 'string') {\n    try {\n      const stats = fs.lstatSync(path.resolve(p, child))\n      stats.name = child\n      child = stats\n    } catch (er) {\n      if (er.code === 'ENOENT')\n        return\n      else\n        throw er\n    }\n  }\n\n  if (child.isDirectory())\n    chownrSync(path.resolve(p, child.name), uid, gid)\n\n  handleEISDirSync(path.resolve(p, child.name), uid, gid)\n}\n\nconst chownrSync = (p, uid, gid) => {\n  let children\n  try {\n    children = readdirSync(p, { withFileTypes: true })\n  } catch (er) {\n    if (er.code === 'ENOENT')\n      return\n    else if (er.code === 'ENOTDIR' || er.code === 'ENOTSUP')\n      return handleEISDirSync(p, uid, gid)\n    else\n      throw er\n  }\n\n  if (children && children.length)\n    children.forEach(child => chownrKidSync(p, child, uid, gid))\n\n  return handleEISDirSync(p, uid, gid)\n}\n\nmodule.exports = chownr\nchownr.sync = chownrSync\n\n\n//# sourceURL=webpack://thelambda/./node_modules/chownr/chownr.js?");

/***/ }),

/***/ "./node_modules/color-support/browser.js":
/*!***********************************************!*\
  !*** ./node_modules/color-support/browser.js ***!
  \***********************************************/
/***/ ((module) => {

eval("module.exports = colorSupport({ alwaysReturn: true }, colorSupport)\n\nfunction colorSupport(options, obj) {\n  obj = obj || {}\n  options = options || {}\n  obj.level = 0\n  obj.hasBasic = false\n  obj.has256 = false\n  obj.has16m = false\n  if (!options.alwaysReturn) {\n    return false\n  }\n  return obj\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/color-support/browser.js?");

/***/ }),

/***/ "./node_modules/concat-map/index.js":
/*!******************************************!*\
  !*** ./node_modules/concat-map/index.js ***!
  \******************************************/
/***/ ((module) => {

eval("module.exports = function (xs, fn) {\n    var res = [];\n    for (var i = 0; i < xs.length; i++) {\n        var x = fn(xs[i], i);\n        if (isArray(x)) res.push.apply(res, x);\n        else res.push(x);\n    }\n    return res;\n};\n\nvar isArray = Array.isArray || function (xs) {\n    return Object.prototype.toString.call(xs) === '[object Array]';\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/concat-map/index.js?");

/***/ }),

/***/ "./node_modules/console-control-strings/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/console-control-strings/index.js ***!
  \*******************************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n\n// These tables borrowed from `ansi`\n\nvar prefix = '\\x1b['\n\nexports.up = function up (num) {\n  return prefix + (num || '') + 'A'\n}\n\nexports.down = function down (num) {\n  return prefix + (num || '') + 'B'\n}\n\nexports.forward = function forward (num) {\n  return prefix + (num || '') + 'C'\n}\n\nexports.back = function back (num) {\n  return prefix + (num || '') + 'D'\n}\n\nexports.nextLine = function nextLine (num) {\n  return prefix + (num || '') + 'E'\n}\n\nexports.previousLine = function previousLine (num) {\n  return prefix + (num || '') + 'F'\n}\n\nexports.horizontalAbsolute = function horizontalAbsolute (num) {\n  if (num == null) throw new Error('horizontalAboslute requires a column to position to')\n  return prefix + num + 'G'\n}\n\nexports.eraseData = function eraseData () {\n  return prefix + 'J'\n}\n\nexports.eraseLine = function eraseLine () {\n  return prefix + 'K'\n}\n\nexports.goto = function (x, y) {\n  return prefix + y + ';' + x + 'H'\n}\n\nexports.gotoSOL = function () {\n  return '\\r'\n}\n\nexports.beep = function () {\n  return '\\x07'\n}\n\nexports.hideCursor = function hideCursor () {\n  return prefix + '?25l'\n}\n\nexports.showCursor = function showCursor () {\n  return prefix + '?25h'\n}\n\nvar colors = {\n  reset: 0,\n// styles\n  bold: 1,\n  italic: 3,\n  underline: 4,\n  inverse: 7,\n// resets\n  stopBold: 22,\n  stopItalic: 23,\n  stopUnderline: 24,\n  stopInverse: 27,\n// colors\n  white: 37,\n  black: 30,\n  blue: 34,\n  cyan: 36,\n  green: 32,\n  magenta: 35,\n  red: 31,\n  yellow: 33,\n  bgWhite: 47,\n  bgBlack: 40,\n  bgBlue: 44,\n  bgCyan: 46,\n  bgGreen: 42,\n  bgMagenta: 45,\n  bgRed: 41,\n  bgYellow: 43,\n\n  grey: 90,\n  brightBlack: 90,\n  brightRed: 91,\n  brightGreen: 92,\n  brightYellow: 93,\n  brightBlue: 94,\n  brightMagenta: 95,\n  brightCyan: 96,\n  brightWhite: 97,\n\n  bgGrey: 100,\n  bgBrightBlack: 100,\n  bgBrightRed: 101,\n  bgBrightGreen: 102,\n  bgBrightYellow: 103,\n  bgBrightBlue: 104,\n  bgBrightMagenta: 105,\n  bgBrightCyan: 106,\n  bgBrightWhite: 107\n}\n\nexports.color = function color (colorWith) {\n  if (arguments.length !== 1 || !Array.isArray(colorWith)) {\n    colorWith = Array.prototype.slice.call(arguments)\n  }\n  return prefix + colorWith.map(colorNameToCode).join(';') + 'm'\n}\n\nfunction colorNameToCode (color) {\n  if (colors[color] != null) return colors[color]\n  throw new Error('Unknown color or style name: ' + color)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/console-control-strings/index.js?");

/***/ }),

/***/ "./node_modules/debug/src/browser.js":
/*!*******************************************!*\
  !*** ./node_modules/debug/src/browser.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/* eslint-env browser */\n\n/**\n * This is the web browser implementation of `debug()`.\n */\n\nexports.formatArgs = formatArgs;\nexports.save = save;\nexports.load = load;\nexports.useColors = useColors;\nexports.storage = localstorage();\nexports.destroy = (() => {\n\tlet warned = false;\n\n\treturn () => {\n\t\tif (!warned) {\n\t\t\twarned = true;\n\t\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t\t}\n\t};\n})();\n\n/**\n * Colors.\n */\n\nexports.colors = [\n\t'#0000CC',\n\t'#0000FF',\n\t'#0033CC',\n\t'#0033FF',\n\t'#0066CC',\n\t'#0066FF',\n\t'#0099CC',\n\t'#0099FF',\n\t'#00CC00',\n\t'#00CC33',\n\t'#00CC66',\n\t'#00CC99',\n\t'#00CCCC',\n\t'#00CCFF',\n\t'#3300CC',\n\t'#3300FF',\n\t'#3333CC',\n\t'#3333FF',\n\t'#3366CC',\n\t'#3366FF',\n\t'#3399CC',\n\t'#3399FF',\n\t'#33CC00',\n\t'#33CC33',\n\t'#33CC66',\n\t'#33CC99',\n\t'#33CCCC',\n\t'#33CCFF',\n\t'#6600CC',\n\t'#6600FF',\n\t'#6633CC',\n\t'#6633FF',\n\t'#66CC00',\n\t'#66CC33',\n\t'#9900CC',\n\t'#9900FF',\n\t'#9933CC',\n\t'#9933FF',\n\t'#99CC00',\n\t'#99CC33',\n\t'#CC0000',\n\t'#CC0033',\n\t'#CC0066',\n\t'#CC0099',\n\t'#CC00CC',\n\t'#CC00FF',\n\t'#CC3300',\n\t'#CC3333',\n\t'#CC3366',\n\t'#CC3399',\n\t'#CC33CC',\n\t'#CC33FF',\n\t'#CC6600',\n\t'#CC6633',\n\t'#CC9900',\n\t'#CC9933',\n\t'#CCCC00',\n\t'#CCCC33',\n\t'#FF0000',\n\t'#FF0033',\n\t'#FF0066',\n\t'#FF0099',\n\t'#FF00CC',\n\t'#FF00FF',\n\t'#FF3300',\n\t'#FF3333',\n\t'#FF3366',\n\t'#FF3399',\n\t'#FF33CC',\n\t'#FF33FF',\n\t'#FF6600',\n\t'#FF6633',\n\t'#FF9900',\n\t'#FF9933',\n\t'#FFCC00',\n\t'#FFCC33'\n];\n\n/**\n * Currently only WebKit-based Web Inspectors, Firefox >= v31,\n * and the Firebug extension (any Firefox version) are known\n * to support \"%c\" CSS customizations.\n *\n * TODO: add a `localStorage` variable to explicitly enable/disable colors\n */\n\n// eslint-disable-next-line complexity\nfunction useColors() {\n\t// NB: In an Electron preload script, document will be defined but not fully\n\t// initialized. Since we know we're in Chrome, we'll just detect this case\n\t// explicitly\n\tif (typeof window !== 'undefined' && window.process && (window.process.type === 'renderer' || window.process.__nwjs)) {\n\t\treturn true;\n\t}\n\n\t// Internet Explorer and Edge do not support colors.\n\tif (typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/(edge|trident)\\/(\\d+)/)) {\n\t\treturn false;\n\t}\n\n\tlet m;\n\n\t// Is webkit? http://stackoverflow.com/a/16459606/376773\n\t// document is undefined in react-native: https://github.com/facebook/react-native/pull/1632\n\treturn (typeof document !== 'undefined' && document.documentElement && document.documentElement.style && document.documentElement.style.WebkitAppearance) ||\n\t\t// Is firebug? http://stackoverflow.com/a/398120/376773\n\t\t(typeof window !== 'undefined' && window.console && (window.console.firebug || (window.console.exception && window.console.table))) ||\n\t\t// Is firefox >= v31?\n\t\t// https://developer.mozilla.org/en-US/docs/Tools/Web_Console#Styling_messages\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && (m = navigator.userAgent.toLowerCase().match(/firefox\\/(\\d+)/)) && parseInt(m[1], 10) >= 31) ||\n\t\t// Double check webkit in userAgent just in case we are in a worker\n\t\t(typeof navigator !== 'undefined' && navigator.userAgent && navigator.userAgent.toLowerCase().match(/applewebkit\\/(\\d+)/));\n}\n\n/**\n * Colorize log arguments if enabled.\n *\n * @api public\n */\n\nfunction formatArgs(args) {\n\targs[0] = (this.useColors ? '%c' : '') +\n\t\tthis.namespace +\n\t\t(this.useColors ? ' %c' : ' ') +\n\t\targs[0] +\n\t\t(this.useColors ? '%c ' : ' ') +\n\t\t'+' + module.exports.humanize(this.diff);\n\n\tif (!this.useColors) {\n\t\treturn;\n\t}\n\n\tconst c = 'color: ' + this.color;\n\targs.splice(1, 0, c, 'color: inherit');\n\n\t// The final \"%c\" is somewhat tricky, because there could be other\n\t// arguments passed either before or after the %c, so we need to\n\t// figure out the correct index to insert the CSS into\n\tlet index = 0;\n\tlet lastC = 0;\n\targs[0].replace(/%[a-zA-Z%]/g, match => {\n\t\tif (match === '%%') {\n\t\t\treturn;\n\t\t}\n\t\tindex++;\n\t\tif (match === '%c') {\n\t\t\t// We only are interested in the *last* %c\n\t\t\t// (the user may have provided their own)\n\t\t\tlastC = index;\n\t\t}\n\t});\n\n\targs.splice(lastC, 0, c);\n}\n\n/**\n * Invokes `console.debug()` when available.\n * No-op when `console.debug` is not a \"function\".\n * If `console.debug` is not available, falls back\n * to `console.log`.\n *\n * @api public\n */\nexports.log = console.debug || console.log || (() => {});\n\n/**\n * Save `namespaces`.\n *\n * @param {String} namespaces\n * @api private\n */\nfunction save(namespaces) {\n\ttry {\n\t\tif (namespaces) {\n\t\t\texports.storage.setItem('debug', namespaces);\n\t\t} else {\n\t\t\texports.storage.removeItem('debug');\n\t\t}\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\n/**\n * Load `namespaces`.\n *\n * @return {String} returns the previously persisted debug modes\n * @api private\n */\nfunction load() {\n\tlet r;\n\ttry {\n\t\tr = exports.storage.getItem('debug');\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n\n\t// If debug isn't set in LS, and we're in Electron, try to load $DEBUG\n\tif (!r && typeof process !== 'undefined' && 'env' in process) {\n\t\tr = process.env.DEBUG;\n\t}\n\n\treturn r;\n}\n\n/**\n * Localstorage attempts to return the localstorage.\n *\n * This is necessary because safari throws\n * when a user disables cookies/localstorage\n * and you attempt to access it.\n *\n * @return {LocalStorage}\n * @api private\n */\n\nfunction localstorage() {\n\ttry {\n\t\t// TVMLKit (Apple TV JS Runtime) does not have a window object, just localStorage in the global context\n\t\t// The Browser also has localStorage in the global context.\n\t\treturn localStorage;\n\t} catch (error) {\n\t\t// Swallow\n\t\t// XXX (@Qix-) should we be logging these?\n\t}\n}\n\nmodule.exports = __webpack_require__(/*! ./common */ \"./node_modules/debug/src/common.js\")(exports);\n\nconst {formatters} = module.exports;\n\n/**\n * Map %j to `JSON.stringify()`, since no Web Inspectors do that by default.\n */\n\nformatters.j = function (v) {\n\ttry {\n\t\treturn JSON.stringify(v);\n\t} catch (error) {\n\t\treturn '[UnexpectedJSONParseError]: ' + error.message;\n\t}\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/debug/src/browser.js?");

/***/ }),

/***/ "./node_modules/debug/src/common.js":
/*!******************************************!*\
  !*** ./node_modules/debug/src/common.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * This is the common logic for both the Node.js and web browser\n * implementations of `debug()`.\n */\n\nfunction setup(env) {\n\tcreateDebug.debug = createDebug;\n\tcreateDebug.default = createDebug;\n\tcreateDebug.coerce = coerce;\n\tcreateDebug.disable = disable;\n\tcreateDebug.enable = enable;\n\tcreateDebug.enabled = enabled;\n\tcreateDebug.humanize = __webpack_require__(/*! ms */ \"./node_modules/ms/index.js\");\n\tcreateDebug.destroy = destroy;\n\n\tObject.keys(env).forEach(key => {\n\t\tcreateDebug[key] = env[key];\n\t});\n\n\t/**\n\t* The currently active debug mode names, and names to skip.\n\t*/\n\n\tcreateDebug.names = [];\n\tcreateDebug.skips = [];\n\n\t/**\n\t* Map of special \"%n\" handling functions, for the debug \"format\" argument.\n\t*\n\t* Valid key names are a single, lower or upper-case letter, i.e. \"n\" and \"N\".\n\t*/\n\tcreateDebug.formatters = {};\n\n\t/**\n\t* Selects a color for a debug namespace\n\t* @param {String} namespace The namespace string for the debug instance to be colored\n\t* @return {Number|String} An ANSI color code for the given namespace\n\t* @api private\n\t*/\n\tfunction selectColor(namespace) {\n\t\tlet hash = 0;\n\n\t\tfor (let i = 0; i < namespace.length; i++) {\n\t\t\thash = ((hash << 5) - hash) + namespace.charCodeAt(i);\n\t\t\thash |= 0; // Convert to 32bit integer\n\t\t}\n\n\t\treturn createDebug.colors[Math.abs(hash) % createDebug.colors.length];\n\t}\n\tcreateDebug.selectColor = selectColor;\n\n\t/**\n\t* Create a debugger with the given `namespace`.\n\t*\n\t* @param {String} namespace\n\t* @return {Function}\n\t* @api public\n\t*/\n\tfunction createDebug(namespace) {\n\t\tlet prevTime;\n\t\tlet enableOverride = null;\n\t\tlet namespacesCache;\n\t\tlet enabledCache;\n\n\t\tfunction debug(...args) {\n\t\t\t// Disabled?\n\t\t\tif (!debug.enabled) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tconst self = debug;\n\n\t\t\t// Set `diff` timestamp\n\t\t\tconst curr = Number(new Date());\n\t\t\tconst ms = curr - (prevTime || curr);\n\t\t\tself.diff = ms;\n\t\t\tself.prev = prevTime;\n\t\t\tself.curr = curr;\n\t\t\tprevTime = curr;\n\n\t\t\targs[0] = createDebug.coerce(args[0]);\n\n\t\t\tif (typeof args[0] !== 'string') {\n\t\t\t\t// Anything else let's inspect with %O\n\t\t\t\targs.unshift('%O');\n\t\t\t}\n\n\t\t\t// Apply any `formatters` transformations\n\t\t\tlet index = 0;\n\t\t\targs[0] = args[0].replace(/%([a-zA-Z%])/g, (match, format) => {\n\t\t\t\t// If we encounter an escaped % then don't increase the array index\n\t\t\t\tif (match === '%%') {\n\t\t\t\t\treturn '%';\n\t\t\t\t}\n\t\t\t\tindex++;\n\t\t\t\tconst formatter = createDebug.formatters[format];\n\t\t\t\tif (typeof formatter === 'function') {\n\t\t\t\t\tconst val = args[index];\n\t\t\t\t\tmatch = formatter.call(self, val);\n\n\t\t\t\t\t// Now we need to remove `args[index]` since it's inlined in the `format`\n\t\t\t\t\targs.splice(index, 1);\n\t\t\t\t\tindex--;\n\t\t\t\t}\n\t\t\t\treturn match;\n\t\t\t});\n\n\t\t\t// Apply env-specific formatting (colors, etc.)\n\t\t\tcreateDebug.formatArgs.call(self, args);\n\n\t\t\tconst logFn = self.log || createDebug.log;\n\t\t\tlogFn.apply(self, args);\n\t\t}\n\n\t\tdebug.namespace = namespace;\n\t\tdebug.useColors = createDebug.useColors();\n\t\tdebug.color = createDebug.selectColor(namespace);\n\t\tdebug.extend = extend;\n\t\tdebug.destroy = createDebug.destroy; // XXX Temporary. Will be removed in the next major release.\n\n\t\tObject.defineProperty(debug, 'enabled', {\n\t\t\tenumerable: true,\n\t\t\tconfigurable: false,\n\t\t\tget: () => {\n\t\t\t\tif (enableOverride !== null) {\n\t\t\t\t\treturn enableOverride;\n\t\t\t\t}\n\t\t\t\tif (namespacesCache !== createDebug.namespaces) {\n\t\t\t\t\tnamespacesCache = createDebug.namespaces;\n\t\t\t\t\tenabledCache = createDebug.enabled(namespace);\n\t\t\t\t}\n\n\t\t\t\treturn enabledCache;\n\t\t\t},\n\t\t\tset: v => {\n\t\t\t\tenableOverride = v;\n\t\t\t}\n\t\t});\n\n\t\t// Env-specific initialization logic for debug instances\n\t\tif (typeof createDebug.init === 'function') {\n\t\t\tcreateDebug.init(debug);\n\t\t}\n\n\t\treturn debug;\n\t}\n\n\tfunction extend(namespace, delimiter) {\n\t\tconst newDebug = createDebug(this.namespace + (typeof delimiter === 'undefined' ? ':' : delimiter) + namespace);\n\t\tnewDebug.log = this.log;\n\t\treturn newDebug;\n\t}\n\n\t/**\n\t* Enables a debug mode by namespaces. This can include modes\n\t* separated by a colon and wildcards.\n\t*\n\t* @param {String} namespaces\n\t* @api public\n\t*/\n\tfunction enable(namespaces) {\n\t\tcreateDebug.save(namespaces);\n\t\tcreateDebug.namespaces = namespaces;\n\n\t\tcreateDebug.names = [];\n\t\tcreateDebug.skips = [];\n\n\t\tlet i;\n\t\tconst split = (typeof namespaces === 'string' ? namespaces : '').split(/[\\s,]+/);\n\t\tconst len = split.length;\n\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif (!split[i]) {\n\t\t\t\t// ignore empty strings\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tnamespaces = split[i].replace(/\\*/g, '.*?');\n\n\t\t\tif (namespaces[0] === '-') {\n\t\t\t\tcreateDebug.skips.push(new RegExp('^' + namespaces.slice(1) + '$'));\n\t\t\t} else {\n\t\t\t\tcreateDebug.names.push(new RegExp('^' + namespaces + '$'));\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t* Disable debug output.\n\t*\n\t* @return {String} namespaces\n\t* @api public\n\t*/\n\tfunction disable() {\n\t\tconst namespaces = [\n\t\t\t...createDebug.names.map(toNamespace),\n\t\t\t...createDebug.skips.map(toNamespace).map(namespace => '-' + namespace)\n\t\t].join(',');\n\t\tcreateDebug.enable('');\n\t\treturn namespaces;\n\t}\n\n\t/**\n\t* Returns true if the given mode name is enabled, false otherwise.\n\t*\n\t* @param {String} name\n\t* @return {Boolean}\n\t* @api public\n\t*/\n\tfunction enabled(name) {\n\t\tif (name[name.length - 1] === '*') {\n\t\t\treturn true;\n\t\t}\n\n\t\tlet i;\n\t\tlet len;\n\n\t\tfor (i = 0, len = createDebug.skips.length; i < len; i++) {\n\t\t\tif (createDebug.skips[i].test(name)) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\tfor (i = 0, len = createDebug.names.length; i < len; i++) {\n\t\t\tif (createDebug.names[i].test(name)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\n\t\treturn false;\n\t}\n\n\t/**\n\t* Convert regexp to namespace\n\t*\n\t* @param {RegExp} regxep\n\t* @return {String} namespace\n\t* @api private\n\t*/\n\tfunction toNamespace(regexp) {\n\t\treturn regexp.toString()\n\t\t\t.substring(2, regexp.toString().length - 2)\n\t\t\t.replace(/\\.\\*\\?$/, '*');\n\t}\n\n\t/**\n\t* Coerce `val`.\n\t*\n\t* @param {Mixed} val\n\t* @return {Mixed}\n\t* @api private\n\t*/\n\tfunction coerce(val) {\n\t\tif (val instanceof Error) {\n\t\t\treturn val.stack || val.message;\n\t\t}\n\t\treturn val;\n\t}\n\n\t/**\n\t* XXX DO NOT USE. This is a temporary stub function.\n\t* XXX It WILL be removed in the next major release.\n\t*/\n\tfunction destroy() {\n\t\tconsole.warn('Instance method `debug.destroy()` is deprecated and no longer does anything. It will be removed in the next major version of `debug`.');\n\t}\n\n\tcreateDebug.enable(createDebug.load());\n\n\treturn createDebug;\n}\n\nmodule.exports = setup;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/debug/src/common.js?");

/***/ }),

/***/ "./node_modules/define-data-property/index.js":
/*!****************************************************!*\
  !*** ./node_modules/define-data-property/index.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar $defineProperty = __webpack_require__(/*! es-define-property */ \"./node_modules/es-define-property/index.js\");\n\nvar $SyntaxError = __webpack_require__(/*! es-errors/syntax */ \"./node_modules/es-errors/syntax.js\");\nvar $TypeError = __webpack_require__(/*! es-errors/type */ \"./node_modules/es-errors/type.js\");\n\nvar gopd = __webpack_require__(/*! gopd */ \"./node_modules/gopd/index.js\");\n\n/** @type {import('.')} */\nmodule.exports = function defineDataProperty(\n\tobj,\n\tproperty,\n\tvalue\n) {\n\tif (!obj || (typeof obj !== 'object' && typeof obj !== 'function')) {\n\t\tthrow new $TypeError('`obj` must be an object or a function`');\n\t}\n\tif (typeof property !== 'string' && typeof property !== 'symbol') {\n\t\tthrow new $TypeError('`property` must be a string or a symbol`');\n\t}\n\tif (arguments.length > 3 && typeof arguments[3] !== 'boolean' && arguments[3] !== null) {\n\t\tthrow new $TypeError('`nonEnumerable`, if provided, must be a boolean or null');\n\t}\n\tif (arguments.length > 4 && typeof arguments[4] !== 'boolean' && arguments[4] !== null) {\n\t\tthrow new $TypeError('`nonWritable`, if provided, must be a boolean or null');\n\t}\n\tif (arguments.length > 5 && typeof arguments[5] !== 'boolean' && arguments[5] !== null) {\n\t\tthrow new $TypeError('`nonConfigurable`, if provided, must be a boolean or null');\n\t}\n\tif (arguments.length > 6 && typeof arguments[6] !== 'boolean') {\n\t\tthrow new $TypeError('`loose`, if provided, must be a boolean');\n\t}\n\n\tvar nonEnumerable = arguments.length > 3 ? arguments[3] : null;\n\tvar nonWritable = arguments.length > 4 ? arguments[4] : null;\n\tvar nonConfigurable = arguments.length > 5 ? arguments[5] : null;\n\tvar loose = arguments.length > 6 ? arguments[6] : false;\n\n\t/* @type {false | TypedPropertyDescriptor<unknown>} */\n\tvar desc = !!gopd && gopd(obj, property);\n\n\tif ($defineProperty) {\n\t\t$defineProperty(obj, property, {\n\t\t\tconfigurable: nonConfigurable === null && desc ? desc.configurable : !nonConfigurable,\n\t\t\tenumerable: nonEnumerable === null && desc ? desc.enumerable : !nonEnumerable,\n\t\t\tvalue: value,\n\t\t\twritable: nonWritable === null && desc ? desc.writable : !nonWritable\n\t\t});\n\t} else if (loose || (!nonEnumerable && !nonWritable && !nonConfigurable)) {\n\t\t// must fall back to [[Set]], and was not explicitly asked to make non-enumerable, non-writable, or non-configurable\n\t\tobj[property] = value; // eslint-disable-line no-param-reassign\n\t} else {\n\t\tthrow new $SyntaxError('This environment does not support defining a property as non-configurable, non-writable, or non-enumerable.');\n\t}\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/define-data-property/index.js?");

/***/ }),

/***/ "./node_modules/delegates/index.js":
/*!*****************************************!*\
  !*** ./node_modules/delegates/index.js ***!
  \*****************************************/
/***/ ((module) => {

eval("\n/**\n * Expose `Delegator`.\n */\n\nmodule.exports = Delegator;\n\n/**\n * Initialize a delegator.\n *\n * @param {Object} proto\n * @param {String} target\n * @api public\n */\n\nfunction Delegator(proto, target) {\n  if (!(this instanceof Delegator)) return new Delegator(proto, target);\n  this.proto = proto;\n  this.target = target;\n  this.methods = [];\n  this.getters = [];\n  this.setters = [];\n  this.fluents = [];\n}\n\n/**\n * Delegate method `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.method = function(name){\n  var proto = this.proto;\n  var target = this.target;\n  this.methods.push(name);\n\n  proto[name] = function(){\n    return this[target][name].apply(this[target], arguments);\n  };\n\n  return this;\n};\n\n/**\n * Delegator accessor `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.access = function(name){\n  return this.getter(name).setter(name);\n};\n\n/**\n * Delegator getter `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.getter = function(name){\n  var proto = this.proto;\n  var target = this.target;\n  this.getters.push(name);\n\n  proto.__defineGetter__(name, function(){\n    return this[target][name];\n  });\n\n  return this;\n};\n\n/**\n * Delegator setter `name`.\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.setter = function(name){\n  var proto = this.proto;\n  var target = this.target;\n  this.setters.push(name);\n\n  proto.__defineSetter__(name, function(val){\n    return this[target][name] = val;\n  });\n\n  return this;\n};\n\n/**\n * Delegator fluent accessor\n *\n * @param {String} name\n * @return {Delegator} self\n * @api public\n */\n\nDelegator.prototype.fluent = function (name) {\n  var proto = this.proto;\n  var target = this.target;\n  this.fluents.push(name);\n\n  proto[name] = function(val){\n    if ('undefined' != typeof val) {\n      this[target][name] = val;\n      return this;\n    } else {\n      return this[target][name];\n    }\n  };\n\n  return this;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/delegates/index.js?");

/***/ }),

/***/ "./node_modules/detect-libc/lib/detect-libc.js":
/*!*****************************************************!*\
  !*** ./node_modules/detect-libc/lib/detect-libc.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright 2017 Lovell Fuller and others.\n// SPDX-License-Identifier: Apache-2.0\n\n\n\nconst childProcess = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'child_process'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()));\nconst { isLinux, getReport } = __webpack_require__(/*! ./process */ \"./node_modules/detect-libc/lib/process.js\");\nconst { LDD_PATH, readFile, readFileSync } = __webpack_require__(/*! ./filesystem */ \"./node_modules/detect-libc/lib/filesystem.js\");\n\nlet cachedFamilyFilesystem;\nlet cachedVersionFilesystem;\n\nconst command = 'getconf GNU_LIBC_VERSION 2>&1 || true; ldd --version 2>&1 || true';\nlet commandOut = '';\n\nconst safeCommand = () => {\n  if (!commandOut) {\n    return new Promise((resolve) => {\n      childProcess.exec(command, (err, out) => {\n        commandOut = err ? ' ' : out;\n        resolve(commandOut);\n      });\n    });\n  }\n  return commandOut;\n};\n\nconst safeCommandSync = () => {\n  if (!commandOut) {\n    try {\n      commandOut = childProcess.execSync(command, { encoding: 'utf8' });\n    } catch (_err) {\n      commandOut = ' ';\n    }\n  }\n  return commandOut;\n};\n\n/**\n * A String constant containing the value `glibc`.\n * @type {string}\n * @public\n */\nconst GLIBC = 'glibc';\n\n/**\n * A Regexp constant to get the GLIBC Version.\n * @type {string}\n */\nconst RE_GLIBC_VERSION = /LIBC[a-z0-9 \\-).]*?(\\d+\\.\\d+)/i;\n\n/**\n * A String constant containing the value `musl`.\n * @type {string}\n * @public\n */\nconst MUSL = 'musl';\n\nconst isFileMusl = (f) => f.includes('libc.musl-') || f.includes('ld-musl-');\n\nconst familyFromReport = () => {\n  const report = getReport();\n  if (report.header && report.header.glibcVersionRuntime) {\n    return GLIBC;\n  }\n  if (Array.isArray(report.sharedObjects)) {\n    if (report.sharedObjects.some(isFileMusl)) {\n      return MUSL;\n    }\n  }\n  return null;\n};\n\nconst familyFromCommand = (out) => {\n  const [getconf, ldd1] = out.split(/[\\r\\n]+/);\n  if (getconf && getconf.includes(GLIBC)) {\n    return GLIBC;\n  }\n  if (ldd1 && ldd1.includes(MUSL)) {\n    return MUSL;\n  }\n  return null;\n};\n\nconst getFamilyFromLddContent = (content) => {\n  if (content.includes('musl')) {\n    return MUSL;\n  }\n  if (content.includes('GNU C Library')) {\n    return GLIBC;\n  }\n  return null;\n};\n\nconst familyFromFilesystem = async () => {\n  if (cachedFamilyFilesystem !== undefined) {\n    return cachedFamilyFilesystem;\n  }\n  cachedFamilyFilesystem = null;\n  try {\n    const lddContent = await readFile(LDD_PATH);\n    cachedFamilyFilesystem = getFamilyFromLddContent(lddContent);\n  } catch (e) {}\n  return cachedFamilyFilesystem;\n};\n\nconst familyFromFilesystemSync = () => {\n  if (cachedFamilyFilesystem !== undefined) {\n    return cachedFamilyFilesystem;\n  }\n  cachedFamilyFilesystem = null;\n  try {\n    const lddContent = readFileSync(LDD_PATH);\n    cachedFamilyFilesystem = getFamilyFromLddContent(lddContent);\n  } catch (e) {}\n  return cachedFamilyFilesystem;\n};\n\n/**\n * Resolves with the libc family when it can be determined, `null` otherwise.\n * @returns {Promise<?string>}\n */\nconst family = async () => {\n  let family = null;\n  if (isLinux()) {\n    family = await familyFromFilesystem();\n    if (!family) {\n      family = familyFromReport();\n    }\n    if (!family) {\n      const out = await safeCommand();\n      family = familyFromCommand(out);\n    }\n  }\n  return family;\n};\n\n/**\n * Returns the libc family when it can be determined, `null` otherwise.\n * @returns {?string}\n */\nconst familySync = () => {\n  let family = null;\n  if (isLinux()) {\n    family = familyFromFilesystemSync();\n    if (!family) {\n      family = familyFromReport();\n    }\n    if (!family) {\n      const out = safeCommandSync();\n      family = familyFromCommand(out);\n    }\n  }\n  return family;\n};\n\n/**\n * Resolves `true` only when the platform is Linux and the libc family is not `glibc`.\n * @returns {Promise<boolean>}\n */\nconst isNonGlibcLinux = async () => isLinux() && await family() !== GLIBC;\n\n/**\n * Returns `true` only when the platform is Linux and the libc family is not `glibc`.\n * @returns {boolean}\n */\nconst isNonGlibcLinuxSync = () => isLinux() && familySync() !== GLIBC;\n\nconst versionFromFilesystem = async () => {\n  if (cachedVersionFilesystem !== undefined) {\n    return cachedVersionFilesystem;\n  }\n  cachedVersionFilesystem = null;\n  try {\n    const lddContent = await readFile(LDD_PATH);\n    const versionMatch = lddContent.match(RE_GLIBC_VERSION);\n    if (versionMatch) {\n      cachedVersionFilesystem = versionMatch[1];\n    }\n  } catch (e) {}\n  return cachedVersionFilesystem;\n};\n\nconst versionFromFilesystemSync = () => {\n  if (cachedVersionFilesystem !== undefined) {\n    return cachedVersionFilesystem;\n  }\n  cachedVersionFilesystem = null;\n  try {\n    const lddContent = readFileSync(LDD_PATH);\n    const versionMatch = lddContent.match(RE_GLIBC_VERSION);\n    if (versionMatch) {\n      cachedVersionFilesystem = versionMatch[1];\n    }\n  } catch (e) {}\n  return cachedVersionFilesystem;\n};\n\nconst versionFromReport = () => {\n  const report = getReport();\n  if (report.header && report.header.glibcVersionRuntime) {\n    return report.header.glibcVersionRuntime;\n  }\n  return null;\n};\n\nconst versionSuffix = (s) => s.trim().split(/\\s+/)[1];\n\nconst versionFromCommand = (out) => {\n  const [getconf, ldd1, ldd2] = out.split(/[\\r\\n]+/);\n  if (getconf && getconf.includes(GLIBC)) {\n    return versionSuffix(getconf);\n  }\n  if (ldd1 && ldd2 && ldd1.includes(MUSL)) {\n    return versionSuffix(ldd2);\n  }\n  return null;\n};\n\n/**\n * Resolves with the libc version when it can be determined, `null` otherwise.\n * @returns {Promise<?string>}\n */\nconst version = async () => {\n  let version = null;\n  if (isLinux()) {\n    version = await versionFromFilesystem();\n    if (!version) {\n      version = versionFromReport();\n    }\n    if (!version) {\n      const out = await safeCommand();\n      version = versionFromCommand(out);\n    }\n  }\n  return version;\n};\n\n/**\n * Returns the libc version when it can be determined, `null` otherwise.\n * @returns {?string}\n */\nconst versionSync = () => {\n  let version = null;\n  if (isLinux()) {\n    version = versionFromFilesystemSync();\n    if (!version) {\n      version = versionFromReport();\n    }\n    if (!version) {\n      const out = safeCommandSync();\n      version = versionFromCommand(out);\n    }\n  }\n  return version;\n};\n\nmodule.exports = {\n  GLIBC,\n  MUSL,\n  family,\n  familySync,\n  isNonGlibcLinux,\n  isNonGlibcLinuxSync,\n  version,\n  versionSync\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/detect-libc/lib/detect-libc.js?");

/***/ }),

/***/ "./node_modules/detect-libc/lib/filesystem.js":
/*!****************************************************!*\
  !*** ./node_modules/detect-libc/lib/filesystem.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright 2017 Lovell Fuller and others.\n// SPDX-License-Identifier: Apache-2.0\n\n\n\nconst fs = __webpack_require__(/*! fs */ \"?2c1d\");\n\n/**\n * The path where we can find the ldd\n */\nconst LDD_PATH = '/usr/bin/ldd';\n\n/**\n * Read the content of a file synchronous\n *\n * @param {string} path\n * @returns {string}\n */\nconst readFileSync = (path) => fs.readFileSync(path, 'utf-8');\n\n/**\n * Read the content of a file\n *\n * @param {string} path\n * @returns {Promise<string>}\n */\nconst readFile = (path) => new Promise((resolve, reject) => {\n  fs.readFile(path, 'utf-8', (err, data) => {\n    if (err) {\n      reject(err);\n    } else {\n      resolve(data);\n    }\n  });\n});\n\nmodule.exports = {\n  LDD_PATH,\n  readFileSync,\n  readFile\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/detect-libc/lib/filesystem.js?");

/***/ }),

/***/ "./node_modules/detect-libc/lib/process.js":
/*!*************************************************!*\
  !*** ./node_modules/detect-libc/lib/process.js ***!
  \*************************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright 2017 Lovell Fuller and others.\n// SPDX-License-Identifier: Apache-2.0\n\n\n\nconst isLinux = () => process.platform === 'linux';\n\nlet report = null;\nconst getReport = () => {\n  if (!report) {\n    /* istanbul ignore next */\n    if (isLinux() && process.report) {\n      const orig = process.report.excludeNetwork;\n      process.report.excludeNetwork = true;\n      report = process.report.getReport();\n      process.report.excludeNetwork = orig;\n    } else {\n      report = {};\n    }\n  }\n  return report;\n};\n\nmodule.exports = { isLinux, getReport };\n\n\n//# sourceURL=webpack://thelambda/./node_modules/detect-libc/lib/process.js?");

/***/ }),

/***/ "./node_modules/dotenv/lib/main.js":
/*!*****************************************!*\
  !*** ./node_modules/dotenv/lib/main.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const fs = __webpack_require__(/*! fs */ \"?a0c3\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst packageJson = __webpack_require__(/*! ../package.json */ \"./node_modules/dotenv/package.json\")\n\nconst version = packageJson.version\n\nconst LINE = /(?:^|^)\\s*(?:export\\s+)?([\\w.-]+)(?:\\s*=\\s*?|:\\s+?)(\\s*'(?:\\\\'|[^'])*'|\\s*\"(?:\\\\\"|[^\"])*\"|\\s*`(?:\\\\`|[^`])*`|[^#\\r\\n]+)?\\s*(?:#.*)?(?:$|$)/mg\n\n// Parse src into an Object\nfunction parse (src) {\n  const obj = {}\n\n  // Convert buffer to string\n  let lines = src.toString()\n\n  // Convert line breaks to same format\n  lines = lines.replace(/\\r\\n?/mg, '\\n')\n\n  let match\n  while ((match = LINE.exec(lines)) != null) {\n    const key = match[1]\n\n    // Default undefined or null to empty string\n    let value = (match[2] || '')\n\n    // Remove whitespace\n    value = value.trim()\n\n    // Check if double quoted\n    const maybeQuote = value[0]\n\n    // Remove surrounding quotes\n    value = value.replace(/^(['\"`])([\\s\\S]*)\\1$/mg, '$2')\n\n    // Expand newlines if double quoted\n    if (maybeQuote === '\"') {\n      value = value.replace(/\\\\n/g, '\\n')\n      value = value.replace(/\\\\r/g, '\\r')\n    }\n\n    // Add to object\n    obj[key] = value\n  }\n\n  return obj\n}\n\nfunction _parseVault (options) {\n  const vaultPath = _vaultPath(options)\n\n  // Parse .env.vault\n  const result = DotenvModule.configDotenv({ path: vaultPath })\n  if (!result.parsed) {\n    const err = new Error(`MISSING_DATA: Cannot parse ${vaultPath} for an unknown reason`)\n    err.code = 'MISSING_DATA'\n    throw err\n  }\n\n  // handle scenario for comma separated keys - for use with key rotation\n  // example: DOTENV_KEY=\"dotenv://:key_1234@dotenvx.com/vault/.env.vault?environment=prod,dotenv://:key_7890@dotenvx.com/vault/.env.vault?environment=prod\"\n  const keys = _dotenvKey(options).split(',')\n  const length = keys.length\n\n  let decrypted\n  for (let i = 0; i < length; i++) {\n    try {\n      // Get full key\n      const key = keys[i].trim()\n\n      // Get instructions for decrypt\n      const attrs = _instructions(result, key)\n\n      // Decrypt\n      decrypted = DotenvModule.decrypt(attrs.ciphertext, attrs.key)\n\n      break\n    } catch (error) {\n      // last key\n      if (i + 1 >= length) {\n        throw error\n      }\n      // try next key\n    }\n  }\n\n  // Parse decrypted .env string\n  return DotenvModule.parse(decrypted)\n}\n\nfunction _log (message) {\n  console.log(`[dotenv@${version}][INFO] ${message}`)\n}\n\nfunction _warn (message) {\n  console.log(`[dotenv@${version}][WARN] ${message}`)\n}\n\nfunction _debug (message) {\n  console.log(`[dotenv@${version}][DEBUG] ${message}`)\n}\n\nfunction _dotenvKey (options) {\n  // prioritize developer directly setting options.DOTENV_KEY\n  if (options && options.DOTENV_KEY && options.DOTENV_KEY.length > 0) {\n    return options.DOTENV_KEY\n  }\n\n  // secondary infra already contains a DOTENV_KEY environment variable\n  if (process.env.DOTENV_KEY && process.env.DOTENV_KEY.length > 0) {\n    return process.env.DOTENV_KEY\n  }\n\n  // fallback to empty string\n  return ''\n}\n\nfunction _instructions (result, dotenvKey) {\n  // Parse DOTENV_KEY. Format is a URI\n  let uri\n  try {\n    uri = new URL(dotenvKey)\n  } catch (error) {\n    if (error.code === 'ERR_INVALID_URL') {\n      const err = new Error('INVALID_DOTENV_KEY: Wrong format. Must be in valid uri format like dotenv://:key_1234@dotenvx.com/vault/.env.vault?environment=development')\n      err.code = 'INVALID_DOTENV_KEY'\n      throw err\n    }\n\n    throw error\n  }\n\n  // Get decrypt key\n  const key = uri.password\n  if (!key) {\n    const err = new Error('INVALID_DOTENV_KEY: Missing key part')\n    err.code = 'INVALID_DOTENV_KEY'\n    throw err\n  }\n\n  // Get environment\n  const environment = uri.searchParams.get('environment')\n  if (!environment) {\n    const err = new Error('INVALID_DOTENV_KEY: Missing environment part')\n    err.code = 'INVALID_DOTENV_KEY'\n    throw err\n  }\n\n  // Get ciphertext payload\n  const environmentKey = `DOTENV_VAULT_${environment.toUpperCase()}`\n  const ciphertext = result.parsed[environmentKey] // DOTENV_VAULT_PRODUCTION\n  if (!ciphertext) {\n    const err = new Error(`NOT_FOUND_DOTENV_ENVIRONMENT: Cannot locate environment ${environmentKey} in your .env.vault file.`)\n    err.code = 'NOT_FOUND_DOTENV_ENVIRONMENT'\n    throw err\n  }\n\n  return { ciphertext, key }\n}\n\nfunction _vaultPath (options) {\n  let possibleVaultPath = null\n\n  if (options && options.path && options.path.length > 0) {\n    if (Array.isArray(options.path)) {\n      for (const filepath of options.path) {\n        if (fs.existsSync(filepath)) {\n          possibleVaultPath = filepath.endsWith('.vault') ? filepath : `${filepath}.vault`\n        }\n      }\n    } else {\n      possibleVaultPath = options.path.endsWith('.vault') ? options.path : `${options.path}.vault`\n    }\n  } else {\n    possibleVaultPath = path.resolve(process.cwd(), '.env.vault')\n  }\n\n  if (fs.existsSync(possibleVaultPath)) {\n    return possibleVaultPath\n  }\n\n  return null\n}\n\nfunction _resolveHome (envPath) {\n  return envPath[0] === '~' ? path.join(os.homedir(), envPath.slice(1)) : envPath\n}\n\nfunction _configVault (options) {\n  _log('Loading env from encrypted .env.vault')\n\n  const parsed = DotenvModule._parseVault(options)\n\n  let processEnv = process.env\n  if (options && options.processEnv != null) {\n    processEnv = options.processEnv\n  }\n\n  DotenvModule.populate(processEnv, parsed, options)\n\n  return { parsed }\n}\n\nfunction configDotenv (options) {\n  const dotenvPath = path.resolve(process.cwd(), '.env')\n  let encoding = 'utf8'\n  const debug = Boolean(options && options.debug)\n\n  if (options && options.encoding) {\n    encoding = options.encoding\n  } else {\n    if (debug) {\n      _debug('No encoding is specified. UTF-8 is used by default')\n    }\n  }\n\n  let optionPaths = [dotenvPath] // default, look for .env\n  if (options && options.path) {\n    if (!Array.isArray(options.path)) {\n      optionPaths = [_resolveHome(options.path)]\n    } else {\n      optionPaths = [] // reset default\n      for (const filepath of options.path) {\n        optionPaths.push(_resolveHome(filepath))\n      }\n    }\n  }\n\n  // Build the parsed data in a temporary object (because we need to return it).  Once we have the final\n  // parsed data, we will combine it with process.env (or options.processEnv if provided).\n  let lastError\n  const parsedAll = {}\n  for (const path of optionPaths) {\n    try {\n      // Specifying an encoding returns a string instead of a buffer\n      const parsed = DotenvModule.parse(fs.readFileSync(path, { encoding }))\n\n      DotenvModule.populate(parsedAll, parsed, options)\n    } catch (e) {\n      if (debug) {\n        _debug(`Failed to load ${path} ${e.message}`)\n      }\n      lastError = e\n    }\n  }\n\n  let processEnv = process.env\n  if (options && options.processEnv != null) {\n    processEnv = options.processEnv\n  }\n\n  DotenvModule.populate(processEnv, parsedAll, options)\n\n  if (lastError) {\n    return { parsed: parsedAll, error: lastError }\n  } else {\n    return { parsed: parsedAll }\n  }\n}\n\n// Populates process.env from .env file\nfunction config (options) {\n  // fallback to original dotenv if DOTENV_KEY is not set\n  if (_dotenvKey(options).length === 0) {\n    return DotenvModule.configDotenv(options)\n  }\n\n  const vaultPath = _vaultPath(options)\n\n  // dotenvKey exists but .env.vault file does not exist\n  if (!vaultPath) {\n    _warn(`You set DOTENV_KEY but you are missing a .env.vault file at ${vaultPath}. Did you forget to build it?`)\n\n    return DotenvModule.configDotenv(options)\n  }\n\n  return DotenvModule._configVault(options)\n}\n\nfunction decrypt (encrypted, keyStr) {\n  const key = Buffer.from(keyStr.slice(-64), 'hex')\n  let ciphertext = Buffer.from(encrypted, 'base64')\n\n  const nonce = ciphertext.subarray(0, 12)\n  const authTag = ciphertext.subarray(-16)\n  ciphertext = ciphertext.subarray(12, -16)\n\n  try {\n    const aesgcm = crypto.createDecipheriv('aes-256-gcm', key, nonce)\n    aesgcm.setAuthTag(authTag)\n    return `${aesgcm.update(ciphertext)}${aesgcm.final()}`\n  } catch (error) {\n    const isRange = error instanceof RangeError\n    const invalidKeyLength = error.message === 'Invalid key length'\n    const decryptionFailed = error.message === 'Unsupported state or unable to authenticate data'\n\n    if (isRange || invalidKeyLength) {\n      const err = new Error('INVALID_DOTENV_KEY: It must be 64 characters long (or more)')\n      err.code = 'INVALID_DOTENV_KEY'\n      throw err\n    } else if (decryptionFailed) {\n      const err = new Error('DECRYPTION_FAILED: Please check your DOTENV_KEY')\n      err.code = 'DECRYPTION_FAILED'\n      throw err\n    } else {\n      throw error\n    }\n  }\n}\n\n// Populate process.env with parsed values\nfunction populate (processEnv, parsed, options = {}) {\n  const debug = Boolean(options && options.debug)\n  const override = Boolean(options && options.override)\n\n  if (typeof parsed !== 'object') {\n    const err = new Error('OBJECT_REQUIRED: Please check the processEnv argument being passed to populate')\n    err.code = 'OBJECT_REQUIRED'\n    throw err\n  }\n\n  // Set process.env\n  for (const key of Object.keys(parsed)) {\n    if (Object.prototype.hasOwnProperty.call(processEnv, key)) {\n      if (override === true) {\n        processEnv[key] = parsed[key]\n      }\n\n      if (debug) {\n        if (override === true) {\n          _debug(`\"${key}\" is already defined and WAS overwritten`)\n        } else {\n          _debug(`\"${key}\" is already defined and was NOT overwritten`)\n        }\n      }\n    } else {\n      processEnv[key] = parsed[key]\n    }\n  }\n}\n\nconst DotenvModule = {\n  configDotenv,\n  _configVault,\n  _parseVault,\n  config,\n  decrypt,\n  parse,\n  populate\n}\n\nmodule.exports.configDotenv = DotenvModule.configDotenv\nmodule.exports._configVault = DotenvModule._configVault\nmodule.exports._parseVault = DotenvModule._parseVault\nmodule.exports.config = DotenvModule.config\nmodule.exports.decrypt = DotenvModule.decrypt\nmodule.exports.parse = DotenvModule.parse\nmodule.exports.populate = DotenvModule.populate\n\nmodule.exports = DotenvModule\n\n\n//# sourceURL=webpack://thelambda/./node_modules/dotenv/lib/main.js?");

/***/ }),

/***/ "./node_modules/emoji-regex/index.js":
/*!*******************************************!*\
  !*** ./node_modules/emoji-regex/index.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function () {\n  // https://mths.be/emoji\n  return /\\uD83C\\uDFF4\\uDB40\\uDC67\\uDB40\\uDC62(?:\\uDB40\\uDC65\\uDB40\\uDC6E\\uDB40\\uDC67|\\uDB40\\uDC73\\uDB40\\uDC63\\uDB40\\uDC74|\\uDB40\\uDC77\\uDB40\\uDC6C\\uDB40\\uDC73)\\uDB40\\uDC7F|\\uD83D\\uDC68(?:\\uD83C\\uDFFC\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68\\uD83C\\uDFFB|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFF\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFB-\\uDFFE])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFE\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFB-\\uDFFD])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFD\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFB\\uDFFC])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\u200D(?:\\u2764\\uFE0F\\u200D(?:\\uD83D\\uDC8B\\u200D)?\\uD83D\\uDC68|(?:\\uD83D[\\uDC68\\uDC69])\\u200D(?:\\uD83D\\uDC66\\u200D\\uD83D\\uDC66|\\uD83D\\uDC67\\u200D(?:\\uD83D[\\uDC66\\uDC67]))|\\uD83D\\uDC66\\u200D\\uD83D\\uDC66|\\uD83D\\uDC67\\u200D(?:\\uD83D[\\uDC66\\uDC67])|(?:\\uD83D[\\uDC68\\uDC69])\\u200D(?:\\uD83D[\\uDC66\\uDC67])|[\\u2695\\u2696\\u2708]\\uFE0F|\\uD83D[\\uDC66\\uDC67]|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|(?:\\uD83C\\uDFFB\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFF\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFE\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFD\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFC\\u200D[\\u2695\\u2696\\u2708])\\uFE0F|\\uD83C\\uDFFB\\u200D(?:\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C[\\uDFFB-\\uDFFF])|(?:\\uD83E\\uDDD1\\uD83C\\uDFFB\\u200D\\uD83E\\uDD1D\\u200D\\uD83E\\uDDD1|\\uD83D\\uDC69\\uD83C\\uDFFC\\u200D\\uD83E\\uDD1D\\u200D\\uD83D\\uDC69)\\uD83C\\uDFFB|\\uD83E\\uDDD1(?:\\uD83C\\uDFFF\\u200D\\uD83E\\uDD1D\\u200D\\uD83E\\uDDD1(?:\\uD83C[\\uDFFB-\\uDFFF])|\\u200D\\uD83E\\uDD1D\\u200D\\uD83E\\uDDD1)|(?:\\uD83E\\uDDD1\\uD83C\\uDFFE\\u200D\\uD83E\\uDD1D\\u200D\\uD83E\\uDDD1|\\uD83D\\uDC69\\uD83C\\uDFFF\\u200D\\uD83E\\uDD1D\\u200D(?:\\uD83D[\\uDC68\\uDC69]))(?:\\uD83C[\\uDFFB-\\uDFFE])|(?:\\uD83E\\uDDD1\\uD83C\\uDFFC\\u200D\\uD83E\\uDD1D\\u200D\\uD83E\\uDDD1|\\uD83D\\uDC69\\uD83C\\uDFFD\\u200D\\uD83E\\uDD1D\\u200D\\uD83D\\uDC69)(?:\\uD83C[\\uDFFB\\uDFFC])|\\uD83D\\uDC69(?:\\uD83C\\uDFFE\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFB-\\uDFFD\\uDFFF])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFC\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFB\\uDFFD-\\uDFFF])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFB\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFC-\\uDFFF])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFD\\u200D(?:\\uD83E\\uDD1D\\u200D\\uD83D\\uDC68(?:\\uD83C[\\uDFFB\\uDFFC\\uDFFE\\uDFFF])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\u200D(?:\\u2764\\uFE0F\\u200D(?:\\uD83D\\uDC8B\\u200D(?:\\uD83D[\\uDC68\\uDC69])|\\uD83D[\\uDC68\\uDC69])|\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD])|\\uD83C\\uDFFF\\u200D(?:\\uD83C[\\uDF3E\\uDF73\\uDF93\\uDFA4\\uDFA8\\uDFEB\\uDFED]|\\uD83D[\\uDCBB\\uDCBC\\uDD27\\uDD2C\\uDE80\\uDE92]|\\uD83E[\\uDDAF-\\uDDB3\\uDDBC\\uDDBD]))|\\uD83D\\uDC69\\u200D\\uD83D\\uDC69\\u200D(?:\\uD83D\\uDC66\\u200D\\uD83D\\uDC66|\\uD83D\\uDC67\\u200D(?:\\uD83D[\\uDC66\\uDC67]))|(?:\\uD83E\\uDDD1\\uD83C\\uDFFD\\u200D\\uD83E\\uDD1D\\u200D\\uD83E\\uDDD1|\\uD83D\\uDC69\\uD83C\\uDFFE\\u200D\\uD83E\\uDD1D\\u200D\\uD83D\\uDC69)(?:\\uD83C[\\uDFFB-\\uDFFD])|\\uD83D\\uDC69\\u200D\\uD83D\\uDC66\\u200D\\uD83D\\uDC66|\\uD83D\\uDC69\\u200D\\uD83D\\uDC69\\u200D(?:\\uD83D[\\uDC66\\uDC67])|(?:\\uD83D\\uDC41\\uFE0F\\u200D\\uD83D\\uDDE8|\\uD83D\\uDC69(?:\\uD83C\\uDFFF\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFE\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFC\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFB\\u200D[\\u2695\\u2696\\u2708]|\\uD83C\\uDFFD\\u200D[\\u2695\\u2696\\u2708]|\\u200D[\\u2695\\u2696\\u2708])|(?:(?:\\u26F9|\\uD83C[\\uDFCB\\uDFCC]|\\uD83D\\uDD75)\\uFE0F|\\uD83D\\uDC6F|\\uD83E[\\uDD3C\\uDDDE\\uDDDF])\\u200D[\\u2640\\u2642]|(?:\\u26F9|\\uD83C[\\uDFCB\\uDFCC]|\\uD83D\\uDD75)(?:\\uD83C[\\uDFFB-\\uDFFF])\\u200D[\\u2640\\u2642]|(?:\\uD83C[\\uDFC3\\uDFC4\\uDFCA]|\\uD83D[\\uDC6E\\uDC71\\uDC73\\uDC77\\uDC81\\uDC82\\uDC86\\uDC87\\uDE45-\\uDE47\\uDE4B\\uDE4D\\uDE4E\\uDEA3\\uDEB4-\\uDEB6]|\\uD83E[\\uDD26\\uDD37-\\uDD39\\uDD3D\\uDD3E\\uDDB8\\uDDB9\\uDDCD-\\uDDCF\\uDDD6-\\uDDDD])(?:(?:\\uD83C[\\uDFFB-\\uDFFF])\\u200D[\\u2640\\u2642]|\\u200D[\\u2640\\u2642])|\\uD83C\\uDFF4\\u200D\\u2620)\\uFE0F|\\uD83D\\uDC69\\u200D\\uD83D\\uDC67\\u200D(?:\\uD83D[\\uDC66\\uDC67])|\\uD83C\\uDFF3\\uFE0F\\u200D\\uD83C\\uDF08|\\uD83D\\uDC15\\u200D\\uD83E\\uDDBA|\\uD83D\\uDC69\\u200D\\uD83D\\uDC66|\\uD83D\\uDC69\\u200D\\uD83D\\uDC67|\\uD83C\\uDDFD\\uD83C\\uDDF0|\\uD83C\\uDDF4\\uD83C\\uDDF2|\\uD83C\\uDDF6\\uD83C\\uDDE6|[#\\*0-9]\\uFE0F\\u20E3|\\uD83C\\uDDE7(?:\\uD83C[\\uDDE6\\uDDE7\\uDDE9-\\uDDEF\\uDDF1-\\uDDF4\\uDDF6-\\uDDF9\\uDDFB\\uDDFC\\uDDFE\\uDDFF])|\\uD83C\\uDDF9(?:\\uD83C[\\uDDE6\\uDDE8\\uDDE9\\uDDEB-\\uDDED\\uDDEF-\\uDDF4\\uDDF7\\uDDF9\\uDDFB\\uDDFC\\uDDFF])|\\uD83C\\uDDEA(?:\\uD83C[\\uDDE6\\uDDE8\\uDDEA\\uDDEC\\uDDED\\uDDF7-\\uDDFA])|\\uD83E\\uDDD1(?:\\uD83C[\\uDFFB-\\uDFFF])|\\uD83C\\uDDF7(?:\\uD83C[\\uDDEA\\uDDF4\\uDDF8\\uDDFA\\uDDFC])|\\uD83D\\uDC69(?:\\uD83C[\\uDFFB-\\uDFFF])|\\uD83C\\uDDF2(?:\\uD83C[\\uDDE6\\uDDE8-\\uDDED\\uDDF0-\\uDDFF])|\\uD83C\\uDDE6(?:\\uD83C[\\uDDE8-\\uDDEC\\uDDEE\\uDDF1\\uDDF2\\uDDF4\\uDDF6-\\uDDFA\\uDDFC\\uDDFD\\uDDFF])|\\uD83C\\uDDF0(?:\\uD83C[\\uDDEA\\uDDEC-\\uDDEE\\uDDF2\\uDDF3\\uDDF5\\uDDF7\\uDDFC\\uDDFE\\uDDFF])|\\uD83C\\uDDED(?:\\uD83C[\\uDDF0\\uDDF2\\uDDF3\\uDDF7\\uDDF9\\uDDFA])|\\uD83C\\uDDE9(?:\\uD83C[\\uDDEA\\uDDEC\\uDDEF\\uDDF0\\uDDF2\\uDDF4\\uDDFF])|\\uD83C\\uDDFE(?:\\uD83C[\\uDDEA\\uDDF9])|\\uD83C\\uDDEC(?:\\uD83C[\\uDDE6\\uDDE7\\uDDE9-\\uDDEE\\uDDF1-\\uDDF3\\uDDF5-\\uDDFA\\uDDFC\\uDDFE])|\\uD83C\\uDDF8(?:\\uD83C[\\uDDE6-\\uDDEA\\uDDEC-\\uDDF4\\uDDF7-\\uDDF9\\uDDFB\\uDDFD-\\uDDFF])|\\uD83C\\uDDEB(?:\\uD83C[\\uDDEE-\\uDDF0\\uDDF2\\uDDF4\\uDDF7])|\\uD83C\\uDDF5(?:\\uD83C[\\uDDE6\\uDDEA-\\uDDED\\uDDF0-\\uDDF3\\uDDF7-\\uDDF9\\uDDFC\\uDDFE])|\\uD83C\\uDDFB(?:\\uD83C[\\uDDE6\\uDDE8\\uDDEA\\uDDEC\\uDDEE\\uDDF3\\uDDFA])|\\uD83C\\uDDF3(?:\\uD83C[\\uDDE6\\uDDE8\\uDDEA-\\uDDEC\\uDDEE\\uDDF1\\uDDF4\\uDDF5\\uDDF7\\uDDFA\\uDDFF])|\\uD83C\\uDDE8(?:\\uD83C[\\uDDE6\\uDDE8\\uDDE9\\uDDEB-\\uDDEE\\uDDF0-\\uDDF5\\uDDF7\\uDDFA-\\uDDFF])|\\uD83C\\uDDF1(?:\\uD83C[\\uDDE6-\\uDDE8\\uDDEE\\uDDF0\\uDDF7-\\uDDFB\\uDDFE])|\\uD83C\\uDDFF(?:\\uD83C[\\uDDE6\\uDDF2\\uDDFC])|\\uD83C\\uDDFC(?:\\uD83C[\\uDDEB\\uDDF8])|\\uD83C\\uDDFA(?:\\uD83C[\\uDDE6\\uDDEC\\uDDF2\\uDDF3\\uDDF8\\uDDFE\\uDDFF])|\\uD83C\\uDDEE(?:\\uD83C[\\uDDE8-\\uDDEA\\uDDF1-\\uDDF4\\uDDF6-\\uDDF9])|\\uD83C\\uDDEF(?:\\uD83C[\\uDDEA\\uDDF2\\uDDF4\\uDDF5])|(?:\\uD83C[\\uDFC3\\uDFC4\\uDFCA]|\\uD83D[\\uDC6E\\uDC71\\uDC73\\uDC77\\uDC81\\uDC82\\uDC86\\uDC87\\uDE45-\\uDE47\\uDE4B\\uDE4D\\uDE4E\\uDEA3\\uDEB4-\\uDEB6]|\\uD83E[\\uDD26\\uDD37-\\uDD39\\uDD3D\\uDD3E\\uDDB8\\uDDB9\\uDDCD-\\uDDCF\\uDDD6-\\uDDDD])(?:\\uD83C[\\uDFFB-\\uDFFF])|(?:\\u26F9|\\uD83C[\\uDFCB\\uDFCC]|\\uD83D\\uDD75)(?:\\uD83C[\\uDFFB-\\uDFFF])|(?:[\\u261D\\u270A-\\u270D]|\\uD83C[\\uDF85\\uDFC2\\uDFC7]|\\uD83D[\\uDC42\\uDC43\\uDC46-\\uDC50\\uDC66\\uDC67\\uDC6B-\\uDC6D\\uDC70\\uDC72\\uDC74-\\uDC76\\uDC78\\uDC7C\\uDC83\\uDC85\\uDCAA\\uDD74\\uDD7A\\uDD90\\uDD95\\uDD96\\uDE4C\\uDE4F\\uDEC0\\uDECC]|\\uD83E[\\uDD0F\\uDD18-\\uDD1C\\uDD1E\\uDD1F\\uDD30-\\uDD36\\uDDB5\\uDDB6\\uDDBB\\uDDD2-\\uDDD5])(?:\\uD83C[\\uDFFB-\\uDFFF])|(?:[\\u231A\\u231B\\u23E9-\\u23EC\\u23F0\\u23F3\\u25FD\\u25FE\\u2614\\u2615\\u2648-\\u2653\\u267F\\u2693\\u26A1\\u26AA\\u26AB\\u26BD\\u26BE\\u26C4\\u26C5\\u26CE\\u26D4\\u26EA\\u26F2\\u26F3\\u26F5\\u26FA\\u26FD\\u2705\\u270A\\u270B\\u2728\\u274C\\u274E\\u2753-\\u2755\\u2757\\u2795-\\u2797\\u27B0\\u27BF\\u2B1B\\u2B1C\\u2B50\\u2B55]|\\uD83C[\\uDC04\\uDCCF\\uDD8E\\uDD91-\\uDD9A\\uDDE6-\\uDDFF\\uDE01\\uDE1A\\uDE2F\\uDE32-\\uDE36\\uDE38-\\uDE3A\\uDE50\\uDE51\\uDF00-\\uDF20\\uDF2D-\\uDF35\\uDF37-\\uDF7C\\uDF7E-\\uDF93\\uDFA0-\\uDFCA\\uDFCF-\\uDFD3\\uDFE0-\\uDFF0\\uDFF4\\uDFF8-\\uDFFF]|\\uD83D[\\uDC00-\\uDC3E\\uDC40\\uDC42-\\uDCFC\\uDCFF-\\uDD3D\\uDD4B-\\uDD4E\\uDD50-\\uDD67\\uDD7A\\uDD95\\uDD96\\uDDA4\\uDDFB-\\uDE4F\\uDE80-\\uDEC5\\uDECC\\uDED0-\\uDED2\\uDED5\\uDEEB\\uDEEC\\uDEF4-\\uDEFA\\uDFE0-\\uDFEB]|\\uD83E[\\uDD0D-\\uDD3A\\uDD3C-\\uDD45\\uDD47-\\uDD71\\uDD73-\\uDD76\\uDD7A-\\uDDA2\\uDDA5-\\uDDAA\\uDDAE-\\uDDCA\\uDDCD-\\uDDFF\\uDE70-\\uDE73\\uDE78-\\uDE7A\\uDE80-\\uDE82\\uDE90-\\uDE95])|(?:[#\\*0-9\\xA9\\xAE\\u203C\\u2049\\u2122\\u2139\\u2194-\\u2199\\u21A9\\u21AA\\u231A\\u231B\\u2328\\u23CF\\u23E9-\\u23F3\\u23F8-\\u23FA\\u24C2\\u25AA\\u25AB\\u25B6\\u25C0\\u25FB-\\u25FE\\u2600-\\u2604\\u260E\\u2611\\u2614\\u2615\\u2618\\u261D\\u2620\\u2622\\u2623\\u2626\\u262A\\u262E\\u262F\\u2638-\\u263A\\u2640\\u2642\\u2648-\\u2653\\u265F\\u2660\\u2663\\u2665\\u2666\\u2668\\u267B\\u267E\\u267F\\u2692-\\u2697\\u2699\\u269B\\u269C\\u26A0\\u26A1\\u26AA\\u26AB\\u26B0\\u26B1\\u26BD\\u26BE\\u26C4\\u26C5\\u26C8\\u26CE\\u26CF\\u26D1\\u26D3\\u26D4\\u26E9\\u26EA\\u26F0-\\u26F5\\u26F7-\\u26FA\\u26FD\\u2702\\u2705\\u2708-\\u270D\\u270F\\u2712\\u2714\\u2716\\u271D\\u2721\\u2728\\u2733\\u2734\\u2744\\u2747\\u274C\\u274E\\u2753-\\u2755\\u2757\\u2763\\u2764\\u2795-\\u2797\\u27A1\\u27B0\\u27BF\\u2934\\u2935\\u2B05-\\u2B07\\u2B1B\\u2B1C\\u2B50\\u2B55\\u3030\\u303D\\u3297\\u3299]|\\uD83C[\\uDC04\\uDCCF\\uDD70\\uDD71\\uDD7E\\uDD7F\\uDD8E\\uDD91-\\uDD9A\\uDDE6-\\uDDFF\\uDE01\\uDE02\\uDE1A\\uDE2F\\uDE32-\\uDE3A\\uDE50\\uDE51\\uDF00-\\uDF21\\uDF24-\\uDF93\\uDF96\\uDF97\\uDF99-\\uDF9B\\uDF9E-\\uDFF0\\uDFF3-\\uDFF5\\uDFF7-\\uDFFF]|\\uD83D[\\uDC00-\\uDCFD\\uDCFF-\\uDD3D\\uDD49-\\uDD4E\\uDD50-\\uDD67\\uDD6F\\uDD70\\uDD73-\\uDD7A\\uDD87\\uDD8A-\\uDD8D\\uDD90\\uDD95\\uDD96\\uDDA4\\uDDA5\\uDDA8\\uDDB1\\uDDB2\\uDDBC\\uDDC2-\\uDDC4\\uDDD1-\\uDDD3\\uDDDC-\\uDDDE\\uDDE1\\uDDE3\\uDDE8\\uDDEF\\uDDF3\\uDDFA-\\uDE4F\\uDE80-\\uDEC5\\uDECB-\\uDED2\\uDED5\\uDEE0-\\uDEE5\\uDEE9\\uDEEB\\uDEEC\\uDEF0\\uDEF3-\\uDEFA\\uDFE0-\\uDFEB]|\\uD83E[\\uDD0D-\\uDD3A\\uDD3C-\\uDD45\\uDD47-\\uDD71\\uDD73-\\uDD76\\uDD7A-\\uDDA2\\uDDA5-\\uDDAA\\uDDAE-\\uDDCA\\uDDCD-\\uDDFF\\uDE70-\\uDE73\\uDE78-\\uDE7A\\uDE80-\\uDE82\\uDE90-\\uDE95])\\uFE0F|(?:[\\u261D\\u26F9\\u270A-\\u270D]|\\uD83C[\\uDF85\\uDFC2-\\uDFC4\\uDFC7\\uDFCA-\\uDFCC]|\\uD83D[\\uDC42\\uDC43\\uDC46-\\uDC50\\uDC66-\\uDC78\\uDC7C\\uDC81-\\uDC83\\uDC85-\\uDC87\\uDC8F\\uDC91\\uDCAA\\uDD74\\uDD75\\uDD7A\\uDD90\\uDD95\\uDD96\\uDE45-\\uDE47\\uDE4B-\\uDE4F\\uDEA3\\uDEB4-\\uDEB6\\uDEC0\\uDECC]|\\uD83E[\\uDD0F\\uDD18-\\uDD1F\\uDD26\\uDD30-\\uDD39\\uDD3C-\\uDD3E\\uDDB5\\uDDB6\\uDDB8\\uDDB9\\uDDBB\\uDDCD-\\uDDCF\\uDDD1-\\uDDDD])/g;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/emoji-regex/index.js?");

/***/ }),

/***/ "./node_modules/es-define-property/index.js":
/*!**************************************************!*\
  !*** ./node_modules/es-define-property/index.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"./node_modules/get-intrinsic/index.js\");\n\n/** @type {import('.')} */\nvar $defineProperty = GetIntrinsic('%Object.defineProperty%', true) || false;\nif ($defineProperty) {\n\ttry {\n\t\t$defineProperty({}, 'a', { value: 1 });\n\t} catch (e) {\n\t\t// IE 8 has a broken defineProperty\n\t\t$defineProperty = false;\n\t}\n}\n\nmodule.exports = $defineProperty;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-define-property/index.js?");

/***/ }),

/***/ "./node_modules/es-errors/eval.js":
/*!****************************************!*\
  !*** ./node_modules/es-errors/eval.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('./eval')} */\nmodule.exports = EvalError;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/eval.js?");

/***/ }),

/***/ "./node_modules/es-errors/index.js":
/*!*****************************************!*\
  !*** ./node_modules/es-errors/index.js ***!
  \*****************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('.')} */\nmodule.exports = Error;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/index.js?");

/***/ }),

/***/ "./node_modules/es-errors/range.js":
/*!*****************************************!*\
  !*** ./node_modules/es-errors/range.js ***!
  \*****************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('./range')} */\nmodule.exports = RangeError;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/range.js?");

/***/ }),

/***/ "./node_modules/es-errors/ref.js":
/*!***************************************!*\
  !*** ./node_modules/es-errors/ref.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('./ref')} */\nmodule.exports = ReferenceError;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/ref.js?");

/***/ }),

/***/ "./node_modules/es-errors/syntax.js":
/*!******************************************!*\
  !*** ./node_modules/es-errors/syntax.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('./syntax')} */\nmodule.exports = SyntaxError;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/syntax.js?");

/***/ }),

/***/ "./node_modules/es-errors/type.js":
/*!****************************************!*\
  !*** ./node_modules/es-errors/type.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('./type')} */\nmodule.exports = TypeError;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/type.js?");

/***/ }),

/***/ "./node_modules/es-errors/uri.js":
/*!***************************************!*\
  !*** ./node_modules/es-errors/uri.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/** @type {import('./uri')} */\nmodule.exports = URIError;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/es-errors/uri.js?");

/***/ }),

/***/ "./node_modules/events/events.js":
/*!***************************************!*\
  !*** ./node_modules/events/events.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nvar R = typeof Reflect === 'object' ? Reflect : null\nvar ReflectApply = R && typeof R.apply === 'function'\n  ? R.apply\n  : function ReflectApply(target, receiver, args) {\n    return Function.prototype.apply.call(target, receiver, args);\n  }\n\nvar ReflectOwnKeys\nif (R && typeof R.ownKeys === 'function') {\n  ReflectOwnKeys = R.ownKeys\n} else if (Object.getOwnPropertySymbols) {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target)\n      .concat(Object.getOwnPropertySymbols(target));\n  };\n} else {\n  ReflectOwnKeys = function ReflectOwnKeys(target) {\n    return Object.getOwnPropertyNames(target);\n  };\n}\n\nfunction ProcessEmitWarning(warning) {\n  if (console && console.warn) console.warn(warning);\n}\n\nvar NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {\n  return value !== value;\n}\n\nfunction EventEmitter() {\n  EventEmitter.init.call(this);\n}\nmodule.exports = EventEmitter;\nmodule.exports.once = once;\n\n// Backwards-compat with node 0.10.x\nEventEmitter.EventEmitter = EventEmitter;\n\nEventEmitter.prototype._events = undefined;\nEventEmitter.prototype._eventsCount = 0;\nEventEmitter.prototype._maxListeners = undefined;\n\n// By default EventEmitters will print a warning if more than 10 listeners are\n// added to it. This is a useful default which helps finding memory leaks.\nvar defaultMaxListeners = 10;\n\nfunction checkListener(listener) {\n  if (typeof listener !== 'function') {\n    throw new TypeError('The \"listener\" argument must be of type Function. Received type ' + typeof listener);\n  }\n}\n\nObject.defineProperty(EventEmitter, 'defaultMaxListeners', {\n  enumerable: true,\n  get: function() {\n    return defaultMaxListeners;\n  },\n  set: function(arg) {\n    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {\n      throw new RangeError('The value of \"defaultMaxListeners\" is out of range. It must be a non-negative number. Received ' + arg + '.');\n    }\n    defaultMaxListeners = arg;\n  }\n});\n\nEventEmitter.init = function() {\n\n  if (this._events === undefined ||\n      this._events === Object.getPrototypeOf(this)._events) {\n    this._events = Object.create(null);\n    this._eventsCount = 0;\n  }\n\n  this._maxListeners = this._maxListeners || undefined;\n};\n\n// Obviously not all Emitters should be limited to 10. This function allows\n// that to be increased. Set to zero for unlimited.\nEventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {\n  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {\n    throw new RangeError('The value of \"n\" is out of range. It must be a non-negative number. Received ' + n + '.');\n  }\n  this._maxListeners = n;\n  return this;\n};\n\nfunction _getMaxListeners(that) {\n  if (that._maxListeners === undefined)\n    return EventEmitter.defaultMaxListeners;\n  return that._maxListeners;\n}\n\nEventEmitter.prototype.getMaxListeners = function getMaxListeners() {\n  return _getMaxListeners(this);\n};\n\nEventEmitter.prototype.emit = function emit(type) {\n  var args = [];\n  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);\n  var doError = (type === 'error');\n\n  var events = this._events;\n  if (events !== undefined)\n    doError = (doError && events.error === undefined);\n  else if (!doError)\n    return false;\n\n  // If there is no 'error' event listener then throw.\n  if (doError) {\n    var er;\n    if (args.length > 0)\n      er = args[0];\n    if (er instanceof Error) {\n      // Note: The comments on the `throw` lines are intentional, they show\n      // up in Node's output if this results in an unhandled exception.\n      throw er; // Unhandled 'error' event\n    }\n    // At least give some kind of context to the user\n    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));\n    err.context = er;\n    throw err; // Unhandled 'error' event\n  }\n\n  var handler = events[type];\n\n  if (handler === undefined)\n    return false;\n\n  if (typeof handler === 'function') {\n    ReflectApply(handler, this, args);\n  } else {\n    var len = handler.length;\n    var listeners = arrayClone(handler, len);\n    for (var i = 0; i < len; ++i)\n      ReflectApply(listeners[i], this, args);\n  }\n\n  return true;\n};\n\nfunction _addListener(target, type, listener, prepend) {\n  var m;\n  var events;\n  var existing;\n\n  checkListener(listener);\n\n  events = target._events;\n  if (events === undefined) {\n    events = target._events = Object.create(null);\n    target._eventsCount = 0;\n  } else {\n    // To avoid recursion in the case that type === \"newListener\"! Before\n    // adding it to the listeners, first emit \"newListener\".\n    if (events.newListener !== undefined) {\n      target.emit('newListener', type,\n                  listener.listener ? listener.listener : listener);\n\n      // Re-assign `events` because a newListener handler could have caused the\n      // this._events to be assigned to a new object\n      events = target._events;\n    }\n    existing = events[type];\n  }\n\n  if (existing === undefined) {\n    // Optimize the case of one listener. Don't need the extra array object.\n    existing = events[type] = listener;\n    ++target._eventsCount;\n  } else {\n    if (typeof existing === 'function') {\n      // Adding the second element, need to change to array.\n      existing = events[type] =\n        prepend ? [listener, existing] : [existing, listener];\n      // If we've already got an array, just append.\n    } else if (prepend) {\n      existing.unshift(listener);\n    } else {\n      existing.push(listener);\n    }\n\n    // Check for listener leak\n    m = _getMaxListeners(target);\n    if (m > 0 && existing.length > m && !existing.warned) {\n      existing.warned = true;\n      // No error code for this since it is a Warning\n      // eslint-disable-next-line no-restricted-syntax\n      var w = new Error('Possible EventEmitter memory leak detected. ' +\n                          existing.length + ' ' + String(type) + ' listeners ' +\n                          'added. Use emitter.setMaxListeners() to ' +\n                          'increase limit');\n      w.name = 'MaxListenersExceededWarning';\n      w.emitter = target;\n      w.type = type;\n      w.count = existing.length;\n      ProcessEmitWarning(w);\n    }\n  }\n\n  return target;\n}\n\nEventEmitter.prototype.addListener = function addListener(type, listener) {\n  return _addListener(this, type, listener, false);\n};\n\nEventEmitter.prototype.on = EventEmitter.prototype.addListener;\n\nEventEmitter.prototype.prependListener =\n    function prependListener(type, listener) {\n      return _addListener(this, type, listener, true);\n    };\n\nfunction onceWrapper() {\n  if (!this.fired) {\n    this.target.removeListener(this.type, this.wrapFn);\n    this.fired = true;\n    if (arguments.length === 0)\n      return this.listener.call(this.target);\n    return this.listener.apply(this.target, arguments);\n  }\n}\n\nfunction _onceWrap(target, type, listener) {\n  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };\n  var wrapped = onceWrapper.bind(state);\n  wrapped.listener = listener;\n  state.wrapFn = wrapped;\n  return wrapped;\n}\n\nEventEmitter.prototype.once = function once(type, listener) {\n  checkListener(listener);\n  this.on(type, _onceWrap(this, type, listener));\n  return this;\n};\n\nEventEmitter.prototype.prependOnceListener =\n    function prependOnceListener(type, listener) {\n      checkListener(listener);\n      this.prependListener(type, _onceWrap(this, type, listener));\n      return this;\n    };\n\n// Emits a 'removeListener' event if and only if the listener was removed.\nEventEmitter.prototype.removeListener =\n    function removeListener(type, listener) {\n      var list, events, position, i, originalListener;\n\n      checkListener(listener);\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      list = events[type];\n      if (list === undefined)\n        return this;\n\n      if (list === listener || list.listener === listener) {\n        if (--this._eventsCount === 0)\n          this._events = Object.create(null);\n        else {\n          delete events[type];\n          if (events.removeListener)\n            this.emit('removeListener', type, list.listener || listener);\n        }\n      } else if (typeof list !== 'function') {\n        position = -1;\n\n        for (i = list.length - 1; i >= 0; i--) {\n          if (list[i] === listener || list[i].listener === listener) {\n            originalListener = list[i].listener;\n            position = i;\n            break;\n          }\n        }\n\n        if (position < 0)\n          return this;\n\n        if (position === 0)\n          list.shift();\n        else {\n          spliceOne(list, position);\n        }\n\n        if (list.length === 1)\n          events[type] = list[0];\n\n        if (events.removeListener !== undefined)\n          this.emit('removeListener', type, originalListener || listener);\n      }\n\n      return this;\n    };\n\nEventEmitter.prototype.off = EventEmitter.prototype.removeListener;\n\nEventEmitter.prototype.removeAllListeners =\n    function removeAllListeners(type) {\n      var listeners, events, i;\n\n      events = this._events;\n      if (events === undefined)\n        return this;\n\n      // not listening for removeListener, no need to emit\n      if (events.removeListener === undefined) {\n        if (arguments.length === 0) {\n          this._events = Object.create(null);\n          this._eventsCount = 0;\n        } else if (events[type] !== undefined) {\n          if (--this._eventsCount === 0)\n            this._events = Object.create(null);\n          else\n            delete events[type];\n        }\n        return this;\n      }\n\n      // emit removeListener for all listeners on all events\n      if (arguments.length === 0) {\n        var keys = Object.keys(events);\n        var key;\n        for (i = 0; i < keys.length; ++i) {\n          key = keys[i];\n          if (key === 'removeListener') continue;\n          this.removeAllListeners(key);\n        }\n        this.removeAllListeners('removeListener');\n        this._events = Object.create(null);\n        this._eventsCount = 0;\n        return this;\n      }\n\n      listeners = events[type];\n\n      if (typeof listeners === 'function') {\n        this.removeListener(type, listeners);\n      } else if (listeners !== undefined) {\n        // LIFO order\n        for (i = listeners.length - 1; i >= 0; i--) {\n          this.removeListener(type, listeners[i]);\n        }\n      }\n\n      return this;\n    };\n\nfunction _listeners(target, type, unwrap) {\n  var events = target._events;\n\n  if (events === undefined)\n    return [];\n\n  var evlistener = events[type];\n  if (evlistener === undefined)\n    return [];\n\n  if (typeof evlistener === 'function')\n    return unwrap ? [evlistener.listener || evlistener] : [evlistener];\n\n  return unwrap ?\n    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);\n}\n\nEventEmitter.prototype.listeners = function listeners(type) {\n  return _listeners(this, type, true);\n};\n\nEventEmitter.prototype.rawListeners = function rawListeners(type) {\n  return _listeners(this, type, false);\n};\n\nEventEmitter.listenerCount = function(emitter, type) {\n  if (typeof emitter.listenerCount === 'function') {\n    return emitter.listenerCount(type);\n  } else {\n    return listenerCount.call(emitter, type);\n  }\n};\n\nEventEmitter.prototype.listenerCount = listenerCount;\nfunction listenerCount(type) {\n  var events = this._events;\n\n  if (events !== undefined) {\n    var evlistener = events[type];\n\n    if (typeof evlistener === 'function') {\n      return 1;\n    } else if (evlistener !== undefined) {\n      return evlistener.length;\n    }\n  }\n\n  return 0;\n}\n\nEventEmitter.prototype.eventNames = function eventNames() {\n  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];\n};\n\nfunction arrayClone(arr, n) {\n  var copy = new Array(n);\n  for (var i = 0; i < n; ++i)\n    copy[i] = arr[i];\n  return copy;\n}\n\nfunction spliceOne(list, index) {\n  for (; index + 1 < list.length; index++)\n    list[index] = list[index + 1];\n  list.pop();\n}\n\nfunction unwrapListeners(arr) {\n  var ret = new Array(arr.length);\n  for (var i = 0; i < ret.length; ++i) {\n    ret[i] = arr[i].listener || arr[i];\n  }\n  return ret;\n}\n\nfunction once(emitter, name) {\n  return new Promise(function (resolve, reject) {\n    function errorListener(err) {\n      emitter.removeListener(name, resolver);\n      reject(err);\n    }\n\n    function resolver() {\n      if (typeof emitter.removeListener === 'function') {\n        emitter.removeListener('error', errorListener);\n      }\n      resolve([].slice.call(arguments));\n    };\n\n    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });\n    if (name !== 'error') {\n      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });\n    }\n  });\n}\n\nfunction addErrorHandlerIfEventEmitter(emitter, handler, flags) {\n  if (typeof emitter.on === 'function') {\n    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);\n  }\n}\n\nfunction eventTargetAgnosticAddListener(emitter, name, listener, flags) {\n  if (typeof emitter.on === 'function') {\n    if (flags.once) {\n      emitter.once(name, listener);\n    } else {\n      emitter.on(name, listener);\n    }\n  } else if (typeof emitter.addEventListener === 'function') {\n    // EventTarget does not have `error` event semantics like Node\n    // EventEmitters, we do not listen for `error` events here.\n    emitter.addEventListener(name, function wrapListener(arg) {\n      // IE does not have builtin `{ once: true }` support so we\n      // have to do it manually.\n      if (flags.once) {\n        emitter.removeEventListener(name, wrapListener);\n      }\n      listener(arg);\n    });\n  } else {\n    throw new TypeError('The \"emitter\" argument must be of type EventEmitter. Received type ' + typeof emitter);\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/events/events.js?");

/***/ }),

/***/ "./node_modules/fs-minipass/index.js":
/*!*******************************************!*\
  !*** ./node_modules/fs-minipass/index.js ***!
  \*******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst MiniPass = __webpack_require__(/*! minipass */ \"./node_modules/fs-minipass/node_modules/minipass/index.js\")\nconst EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter)\nconst fs = __webpack_require__(/*! fs */ \"?beec\")\n\nlet writev = fs.writev\n/* istanbul ignore next */\nif (!writev) {\n  // This entire block can be removed if support for earlier than Node.js\n  // 12.9.0 is not needed.\n  const binding = process.binding('fs')\n  const FSReqWrap = binding.FSReqWrap || binding.FSReqCallback\n\n  writev = (fd, iovec, pos, cb) => {\n    const done = (er, bw) => cb(er, bw, iovec)\n    const req = new FSReqWrap()\n    req.oncomplete = done\n    binding.writeBuffers(fd, iovec, pos, req)\n  }\n}\n\nconst _autoClose = Symbol('_autoClose')\nconst _close = Symbol('_close')\nconst _ended = Symbol('_ended')\nconst _fd = Symbol('_fd')\nconst _finished = Symbol('_finished')\nconst _flags = Symbol('_flags')\nconst _flush = Symbol('_flush')\nconst _handleChunk = Symbol('_handleChunk')\nconst _makeBuf = Symbol('_makeBuf')\nconst _mode = Symbol('_mode')\nconst _needDrain = Symbol('_needDrain')\nconst _onerror = Symbol('_onerror')\nconst _onopen = Symbol('_onopen')\nconst _onread = Symbol('_onread')\nconst _onwrite = Symbol('_onwrite')\nconst _open = Symbol('_open')\nconst _path = Symbol('_path')\nconst _pos = Symbol('_pos')\nconst _queue = Symbol('_queue')\nconst _read = Symbol('_read')\nconst _readSize = Symbol('_readSize')\nconst _reading = Symbol('_reading')\nconst _remain = Symbol('_remain')\nconst _size = Symbol('_size')\nconst _write = Symbol('_write')\nconst _writing = Symbol('_writing')\nconst _defaultFlag = Symbol('_defaultFlag')\nconst _errored = Symbol('_errored')\n\nclass ReadStream extends MiniPass {\n  constructor (path, opt) {\n    opt = opt || {}\n    super(opt)\n\n    this.readable = true\n    this.writable = false\n\n    if (typeof path !== 'string')\n      throw new TypeError('path must be a string')\n\n    this[_errored] = false\n    this[_fd] = typeof opt.fd === 'number' ? opt.fd : null\n    this[_path] = path\n    this[_readSize] = opt.readSize || 16*1024*1024\n    this[_reading] = false\n    this[_size] = typeof opt.size === 'number' ? opt.size : Infinity\n    this[_remain] = this[_size]\n    this[_autoClose] = typeof opt.autoClose === 'boolean' ?\n      opt.autoClose : true\n\n    if (typeof this[_fd] === 'number')\n      this[_read]()\n    else\n      this[_open]()\n  }\n\n  get fd () { return this[_fd] }\n  get path () { return this[_path] }\n\n  write () {\n    throw new TypeError('this is a readable stream')\n  }\n\n  end () {\n    throw new TypeError('this is a readable stream')\n  }\n\n  [_open] () {\n    fs.open(this[_path], 'r', (er, fd) => this[_onopen](er, fd))\n  }\n\n  [_onopen] (er, fd) {\n    if (er)\n      this[_onerror](er)\n    else {\n      this[_fd] = fd\n      this.emit('open', fd)\n      this[_read]()\n    }\n  }\n\n  [_makeBuf] () {\n    return Buffer.allocUnsafe(Math.min(this[_readSize], this[_remain]))\n  }\n\n  [_read] () {\n    if (!this[_reading]) {\n      this[_reading] = true\n      const buf = this[_makeBuf]()\n      /* istanbul ignore if */\n      if (buf.length === 0)\n        return process.nextTick(() => this[_onread](null, 0, buf))\n      fs.read(this[_fd], buf, 0, buf.length, null, (er, br, buf) =>\n        this[_onread](er, br, buf))\n    }\n  }\n\n  [_onread] (er, br, buf) {\n    this[_reading] = false\n    if (er)\n      this[_onerror](er)\n    else if (this[_handleChunk](br, buf))\n      this[_read]()\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.close(fd, er => er ? this.emit('error', er) : this.emit('close'))\n    }\n  }\n\n  [_onerror] (er) {\n    this[_reading] = true\n    this[_close]()\n    this.emit('error', er)\n  }\n\n  [_handleChunk] (br, buf) {\n    let ret = false\n    // no effect if infinite\n    this[_remain] -= br\n    if (br > 0)\n      ret = super.write(br < buf.length ? buf.slice(0, br) : buf)\n\n    if (br === 0 || this[_remain] <= 0) {\n      ret = false\n      this[_close]()\n      super.end()\n    }\n\n    return ret\n  }\n\n  emit (ev, data) {\n    switch (ev) {\n      case 'prefinish':\n      case 'finish':\n        break\n\n      case 'drain':\n        if (typeof this[_fd] === 'number')\n          this[_read]()\n        break\n\n      case 'error':\n        if (this[_errored])\n          return\n        this[_errored] = true\n        return super.emit(ev, data)\n\n      default:\n        return super.emit(ev, data)\n    }\n  }\n}\n\nclass ReadStreamSync extends ReadStream {\n  [_open] () {\n    let threw = true\n    try {\n      this[_onopen](null, fs.openSync(this[_path], 'r'))\n      threw = false\n    } finally {\n      if (threw)\n        this[_close]()\n    }\n  }\n\n  [_read] () {\n    let threw = true\n    try {\n      if (!this[_reading]) {\n        this[_reading] = true\n        do {\n          const buf = this[_makeBuf]()\n          /* istanbul ignore next */\n          const br = buf.length === 0 ? 0\n            : fs.readSync(this[_fd], buf, 0, buf.length, null)\n          if (!this[_handleChunk](br, buf))\n            break\n        } while (true)\n        this[_reading] = false\n      }\n      threw = false\n    } finally {\n      if (threw)\n        this[_close]()\n    }\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.closeSync(fd)\n      this.emit('close')\n    }\n  }\n}\n\nclass WriteStream extends EE {\n  constructor (path, opt) {\n    opt = opt || {}\n    super(opt)\n    this.readable = false\n    this.writable = true\n    this[_errored] = false\n    this[_writing] = false\n    this[_ended] = false\n    this[_needDrain] = false\n    this[_queue] = []\n    this[_path] = path\n    this[_fd] = typeof opt.fd === 'number' ? opt.fd : null\n    this[_mode] = opt.mode === undefined ? 0o666 : opt.mode\n    this[_pos] = typeof opt.start === 'number' ? opt.start : null\n    this[_autoClose] = typeof opt.autoClose === 'boolean' ?\n      opt.autoClose : true\n\n    // truncating makes no sense when writing into the middle\n    const defaultFlag = this[_pos] !== null ? 'r+' : 'w'\n    this[_defaultFlag] = opt.flags === undefined\n    this[_flags] = this[_defaultFlag] ? defaultFlag : opt.flags\n\n    if (this[_fd] === null)\n      this[_open]()\n  }\n\n  emit (ev, data) {\n    if (ev === 'error') {\n      if (this[_errored])\n        return\n      this[_errored] = true\n    }\n    return super.emit(ev, data)\n  }\n\n\n  get fd () { return this[_fd] }\n  get path () { return this[_path] }\n\n  [_onerror] (er) {\n    this[_close]()\n    this[_writing] = true\n    this.emit('error', er)\n  }\n\n  [_open] () {\n    fs.open(this[_path], this[_flags], this[_mode],\n      (er, fd) => this[_onopen](er, fd))\n  }\n\n  [_onopen] (er, fd) {\n    if (this[_defaultFlag] &&\n        this[_flags] === 'r+' &&\n        er && er.code === 'ENOENT') {\n      this[_flags] = 'w'\n      this[_open]()\n    } else if (er)\n      this[_onerror](er)\n    else {\n      this[_fd] = fd\n      this.emit('open', fd)\n      this[_flush]()\n    }\n  }\n\n  end (buf, enc) {\n    if (buf)\n      this.write(buf, enc)\n\n    this[_ended] = true\n\n    // synthetic after-write logic, where drain/finish live\n    if (!this[_writing] && !this[_queue].length &&\n        typeof this[_fd] === 'number')\n      this[_onwrite](null, 0)\n    return this\n  }\n\n  write (buf, enc) {\n    if (typeof buf === 'string')\n      buf = Buffer.from(buf, enc)\n\n    if (this[_ended]) {\n      this.emit('error', new Error('write() after end()'))\n      return false\n    }\n\n    if (this[_fd] === null || this[_writing] || this[_queue].length) {\n      this[_queue].push(buf)\n      this[_needDrain] = true\n      return false\n    }\n\n    this[_writing] = true\n    this[_write](buf)\n    return true\n  }\n\n  [_write] (buf) {\n    fs.write(this[_fd], buf, 0, buf.length, this[_pos], (er, bw) =>\n      this[_onwrite](er, bw))\n  }\n\n  [_onwrite] (er, bw) {\n    if (er)\n      this[_onerror](er)\n    else {\n      if (this[_pos] !== null)\n        this[_pos] += bw\n      if (this[_queue].length)\n        this[_flush]()\n      else {\n        this[_writing] = false\n\n        if (this[_ended] && !this[_finished]) {\n          this[_finished] = true\n          this[_close]()\n          this.emit('finish')\n        } else if (this[_needDrain]) {\n          this[_needDrain] = false\n          this.emit('drain')\n        }\n      }\n    }\n  }\n\n  [_flush] () {\n    if (this[_queue].length === 0) {\n      if (this[_ended])\n        this[_onwrite](null, 0)\n    } else if (this[_queue].length === 1)\n      this[_write](this[_queue].pop())\n    else {\n      const iovec = this[_queue]\n      this[_queue] = []\n      writev(this[_fd], iovec, this[_pos],\n        (er, bw) => this[_onwrite](er, bw))\n    }\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.close(fd, er => er ? this.emit('error', er) : this.emit('close'))\n    }\n  }\n}\n\nclass WriteStreamSync extends WriteStream {\n  [_open] () {\n    let fd\n    // only wrap in a try{} block if we know we'll retry, to avoid\n    // the rethrow obscuring the error's source frame in most cases.\n    if (this[_defaultFlag] && this[_flags] === 'r+') {\n      try {\n        fd = fs.openSync(this[_path], this[_flags], this[_mode])\n      } catch (er) {\n        if (er.code === 'ENOENT') {\n          this[_flags] = 'w'\n          return this[_open]()\n        } else\n          throw er\n      }\n    } else\n      fd = fs.openSync(this[_path], this[_flags], this[_mode])\n\n    this[_onopen](null, fd)\n  }\n\n  [_close] () {\n    if (this[_autoClose] && typeof this[_fd] === 'number') {\n      const fd = this[_fd]\n      this[_fd] = null\n      fs.closeSync(fd)\n      this.emit('close')\n    }\n  }\n\n  [_write] (buf) {\n    // throw the original, but try to close if it fails\n    let threw = true\n    try {\n      this[_onwrite](null,\n        fs.writeSync(this[_fd], buf, 0, buf.length, this[_pos]))\n      threw = false\n    } finally {\n      if (threw)\n        try { this[_close]() } catch (_) {}\n    }\n  }\n}\n\nexports.ReadStream = ReadStream\nexports.ReadStreamSync = ReadStreamSync\n\nexports.WriteStream = WriteStream\nexports.WriteStreamSync = WriteStreamSync\n\n\n//# sourceURL=webpack://thelambda/./node_modules/fs-minipass/index.js?");

/***/ }),

/***/ "./node_modules/fs-minipass/node_modules/minipass/index.js":
/*!*****************************************************************!*\
  !*** ./node_modules/fs-minipass/node_modules/minipass/index.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst proc = typeof process === 'object' && process ? process : {\n  stdout: null,\n  stderr: null,\n}\nconst EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst Stream = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst SD = (__webpack_require__(/*! string_decoder */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder)\n\nconst EOF = Symbol('EOF')\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd')\nconst EMITTED_END = Symbol('emittedEnd')\nconst EMITTING_END = Symbol('emittingEnd')\nconst EMITTED_ERROR = Symbol('emittedError')\nconst CLOSED = Symbol('closed')\nconst READ = Symbol('read')\nconst FLUSH = Symbol('flush')\nconst FLUSHCHUNK = Symbol('flushChunk')\nconst ENCODING = Symbol('encoding')\nconst DECODER = Symbol('decoder')\nconst FLOWING = Symbol('flowing')\nconst PAUSED = Symbol('paused')\nconst RESUME = Symbol('resume')\nconst BUFFERLENGTH = Symbol('bufferLength')\nconst BUFFERPUSH = Symbol('bufferPush')\nconst BUFFERSHIFT = Symbol('bufferShift')\nconst OBJECTMODE = Symbol('objectMode')\nconst DESTROYED = Symbol('destroyed')\nconst EMITDATA = Symbol('emitData')\nconst EMITEND = Symbol('emitEnd')\nconst EMITEND2 = Symbol('emitEnd2')\nconst ASYNC = Symbol('async')\n\nconst defer = fn => Promise.resolve().then(fn)\n\n// TODO remove when Node v8 support drops\nconst doIter = __webpack_require__.g._MP_NO_ITERATOR_SYMBOLS_  !== '1'\nconst ASYNCITERATOR = doIter && Symbol.asyncIterator\n  || Symbol('asyncIterator not implemented')\nconst ITERATOR = doIter && Symbol.iterator\n  || Symbol('iterator not implemented')\n\n// events that mean 'the stream is over'\n// these are treated specially, and re-emitted\n// if they are listened for after emitting.\nconst isEndish = ev =>\n  ev === 'end' ||\n  ev === 'finish' ||\n  ev === 'prefinish'\n\nconst isArrayBuffer = b => b instanceof ArrayBuffer ||\n  typeof b === 'object' &&\n  b.constructor &&\n  b.constructor.name === 'ArrayBuffer' &&\n  b.byteLength >= 0\n\nconst isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)\n\nclass Pipe {\n  constructor (src, dest, opts) {\n    this.src = src\n    this.dest = dest\n    this.opts = opts\n    this.ondrain = () => src[RESUME]()\n    dest.on('drain', this.ondrain)\n  }\n  unpipe () {\n    this.dest.removeListener('drain', this.ondrain)\n  }\n  // istanbul ignore next - only here for the prototype\n  proxyErrors () {}\n  end () {\n    this.unpipe()\n    if (this.opts.end)\n      this.dest.end()\n  }\n}\n\nclass PipeProxyErrors extends Pipe {\n  unpipe () {\n    this.src.removeListener('error', this.proxyErrors)\n    super.unpipe()\n  }\n  constructor (src, dest, opts) {\n    super(src, dest, opts)\n    this.proxyErrors = er => dest.emit('error', er)\n    src.on('error', this.proxyErrors)\n  }\n}\n\nmodule.exports = class Minipass extends Stream {\n  constructor (options) {\n    super()\n    this[FLOWING] = false\n    // whether we're explicitly paused\n    this[PAUSED] = false\n    this.pipes = []\n    this.buffer = []\n    this[OBJECTMODE] = options && options.objectMode || false\n    if (this[OBJECTMODE])\n      this[ENCODING] = null\n    else\n      this[ENCODING] = options && options.encoding || null\n    if (this[ENCODING] === 'buffer')\n      this[ENCODING] = null\n    this[ASYNC] = options && !!options.async || false\n    this[DECODER] = this[ENCODING] ? new SD(this[ENCODING]) : null\n    this[EOF] = false\n    this[EMITTED_END] = false\n    this[EMITTING_END] = false\n    this[CLOSED] = false\n    this[EMITTED_ERROR] = null\n    this.writable = true\n    this.readable = true\n    this[BUFFERLENGTH] = 0\n    this[DESTROYED] = false\n  }\n\n  get bufferLength () { return this[BUFFERLENGTH] }\n\n  get encoding () { return this[ENCODING] }\n  set encoding (enc) {\n    if (this[OBJECTMODE])\n      throw new Error('cannot set encoding in objectMode')\n\n    if (this[ENCODING] && enc !== this[ENCODING] &&\n        (this[DECODER] && this[DECODER].lastNeed || this[BUFFERLENGTH]))\n      throw new Error('cannot change encoding')\n\n    if (this[ENCODING] !== enc) {\n      this[DECODER] = enc ? new SD(enc) : null\n      if (this.buffer.length)\n        this.buffer = this.buffer.map(chunk => this[DECODER].write(chunk))\n    }\n\n    this[ENCODING] = enc\n  }\n\n  setEncoding (enc) {\n    this.encoding = enc\n  }\n\n  get objectMode () { return this[OBJECTMODE] }\n  set objectMode (om) { this[OBJECTMODE] = this[OBJECTMODE] || !!om }\n\n  get ['async'] () { return this[ASYNC] }\n  set ['async'] (a) { this[ASYNC] = this[ASYNC] || !!a }\n\n  write (chunk, encoding, cb) {\n    if (this[EOF])\n      throw new Error('write after end')\n\n    if (this[DESTROYED]) {\n      this.emit('error', Object.assign(\n        new Error('Cannot call write after a stream was destroyed'),\n        { code: 'ERR_STREAM_DESTROYED' }\n      ))\n      return true\n    }\n\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n\n    if (!encoding)\n      encoding = 'utf8'\n\n    const fn = this[ASYNC] ? defer : f => f()\n\n    // convert array buffers and typed array views into buffers\n    // at some point in the future, we may want to do the opposite!\n    // leave strings and buffers as-is\n    // anything else switches us into object mode\n    if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n      if (isArrayBufferView(chunk))\n        chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n      else if (isArrayBuffer(chunk))\n        chunk = Buffer.from(chunk)\n      else if (typeof chunk !== 'string')\n        // use the setter so we throw if we have encoding set\n        this.objectMode = true\n    }\n\n    // handle object mode up front, since it's simpler\n    // this yields better performance, fewer checks later.\n    if (this[OBJECTMODE]) {\n      /* istanbul ignore if - maybe impossible? */\n      if (this.flowing && this[BUFFERLENGTH] !== 0)\n        this[FLUSH](true)\n\n      if (this.flowing)\n        this.emit('data', chunk)\n      else\n        this[BUFFERPUSH](chunk)\n\n      if (this[BUFFERLENGTH] !== 0)\n        this.emit('readable')\n\n      if (cb)\n        fn(cb)\n\n      return this.flowing\n    }\n\n    // at this point the chunk is a buffer or string\n    // don't buffer it up or send it to the decoder\n    if (!chunk.length) {\n      if (this[BUFFERLENGTH] !== 0)\n        this.emit('readable')\n      if (cb)\n        fn(cb)\n      return this.flowing\n    }\n\n    // fast-path writing strings of same encoding to a stream with\n    // an empty buffer, skipping the buffer/decoder dance\n    if (typeof chunk === 'string' &&\n        // unless it is a string already ready for us to use\n        !(encoding === this[ENCODING] && !this[DECODER].lastNeed)) {\n      chunk = Buffer.from(chunk, encoding)\n    }\n\n    if (Buffer.isBuffer(chunk) && this[ENCODING])\n      chunk = this[DECODER].write(chunk)\n\n    // Note: flushing CAN potentially switch us into not-flowing mode\n    if (this.flowing && this[BUFFERLENGTH] !== 0)\n      this[FLUSH](true)\n\n    if (this.flowing)\n      this.emit('data', chunk)\n    else\n      this[BUFFERPUSH](chunk)\n\n    if (this[BUFFERLENGTH] !== 0)\n      this.emit('readable')\n\n    if (cb)\n      fn(cb)\n\n    return this.flowing\n  }\n\n  read (n) {\n    if (this[DESTROYED])\n      return null\n\n    if (this[BUFFERLENGTH] === 0 || n === 0 || n > this[BUFFERLENGTH]) {\n      this[MAYBE_EMIT_END]()\n      return null\n    }\n\n    if (this[OBJECTMODE])\n      n = null\n\n    if (this.buffer.length > 1 && !this[OBJECTMODE]) {\n      if (this.encoding)\n        this.buffer = [this.buffer.join('')]\n      else\n        this.buffer = [Buffer.concat(this.buffer, this[BUFFERLENGTH])]\n    }\n\n    const ret = this[READ](n || null, this.buffer[0])\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [READ] (n, chunk) {\n    if (n === chunk.length || n === null)\n      this[BUFFERSHIFT]()\n    else {\n      this.buffer[0] = chunk.slice(n)\n      chunk = chunk.slice(0, n)\n      this[BUFFERLENGTH] -= n\n    }\n\n    this.emit('data', chunk)\n\n    if (!this.buffer.length && !this[EOF])\n      this.emit('drain')\n\n    return chunk\n  }\n\n  end (chunk, encoding, cb) {\n    if (typeof chunk === 'function')\n      cb = chunk, chunk = null\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n    if (chunk)\n      this.write(chunk, encoding)\n    if (cb)\n      this.once('end', cb)\n    this[EOF] = true\n    this.writable = false\n\n    // if we haven't written anything, then go ahead and emit,\n    // even if we're not reading.\n    // we'll re-emit if a new 'end' listener is added anyway.\n    // This makes MP more suitable to write-only use cases.\n    if (this.flowing || !this[PAUSED])\n      this[MAYBE_EMIT_END]()\n    return this\n  }\n\n  // don't let the internal resume be overwritten\n  [RESUME] () {\n    if (this[DESTROYED])\n      return\n\n    this[PAUSED] = false\n    this[FLOWING] = true\n    this.emit('resume')\n    if (this.buffer.length)\n      this[FLUSH]()\n    else if (this[EOF])\n      this[MAYBE_EMIT_END]()\n    else\n      this.emit('drain')\n  }\n\n  resume () {\n    return this[RESUME]()\n  }\n\n  pause () {\n    this[FLOWING] = false\n    this[PAUSED] = true\n  }\n\n  get destroyed () {\n    return this[DESTROYED]\n  }\n\n  get flowing () {\n    return this[FLOWING]\n  }\n\n  get paused () {\n    return this[PAUSED]\n  }\n\n  [BUFFERPUSH] (chunk) {\n    if (this[OBJECTMODE])\n      this[BUFFERLENGTH] += 1\n    else\n      this[BUFFERLENGTH] += chunk.length\n    this.buffer.push(chunk)\n  }\n\n  [BUFFERSHIFT] () {\n    if (this.buffer.length) {\n      if (this[OBJECTMODE])\n        this[BUFFERLENGTH] -= 1\n      else\n        this[BUFFERLENGTH] -= this.buffer[0].length\n    }\n    return this.buffer.shift()\n  }\n\n  [FLUSH] (noDrain) {\n    do {} while (this[FLUSHCHUNK](this[BUFFERSHIFT]()))\n\n    if (!noDrain && !this.buffer.length && !this[EOF])\n      this.emit('drain')\n  }\n\n  [FLUSHCHUNK] (chunk) {\n    return chunk ? (this.emit('data', chunk), this.flowing) : false\n  }\n\n  pipe (dest, opts) {\n    if (this[DESTROYED])\n      return\n\n    const ended = this[EMITTED_END]\n    opts = opts || {}\n    if (dest === proc.stdout || dest === proc.stderr)\n      opts.end = false\n    else\n      opts.end = opts.end !== false\n    opts.proxyErrors = !!opts.proxyErrors\n\n    // piping an ended stream ends immediately\n    if (ended) {\n      if (opts.end)\n        dest.end()\n    } else {\n      this.pipes.push(!opts.proxyErrors ? new Pipe(this, dest, opts)\n        : new PipeProxyErrors(this, dest, opts))\n      if (this[ASYNC])\n        defer(() => this[RESUME]())\n      else\n        this[RESUME]()\n    }\n\n    return dest\n  }\n\n  unpipe (dest) {\n    const p = this.pipes.find(p => p.dest === dest)\n    if (p) {\n      this.pipes.splice(this.pipes.indexOf(p), 1)\n      p.unpipe()\n    }\n  }\n\n  addListener (ev, fn) {\n    return this.on(ev, fn)\n  }\n\n  on (ev, fn) {\n    const ret = super.on(ev, fn)\n    if (ev === 'data' && !this.pipes.length && !this.flowing)\n      this[RESUME]()\n    else if (ev === 'readable' && this[BUFFERLENGTH] !== 0)\n      super.emit('readable')\n    else if (isEndish(ev) && this[EMITTED_END]) {\n      super.emit(ev)\n      this.removeAllListeners(ev)\n    } else if (ev === 'error' && this[EMITTED_ERROR]) {\n      if (this[ASYNC])\n        defer(() => fn.call(this, this[EMITTED_ERROR]))\n      else\n        fn.call(this, this[EMITTED_ERROR])\n    }\n    return ret\n  }\n\n  get emittedEnd () {\n    return this[EMITTED_END]\n  }\n\n  [MAYBE_EMIT_END] () {\n    if (!this[EMITTING_END] &&\n        !this[EMITTED_END] &&\n        !this[DESTROYED] &&\n        this.buffer.length === 0 &&\n        this[EOF]) {\n      this[EMITTING_END] = true\n      this.emit('end')\n      this.emit('prefinish')\n      this.emit('finish')\n      if (this[CLOSED])\n        this.emit('close')\n      this[EMITTING_END] = false\n    }\n  }\n\n  emit (ev, data, ...extra) {\n    // error and close are only events allowed after calling destroy()\n    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && this[DESTROYED])\n      return\n    else if (ev === 'data') {\n      return !data ? false\n        : this[ASYNC] ? defer(() => this[EMITDATA](data))\n        : this[EMITDATA](data)\n    } else if (ev === 'end') {\n      return this[EMITEND]()\n    } else if (ev === 'close') {\n      this[CLOSED] = true\n      // don't emit close before 'end' and 'finish'\n      if (!this[EMITTED_END] && !this[DESTROYED])\n        return\n      const ret = super.emit('close')\n      this.removeAllListeners('close')\n      return ret\n    } else if (ev === 'error') {\n      this[EMITTED_ERROR] = data\n      const ret = super.emit('error', data)\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'resume') {\n      const ret = super.emit('resume')\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'finish' || ev === 'prefinish') {\n      const ret = super.emit(ev)\n      this.removeAllListeners(ev)\n      return ret\n    }\n\n    // Some other unknown event\n    const ret = super.emit(ev, data, ...extra)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITDATA] (data) {\n    for (const p of this.pipes) {\n      if (p.dest.write(data) === false)\n        this.pause()\n    }\n    const ret = super.emit('data', data)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITEND] () {\n    if (this[EMITTED_END])\n      return\n\n    this[EMITTED_END] = true\n    this.readable = false\n    if (this[ASYNC])\n      defer(() => this[EMITEND2]())\n    else\n      this[EMITEND2]()\n  }\n\n  [EMITEND2] () {\n    if (this[DECODER]) {\n      const data = this[DECODER].end()\n      if (data) {\n        for (const p of this.pipes) {\n          p.dest.write(data)\n        }\n        super.emit('data', data)\n      }\n    }\n\n    for (const p of this.pipes) {\n      p.end()\n    }\n    const ret = super.emit('end')\n    this.removeAllListeners('end')\n    return ret\n  }\n\n  // const all = await stream.collect()\n  collect () {\n    const buf = []\n    if (!this[OBJECTMODE])\n      buf.dataLength = 0\n    // set the promise first, in case an error is raised\n    // by triggering the flow here.\n    const p = this.promise()\n    this.on('data', c => {\n      buf.push(c)\n      if (!this[OBJECTMODE])\n        buf.dataLength += c.length\n    })\n    return p.then(() => buf)\n  }\n\n  // const data = await stream.concat()\n  concat () {\n    return this[OBJECTMODE]\n      ? Promise.reject(new Error('cannot concat in objectMode'))\n      : this.collect().then(buf =>\n          this[OBJECTMODE]\n            ? Promise.reject(new Error('cannot concat in objectMode'))\n            : this[ENCODING] ? buf.join('') : Buffer.concat(buf, buf.dataLength))\n  }\n\n  // stream.promise().then(() => done, er => emitted error)\n  promise () {\n    return new Promise((resolve, reject) => {\n      this.on(DESTROYED, () => reject(new Error('stream destroyed')))\n      this.on('error', er => reject(er))\n      this.on('end', () => resolve())\n    })\n  }\n\n  // for await (let chunk of stream)\n  [ASYNCITERATOR] () {\n    const next = () => {\n      const res = this.read()\n      if (res !== null)\n        return Promise.resolve({ done: false, value: res })\n\n      if (this[EOF])\n        return Promise.resolve({ done: true })\n\n      let resolve = null\n      let reject = null\n      const onerr = er => {\n        this.removeListener('data', ondata)\n        this.removeListener('end', onend)\n        reject(er)\n      }\n      const ondata = value => {\n        this.removeListener('error', onerr)\n        this.removeListener('end', onend)\n        this.pause()\n        resolve({ value: value, done: !!this[EOF] })\n      }\n      const onend = () => {\n        this.removeListener('error', onerr)\n        this.removeListener('data', ondata)\n        resolve({ done: true })\n      }\n      const ondestroy = () => onerr(new Error('stream destroyed'))\n      return new Promise((res, rej) => {\n        reject = rej\n        resolve = res\n        this.once(DESTROYED, ondestroy)\n        this.once('error', onerr)\n        this.once('end', onend)\n        this.once('data', ondata)\n      })\n    }\n\n    return { next }\n  }\n\n  // for (let chunk of stream)\n  [ITERATOR] () {\n    const next = () => {\n      const value = this.read()\n      const done = value === null\n      return { value, done }\n    }\n    return { next }\n  }\n\n  destroy (er) {\n    if (this[DESTROYED]) {\n      if (er)\n        this.emit('error', er)\n      else\n        this.emit(DESTROYED)\n      return this\n    }\n\n    this[DESTROYED] = true\n\n    // throw away all buffered data, it's never coming out\n    this.buffer.length = 0\n    this[BUFFERLENGTH] = 0\n\n    if (typeof this.close === 'function' && !this[CLOSED])\n      this.close()\n\n    if (er)\n      this.emit('error', er)\n    else // if no error to emit, still reject pending promises\n      this.emit(DESTROYED)\n\n    return this\n  }\n\n  static isStream (s) {\n    return !!s && (s instanceof Minipass || s instanceof Stream ||\n      s instanceof EE && (\n        typeof s.pipe === 'function' || // readable\n        (typeof s.write === 'function' && typeof s.end === 'function') // writable\n      ))\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/fs-minipass/node_modules/minipass/index.js?");

/***/ }),

/***/ "./node_modules/fs.realpath/index.js":
/*!*******************************************!*\
  !*** ./node_modules/fs.realpath/index.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = realpath\nrealpath.realpath = realpath\nrealpath.sync = realpathSync\nrealpath.realpathSync = realpathSync\nrealpath.monkeypatch = monkeypatch\nrealpath.unmonkeypatch = unmonkeypatch\n\nvar fs = __webpack_require__(/*! fs */ \"?6882\")\nvar origRealpath = fs.realpath\nvar origRealpathSync = fs.realpathSync\n\nvar version = process.version\nvar ok = /^v[0-5]\\./.test(version)\nvar old = __webpack_require__(/*! ./old.js */ \"./node_modules/fs.realpath/old.js\")\n\nfunction newError (er) {\n  return er && er.syscall === 'realpath' && (\n    er.code === 'ELOOP' ||\n    er.code === 'ENOMEM' ||\n    er.code === 'ENAMETOOLONG'\n  )\n}\n\nfunction realpath (p, cache, cb) {\n  if (ok) {\n    return origRealpath(p, cache, cb)\n  }\n\n  if (typeof cache === 'function') {\n    cb = cache\n    cache = null\n  }\n  origRealpath(p, cache, function (er, result) {\n    if (newError(er)) {\n      old.realpath(p, cache, cb)\n    } else {\n      cb(er, result)\n    }\n  })\n}\n\nfunction realpathSync (p, cache) {\n  if (ok) {\n    return origRealpathSync(p, cache)\n  }\n\n  try {\n    return origRealpathSync(p, cache)\n  } catch (er) {\n    if (newError(er)) {\n      return old.realpathSync(p, cache)\n    } else {\n      throw er\n    }\n  }\n}\n\nfunction monkeypatch () {\n  fs.realpath = realpath\n  fs.realpathSync = realpathSync\n}\n\nfunction unmonkeypatch () {\n  fs.realpath = origRealpath\n  fs.realpathSync = origRealpathSync\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/fs.realpath/index.js?");

/***/ }),

/***/ "./node_modules/fs.realpath/old.js":
/*!*****************************************!*\
  !*** ./node_modules/fs.realpath/old.js ***!
  \*****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar pathModule = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nvar isWindows = process.platform === 'win32';\nvar fs = __webpack_require__(/*! fs */ \"?6882\");\n\n// JavaScript implementation of realpath, ported from node pre-v6\n\nvar DEBUG = process.env.NODE_DEBUG && /fs/.test(process.env.NODE_DEBUG);\n\nfunction rethrow() {\n  // Only enable in debug mode. A backtrace uses ~1000 bytes of heap space and\n  // is fairly slow to generate.\n  var callback;\n  if (DEBUG) {\n    var backtrace = new Error;\n    callback = debugCallback;\n  } else\n    callback = missingCallback;\n\n  return callback;\n\n  function debugCallback(err) {\n    if (err) {\n      backtrace.message = err.message;\n      err = backtrace;\n      missingCallback(err);\n    }\n  }\n\n  function missingCallback(err) {\n    if (err) {\n      if (process.throwDeprecation)\n        throw err;  // Forgot a callback but don't know where? Use NODE_DEBUG=fs\n      else if (!process.noDeprecation) {\n        var msg = 'fs: missing callback ' + (err.stack || err.message);\n        if (process.traceDeprecation)\n          console.trace(msg);\n        else\n          console.error(msg);\n      }\n    }\n  }\n}\n\nfunction maybeCallback(cb) {\n  return typeof cb === 'function' ? cb : rethrow();\n}\n\nvar normalize = pathModule.normalize;\n\n// Regexp that finds the next partion of a (partial) path\n// result is [base_with_slash, base], e.g. ['somedir/', 'somedir']\nif (isWindows) {\n  var nextPartRe = /(.*?)(?:[\\/\\\\]+|$)/g;\n} else {\n  var nextPartRe = /(.*?)(?:[\\/]+|$)/g;\n}\n\n// Regex to find the device root, including trailing slash. E.g. 'c:\\\\'.\nif (isWindows) {\n  var splitRootRe = /^(?:[a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/][^\\\\\\/]+)?[\\\\\\/]*/;\n} else {\n  var splitRootRe = /^[\\/]*/;\n}\n\nexports.realpathSync = function realpathSync(p, cache) {\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return cache[p];\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstatSync(base);\n      knownHard[base] = true;\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  // NB: p.length changes.\n  while (pos < p.length) {\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      continue;\n    }\n\n    var resolvedLink;\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // some known symbolic link.  no need to stat again.\n      resolvedLink = cache[base];\n    } else {\n      var stat = fs.lstatSync(base);\n      if (!stat.isSymbolicLink()) {\n        knownHard[base] = true;\n        if (cache) cache[base] = base;\n        continue;\n      }\n\n      // read the link if it wasn't read before\n      // dev/ino always return 0 on windows, so skip the check.\n      var linkTarget = null;\n      if (!isWindows) {\n        var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n        if (seenLinks.hasOwnProperty(id)) {\n          linkTarget = seenLinks[id];\n        }\n      }\n      if (linkTarget === null) {\n        fs.statSync(base);\n        linkTarget = fs.readlinkSync(base);\n      }\n      resolvedLink = pathModule.resolve(previous, linkTarget);\n      // track this, if given a cache.\n      if (cache) cache[base] = resolvedLink;\n      if (!isWindows) seenLinks[id] = linkTarget;\n    }\n\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n\n  if (cache) cache[original] = p;\n\n  return p;\n};\n\n\nexports.realpath = function realpath(p, cache, cb) {\n  if (typeof cb !== 'function') {\n    cb = maybeCallback(cache);\n    cache = null;\n  }\n\n  // make p is absolute\n  p = pathModule.resolve(p);\n\n  if (cache && Object.prototype.hasOwnProperty.call(cache, p)) {\n    return process.nextTick(cb.bind(null, null, cache[p]));\n  }\n\n  var original = p,\n      seenLinks = {},\n      knownHard = {};\n\n  // current character position in p\n  var pos;\n  // the partial path so far, including a trailing slash if any\n  var current;\n  // the partial path without a trailing slash (except when pointing at a root)\n  var base;\n  // the partial path scanned in the previous round, with slash\n  var previous;\n\n  start();\n\n  function start() {\n    // Skip over roots\n    var m = splitRootRe.exec(p);\n    pos = m[0].length;\n    current = m[0];\n    base = m[0];\n    previous = '';\n\n    // On windows, check that the root exists. On unix there is no need.\n    if (isWindows && !knownHard[base]) {\n      fs.lstat(base, function(err) {\n        if (err) return cb(err);\n        knownHard[base] = true;\n        LOOP();\n      });\n    } else {\n      process.nextTick(LOOP);\n    }\n  }\n\n  // walk down the path, swapping out linked pathparts for their real\n  // values\n  function LOOP() {\n    // stop if scanned past end of path\n    if (pos >= p.length) {\n      if (cache) cache[original] = p;\n      return cb(null, p);\n    }\n\n    // find the next part\n    nextPartRe.lastIndex = pos;\n    var result = nextPartRe.exec(p);\n    previous = current;\n    current += result[0];\n    base = previous + result[1];\n    pos = nextPartRe.lastIndex;\n\n    // continue if not a symlink\n    if (knownHard[base] || (cache && cache[base] === base)) {\n      return process.nextTick(LOOP);\n    }\n\n    if (cache && Object.prototype.hasOwnProperty.call(cache, base)) {\n      // known symbolic link.  no need to stat again.\n      return gotResolvedLink(cache[base]);\n    }\n\n    return fs.lstat(base, gotStat);\n  }\n\n  function gotStat(err, stat) {\n    if (err) return cb(err);\n\n    // if not a symlink, skip to the next path part\n    if (!stat.isSymbolicLink()) {\n      knownHard[base] = true;\n      if (cache) cache[base] = base;\n      return process.nextTick(LOOP);\n    }\n\n    // stat & read the link if not read before\n    // call gotTarget as soon as the link target is known\n    // dev/ino always return 0 on windows, so skip the check.\n    if (!isWindows) {\n      var id = stat.dev.toString(32) + ':' + stat.ino.toString(32);\n      if (seenLinks.hasOwnProperty(id)) {\n        return gotTarget(null, seenLinks[id], base);\n      }\n    }\n    fs.stat(base, function(err) {\n      if (err) return cb(err);\n\n      fs.readlink(base, function(err, target) {\n        if (!isWindows) seenLinks[id] = target;\n        gotTarget(err, target);\n      });\n    });\n  }\n\n  function gotTarget(err, target, base) {\n    if (err) return cb(err);\n\n    var resolvedLink = pathModule.resolve(previous, target);\n    if (cache) cache[base] = resolvedLink;\n    gotResolvedLink(resolvedLink);\n  }\n\n  function gotResolvedLink(resolvedLink) {\n    // resolve the link, then start over\n    p = pathModule.resolve(resolvedLink, p.slice(pos));\n    start();\n  }\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/fs.realpath/old.js?");

/***/ }),

/***/ "./node_modules/function-bind/implementation.js":
/*!******************************************************!*\
  !*** ./node_modules/function-bind/implementation.js ***!
  \******************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* eslint no-invalid-this: 1 */\n\nvar ERROR_MESSAGE = 'Function.prototype.bind called on incompatible ';\nvar toStr = Object.prototype.toString;\nvar max = Math.max;\nvar funcType = '[object Function]';\n\nvar concatty = function concatty(a, b) {\n    var arr = [];\n\n    for (var i = 0; i < a.length; i += 1) {\n        arr[i] = a[i];\n    }\n    for (var j = 0; j < b.length; j += 1) {\n        arr[j + a.length] = b[j];\n    }\n\n    return arr;\n};\n\nvar slicy = function slicy(arrLike, offset) {\n    var arr = [];\n    for (var i = offset || 0, j = 0; i < arrLike.length; i += 1, j += 1) {\n        arr[j] = arrLike[i];\n    }\n    return arr;\n};\n\nvar joiny = function (arr, joiner) {\n    var str = '';\n    for (var i = 0; i < arr.length; i += 1) {\n        str += arr[i];\n        if (i + 1 < arr.length) {\n            str += joiner;\n        }\n    }\n    return str;\n};\n\nmodule.exports = function bind(that) {\n    var target = this;\n    if (typeof target !== 'function' || toStr.apply(target) !== funcType) {\n        throw new TypeError(ERROR_MESSAGE + target);\n    }\n    var args = slicy(arguments, 1);\n\n    var bound;\n    var binder = function () {\n        if (this instanceof bound) {\n            var result = target.apply(\n                this,\n                concatty(args, arguments)\n            );\n            if (Object(result) === result) {\n                return result;\n            }\n            return this;\n        }\n        return target.apply(\n            that,\n            concatty(args, arguments)\n        );\n\n    };\n\n    var boundLength = max(0, target.length - args.length);\n    var boundArgs = [];\n    for (var i = 0; i < boundLength; i++) {\n        boundArgs[i] = '$' + i;\n    }\n\n    bound = Function('binder', 'return function (' + joiny(boundArgs, ',') + '){ return binder.apply(this,arguments); }')(binder);\n\n    if (target.prototype) {\n        var Empty = function Empty() {};\n        Empty.prototype = target.prototype;\n        bound.prototype = new Empty();\n        Empty.prototype = null;\n    }\n\n    return bound;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/function-bind/implementation.js?");

/***/ }),

/***/ "./node_modules/function-bind/index.js":
/*!*********************************************!*\
  !*** ./node_modules/function-bind/index.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar implementation = __webpack_require__(/*! ./implementation */ \"./node_modules/function-bind/implementation.js\");\n\nmodule.exports = Function.prototype.bind || implementation;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/function-bind/index.js?");

/***/ }),

/***/ "./node_modules/gauge/base-theme.js":
/*!******************************************!*\
  !*** ./node_modules/gauge/base-theme.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar spin = __webpack_require__(/*! ./spin.js */ \"./node_modules/gauge/spin.js\")\nvar progressBar = __webpack_require__(/*! ./progress-bar.js */ \"./node_modules/gauge/progress-bar.js\")\n\nmodule.exports = {\n  activityIndicator: function (values, theme, width) {\n    if (values.spun == null) return\n    return spin(theme, values.spun)\n  },\n  progressbar: function (values, theme, width) {\n    if (values.completed == null) return\n    return progressBar(theme, width, values.completed)\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/base-theme.js?");

/***/ }),

/***/ "./node_modules/gauge/error.js":
/*!*************************************!*\
  !*** ./node_modules/gauge/error.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\n\nvar User = exports.User = function User (msg) {\n  var err = new Error(msg)\n  Error.captureStackTrace(err, User)\n  err.code = 'EGAUGE'\n  return err\n}\n\nexports.MissingTemplateValue = function MissingTemplateValue (item, values) {\n  var err = new User(util.format('Missing template value \"%s\"', item.type))\n  Error.captureStackTrace(err, MissingTemplateValue)\n  err.template = item\n  err.values = values\n  return err\n}\n\nexports.Internal = function Internal (msg) {\n  var err = new Error(msg)\n  Error.captureStackTrace(err, Internal)\n  err.code = 'EGAUGEINTERNAL'\n  return err\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/error.js?");

/***/ }),

/***/ "./node_modules/gauge/has-color.js":
/*!*****************************************!*\
  !*** ./node_modules/gauge/has-color.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar colorSupport = __webpack_require__(/*! color-support */ \"./node_modules/color-support/browser.js\")\n\nmodule.exports = colorSupport().hasBasic\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/has-color.js?");

/***/ }),

/***/ "./node_modules/gauge/index.js":
/*!*************************************!*\
  !*** ./node_modules/gauge/index.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar Plumbing = __webpack_require__(/*! ./plumbing.js */ \"./node_modules/gauge/plumbing.js\")\nvar hasUnicode = __webpack_require__(/*! has-unicode */ \"./node_modules/has-unicode/index.js\")\nvar hasColor = __webpack_require__(/*! ./has-color.js */ \"./node_modules/gauge/has-color.js\")\nvar onExit = __webpack_require__(/*! signal-exit */ \"./node_modules/signal-exit/index.js\")\nvar defaultThemes = __webpack_require__(/*! ./themes */ \"./node_modules/gauge/themes.js\")\nvar setInterval = __webpack_require__(/*! ./set-interval.js */ \"./node_modules/gauge/set-interval.js\")\nvar process = __webpack_require__(/*! ./process.js */ \"./node_modules/gauge/process.js\")\nvar setImmediate = __webpack_require__(/*! ./set-immediate */ \"./node_modules/gauge/set-immediate.js\")\n\nmodule.exports = Gauge\n\nfunction callWith (obj, method) {\n  return function () {\n    return method.call(obj)\n  }\n}\n\nfunction Gauge (arg1, arg2) {\n  var options, writeTo\n  if (arg1 && arg1.write) {\n    writeTo = arg1\n    options = arg2 || {}\n  } else if (arg2 && arg2.write) {\n    writeTo = arg2\n    options = arg1 || {}\n  } else {\n    writeTo = process.stderr\n    options = arg1 || arg2 || {}\n  }\n\n  this._status = {\n    spun: 0,\n    section: '',\n    subsection: ''\n  }\n  this._paused = false // are we paused for back pressure?\n  this._disabled = true // are all progress bar updates disabled?\n  this._showing = false // do we WANT the progress bar on screen\n  this._onScreen = false // IS the progress bar on screen\n  this._needsRedraw = false // should we print something at next tick?\n  this._hideCursor = options.hideCursor == null ? true : options.hideCursor\n  this._fixedFramerate = options.fixedFramerate == null\n    ? !(/^v0\\.8\\./.test(process.version))\n    : options.fixedFramerate\n  this._lastUpdateAt = null\n  this._updateInterval = options.updateInterval == null ? 50 : options.updateInterval\n\n  this._themes = options.themes || defaultThemes\n  this._theme = options.theme\n  var theme = this._computeTheme(options.theme)\n  var template = options.template || [\n    {type: 'progressbar', length: 20},\n    {type: 'activityIndicator', kerning: 1, length: 1},\n    {type: 'section', kerning: 1, default: ''},\n    {type: 'subsection', kerning: 1, default: ''}\n  ]\n  this.setWriteTo(writeTo, options.tty)\n  var PlumbingClass = options.Plumbing || Plumbing\n  this._gauge = new PlumbingClass(theme, template, this.getWidth())\n\n  this._$$doRedraw = callWith(this, this._doRedraw)\n  this._$$handleSizeChange = callWith(this, this._handleSizeChange)\n\n  this._cleanupOnExit = options.cleanupOnExit == null || options.cleanupOnExit\n  this._removeOnExit = null\n\n  if (options.enabled || (options.enabled == null && this._tty && this._tty.isTTY)) {\n    this.enable()\n  } else {\n    this.disable()\n  }\n}\nGauge.prototype = {}\n\nGauge.prototype.isEnabled = function () {\n  return !this._disabled\n}\n\nGauge.prototype.setTemplate = function (template) {\n  this._gauge.setTemplate(template)\n  if (this._showing) this._requestRedraw()\n}\n\nGauge.prototype._computeTheme = function (theme) {\n  if (!theme) theme = {}\n  if (typeof theme === 'string') {\n    theme = this._themes.getTheme(theme)\n  } else if (theme && (Object.keys(theme).length === 0 || theme.hasUnicode != null || theme.hasColor != null)) {\n    var useUnicode = theme.hasUnicode == null ? hasUnicode() : theme.hasUnicode\n    var useColor = theme.hasColor == null ? hasColor : theme.hasColor\n    theme = this._themes.getDefault({hasUnicode: useUnicode, hasColor: useColor, platform: theme.platform})\n  }\n  return theme\n}\n\nGauge.prototype.setThemeset = function (themes) {\n  this._themes = themes\n  this.setTheme(this._theme)\n}\n\nGauge.prototype.setTheme = function (theme) {\n  this._gauge.setTheme(this._computeTheme(theme))\n  if (this._showing) this._requestRedraw()\n  this._theme = theme\n}\n\nGauge.prototype._requestRedraw = function () {\n  this._needsRedraw = true\n  if (!this._fixedFramerate) this._doRedraw()\n}\n\nGauge.prototype.getWidth = function () {\n  return ((this._tty && this._tty.columns) || 80) - 1\n}\n\nGauge.prototype.setWriteTo = function (writeTo, tty) {\n  var enabled = !this._disabled\n  if (enabled) this.disable()\n  this._writeTo = writeTo\n  this._tty = tty ||\n    (writeTo === process.stderr && process.stdout.isTTY && process.stdout) ||\n    (writeTo.isTTY && writeTo) ||\n    this._tty\n  if (this._gauge) this._gauge.setWidth(this.getWidth())\n  if (enabled) this.enable()\n}\n\nGauge.prototype.enable = function () {\n  if (!this._disabled) return\n  this._disabled = false\n  if (this._tty) this._enableEvents()\n  if (this._showing) this.show()\n}\n\nGauge.prototype.disable = function () {\n  if (this._disabled) return\n  if (this._showing) {\n    this._lastUpdateAt = null\n    this._showing = false\n    this._doRedraw()\n    this._showing = true\n  }\n  this._disabled = true\n  if (this._tty) this._disableEvents()\n}\n\nGauge.prototype._enableEvents = function () {\n  if (this._cleanupOnExit) {\n    this._removeOnExit = onExit(callWith(this, this.disable))\n  }\n  this._tty.on('resize', this._$$handleSizeChange)\n  if (this._fixedFramerate) {\n    this.redrawTracker = setInterval(this._$$doRedraw, this._updateInterval)\n    if (this.redrawTracker.unref) this.redrawTracker.unref()\n  }\n}\n\nGauge.prototype._disableEvents = function () {\n  this._tty.removeListener('resize', this._$$handleSizeChange)\n  if (this._fixedFramerate) clearInterval(this.redrawTracker)\n  if (this._removeOnExit) this._removeOnExit()\n}\n\nGauge.prototype.hide = function (cb) {\n  if (this._disabled) return cb && process.nextTick(cb)\n  if (!this._showing) return cb && process.nextTick(cb)\n  this._showing = false\n  this._doRedraw()\n  cb && setImmediate(cb)\n}\n\nGauge.prototype.show = function (section, completed) {\n  this._showing = true\n  if (typeof section === 'string') {\n    this._status.section = section\n  } else if (typeof section === 'object') {\n    var sectionKeys = Object.keys(section)\n    for (var ii = 0; ii < sectionKeys.length; ++ii) {\n      var key = sectionKeys[ii]\n      this._status[key] = section[key]\n    }\n  }\n  if (completed != null) this._status.completed = completed\n  if (this._disabled) return\n  this._requestRedraw()\n}\n\nGauge.prototype.pulse = function (subsection) {\n  this._status.subsection = subsection || ''\n  this._status.spun++\n  if (this._disabled) return\n  if (!this._showing) return\n  this._requestRedraw()\n}\n\nGauge.prototype._handleSizeChange = function () {\n  this._gauge.setWidth(this._tty.columns - 1)\n  this._requestRedraw()\n}\n\nGauge.prototype._doRedraw = function () {\n  if (this._disabled || this._paused) return\n  if (!this._fixedFramerate) {\n    var now = Date.now()\n    if (this._lastUpdateAt && now - this._lastUpdateAt < this._updateInterval) return\n    this._lastUpdateAt = now\n  }\n  if (!this._showing && this._onScreen) {\n    this._onScreen = false\n    var result = this._gauge.hide()\n    if (this._hideCursor) {\n      result += this._gauge.showCursor()\n    }\n    return this._writeTo.write(result)\n  }\n  if (!this._showing && !this._onScreen) return\n  if (this._showing && !this._onScreen) {\n    this._onScreen = true\n    this._needsRedraw = true\n    if (this._hideCursor) {\n      this._writeTo.write(this._gauge.hideCursor())\n    }\n  }\n  if (!this._needsRedraw) return\n  if (!this._writeTo.write(this._gauge.show(this._status))) {\n    this._paused = true\n    this._writeTo.on('drain', callWith(this, function () {\n      this._paused = false\n      this._doRedraw()\n    }))\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/index.js?");

/***/ }),

/***/ "./node_modules/gauge/plumbing.js":
/*!****************************************!*\
  !*** ./node_modules/gauge/plumbing.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar consoleControl = __webpack_require__(/*! console-control-strings */ \"./node_modules/console-control-strings/index.js\")\nvar renderTemplate = __webpack_require__(/*! ./render-template.js */ \"./node_modules/gauge/render-template.js\")\nvar validate = __webpack_require__(/*! aproba */ \"./node_modules/aproba/index.js\")\n\nvar Plumbing = module.exports = function (theme, template, width) {\n  if (!width) width = 80\n  validate('OAN', [theme, template, width])\n  this.showing = false\n  this.theme = theme\n  this.width = width\n  this.template = template\n}\nPlumbing.prototype = {}\n\nPlumbing.prototype.setTheme = function (theme) {\n  validate('O', [theme])\n  this.theme = theme\n}\n\nPlumbing.prototype.setTemplate = function (template) {\n  validate('A', [template])\n  this.template = template\n}\n\nPlumbing.prototype.setWidth = function (width) {\n  validate('N', [width])\n  this.width = width\n}\n\nPlumbing.prototype.hide = function () {\n  return consoleControl.gotoSOL() + consoleControl.eraseLine()\n}\n\nPlumbing.prototype.hideCursor = consoleControl.hideCursor\n\nPlumbing.prototype.showCursor = consoleControl.showCursor\n\nPlumbing.prototype.show = function (status) {\n  var values = Object.create(this.theme)\n  for (var key in status) {\n    values[key] = status[key]\n  }\n\n  return renderTemplate(this.width, this.template, values).trim() +\n         consoleControl.color('reset') +\n         consoleControl.eraseLine() + consoleControl.gotoSOL()\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/plumbing.js?");

/***/ }),

/***/ "./node_modules/gauge/process.js":
/*!***************************************!*\
  !*** ./node_modules/gauge/process.js ***!
  \***************************************/
/***/ ((module) => {

"use strict";
eval("\n// this exists so we can replace it during testing\nmodule.exports = process\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/process.js?");

/***/ }),

/***/ "./node_modules/gauge/progress-bar.js":
/*!********************************************!*\
  !*** ./node_modules/gauge/progress-bar.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar validate = __webpack_require__(/*! aproba */ \"./node_modules/aproba/index.js\")\nvar renderTemplate = __webpack_require__(/*! ./render-template.js */ \"./node_modules/gauge/render-template.js\")\nvar wideTruncate = __webpack_require__(/*! ./wide-truncate */ \"./node_modules/gauge/wide-truncate.js\")\nvar stringWidth = __webpack_require__(/*! string-width */ \"./node_modules/string-width/index.js\")\n\nmodule.exports = function (theme, width, completed) {\n  validate('ONN', [theme, width, completed])\n  if (completed < 0) completed = 0\n  if (completed > 1) completed = 1\n  if (width <= 0) return ''\n  var sofar = Math.round(width * completed)\n  var rest = width - sofar\n  var template = [\n    {type: 'complete', value: repeat(theme.complete, sofar), length: sofar},\n    {type: 'remaining', value: repeat(theme.remaining, rest), length: rest}\n  ]\n  return renderTemplate(width, template, theme)\n}\n\n// lodash's way of repeating\nfunction repeat (string, width) {\n  var result = ''\n  var n = width\n  do {\n    if (n % 2) {\n      result += string\n    }\n    n = Math.floor(n / 2)\n    /* eslint no-self-assign: 0 */\n    string += string\n  } while (n && stringWidth(result) < width)\n\n  return wideTruncate(result, width)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/progress-bar.js?");

/***/ }),

/***/ "./node_modules/gauge/render-template.js":
/*!***********************************************!*\
  !*** ./node_modules/gauge/render-template.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar align = __webpack_require__(/*! wide-align */ \"./node_modules/wide-align/align.js\")\nvar validate = __webpack_require__(/*! aproba */ \"./node_modules/aproba/index.js\")\nvar wideTruncate = __webpack_require__(/*! ./wide-truncate */ \"./node_modules/gauge/wide-truncate.js\")\nvar error = __webpack_require__(/*! ./error */ \"./node_modules/gauge/error.js\")\nvar TemplateItem = __webpack_require__(/*! ./template-item */ \"./node_modules/gauge/template-item.js\")\n\nfunction renderValueWithValues (values) {\n  return function (item) {\n    return renderValue(item, values)\n  }\n}\n\nvar renderTemplate = module.exports = function (width, template, values) {\n  var items = prepareItems(width, template, values)\n  var rendered = items.map(renderValueWithValues(values)).join('')\n  return align.left(wideTruncate(rendered, width), width)\n}\n\nfunction preType (item) {\n  var cappedTypeName = item.type[0].toUpperCase() + item.type.slice(1)\n  return 'pre' + cappedTypeName\n}\n\nfunction postType (item) {\n  var cappedTypeName = item.type[0].toUpperCase() + item.type.slice(1)\n  return 'post' + cappedTypeName\n}\n\nfunction hasPreOrPost (item, values) {\n  if (!item.type) return\n  return values[preType(item)] || values[postType(item)]\n}\n\nfunction generatePreAndPost (baseItem, parentValues) {\n  var item = Object.assign({}, baseItem)\n  var values = Object.create(parentValues)\n  var template = []\n  var pre = preType(item)\n  var post = postType(item)\n  if (values[pre]) {\n    template.push({value: values[pre]})\n    values[pre] = null\n  }\n  item.minLength = null\n  item.length = null\n  item.maxLength = null\n  template.push(item)\n  values[item.type] = values[item.type]\n  if (values[post]) {\n    template.push({value: values[post]})\n    values[post] = null\n  }\n  return function ($1, $2, length) {\n    return renderTemplate(length, template, values)\n  }\n}\n\nfunction prepareItems (width, template, values) {\n  function cloneAndObjectify (item, index, arr) {\n    var cloned = new TemplateItem(item, width)\n    var type = cloned.type\n    if (cloned.value == null) {\n      if (!(type in values)) {\n        if (cloned.default == null) {\n          throw new error.MissingTemplateValue(cloned, values)\n        } else {\n          cloned.value = cloned.default\n        }\n      } else {\n        cloned.value = values[type]\n      }\n    }\n    if (cloned.value == null || cloned.value === '') return null\n    cloned.index = index\n    cloned.first = index === 0\n    cloned.last = index === arr.length - 1\n    if (hasPreOrPost(cloned, values)) cloned.value = generatePreAndPost(cloned, values)\n    return cloned\n  }\n\n  var output = template.map(cloneAndObjectify).filter(function (item) { return item != null })\n\n  var remainingSpace = width\n  var variableCount = output.length\n\n  function consumeSpace (length) {\n    if (length > remainingSpace) length = remainingSpace\n    remainingSpace -= length\n  }\n\n  function finishSizing (item, length) {\n    if (item.finished) throw new error.Internal('Tried to finish template item that was already finished')\n    if (length === Infinity) throw new error.Internal('Length of template item cannot be infinity')\n    if (length != null) item.length = length\n    item.minLength = null\n    item.maxLength = null\n    --variableCount\n    item.finished = true\n    if (item.length == null) item.length = item.getBaseLength()\n    if (item.length == null) throw new error.Internal('Finished template items must have a length')\n    consumeSpace(item.getLength())\n  }\n\n  output.forEach(function (item) {\n    if (!item.kerning) return\n    var prevPadRight = item.first ? 0 : output[item.index - 1].padRight\n    if (!item.first && prevPadRight < item.kerning) item.padLeft = item.kerning - prevPadRight\n    if (!item.last) item.padRight = item.kerning\n  })\n\n  // Finish any that have a fixed (literal or intuited) length\n  output.forEach(function (item) {\n    if (item.getBaseLength() == null) return\n    finishSizing(item)\n  })\n\n  var resized = 0\n  var resizing\n  var hunkSize\n  do {\n    resizing = false\n    hunkSize = Math.round(remainingSpace / variableCount)\n    output.forEach(function (item) {\n      if (item.finished) return\n      if (!item.maxLength) return\n      if (item.getMaxLength() < hunkSize) {\n        finishSizing(item, item.maxLength)\n        resizing = true\n      }\n    })\n  } while (resizing && resized++ < output.length)\n  if (resizing) throw new error.Internal('Resize loop iterated too many times while determining maxLength')\n\n  resized = 0\n  do {\n    resizing = false\n    hunkSize = Math.round(remainingSpace / variableCount)\n    output.forEach(function (item) {\n      if (item.finished) return\n      if (!item.minLength) return\n      if (item.getMinLength() >= hunkSize) {\n        finishSizing(item, item.minLength)\n        resizing = true\n      }\n    })\n  } while (resizing && resized++ < output.length)\n  if (resizing) throw new error.Internal('Resize loop iterated too many times while determining minLength')\n\n  hunkSize = Math.round(remainingSpace / variableCount)\n  output.forEach(function (item) {\n    if (item.finished) return\n    finishSizing(item, hunkSize)\n  })\n\n  return output\n}\n\nfunction renderFunction (item, values, length) {\n  validate('OON', arguments)\n  if (item.type) {\n    return item.value(values, values[item.type + 'Theme'] || {}, length)\n  } else {\n    return item.value(values, {}, length)\n  }\n}\n\nfunction renderValue (item, values) {\n  var length = item.getBaseLength()\n  var value = typeof item.value === 'function' ? renderFunction(item, values, length) : item.value\n  if (value == null || value === '') return ''\n  var alignWith = align[item.align] || align.left\n  var leftPadding = item.padLeft ? align.left('', item.padLeft) : ''\n  var rightPadding = item.padRight ? align.right('', item.padRight) : ''\n  var truncated = wideTruncate(String(value), length)\n  var aligned = alignWith(truncated, length)\n  return leftPadding + aligned + rightPadding\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/render-template.js?");

/***/ }),

/***/ "./node_modules/gauge/set-immediate.js":
/*!*********************************************!*\
  !*** ./node_modules/gauge/set-immediate.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar process = __webpack_require__(/*! ./process */ \"./node_modules/gauge/process.js\")\ntry {\n  module.exports = setImmediate\n} catch (ex) {\n  module.exports = process.nextTick\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/set-immediate.js?");

/***/ }),

/***/ "./node_modules/gauge/set-interval.js":
/*!********************************************!*\
  !*** ./node_modules/gauge/set-interval.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("\n// this exists so we can replace it during testing\nmodule.exports = setInterval\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/set-interval.js?");

/***/ }),

/***/ "./node_modules/gauge/spin.js":
/*!************************************!*\
  !*** ./node_modules/gauge/spin.js ***!
  \************************************/
/***/ ((module) => {

"use strict";
eval("\n\nmodule.exports = function spin (spinstr, spun) {\n  return spinstr[spun % spinstr.length]\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/spin.js?");

/***/ }),

/***/ "./node_modules/gauge/template-item.js":
/*!*********************************************!*\
  !*** ./node_modules/gauge/template-item.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar stringWidth = __webpack_require__(/*! string-width */ \"./node_modules/string-width/index.js\")\n\nmodule.exports = TemplateItem\n\nfunction isPercent (num) {\n  if (typeof num !== 'string') return false\n  return num.slice(-1) === '%'\n}\n\nfunction percent (num) {\n  return Number(num.slice(0, -1)) / 100\n}\n\nfunction TemplateItem (values, outputLength) {\n  this.overallOutputLength = outputLength\n  this.finished = false\n  this.type = null\n  this.value = null\n  this.length = null\n  this.maxLength = null\n  this.minLength = null\n  this.kerning = null\n  this.align = 'left'\n  this.padLeft = 0\n  this.padRight = 0\n  this.index = null\n  this.first = null\n  this.last = null\n  if (typeof values === 'string') {\n    this.value = values\n  } else {\n    for (var prop in values) this[prop] = values[prop]\n  }\n  // Realize percents\n  if (isPercent(this.length)) {\n    this.length = Math.round(this.overallOutputLength * percent(this.length))\n  }\n  if (isPercent(this.minLength)) {\n    this.minLength = Math.round(this.overallOutputLength * percent(this.minLength))\n  }\n  if (isPercent(this.maxLength)) {\n    this.maxLength = Math.round(this.overallOutputLength * percent(this.maxLength))\n  }\n  return this\n}\n\nTemplateItem.prototype = {}\n\nTemplateItem.prototype.getBaseLength = function () {\n  var length = this.length\n  if (length == null && typeof this.value === 'string' && this.maxLength == null && this.minLength == null) {\n    length = stringWidth(this.value)\n  }\n  return length\n}\n\nTemplateItem.prototype.getLength = function () {\n  var length = this.getBaseLength()\n  if (length == null) return null\n  return length + this.padLeft + this.padRight\n}\n\nTemplateItem.prototype.getMaxLength = function () {\n  if (this.maxLength == null) return null\n  return this.maxLength + this.padLeft + this.padRight\n}\n\nTemplateItem.prototype.getMinLength = function () {\n  if (this.minLength == null) return null\n  return this.minLength + this.padLeft + this.padRight\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/template-item.js?");

/***/ }),

/***/ "./node_modules/gauge/theme-set.js":
/*!*****************************************!*\
  !*** ./node_modules/gauge/theme-set.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar objectAssign = __webpack_require__(/*! object-assign */ \"./node_modules/object-assign/index.js\")\n\nmodule.exports = function () {\n  return ThemeSetProto.newThemeSet()\n}\n\nvar ThemeSetProto = {}\n\nThemeSetProto.baseTheme = __webpack_require__(/*! ./base-theme.js */ \"./node_modules/gauge/base-theme.js\")\n\nThemeSetProto.newTheme = function (parent, theme) {\n  if (!theme) {\n    theme = parent\n    parent = this.baseTheme\n  }\n  return objectAssign({}, parent, theme)\n}\n\nThemeSetProto.getThemeNames = function () {\n  return Object.keys(this.themes)\n}\n\nThemeSetProto.addTheme = function (name, parent, theme) {\n  this.themes[name] = this.newTheme(parent, theme)\n}\n\nThemeSetProto.addToAllThemes = function (theme) {\n  var themes = this.themes\n  Object.keys(themes).forEach(function (name) {\n    objectAssign(themes[name], theme)\n  })\n  objectAssign(this.baseTheme, theme)\n}\n\nThemeSetProto.getTheme = function (name) {\n  if (!this.themes[name]) throw this.newMissingThemeError(name)\n  return this.themes[name]\n}\n\nThemeSetProto.setDefault = function (opts, name) {\n  if (name == null) {\n    name = opts\n    opts = {}\n  }\n  var platform = opts.platform == null ? 'fallback' : opts.platform\n  var hasUnicode = !!opts.hasUnicode\n  var hasColor = !!opts.hasColor\n  if (!this.defaults[platform]) this.defaults[platform] = {true: {}, false: {}}\n  this.defaults[platform][hasUnicode][hasColor] = name\n}\n\nThemeSetProto.getDefault = function (opts) {\n  if (!opts) opts = {}\n  var platformName = opts.platform || process.platform\n  var platform = this.defaults[platformName] || this.defaults.fallback\n  var hasUnicode = !!opts.hasUnicode\n  var hasColor = !!opts.hasColor\n  if (!platform) throw this.newMissingDefaultThemeError(platformName, hasUnicode, hasColor)\n  if (!platform[hasUnicode][hasColor]) {\n    if (hasUnicode && hasColor && platform[!hasUnicode][hasColor]) {\n      hasUnicode = false\n    } else if (hasUnicode && hasColor && platform[hasUnicode][!hasColor]) {\n      hasColor = false\n    } else if (hasUnicode && hasColor && platform[!hasUnicode][!hasColor]) {\n      hasUnicode = false\n      hasColor = false\n    } else if (hasUnicode && !hasColor && platform[!hasUnicode][hasColor]) {\n      hasUnicode = false\n    } else if (!hasUnicode && hasColor && platform[hasUnicode][!hasColor]) {\n      hasColor = false\n    } else if (platform === this.defaults.fallback) {\n      throw this.newMissingDefaultThemeError(platformName, hasUnicode, hasColor)\n    }\n  }\n  if (platform[hasUnicode][hasColor]) {\n    return this.getTheme(platform[hasUnicode][hasColor])\n  } else {\n    return this.getDefault(objectAssign({}, opts, {platform: 'fallback'}))\n  }\n}\n\nThemeSetProto.newMissingThemeError = function newMissingThemeError (name) {\n  var err = new Error('Could not find a gauge theme named \"' + name + '\"')\n  Error.captureStackTrace.call(err, newMissingThemeError)\n  err.theme = name\n  err.code = 'EMISSINGTHEME'\n  return err\n}\n\nThemeSetProto.newMissingDefaultThemeError = function newMissingDefaultThemeError (platformName, hasUnicode, hasColor) {\n  var err = new Error(\n    'Could not find a gauge theme for your platform/unicode/color use combo:\\n' +\n    '    platform = ' + platformName + '\\n' +\n    '    hasUnicode = ' + hasUnicode + '\\n' +\n    '    hasColor = ' + hasColor)\n  Error.captureStackTrace.call(err, newMissingDefaultThemeError)\n  err.platform = platformName\n  err.hasUnicode = hasUnicode\n  err.hasColor = hasColor\n  err.code = 'EMISSINGTHEME'\n  return err\n}\n\nThemeSetProto.newThemeSet = function () {\n  var themeset = function (opts) {\n    return themeset.getDefault(opts)\n  }\n  return objectAssign(themeset, ThemeSetProto, {\n    themes: objectAssign({}, this.themes),\n    baseTheme: objectAssign({}, this.baseTheme),\n    defaults: JSON.parse(JSON.stringify(this.defaults || {}))\n  })\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/theme-set.js?");

/***/ }),

/***/ "./node_modules/gauge/themes.js":
/*!**************************************!*\
  !*** ./node_modules/gauge/themes.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar color = (__webpack_require__(/*! console-control-strings */ \"./node_modules/console-control-strings/index.js\").color)\nvar ThemeSet = __webpack_require__(/*! ./theme-set.js */ \"./node_modules/gauge/theme-set.js\")\n\nvar themes = module.exports = new ThemeSet()\n\nthemes.addTheme('ASCII', {\n  preProgressbar: '[',\n  postProgressbar: ']',\n  progressbarTheme: {\n    complete: '#',\n    remaining: '.'\n  },\n  activityIndicatorTheme: '-\\\\|/',\n  preSubsection: '>'\n})\n\nthemes.addTheme('colorASCII', themes.getTheme('ASCII'), {\n  progressbarTheme: {\n    preComplete: color('bgBrightWhite', 'brightWhite'),\n    complete: '#',\n    postComplete: color('reset'),\n    preRemaining: color('bgBrightBlack', 'brightBlack'),\n    remaining: '.',\n    postRemaining: color('reset')\n  }\n})\n\nthemes.addTheme('brailleSpinner', {\n  preProgressbar: '',\n  postProgressbar: '',\n  progressbarTheme: {\n    complete: '#',\n    remaining: ''\n  },\n  activityIndicatorTheme: '',\n  preSubsection: '>'\n})\n\nthemes.addTheme('colorBrailleSpinner', themes.getTheme('brailleSpinner'), {\n  progressbarTheme: {\n    preComplete: color('bgBrightWhite', 'brightWhite'),\n    complete: '#',\n    postComplete: color('reset'),\n    preRemaining: color('bgBrightBlack', 'brightBlack'),\n    remaining: '',\n    postRemaining: color('reset')\n  }\n})\n\nthemes.setDefault({}, 'ASCII')\nthemes.setDefault({hasColor: true}, 'colorASCII')\nthemes.setDefault({platform: 'darwin', hasUnicode: true}, 'brailleSpinner')\nthemes.setDefault({platform: 'darwin', hasUnicode: true, hasColor: true}, 'colorBrailleSpinner')\nthemes.setDefault({platform: 'linux', hasUnicode: true}, 'brailleSpinner')\nthemes.setDefault({platform: 'linux', hasUnicode: true, hasColor: true}, 'colorBrailleSpinner')\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/themes.js?");

/***/ }),

/***/ "./node_modules/gauge/wide-truncate.js":
/*!*********************************************!*\
  !*** ./node_modules/gauge/wide-truncate.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar stringWidth = __webpack_require__(/*! string-width */ \"./node_modules/string-width/index.js\")\nvar stripAnsi = __webpack_require__(/*! strip-ansi */ \"./node_modules/strip-ansi/index.js\")\n\nmodule.exports = wideTruncate\n\nfunction wideTruncate (str, target) {\n  if (stringWidth(str) === 0) return str\n  if (target <= 0) return ''\n  if (stringWidth(str) <= target) return str\n\n  // We compute the number of bytes of ansi sequences here and add\n  // that to our initial truncation to ensure that we don't slice one\n  // that we want to keep in half.\n  var noAnsi = stripAnsi(str)\n  var ansiSize = str.length + noAnsi.length\n  var truncated = str.slice(0, target + ansiSize)\n\n  // we have to shrink the result to account for our ansi sequence buffer\n  // (if an ansi sequence was truncated) and double width characters.\n  while (stringWidth(truncated) > target) {\n    truncated = truncated.slice(0, -1)\n  }\n  return truncated\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gauge/wide-truncate.js?");

/***/ }),

/***/ "./node_modules/get-intrinsic/index.js":
/*!*********************************************!*\
  !*** ./node_modules/get-intrinsic/index.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar undefined;\n\nvar $Error = __webpack_require__(/*! es-errors */ \"./node_modules/es-errors/index.js\");\nvar $EvalError = __webpack_require__(/*! es-errors/eval */ \"./node_modules/es-errors/eval.js\");\nvar $RangeError = __webpack_require__(/*! es-errors/range */ \"./node_modules/es-errors/range.js\");\nvar $ReferenceError = __webpack_require__(/*! es-errors/ref */ \"./node_modules/es-errors/ref.js\");\nvar $SyntaxError = __webpack_require__(/*! es-errors/syntax */ \"./node_modules/es-errors/syntax.js\");\nvar $TypeError = __webpack_require__(/*! es-errors/type */ \"./node_modules/es-errors/type.js\");\nvar $URIError = __webpack_require__(/*! es-errors/uri */ \"./node_modules/es-errors/uri.js\");\n\nvar $Function = Function;\n\n// eslint-disable-next-line consistent-return\nvar getEvalledConstructor = function (expressionSyntax) {\n\ttry {\n\t\treturn $Function('\"use strict\"; return (' + expressionSyntax + ').constructor;')();\n\t} catch (e) {}\n};\n\nvar $gOPD = Object.getOwnPropertyDescriptor;\nif ($gOPD) {\n\ttry {\n\t\t$gOPD({}, '');\n\t} catch (e) {\n\t\t$gOPD = null; // this is IE 8, which has a broken gOPD\n\t}\n}\n\nvar throwTypeError = function () {\n\tthrow new $TypeError();\n};\nvar ThrowTypeError = $gOPD\n\t? (function () {\n\t\ttry {\n\t\t\t// eslint-disable-next-line no-unused-expressions, no-caller, no-restricted-properties\n\t\t\targuments.callee; // IE 8 does not throw here\n\t\t\treturn throwTypeError;\n\t\t} catch (calleeThrows) {\n\t\t\ttry {\n\t\t\t\t// IE 8 throws on Object.getOwnPropertyDescriptor(arguments, '')\n\t\t\t\treturn $gOPD(arguments, 'callee').get;\n\t\t\t} catch (gOPDthrows) {\n\t\t\t\treturn throwTypeError;\n\t\t\t}\n\t\t}\n\t}())\n\t: throwTypeError;\n\nvar hasSymbols = __webpack_require__(/*! has-symbols */ \"./node_modules/has-symbols/index.js\")();\nvar hasProto = __webpack_require__(/*! has-proto */ \"./node_modules/has-proto/index.js\")();\n\nvar getProto = Object.getPrototypeOf || (\n\thasProto\n\t\t? function (x) { return x.__proto__; } // eslint-disable-line no-proto\n\t\t: null\n);\n\nvar needsEval = {};\n\nvar TypedArray = typeof Uint8Array === 'undefined' || !getProto ? undefined : getProto(Uint8Array);\n\nvar INTRINSICS = {\n\t__proto__: null,\n\t'%AggregateError%': typeof AggregateError === 'undefined' ? undefined : AggregateError,\n\t'%Array%': Array,\n\t'%ArrayBuffer%': typeof ArrayBuffer === 'undefined' ? undefined : ArrayBuffer,\n\t'%ArrayIteratorPrototype%': hasSymbols && getProto ? getProto([][Symbol.iterator]()) : undefined,\n\t'%AsyncFromSyncIteratorPrototype%': undefined,\n\t'%AsyncFunction%': needsEval,\n\t'%AsyncGenerator%': needsEval,\n\t'%AsyncGeneratorFunction%': needsEval,\n\t'%AsyncIteratorPrototype%': needsEval,\n\t'%Atomics%': typeof Atomics === 'undefined' ? undefined : Atomics,\n\t'%BigInt%': typeof BigInt === 'undefined' ? undefined : BigInt,\n\t'%BigInt64Array%': typeof BigInt64Array === 'undefined' ? undefined : BigInt64Array,\n\t'%BigUint64Array%': typeof BigUint64Array === 'undefined' ? undefined : BigUint64Array,\n\t'%Boolean%': Boolean,\n\t'%DataView%': typeof DataView === 'undefined' ? undefined : DataView,\n\t'%Date%': Date,\n\t'%decodeURI%': decodeURI,\n\t'%decodeURIComponent%': decodeURIComponent,\n\t'%encodeURI%': encodeURI,\n\t'%encodeURIComponent%': encodeURIComponent,\n\t'%Error%': $Error,\n\t'%eval%': eval, // eslint-disable-line no-eval\n\t'%EvalError%': $EvalError,\n\t'%Float32Array%': typeof Float32Array === 'undefined' ? undefined : Float32Array,\n\t'%Float64Array%': typeof Float64Array === 'undefined' ? undefined : Float64Array,\n\t'%FinalizationRegistry%': typeof FinalizationRegistry === 'undefined' ? undefined : FinalizationRegistry,\n\t'%Function%': $Function,\n\t'%GeneratorFunction%': needsEval,\n\t'%Int8Array%': typeof Int8Array === 'undefined' ? undefined : Int8Array,\n\t'%Int16Array%': typeof Int16Array === 'undefined' ? undefined : Int16Array,\n\t'%Int32Array%': typeof Int32Array === 'undefined' ? undefined : Int32Array,\n\t'%isFinite%': isFinite,\n\t'%isNaN%': isNaN,\n\t'%IteratorPrototype%': hasSymbols && getProto ? getProto(getProto([][Symbol.iterator]())) : undefined,\n\t'%JSON%': typeof JSON === 'object' ? JSON : undefined,\n\t'%Map%': typeof Map === 'undefined' ? undefined : Map,\n\t'%MapIteratorPrototype%': typeof Map === 'undefined' || !hasSymbols || !getProto ? undefined : getProto(new Map()[Symbol.iterator]()),\n\t'%Math%': Math,\n\t'%Number%': Number,\n\t'%Object%': Object,\n\t'%parseFloat%': parseFloat,\n\t'%parseInt%': parseInt,\n\t'%Promise%': typeof Promise === 'undefined' ? undefined : Promise,\n\t'%Proxy%': typeof Proxy === 'undefined' ? undefined : Proxy,\n\t'%RangeError%': $RangeError,\n\t'%ReferenceError%': $ReferenceError,\n\t'%Reflect%': typeof Reflect === 'undefined' ? undefined : Reflect,\n\t'%RegExp%': RegExp,\n\t'%Set%': typeof Set === 'undefined' ? undefined : Set,\n\t'%SetIteratorPrototype%': typeof Set === 'undefined' || !hasSymbols || !getProto ? undefined : getProto(new Set()[Symbol.iterator]()),\n\t'%SharedArrayBuffer%': typeof SharedArrayBuffer === 'undefined' ? undefined : SharedArrayBuffer,\n\t'%String%': String,\n\t'%StringIteratorPrototype%': hasSymbols && getProto ? getProto(''[Symbol.iterator]()) : undefined,\n\t'%Symbol%': hasSymbols ? Symbol : undefined,\n\t'%SyntaxError%': $SyntaxError,\n\t'%ThrowTypeError%': ThrowTypeError,\n\t'%TypedArray%': TypedArray,\n\t'%TypeError%': $TypeError,\n\t'%Uint8Array%': typeof Uint8Array === 'undefined' ? undefined : Uint8Array,\n\t'%Uint8ClampedArray%': typeof Uint8ClampedArray === 'undefined' ? undefined : Uint8ClampedArray,\n\t'%Uint16Array%': typeof Uint16Array === 'undefined' ? undefined : Uint16Array,\n\t'%Uint32Array%': typeof Uint32Array === 'undefined' ? undefined : Uint32Array,\n\t'%URIError%': $URIError,\n\t'%WeakMap%': typeof WeakMap === 'undefined' ? undefined : WeakMap,\n\t'%WeakRef%': typeof WeakRef === 'undefined' ? undefined : WeakRef,\n\t'%WeakSet%': typeof WeakSet === 'undefined' ? undefined : WeakSet\n};\n\nif (getProto) {\n\ttry {\n\t\tnull.error; // eslint-disable-line no-unused-expressions\n\t} catch (e) {\n\t\t// https://github.com/tc39/proposal-shadowrealm/pull/384#issuecomment-1364264229\n\t\tvar errorProto = getProto(getProto(e));\n\t\tINTRINSICS['%Error.prototype%'] = errorProto;\n\t}\n}\n\nvar doEval = function doEval(name) {\n\tvar value;\n\tif (name === '%AsyncFunction%') {\n\t\tvalue = getEvalledConstructor('async function () {}');\n\t} else if (name === '%GeneratorFunction%') {\n\t\tvalue = getEvalledConstructor('function* () {}');\n\t} else if (name === '%AsyncGeneratorFunction%') {\n\t\tvalue = getEvalledConstructor('async function* () {}');\n\t} else if (name === '%AsyncGenerator%') {\n\t\tvar fn = doEval('%AsyncGeneratorFunction%');\n\t\tif (fn) {\n\t\t\tvalue = fn.prototype;\n\t\t}\n\t} else if (name === '%AsyncIteratorPrototype%') {\n\t\tvar gen = doEval('%AsyncGenerator%');\n\t\tif (gen && getProto) {\n\t\t\tvalue = getProto(gen.prototype);\n\t\t}\n\t}\n\n\tINTRINSICS[name] = value;\n\n\treturn value;\n};\n\nvar LEGACY_ALIASES = {\n\t__proto__: null,\n\t'%ArrayBufferPrototype%': ['ArrayBuffer', 'prototype'],\n\t'%ArrayPrototype%': ['Array', 'prototype'],\n\t'%ArrayProto_entries%': ['Array', 'prototype', 'entries'],\n\t'%ArrayProto_forEach%': ['Array', 'prototype', 'forEach'],\n\t'%ArrayProto_keys%': ['Array', 'prototype', 'keys'],\n\t'%ArrayProto_values%': ['Array', 'prototype', 'values'],\n\t'%AsyncFunctionPrototype%': ['AsyncFunction', 'prototype'],\n\t'%AsyncGenerator%': ['AsyncGeneratorFunction', 'prototype'],\n\t'%AsyncGeneratorPrototype%': ['AsyncGeneratorFunction', 'prototype', 'prototype'],\n\t'%BooleanPrototype%': ['Boolean', 'prototype'],\n\t'%DataViewPrototype%': ['DataView', 'prototype'],\n\t'%DatePrototype%': ['Date', 'prototype'],\n\t'%ErrorPrototype%': ['Error', 'prototype'],\n\t'%EvalErrorPrototype%': ['EvalError', 'prototype'],\n\t'%Float32ArrayPrototype%': ['Float32Array', 'prototype'],\n\t'%Float64ArrayPrototype%': ['Float64Array', 'prototype'],\n\t'%FunctionPrototype%': ['Function', 'prototype'],\n\t'%Generator%': ['GeneratorFunction', 'prototype'],\n\t'%GeneratorPrototype%': ['GeneratorFunction', 'prototype', 'prototype'],\n\t'%Int8ArrayPrototype%': ['Int8Array', 'prototype'],\n\t'%Int16ArrayPrototype%': ['Int16Array', 'prototype'],\n\t'%Int32ArrayPrototype%': ['Int32Array', 'prototype'],\n\t'%JSONParse%': ['JSON', 'parse'],\n\t'%JSONStringify%': ['JSON', 'stringify'],\n\t'%MapPrototype%': ['Map', 'prototype'],\n\t'%NumberPrototype%': ['Number', 'prototype'],\n\t'%ObjectPrototype%': ['Object', 'prototype'],\n\t'%ObjProto_toString%': ['Object', 'prototype', 'toString'],\n\t'%ObjProto_valueOf%': ['Object', 'prototype', 'valueOf'],\n\t'%PromisePrototype%': ['Promise', 'prototype'],\n\t'%PromiseProto_then%': ['Promise', 'prototype', 'then'],\n\t'%Promise_all%': ['Promise', 'all'],\n\t'%Promise_reject%': ['Promise', 'reject'],\n\t'%Promise_resolve%': ['Promise', 'resolve'],\n\t'%RangeErrorPrototype%': ['RangeError', 'prototype'],\n\t'%ReferenceErrorPrototype%': ['ReferenceError', 'prototype'],\n\t'%RegExpPrototype%': ['RegExp', 'prototype'],\n\t'%SetPrototype%': ['Set', 'prototype'],\n\t'%SharedArrayBufferPrototype%': ['SharedArrayBuffer', 'prototype'],\n\t'%StringPrototype%': ['String', 'prototype'],\n\t'%SymbolPrototype%': ['Symbol', 'prototype'],\n\t'%SyntaxErrorPrototype%': ['SyntaxError', 'prototype'],\n\t'%TypedArrayPrototype%': ['TypedArray', 'prototype'],\n\t'%TypeErrorPrototype%': ['TypeError', 'prototype'],\n\t'%Uint8ArrayPrototype%': ['Uint8Array', 'prototype'],\n\t'%Uint8ClampedArrayPrototype%': ['Uint8ClampedArray', 'prototype'],\n\t'%Uint16ArrayPrototype%': ['Uint16Array', 'prototype'],\n\t'%Uint32ArrayPrototype%': ['Uint32Array', 'prototype'],\n\t'%URIErrorPrototype%': ['URIError', 'prototype'],\n\t'%WeakMapPrototype%': ['WeakMap', 'prototype'],\n\t'%WeakSetPrototype%': ['WeakSet', 'prototype']\n};\n\nvar bind = __webpack_require__(/*! function-bind */ \"./node_modules/function-bind/index.js\");\nvar hasOwn = __webpack_require__(/*! hasown */ \"./node_modules/hasown/index.js\");\nvar $concat = bind.call(Function.call, Array.prototype.concat);\nvar $spliceApply = bind.call(Function.apply, Array.prototype.splice);\nvar $replace = bind.call(Function.call, String.prototype.replace);\nvar $strSlice = bind.call(Function.call, String.prototype.slice);\nvar $exec = bind.call(Function.call, RegExp.prototype.exec);\n\n/* adapted from https://github.com/lodash/lodash/blob/4.17.15/dist/lodash.js#L6735-L6744 */\nvar rePropName = /[^%.[\\]]+|\\[(?:(-?\\d+(?:\\.\\d+)?)|([\"'])((?:(?!\\2)[^\\\\]|\\\\.)*?)\\2)\\]|(?=(?:\\.|\\[\\])(?:\\.|\\[\\]|%$))/g;\nvar reEscapeChar = /\\\\(\\\\)?/g; /** Used to match backslashes in property paths. */\nvar stringToPath = function stringToPath(string) {\n\tvar first = $strSlice(string, 0, 1);\n\tvar last = $strSlice(string, -1);\n\tif (first === '%' && last !== '%') {\n\t\tthrow new $SyntaxError('invalid intrinsic syntax, expected closing `%`');\n\t} else if (last === '%' && first !== '%') {\n\t\tthrow new $SyntaxError('invalid intrinsic syntax, expected opening `%`');\n\t}\n\tvar result = [];\n\t$replace(string, rePropName, function (match, number, quote, subString) {\n\t\tresult[result.length] = quote ? $replace(subString, reEscapeChar, '$1') : number || match;\n\t});\n\treturn result;\n};\n/* end adaptation */\n\nvar getBaseIntrinsic = function getBaseIntrinsic(name, allowMissing) {\n\tvar intrinsicName = name;\n\tvar alias;\n\tif (hasOwn(LEGACY_ALIASES, intrinsicName)) {\n\t\talias = LEGACY_ALIASES[intrinsicName];\n\t\tintrinsicName = '%' + alias[0] + '%';\n\t}\n\n\tif (hasOwn(INTRINSICS, intrinsicName)) {\n\t\tvar value = INTRINSICS[intrinsicName];\n\t\tif (value === needsEval) {\n\t\t\tvalue = doEval(intrinsicName);\n\t\t}\n\t\tif (typeof value === 'undefined' && !allowMissing) {\n\t\t\tthrow new $TypeError('intrinsic ' + name + ' exists, but is not available. Please file an issue!');\n\t\t}\n\n\t\treturn {\n\t\t\talias: alias,\n\t\t\tname: intrinsicName,\n\t\t\tvalue: value\n\t\t};\n\t}\n\n\tthrow new $SyntaxError('intrinsic ' + name + ' does not exist!');\n};\n\nmodule.exports = function GetIntrinsic(name, allowMissing) {\n\tif (typeof name !== 'string' || name.length === 0) {\n\t\tthrow new $TypeError('intrinsic name must be a non-empty string');\n\t}\n\tif (arguments.length > 1 && typeof allowMissing !== 'boolean') {\n\t\tthrow new $TypeError('\"allowMissing\" argument must be a boolean');\n\t}\n\n\tif ($exec(/^%?[^%]*%?$/, name) === null) {\n\t\tthrow new $SyntaxError('`%` may not be present anywhere but at the beginning and end of the intrinsic name');\n\t}\n\tvar parts = stringToPath(name);\n\tvar intrinsicBaseName = parts.length > 0 ? parts[0] : '';\n\n\tvar intrinsic = getBaseIntrinsic('%' + intrinsicBaseName + '%', allowMissing);\n\tvar intrinsicRealName = intrinsic.name;\n\tvar value = intrinsic.value;\n\tvar skipFurtherCaching = false;\n\n\tvar alias = intrinsic.alias;\n\tif (alias) {\n\t\tintrinsicBaseName = alias[0];\n\t\t$spliceApply(parts, $concat([0, 1], alias));\n\t}\n\n\tfor (var i = 1, isOwn = true; i < parts.length; i += 1) {\n\t\tvar part = parts[i];\n\t\tvar first = $strSlice(part, 0, 1);\n\t\tvar last = $strSlice(part, -1);\n\t\tif (\n\t\t\t(\n\t\t\t\t(first === '\"' || first === \"'\" || first === '`')\n\t\t\t\t|| (last === '\"' || last === \"'\" || last === '`')\n\t\t\t)\n\t\t\t&& first !== last\n\t\t) {\n\t\t\tthrow new $SyntaxError('property names with quotes must have matching quotes');\n\t\t}\n\t\tif (part === 'constructor' || !isOwn) {\n\t\t\tskipFurtherCaching = true;\n\t\t}\n\n\t\tintrinsicBaseName += '.' + part;\n\t\tintrinsicRealName = '%' + intrinsicBaseName + '%';\n\n\t\tif (hasOwn(INTRINSICS, intrinsicRealName)) {\n\t\t\tvalue = INTRINSICS[intrinsicRealName];\n\t\t} else if (value != null) {\n\t\t\tif (!(part in value)) {\n\t\t\t\tif (!allowMissing) {\n\t\t\t\t\tthrow new $TypeError('base intrinsic for ' + name + ' exists, but the property is not available.');\n\t\t\t\t}\n\t\t\t\treturn void undefined;\n\t\t\t}\n\t\t\tif ($gOPD && (i + 1) >= parts.length) {\n\t\t\t\tvar desc = $gOPD(value, part);\n\t\t\t\tisOwn = !!desc;\n\n\t\t\t\t// By convention, when a data property is converted to an accessor\n\t\t\t\t// property to emulate a data property that does not suffer from\n\t\t\t\t// the override mistake, that accessor's getter is marked with\n\t\t\t\t// an `originalValue` property. Here, when we detect this, we\n\t\t\t\t// uphold the illusion by pretending to see that original data\n\t\t\t\t// property, i.e., returning the value rather than the getter\n\t\t\t\t// itself.\n\t\t\t\tif (isOwn && 'get' in desc && !('originalValue' in desc.get)) {\n\t\t\t\t\tvalue = desc.get;\n\t\t\t\t} else {\n\t\t\t\t\tvalue = value[part];\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tisOwn = hasOwn(value, part);\n\t\t\t\tvalue = value[part];\n\t\t\t}\n\n\t\t\tif (isOwn && !skipFurtherCaching) {\n\t\t\t\tINTRINSICS[intrinsicRealName] = value;\n\t\t\t}\n\t\t}\n\t}\n\treturn value;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/get-intrinsic/index.js?");

/***/ }),

/***/ "./node_modules/glob/common.js":
/*!*************************************!*\
  !*** ./node_modules/glob/common.js ***!
  \*************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("exports.setopts = setopts\nexports.ownProp = ownProp\nexports.makeAbs = makeAbs\nexports.finish = finish\nexports.mark = mark\nexports.isIgnored = isIgnored\nexports.childrenIgnored = childrenIgnored\n\nfunction ownProp (obj, field) {\n  return Object.prototype.hasOwnProperty.call(obj, field)\n}\n\nvar fs = __webpack_require__(/*! fs */ \"?a40c\")\nvar path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nvar minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\")\nvar isAbsolute = __webpack_require__(/*! path-is-absolute */ \"./node_modules/path-is-absolute/index.js\")\nvar Minimatch = minimatch.Minimatch\n\nfunction alphasort (a, b) {\n  return a.localeCompare(b, 'en')\n}\n\nfunction setupIgnores (self, options) {\n  self.ignore = options.ignore || []\n\n  if (!Array.isArray(self.ignore))\n    self.ignore = [self.ignore]\n\n  if (self.ignore.length) {\n    self.ignore = self.ignore.map(ignoreMap)\n  }\n}\n\n// ignore patterns are always in dot:true mode.\nfunction ignoreMap (pattern) {\n  var gmatcher = null\n  if (pattern.slice(-3) === '/**') {\n    var gpattern = pattern.replace(/(\\/\\*\\*)+$/, '')\n    gmatcher = new Minimatch(gpattern, { dot: true })\n  }\n\n  return {\n    matcher: new Minimatch(pattern, { dot: true }),\n    gmatcher: gmatcher\n  }\n}\n\nfunction setopts (self, pattern, options) {\n  if (!options)\n    options = {}\n\n  // base-matching: just use globstar for that.\n  if (options.matchBase && -1 === pattern.indexOf(\"/\")) {\n    if (options.noglobstar) {\n      throw new Error(\"base matching requires globstar\")\n    }\n    pattern = \"**/\" + pattern\n  }\n\n  self.silent = !!options.silent\n  self.pattern = pattern\n  self.strict = options.strict !== false\n  self.realpath = !!options.realpath\n  self.realpathCache = options.realpathCache || Object.create(null)\n  self.follow = !!options.follow\n  self.dot = !!options.dot\n  self.mark = !!options.mark\n  self.nodir = !!options.nodir\n  if (self.nodir)\n    self.mark = true\n  self.sync = !!options.sync\n  self.nounique = !!options.nounique\n  self.nonull = !!options.nonull\n  self.nosort = !!options.nosort\n  self.nocase = !!options.nocase\n  self.stat = !!options.stat\n  self.noprocess = !!options.noprocess\n  self.absolute = !!options.absolute\n  self.fs = options.fs || fs\n\n  self.maxLength = options.maxLength || Infinity\n  self.cache = options.cache || Object.create(null)\n  self.statCache = options.statCache || Object.create(null)\n  self.symlinks = options.symlinks || Object.create(null)\n\n  setupIgnores(self, options)\n\n  self.changedCwd = false\n  var cwd = process.cwd()\n  if (!ownProp(options, \"cwd\"))\n    self.cwd = cwd\n  else {\n    self.cwd = path.resolve(options.cwd)\n    self.changedCwd = self.cwd !== cwd\n  }\n\n  self.root = options.root || path.resolve(self.cwd, \"/\")\n  self.root = path.resolve(self.root)\n  if (process.platform === \"win32\")\n    self.root = self.root.replace(/\\\\/g, \"/\")\n\n  // TODO: is an absolute `cwd` supposed to be resolved against `root`?\n  // e.g. { cwd: '/test', root: __dirname } === path.join(__dirname, '/test')\n  self.cwdAbs = isAbsolute(self.cwd) ? self.cwd : makeAbs(self, self.cwd)\n  if (process.platform === \"win32\")\n    self.cwdAbs = self.cwdAbs.replace(/\\\\/g, \"/\")\n  self.nomount = !!options.nomount\n\n  // disable comments and negation in Minimatch.\n  // Note that they are not supported in Glob itself anyway.\n  options.nonegate = true\n  options.nocomment = true\n  // always treat \\ in patterns as escapes, not path separators\n  options.allowWindowsEscape = false\n\n  self.minimatch = new Minimatch(pattern, options)\n  self.options = self.minimatch.options\n}\n\nfunction finish (self) {\n  var nou = self.nounique\n  var all = nou ? [] : Object.create(null)\n\n  for (var i = 0, l = self.matches.length; i < l; i ++) {\n    var matches = self.matches[i]\n    if (!matches || Object.keys(matches).length === 0) {\n      if (self.nonull) {\n        // do like the shell, and spit out the literal glob\n        var literal = self.minimatch.globSet[i]\n        if (nou)\n          all.push(literal)\n        else\n          all[literal] = true\n      }\n    } else {\n      // had matches\n      var m = Object.keys(matches)\n      if (nou)\n        all.push.apply(all, m)\n      else\n        m.forEach(function (m) {\n          all[m] = true\n        })\n    }\n  }\n\n  if (!nou)\n    all = Object.keys(all)\n\n  if (!self.nosort)\n    all = all.sort(alphasort)\n\n  // at *some* point we statted all of these\n  if (self.mark) {\n    for (var i = 0; i < all.length; i++) {\n      all[i] = self._mark(all[i])\n    }\n    if (self.nodir) {\n      all = all.filter(function (e) {\n        var notDir = !(/\\/$/.test(e))\n        var c = self.cache[e] || self.cache[makeAbs(self, e)]\n        if (notDir && c)\n          notDir = c !== 'DIR' && !Array.isArray(c)\n        return notDir\n      })\n    }\n  }\n\n  if (self.ignore.length)\n    all = all.filter(function(m) {\n      return !isIgnored(self, m)\n    })\n\n  self.found = all\n}\n\nfunction mark (self, p) {\n  var abs = makeAbs(self, p)\n  var c = self.cache[abs]\n  var m = p\n  if (c) {\n    var isDir = c === 'DIR' || Array.isArray(c)\n    var slash = p.slice(-1) === '/'\n\n    if (isDir && !slash)\n      m += '/'\n    else if (!isDir && slash)\n      m = m.slice(0, -1)\n\n    if (m !== p) {\n      var mabs = makeAbs(self, m)\n      self.statCache[mabs] = self.statCache[abs]\n      self.cache[mabs] = self.cache[abs]\n    }\n  }\n\n  return m\n}\n\n// lotta situps...\nfunction makeAbs (self, f) {\n  var abs = f\n  if (f.charAt(0) === '/') {\n    abs = path.join(self.root, f)\n  } else if (isAbsolute(f) || f === '') {\n    abs = f\n  } else if (self.changedCwd) {\n    abs = path.resolve(self.cwd, f)\n  } else {\n    abs = path.resolve(f)\n  }\n\n  if (process.platform === 'win32')\n    abs = abs.replace(/\\\\/g, '/')\n\n  return abs\n}\n\n\n// Return true, if pattern ends with globstar '**', for the accompanying parent directory.\n// Ex:- If node_modules/** is the pattern, add 'node_modules' to ignore list along with it's contents\nfunction isIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return item.matcher.match(path) || !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\nfunction childrenIgnored (self, path) {\n  if (!self.ignore.length)\n    return false\n\n  return self.ignore.some(function(item) {\n    return !!(item.gmatcher && item.gmatcher.match(path))\n  })\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/glob/common.js?");

/***/ }),

/***/ "./node_modules/glob/glob.js":
/*!***********************************!*\
  !*** ./node_modules/glob/glob.js ***!
  \***********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Approach:\n//\n// 1. Get the minimatch set\n// 2. For each pattern in the set, PROCESS(pattern, false)\n// 3. Store matches per-set, then uniq them\n//\n// PROCESS(pattern, inGlobStar)\n// Get the first [n] items from pattern that are all strings\n// Join these together.  This is PREFIX.\n//   If there is no more remaining, then stat(PREFIX) and\n//   add to matches if it succeeds.  END.\n//\n// If inGlobStar and PREFIX is symlink and points to dir\n//   set ENTRIES = []\n// else readdir(PREFIX) as ENTRIES\n//   If fail, END\n//\n// with ENTRIES\n//   If pattern[n] is GLOBSTAR\n//     // handle the case where the globstar match is empty\n//     // by pruning it out, and testing the resulting pattern\n//     PROCESS(pattern[0..n] + pattern[n+1 .. $], false)\n//     // handle other cases.\n//     for ENTRY in ENTRIES (not dotfiles)\n//       // attach globstar + tail onto the entry\n//       // Mark that this entry is a globstar match\n//       PROCESS(pattern[0..n] + ENTRY + pattern[n .. $], true)\n//\n//   else // not globstar\n//     for ENTRY in ENTRIES (not dotfiles, unless pattern[n] is dot)\n//       Test ENTRY against pattern[n]\n//       If fails, continue\n//       If passes, PROCESS(pattern[0..n] + item + pattern[n+1 .. $])\n//\n// Caveat:\n//   Cache all stats and readdirs results to minimize syscall.  Since all\n//   we ever care about is existence and directory-ness, we can just keep\n//   `true` for files, and [children,...] for directories, or `false` for\n//   things that don't exist.\n\nmodule.exports = glob\n\nvar rp = __webpack_require__(/*! fs.realpath */ \"./node_modules/fs.realpath/index.js\")\nvar minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\")\nvar Minimatch = minimatch.Minimatch\nvar inherits = __webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")\nvar EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter)\nvar path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nvar assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nvar isAbsolute = __webpack_require__(/*! path-is-absolute */ \"./node_modules/path-is-absolute/index.js\")\nvar globSync = __webpack_require__(/*! ./sync.js */ \"./node_modules/glob/sync.js\")\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/glob/common.js\")\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar inflight = __webpack_require__(/*! inflight */ \"./node_modules/inflight/inflight.js\")\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nvar once = __webpack_require__(/*! once */ \"./node_modules/once/once.js\")\n\nfunction glob (pattern, options, cb) {\n  if (typeof options === 'function') cb = options, options = {}\n  if (!options) options = {}\n\n  if (options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return globSync(pattern, options)\n  }\n\n  return new Glob(pattern, options, cb)\n}\n\nglob.sync = globSync\nvar GlobSync = glob.GlobSync = globSync.GlobSync\n\n// old api surface\nglob.glob = glob\n\nfunction extend (origin, add) {\n  if (add === null || typeof add !== 'object') {\n    return origin\n  }\n\n  var keys = Object.keys(add)\n  var i = keys.length\n  while (i--) {\n    origin[keys[i]] = add[keys[i]]\n  }\n  return origin\n}\n\nglob.hasMagic = function (pattern, options_) {\n  var options = extend({}, options_)\n  options.noprocess = true\n\n  var g = new Glob(pattern, options)\n  var set = g.minimatch.set\n\n  if (!pattern)\n    return false\n\n  if (set.length > 1)\n    return true\n\n  for (var j = 0; j < set[0].length; j++) {\n    if (typeof set[0][j] !== 'string')\n      return true\n  }\n\n  return false\n}\n\nglob.Glob = Glob\ninherits(Glob, EE)\nfunction Glob (pattern, options, cb) {\n  if (typeof options === 'function') {\n    cb = options\n    options = null\n  }\n\n  if (options && options.sync) {\n    if (cb)\n      throw new TypeError('callback provided to sync glob')\n    return new GlobSync(pattern, options)\n  }\n\n  if (!(this instanceof Glob))\n    return new Glob(pattern, options, cb)\n\n  setopts(this, pattern, options)\n  this._didRealPath = false\n\n  // process each pattern in the minimatch set\n  var n = this.minimatch.set.length\n\n  // The matches are stored as {<filename>: true,...} so that\n  // duplicates are automagically pruned.\n  // Later, we do an Object.keys() on these.\n  // Keep them as a list so we can fill in when nonull is set.\n  this.matches = new Array(n)\n\n  if (typeof cb === 'function') {\n    cb = once(cb)\n    this.on('error', cb)\n    this.on('end', function (matches) {\n      cb(null, matches)\n    })\n  }\n\n  var self = this\n  this._processing = 0\n\n  this._emitQueue = []\n  this._processQueue = []\n  this.paused = false\n\n  if (this.noprocess)\n    return this\n\n  if (n === 0)\n    return done()\n\n  var sync = true\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false, done)\n  }\n  sync = false\n\n  function done () {\n    --self._processing\n    if (self._processing <= 0) {\n      if (sync) {\n        process.nextTick(function () {\n          self._finish()\n        })\n      } else {\n        self._finish()\n      }\n    }\n  }\n}\n\nGlob.prototype._finish = function () {\n  assert(this instanceof Glob)\n  if (this.aborted)\n    return\n\n  if (this.realpath && !this._didRealpath)\n    return this._realpath()\n\n  common.finish(this)\n  this.emit('end', this.found)\n}\n\nGlob.prototype._realpath = function () {\n  if (this._didRealpath)\n    return\n\n  this._didRealpath = true\n\n  var n = this.matches.length\n  if (n === 0)\n    return this._finish()\n\n  var self = this\n  for (var i = 0; i < this.matches.length; i++)\n    this._realpathSet(i, next)\n\n  function next () {\n    if (--n === 0)\n      self._finish()\n  }\n}\n\nGlob.prototype._realpathSet = function (index, cb) {\n  var matchset = this.matches[index]\n  if (!matchset)\n    return cb()\n\n  var found = Object.keys(matchset)\n  var self = this\n  var n = found.length\n\n  if (n === 0)\n    return cb()\n\n  var set = this.matches[index] = Object.create(null)\n  found.forEach(function (p, i) {\n    // If there's a problem with the stat, then it means that\n    // one or more of the links in the realpath couldn't be\n    // resolved.  just return the abs value in that case.\n    p = self._makeAbs(p)\n    rp.realpath(p, self.realpathCache, function (er, real) {\n      if (!er)\n        set[real] = true\n      else if (er.syscall === 'stat')\n        set[p] = true\n      else\n        self.emit('error', er) // srsly wtf right here\n\n      if (--n === 0) {\n        self.matches[index] = set\n        cb()\n      }\n    })\n  })\n}\n\nGlob.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlob.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n\nGlob.prototype.abort = function () {\n  this.aborted = true\n  this.emit('abort')\n}\n\nGlob.prototype.pause = function () {\n  if (!this.paused) {\n    this.paused = true\n    this.emit('pause')\n  }\n}\n\nGlob.prototype.resume = function () {\n  if (this.paused) {\n    this.emit('resume')\n    this.paused = false\n    if (this._emitQueue.length) {\n      var eq = this._emitQueue.slice(0)\n      this._emitQueue.length = 0\n      for (var i = 0; i < eq.length; i ++) {\n        var e = eq[i]\n        this._emitMatch(e[0], e[1])\n      }\n    }\n    if (this._processQueue.length) {\n      var pq = this._processQueue.slice(0)\n      this._processQueue.length = 0\n      for (var i = 0; i < pq.length; i ++) {\n        var p = pq[i]\n        this._processing--\n        this._process(p[0], p[1], p[2], p[3])\n      }\n    }\n  }\n}\n\nGlob.prototype._process = function (pattern, index, inGlobStar, cb) {\n  assert(this instanceof Glob)\n  assert(typeof cb === 'function')\n\n  if (this.aborted)\n    return\n\n  this._processing++\n  if (this.paused) {\n    this._processQueue.push([pattern, index, inGlobStar, cb])\n    return\n  }\n\n  //console.error('PROCESS %d', this._processing, pattern)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // see if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index, cb)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) ||\n      isAbsolute(pattern.map(function (p) {\n        return typeof p === 'string' ? p : '[*]'\n      }).join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip _processing\n  if (childrenIgnored(this, read))\n    return cb()\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar, cb)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar, cb)\n}\n\nGlob.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    return self._processReaddir2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\nGlob.prototype._processReaddir2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return cb()\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  //console.error('prd2', prefix, entries, remain[0]._glob, matchedEntries)\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return cb()\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return cb()\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix) {\n      if (prefix !== '/')\n        e = prefix + '/' + e\n      else\n        e = prefix + e\n    }\n    this._process([e].concat(remain), index, inGlobStar, cb)\n  }\n  cb()\n}\n\nGlob.prototype._emitMatch = function (index, e) {\n  if (this.aborted)\n    return\n\n  if (isIgnored(this, e))\n    return\n\n  if (this.paused) {\n    this._emitQueue.push([index, e])\n    return\n  }\n\n  var abs = isAbsolute(e) ? e : this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute)\n    e = abs\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  var st = this.statCache[abs]\n  if (st)\n    this.emit('stat', e, st)\n\n  this.emit('match', e)\n}\n\nGlob.prototype._readdirInGlobStar = function (abs, cb) {\n  if (this.aborted)\n    return\n\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false, cb)\n\n  var lstatkey = 'lstat\\0' + abs\n  var self = this\n  var lstatcb = inflight(lstatkey, lstatcb_)\n\n  if (lstatcb)\n    self.fs.lstat(abs, lstatcb)\n\n  function lstatcb_ (er, lstat) {\n    if (er && er.code === 'ENOENT')\n      return cb()\n\n    var isSym = lstat && lstat.isSymbolicLink()\n    self.symlinks[abs] = isSym\n\n    // If it's not a symlink or a dir, then it's definitely a regular file.\n    // don't bother doing a readdir in that case.\n    if (!isSym && lstat && !lstat.isDirectory()) {\n      self.cache[abs] = 'FILE'\n      cb()\n    } else\n      self._readdir(abs, false, cb)\n  }\n}\n\nGlob.prototype._readdir = function (abs, inGlobStar, cb) {\n  if (this.aborted)\n    return\n\n  cb = inflight('readdir\\0'+abs+'\\0'+inGlobStar, cb)\n  if (!cb)\n    return\n\n  //console.error('RD %j %j', +inGlobStar, abs)\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs, cb)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return cb()\n\n    if (Array.isArray(c))\n      return cb(null, c)\n  }\n\n  var self = this\n  self.fs.readdir(abs, readdirCb(this, abs, cb))\n}\n\nfunction readdirCb (self, abs, cb) {\n  return function (er, entries) {\n    if (er)\n      self._readdirError(abs, er, cb)\n    else\n      self._readdirEntries(abs, entries, cb)\n  }\n}\n\nGlob.prototype._readdirEntries = function (abs, entries, cb) {\n  if (this.aborted)\n    return\n\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n  return cb(null, entries)\n}\n\nGlob.prototype._readdirError = function (f, er, cb) {\n  if (this.aborted)\n    return\n\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        this.emit('error', error)\n        this.abort()\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict) {\n        this.emit('error', er)\n        // If the error is handled, then we abort\n        // if not, we threw out of here\n        this.abort()\n      }\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n\n  return cb()\n}\n\nGlob.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar, cb) {\n  var self = this\n  this._readdir(abs, inGlobStar, function (er, entries) {\n    self._processGlobStar2(prefix, read, abs, remain, index, inGlobStar, entries, cb)\n  })\n}\n\n\nGlob.prototype._processGlobStar2 = function (prefix, read, abs, remain, index, inGlobStar, entries, cb) {\n  //console.error('pgs2', prefix, remain[0], entries)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return cb()\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false, cb)\n\n  var isSym = this.symlinks[abs]\n  var len = entries.length\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return cb()\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true, cb)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true, cb)\n  }\n\n  cb()\n}\n\nGlob.prototype._processSimple = function (prefix, index, cb) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var self = this\n  this._stat(prefix, function (er, exists) {\n    self._processSimple2(prefix, index, er, exists, cb)\n  })\n}\nGlob.prototype._processSimple2 = function (prefix, index, er, exists, cb) {\n\n  //console.error('ps2', prefix, exists)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return cb()\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n  cb()\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlob.prototype._stat = function (f, cb) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return cb()\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return cb(null, c)\n\n    if (needDir && c === 'FILE')\n      return cb()\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (stat !== undefined) {\n    if (stat === false)\n      return cb(null, stat)\n    else {\n      var type = stat.isDirectory() ? 'DIR' : 'FILE'\n      if (needDir && type === 'FILE')\n        return cb()\n      else\n        return cb(null, type, stat)\n    }\n  }\n\n  var self = this\n  var statcb = inflight('stat\\0' + abs, lstatcb_)\n  if (statcb)\n    self.fs.lstat(abs, statcb)\n\n  function lstatcb_ (er, lstat) {\n    if (lstat && lstat.isSymbolicLink()) {\n      // If it's a symlink, then treat it as the target, unless\n      // the target does not exist, then treat it as a file.\n      return self.fs.stat(abs, function (er, stat) {\n        if (er)\n          self._stat2(f, abs, null, lstat, cb)\n        else\n          self._stat2(f, abs, er, stat, cb)\n      })\n    } else {\n      self._stat2(f, abs, er, lstat, cb)\n    }\n  }\n}\n\nGlob.prototype._stat2 = function (f, abs, er, stat, cb) {\n  if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n    this.statCache[abs] = false\n    return cb()\n  }\n\n  var needDir = f.slice(-1) === '/'\n  this.statCache[abs] = stat\n\n  if (abs.slice(-1) === '/' && stat && !stat.isDirectory())\n    return cb(null, false, stat)\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return cb()\n\n  return cb(null, c, stat)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/glob/glob.js?");

/***/ }),

/***/ "./node_modules/glob/sync.js":
/*!***********************************!*\
  !*** ./node_modules/glob/sync.js ***!
  \***********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = globSync\nglobSync.GlobSync = GlobSync\n\nvar rp = __webpack_require__(/*! fs.realpath */ \"./node_modules/fs.realpath/index.js\")\nvar minimatch = __webpack_require__(/*! minimatch */ \"./node_modules/minimatch/minimatch.js\")\nvar Minimatch = minimatch.Minimatch\nvar Glob = (__webpack_require__(/*! ./glob.js */ \"./node_modules/glob/glob.js\").Glob)\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\nvar path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nvar assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nvar isAbsolute = __webpack_require__(/*! path-is-absolute */ \"./node_modules/path-is-absolute/index.js\")\nvar common = __webpack_require__(/*! ./common.js */ \"./node_modules/glob/common.js\")\nvar setopts = common.setopts\nvar ownProp = common.ownProp\nvar childrenIgnored = common.childrenIgnored\nvar isIgnored = common.isIgnored\n\nfunction globSync (pattern, options) {\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  return new GlobSync(pattern, options).found\n}\n\nfunction GlobSync (pattern, options) {\n  if (!pattern)\n    throw new Error('must provide pattern')\n\n  if (typeof options === 'function' || arguments.length === 3)\n    throw new TypeError('callback provided to sync glob\\n'+\n                        'See: https://github.com/isaacs/node-glob/issues/167')\n\n  if (!(this instanceof GlobSync))\n    return new GlobSync(pattern, options)\n\n  setopts(this, pattern, options)\n\n  if (this.noprocess)\n    return this\n\n  var n = this.minimatch.set.length\n  this.matches = new Array(n)\n  for (var i = 0; i < n; i ++) {\n    this._process(this.minimatch.set[i], i, false)\n  }\n  this._finish()\n}\n\nGlobSync.prototype._finish = function () {\n  assert.ok(this instanceof GlobSync)\n  if (this.realpath) {\n    var self = this\n    this.matches.forEach(function (matchset, index) {\n      var set = self.matches[index] = Object.create(null)\n      for (var p in matchset) {\n        try {\n          p = self._makeAbs(p)\n          var real = rp.realpathSync(p, self.realpathCache)\n          set[real] = true\n        } catch (er) {\n          if (er.syscall === 'stat')\n            set[self._makeAbs(p)] = true\n          else\n            throw er\n        }\n      }\n    })\n  }\n  common.finish(this)\n}\n\n\nGlobSync.prototype._process = function (pattern, index, inGlobStar) {\n  assert.ok(this instanceof GlobSync)\n\n  // Get the first [n] parts of pattern that are all strings.\n  var n = 0\n  while (typeof pattern[n] === 'string') {\n    n ++\n  }\n  // now n is the index of the first one that is *not* a string.\n\n  // See if there's anything else\n  var prefix\n  switch (n) {\n    // if not, then this is rather simple\n    case pattern.length:\n      this._processSimple(pattern.join('/'), index)\n      return\n\n    case 0:\n      // pattern *starts* with some non-trivial item.\n      // going to readdir(cwd), but not include the prefix in matches.\n      prefix = null\n      break\n\n    default:\n      // pattern has some string bits in the front.\n      // whatever it starts with, whether that's 'absolute' like /foo/bar,\n      // or 'relative' like '../baz'\n      prefix = pattern.slice(0, n).join('/')\n      break\n  }\n\n  var remain = pattern.slice(n)\n\n  // get the list of entries.\n  var read\n  if (prefix === null)\n    read = '.'\n  else if (isAbsolute(prefix) ||\n      isAbsolute(pattern.map(function (p) {\n        return typeof p === 'string' ? p : '[*]'\n      }).join('/'))) {\n    if (!prefix || !isAbsolute(prefix))\n      prefix = '/' + prefix\n    read = prefix\n  } else\n    read = prefix\n\n  var abs = this._makeAbs(read)\n\n  //if ignored, skip processing\n  if (childrenIgnored(this, read))\n    return\n\n  var isGlobStar = remain[0] === minimatch.GLOBSTAR\n  if (isGlobStar)\n    this._processGlobStar(prefix, read, abs, remain, index, inGlobStar)\n  else\n    this._processReaddir(prefix, read, abs, remain, index, inGlobStar)\n}\n\n\nGlobSync.prototype._processReaddir = function (prefix, read, abs, remain, index, inGlobStar) {\n  var entries = this._readdir(abs, inGlobStar)\n\n  // if the abs isn't a dir, then nothing can match!\n  if (!entries)\n    return\n\n  // It will only match dot entries if it starts with a dot, or if\n  // dot is set.  Stuff like @(.foo|.bar) isn't allowed.\n  var pn = remain[0]\n  var negate = !!this.minimatch.negate\n  var rawGlob = pn._glob\n  var dotOk = this.dot || rawGlob.charAt(0) === '.'\n\n  var matchedEntries = []\n  for (var i = 0; i < entries.length; i++) {\n    var e = entries[i]\n    if (e.charAt(0) !== '.' || dotOk) {\n      var m\n      if (negate && !prefix) {\n        m = !e.match(pn)\n      } else {\n        m = e.match(pn)\n      }\n      if (m)\n        matchedEntries.push(e)\n    }\n  }\n\n  var len = matchedEntries.length\n  // If there are no matched entries, then nothing matches.\n  if (len === 0)\n    return\n\n  // if this is the last remaining pattern bit, then no need for\n  // an additional stat *unless* the user has specified mark or\n  // stat explicitly.  We know they exist, since readdir returned\n  // them.\n\n  if (remain.length === 1 && !this.mark && !this.stat) {\n    if (!this.matches[index])\n      this.matches[index] = Object.create(null)\n\n    for (var i = 0; i < len; i ++) {\n      var e = matchedEntries[i]\n      if (prefix) {\n        if (prefix.slice(-1) !== '/')\n          e = prefix + '/' + e\n        else\n          e = prefix + e\n      }\n\n      if (e.charAt(0) === '/' && !this.nomount) {\n        e = path.join(this.root, e)\n      }\n      this._emitMatch(index, e)\n    }\n    // This was the last one, and no stats were needed\n    return\n  }\n\n  // now test all matched entries as stand-ins for that part\n  // of the pattern.\n  remain.shift()\n  for (var i = 0; i < len; i ++) {\n    var e = matchedEntries[i]\n    var newPattern\n    if (prefix)\n      newPattern = [prefix, e]\n    else\n      newPattern = [e]\n    this._process(newPattern.concat(remain), index, inGlobStar)\n  }\n}\n\n\nGlobSync.prototype._emitMatch = function (index, e) {\n  if (isIgnored(this, e))\n    return\n\n  var abs = this._makeAbs(e)\n\n  if (this.mark)\n    e = this._mark(e)\n\n  if (this.absolute) {\n    e = abs\n  }\n\n  if (this.matches[index][e])\n    return\n\n  if (this.nodir) {\n    var c = this.cache[abs]\n    if (c === 'DIR' || Array.isArray(c))\n      return\n  }\n\n  this.matches[index][e] = true\n\n  if (this.stat)\n    this._stat(e)\n}\n\n\nGlobSync.prototype._readdirInGlobStar = function (abs) {\n  // follow all symlinked directories forever\n  // just proceed as if this is a non-globstar situation\n  if (this.follow)\n    return this._readdir(abs, false)\n\n  var entries\n  var lstat\n  var stat\n  try {\n    lstat = this.fs.lstatSync(abs)\n  } catch (er) {\n    if (er.code === 'ENOENT') {\n      // lstat failed, doesn't exist\n      return null\n    }\n  }\n\n  var isSym = lstat && lstat.isSymbolicLink()\n  this.symlinks[abs] = isSym\n\n  // If it's not a symlink or a dir, then it's definitely a regular file.\n  // don't bother doing a readdir in that case.\n  if (!isSym && lstat && !lstat.isDirectory())\n    this.cache[abs] = 'FILE'\n  else\n    entries = this._readdir(abs, false)\n\n  return entries\n}\n\nGlobSync.prototype._readdir = function (abs, inGlobStar) {\n  var entries\n\n  if (inGlobStar && !ownProp(this.symlinks, abs))\n    return this._readdirInGlobStar(abs)\n\n  if (ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n    if (!c || c === 'FILE')\n      return null\n\n    if (Array.isArray(c))\n      return c\n  }\n\n  try {\n    return this._readdirEntries(abs, this.fs.readdirSync(abs))\n  } catch (er) {\n    this._readdirError(abs, er)\n    return null\n  }\n}\n\nGlobSync.prototype._readdirEntries = function (abs, entries) {\n  // if we haven't asked to stat everything, then just\n  // assume that everything in there exists, so we can avoid\n  // having to stat it a second time.\n  if (!this.mark && !this.stat) {\n    for (var i = 0; i < entries.length; i ++) {\n      var e = entries[i]\n      if (abs === '/')\n        e = abs + e\n      else\n        e = abs + '/' + e\n      this.cache[e] = true\n    }\n  }\n\n  this.cache[abs] = entries\n\n  // mark and cache dir-ness\n  return entries\n}\n\nGlobSync.prototype._readdirError = function (f, er) {\n  // handle errors, and cache the information\n  switch (er.code) {\n    case 'ENOTSUP': // https://github.com/isaacs/node-glob/issues/205\n    case 'ENOTDIR': // totally normal. means it *does* exist.\n      var abs = this._makeAbs(f)\n      this.cache[abs] = 'FILE'\n      if (abs === this.cwdAbs) {\n        var error = new Error(er.code + ' invalid cwd ' + this.cwd)\n        error.path = this.cwd\n        error.code = er.code\n        throw error\n      }\n      break\n\n    case 'ENOENT': // not terribly unusual\n    case 'ELOOP':\n    case 'ENAMETOOLONG':\n    case 'UNKNOWN':\n      this.cache[this._makeAbs(f)] = false\n      break\n\n    default: // some unusual error.  Treat as failure.\n      this.cache[this._makeAbs(f)] = false\n      if (this.strict)\n        throw er\n      if (!this.silent)\n        console.error('glob error', er)\n      break\n  }\n}\n\nGlobSync.prototype._processGlobStar = function (prefix, read, abs, remain, index, inGlobStar) {\n\n  var entries = this._readdir(abs, inGlobStar)\n\n  // no entries means not a dir, so it can never have matches\n  // foo.txt/** doesn't match foo.txt\n  if (!entries)\n    return\n\n  // test without the globstar, and with every child both below\n  // and replacing the globstar.\n  var remainWithoutGlobStar = remain.slice(1)\n  var gspref = prefix ? [ prefix ] : []\n  var noGlobStar = gspref.concat(remainWithoutGlobStar)\n\n  // the noGlobStar pattern exits the inGlobStar state\n  this._process(noGlobStar, index, false)\n\n  var len = entries.length\n  var isSym = this.symlinks[abs]\n\n  // If it's a symlink, and we're in a globstar, then stop\n  if (isSym && inGlobStar)\n    return\n\n  for (var i = 0; i < len; i++) {\n    var e = entries[i]\n    if (e.charAt(0) === '.' && !this.dot)\n      continue\n\n    // these two cases enter the inGlobStar state\n    var instead = gspref.concat(entries[i], remainWithoutGlobStar)\n    this._process(instead, index, true)\n\n    var below = gspref.concat(entries[i], remain)\n    this._process(below, index, true)\n  }\n}\n\nGlobSync.prototype._processSimple = function (prefix, index) {\n  // XXX review this.  Shouldn't it be doing the mounting etc\n  // before doing stat?  kinda weird?\n  var exists = this._stat(prefix)\n\n  if (!this.matches[index])\n    this.matches[index] = Object.create(null)\n\n  // If it doesn't exist, then just mark the lack of results\n  if (!exists)\n    return\n\n  if (prefix && isAbsolute(prefix) && !this.nomount) {\n    var trail = /[\\/\\\\]$/.test(prefix)\n    if (prefix.charAt(0) === '/') {\n      prefix = path.join(this.root, prefix)\n    } else {\n      prefix = path.resolve(this.root, prefix)\n      if (trail)\n        prefix += '/'\n    }\n  }\n\n  if (process.platform === 'win32')\n    prefix = prefix.replace(/\\\\/g, '/')\n\n  // Mark this as a match\n  this._emitMatch(index, prefix)\n}\n\n// Returns either 'DIR', 'FILE', or false\nGlobSync.prototype._stat = function (f) {\n  var abs = this._makeAbs(f)\n  var needDir = f.slice(-1) === '/'\n\n  if (f.length > this.maxLength)\n    return false\n\n  if (!this.stat && ownProp(this.cache, abs)) {\n    var c = this.cache[abs]\n\n    if (Array.isArray(c))\n      c = 'DIR'\n\n    // It exists, but maybe not how we need it\n    if (!needDir || c === 'DIR')\n      return c\n\n    if (needDir && c === 'FILE')\n      return false\n\n    // otherwise we have to stat, because maybe c=true\n    // if we know it exists, but not what it is.\n  }\n\n  var exists\n  var stat = this.statCache[abs]\n  if (!stat) {\n    var lstat\n    try {\n      lstat = this.fs.lstatSync(abs)\n    } catch (er) {\n      if (er && (er.code === 'ENOENT' || er.code === 'ENOTDIR')) {\n        this.statCache[abs] = false\n        return false\n      }\n    }\n\n    if (lstat && lstat.isSymbolicLink()) {\n      try {\n        stat = this.fs.statSync(abs)\n      } catch (er) {\n        stat = lstat\n      }\n    } else {\n      stat = lstat\n    }\n  }\n\n  this.statCache[abs] = stat\n\n  var c = true\n  if (stat)\n    c = stat.isDirectory() ? 'DIR' : 'FILE'\n\n  this.cache[abs] = this.cache[abs] || c\n\n  if (needDir && c === 'FILE')\n    return false\n\n  return c\n}\n\nGlobSync.prototype._mark = function (p) {\n  return common.mark(this, p)\n}\n\nGlobSync.prototype._makeAbs = function (f) {\n  return common.makeAbs(this, f)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/glob/sync.js?");

/***/ }),

/***/ "./node_modules/gopd/index.js":
/*!************************************!*\
  !*** ./node_modules/gopd/index.js ***!
  \************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"./node_modules/get-intrinsic/index.js\");\n\nvar $gOPD = GetIntrinsic('%Object.getOwnPropertyDescriptor%', true);\n\nif ($gOPD) {\n\ttry {\n\t\t$gOPD([], 'length');\n\t} catch (e) {\n\t\t// IE 8 has a broken gOPD\n\t\t$gOPD = null;\n\t}\n}\n\nmodule.exports = $gOPD;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/gopd/index.js?");

/***/ }),

/***/ "./node_modules/has-property-descriptors/index.js":
/*!********************************************************!*\
  !*** ./node_modules/has-property-descriptors/index.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar $defineProperty = __webpack_require__(/*! es-define-property */ \"./node_modules/es-define-property/index.js\");\n\nvar hasPropertyDescriptors = function hasPropertyDescriptors() {\n\treturn !!$defineProperty;\n};\n\nhasPropertyDescriptors.hasArrayLengthDefineBug = function hasArrayLengthDefineBug() {\n\t// node v0.6 has a bug where array lengths can be Set but not Defined\n\tif (!$defineProperty) {\n\t\treturn null;\n\t}\n\ttry {\n\t\treturn $defineProperty([], 'length', { value: 1 }).length !== 1;\n\t} catch (e) {\n\t\t// In Firefox 4-22, defining length on an array throws an exception.\n\t\treturn true;\n\t}\n};\n\nmodule.exports = hasPropertyDescriptors;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/has-property-descriptors/index.js?");

/***/ }),

/***/ "./node_modules/has-proto/index.js":
/*!*****************************************!*\
  !*** ./node_modules/has-proto/index.js ***!
  \*****************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar test = {\n\t__proto__: null,\n\tfoo: {}\n};\n\nvar $Object = Object;\n\n/** @type {import('.')} */\nmodule.exports = function hasProto() {\n\t// @ts-expect-error: TS errors on an inherited property for some reason\n\treturn { __proto__: test }.foo === test.foo\n\t\t&& !(test instanceof $Object);\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/has-proto/index.js?");

/***/ }),

/***/ "./node_modules/has-symbols/index.js":
/*!*******************************************!*\
  !*** ./node_modules/has-symbols/index.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar origSymbol = typeof Symbol !== 'undefined' && Symbol;\nvar hasSymbolSham = __webpack_require__(/*! ./shams */ \"./node_modules/has-symbols/shams.js\");\n\nmodule.exports = function hasNativeSymbols() {\n\tif (typeof origSymbol !== 'function') { return false; }\n\tif (typeof Symbol !== 'function') { return false; }\n\tif (typeof origSymbol('foo') !== 'symbol') { return false; }\n\tif (typeof Symbol('bar') !== 'symbol') { return false; }\n\n\treturn hasSymbolSham();\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/has-symbols/index.js?");

/***/ }),

/***/ "./node_modules/has-symbols/shams.js":
/*!*******************************************!*\
  !*** ./node_modules/has-symbols/shams.js ***!
  \*******************************************/
/***/ ((module) => {

"use strict";
eval("\n\n/* eslint complexity: [2, 18], max-statements: [2, 33] */\nmodule.exports = function hasSymbols() {\n\tif (typeof Symbol !== 'function' || typeof Object.getOwnPropertySymbols !== 'function') { return false; }\n\tif (typeof Symbol.iterator === 'symbol') { return true; }\n\n\tvar obj = {};\n\tvar sym = Symbol('test');\n\tvar symObj = Object(sym);\n\tif (typeof sym === 'string') { return false; }\n\n\tif (Object.prototype.toString.call(sym) !== '[object Symbol]') { return false; }\n\tif (Object.prototype.toString.call(symObj) !== '[object Symbol]') { return false; }\n\n\t// temp disabled per https://github.com/ljharb/object.assign/issues/17\n\t// if (sym instanceof Symbol) { return false; }\n\t// temp disabled per https://github.com/WebReflection/get-own-property-symbols/issues/4\n\t// if (!(symObj instanceof Symbol)) { return false; }\n\n\t// if (typeof Symbol.prototype.toString !== 'function') { return false; }\n\t// if (String(sym) !== Symbol.prototype.toString.call(sym)) { return false; }\n\n\tvar symVal = 42;\n\tobj[sym] = symVal;\n\tfor (sym in obj) { return false; } // eslint-disable-line no-restricted-syntax, no-unreachable-loop\n\tif (typeof Object.keys === 'function' && Object.keys(obj).length !== 0) { return false; }\n\n\tif (typeof Object.getOwnPropertyNames === 'function' && Object.getOwnPropertyNames(obj).length !== 0) { return false; }\n\n\tvar syms = Object.getOwnPropertySymbols(obj);\n\tif (syms.length !== 1 || syms[0] !== sym) { return false; }\n\n\tif (!Object.prototype.propertyIsEnumerable.call(obj, sym)) { return false; }\n\n\tif (typeof Object.getOwnPropertyDescriptor === 'function') {\n\t\tvar descriptor = Object.getOwnPropertyDescriptor(obj, sym);\n\t\tif (descriptor.value !== symVal || descriptor.enumerable !== true) { return false; }\n\t}\n\n\treturn true;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/has-symbols/shams.js?");

/***/ }),

/***/ "./node_modules/has-unicode/index.js":
/*!*******************************************!*\
  !*** ./node_modules/has-unicode/index.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nvar os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\n\nvar hasUnicode = module.exports = function () {\n  // Recent Win32 platforms (>XP) CAN support unicode in the console but\n  // don't have to, and in non-english locales often use traditional local\n  // code pages. There's no way, short of windows system calls or execing\n  // the chcp command line program to figure this out. As such, we default\n  // this to false and encourage your users to override it via config if\n  // appropriate.\n  if (os.type() == \"Windows_NT\") { return false }\n\n  var isUTF8 = /UTF-?8$/i\n  var ctype = process.env.LC_ALL || process.env.LC_CTYPE || process.env.LANG\n  return isUTF8.test(ctype)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/has-unicode/index.js?");

/***/ }),

/***/ "./node_modules/hasown/index.js":
/*!**************************************!*\
  !*** ./node_modules/hasown/index.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar call = Function.prototype.call;\nvar $hasOwn = Object.prototype.hasOwnProperty;\nvar bind = __webpack_require__(/*! function-bind */ \"./node_modules/function-bind/index.js\");\n\n/** @type {import('.')} */\nmodule.exports = bind.call(call, $hasOwn);\n\n\n//# sourceURL=webpack://thelambda/./node_modules/hasown/index.js?");

/***/ }),

/***/ "./node_modules/https-proxy-agent/dist/agent.js":
/*!******************************************************!*\
  !*** ./node_modules/https-proxy-agent/dist/agent.js ***!
  \******************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst net_1 = __importDefault(__webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'net'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())));\nconst tls_1 = __importDefault(__webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'tls'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())));\nconst url_1 = __importDefault(__webpack_require__(/*! url */ \"./node_modules/url/url.js\"));\nconst assert_1 = __importDefault(__webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())));\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\"));\nconst agent_base_1 = __webpack_require__(/*! agent-base */ \"./node_modules/agent-base/dist/src/index.js\");\nconst parse_proxy_response_1 = __importDefault(__webpack_require__(/*! ./parse-proxy-response */ \"./node_modules/https-proxy-agent/dist/parse-proxy-response.js\"));\nconst debug = debug_1.default('https-proxy-agent:agent');\n/**\n * The `HttpsProxyAgent` implements an HTTP Agent subclass that connects to\n * the specified \"HTTP(s) proxy server\" in order to proxy HTTPS requests.\n *\n * Outgoing HTTP requests are first tunneled through the proxy server using the\n * `CONNECT` HTTP request method to establish a connection to the proxy server,\n * and then the proxy server connects to the destination target and issues the\n * HTTP request from the proxy server.\n *\n * `https:` requests have their socket connection upgraded to TLS once\n * the connection to the proxy server has been established.\n *\n * @api public\n */\nclass HttpsProxyAgent extends agent_base_1.Agent {\n    constructor(_opts) {\n        let opts;\n        if (typeof _opts === 'string') {\n            opts = url_1.default.parse(_opts);\n        }\n        else {\n            opts = _opts;\n        }\n        if (!opts) {\n            throw new Error('an HTTP(S) proxy server `host` and `port` must be specified!');\n        }\n        debug('creating new HttpsProxyAgent instance: %o', opts);\n        super(opts);\n        const proxy = Object.assign({}, opts);\n        // If `true`, then connect to the proxy server over TLS.\n        // Defaults to `false`.\n        this.secureProxy = opts.secureProxy || isHTTPS(proxy.protocol);\n        // Prefer `hostname` over `host`, and set the `port` if needed.\n        proxy.host = proxy.hostname || proxy.host;\n        if (typeof proxy.port === 'string') {\n            proxy.port = parseInt(proxy.port, 10);\n        }\n        if (!proxy.port && proxy.host) {\n            proxy.port = this.secureProxy ? 443 : 80;\n        }\n        // ALPN is supported by Node.js >= v5.\n        // attempt to negotiate http/1.1 for proxy servers that support http/2\n        if (this.secureProxy && !('ALPNProtocols' in proxy)) {\n            proxy.ALPNProtocols = ['http 1.1'];\n        }\n        if (proxy.host && proxy.path) {\n            // If both a `host` and `path` are specified then it's most likely\n            // the result of a `url.parse()` call... we need to remove the\n            // `path` portion so that `net.connect()` doesn't attempt to open\n            // that as a Unix socket file.\n            delete proxy.path;\n            delete proxy.pathname;\n        }\n        this.proxy = proxy;\n    }\n    /**\n     * Called when the node-core HTTP client library is creating a\n     * new HTTP request.\n     *\n     * @api protected\n     */\n    callback(req, opts) {\n        return __awaiter(this, void 0, void 0, function* () {\n            const { proxy, secureProxy } = this;\n            // Create a socket connection to the proxy server.\n            let socket;\n            if (secureProxy) {\n                debug('Creating `tls.Socket`: %o', proxy);\n                socket = tls_1.default.connect(proxy);\n            }\n            else {\n                debug('Creating `net.Socket`: %o', proxy);\n                socket = net_1.default.connect(proxy);\n            }\n            const headers = Object.assign({}, proxy.headers);\n            const hostname = `${opts.host}:${opts.port}`;\n            let payload = `CONNECT ${hostname} HTTP/1.1\\r\\n`;\n            // Inject the `Proxy-Authorization` header if necessary.\n            if (proxy.auth) {\n                headers['Proxy-Authorization'] = `Basic ${Buffer.from(proxy.auth).toString('base64')}`;\n            }\n            // The `Host` header should only include the port\n            // number when it is not the default port.\n            let { host, port, secureEndpoint } = opts;\n            if (!isDefaultPort(port, secureEndpoint)) {\n                host += `:${port}`;\n            }\n            headers.Host = host;\n            headers.Connection = 'close';\n            for (const name of Object.keys(headers)) {\n                payload += `${name}: ${headers[name]}\\r\\n`;\n            }\n            const proxyResponsePromise = parse_proxy_response_1.default(socket);\n            socket.write(`${payload}\\r\\n`);\n            const { statusCode, buffered } = yield proxyResponsePromise;\n            if (statusCode === 200) {\n                req.once('socket', resume);\n                if (opts.secureEndpoint) {\n                    // The proxy is connecting to a TLS server, so upgrade\n                    // this socket connection to a TLS connection.\n                    debug('Upgrading socket connection to TLS');\n                    const servername = opts.servername || opts.host;\n                    return tls_1.default.connect(Object.assign(Object.assign({}, omit(opts, 'host', 'hostname', 'path', 'port')), { socket,\n                        servername }));\n                }\n                return socket;\n            }\n            // Some other status code that's not 200... need to re-play the HTTP\n            // header \"data\" events onto the socket once the HTTP machinery is\n            // attached so that the node core `http` can parse and handle the\n            // error status code.\n            // Close the original socket, and a new \"fake\" socket is returned\n            // instead, so that the proxy doesn't get the HTTP request\n            // written to it (which may contain `Authorization` headers or other\n            // sensitive data).\n            //\n            // See: https://hackerone.com/reports/541502\n            socket.destroy();\n            const fakeSocket = new net_1.default.Socket({ writable: false });\n            fakeSocket.readable = true;\n            // Need to wait for the \"socket\" event to re-play the \"data\" events.\n            req.once('socket', (s) => {\n                debug('replaying proxy buffer for failed request');\n                assert_1.default(s.listenerCount('data') > 0);\n                // Replay the \"buffered\" Buffer onto the fake `socket`, since at\n                // this point the HTTP module machinery has been hooked up for\n                // the user.\n                s.push(buffered);\n                s.push(null);\n            });\n            return fakeSocket;\n        });\n    }\n}\nexports[\"default\"] = HttpsProxyAgent;\nfunction resume(socket) {\n    socket.resume();\n}\nfunction isDefaultPort(port, secure) {\n    return Boolean((!secure && port === 80) || (secure && port === 443));\n}\nfunction isHTTPS(protocol) {\n    return typeof protocol === 'string' ? /^https:?$/i.test(protocol) : false;\n}\nfunction omit(obj, ...keys) {\n    const ret = {};\n    let key;\n    for (key in obj) {\n        if (!keys.includes(key)) {\n            ret[key] = obj[key];\n        }\n    }\n    return ret;\n}\n//# sourceMappingURL=agent.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/https-proxy-agent/dist/agent.js?");

/***/ }),

/***/ "./node_modules/https-proxy-agent/dist/index.js":
/*!******************************************************!*\
  !*** ./node_modules/https-proxy-agent/dist/index.js ***!
  \******************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nconst agent_1 = __importDefault(__webpack_require__(/*! ./agent */ \"./node_modules/https-proxy-agent/dist/agent.js\"));\nfunction createHttpsProxyAgent(opts) {\n    return new agent_1.default(opts);\n}\n(function (createHttpsProxyAgent) {\n    createHttpsProxyAgent.HttpsProxyAgent = agent_1.default;\n    createHttpsProxyAgent.prototype = agent_1.default.prototype;\n})(createHttpsProxyAgent || (createHttpsProxyAgent = {}));\nmodule.exports = createHttpsProxyAgent;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/https-proxy-agent/dist/index.js?");

/***/ }),

/***/ "./node_modules/https-proxy-agent/dist/parse-proxy-response.js":
/*!*********************************************************************!*\
  !*** ./node_modules/https-proxy-agent/dist/parse-proxy-response.js ***!
  \*********************************************************************/
/***/ (function(__unused_webpack_module, exports, __webpack_require__) {

"use strict";
eval("\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst debug_1 = __importDefault(__webpack_require__(/*! debug */ \"./node_modules/debug/src/browser.js\"));\nconst debug = debug_1.default('https-proxy-agent:parse-proxy-response');\nfunction parseProxyResponse(socket) {\n    return new Promise((resolve, reject) => {\n        // we need to buffer any HTTP traffic that happens with the proxy before we get\n        // the CONNECT response, so that if the response is anything other than an \"200\"\n        // response code, then we can re-play the \"data\" events on the socket once the\n        // HTTP parser is hooked up...\n        let buffersLength = 0;\n        const buffers = [];\n        function read() {\n            const b = socket.read();\n            if (b)\n                ondata(b);\n            else\n                socket.once('readable', read);\n        }\n        function cleanup() {\n            socket.removeListener('end', onend);\n            socket.removeListener('error', onerror);\n            socket.removeListener('close', onclose);\n            socket.removeListener('readable', read);\n        }\n        function onclose(err) {\n            debug('onclose had error %o', err);\n        }\n        function onend() {\n            debug('onend');\n        }\n        function onerror(err) {\n            cleanup();\n            debug('onerror %o', err);\n            reject(err);\n        }\n        function ondata(b) {\n            buffers.push(b);\n            buffersLength += b.length;\n            const buffered = Buffer.concat(buffers, buffersLength);\n            const endOfHeaders = buffered.indexOf('\\r\\n\\r\\n');\n            if (endOfHeaders === -1) {\n                // keep buffering\n                debug('have not received end of HTTP headers yet...');\n                read();\n                return;\n            }\n            const firstLine = buffered.toString('ascii', 0, buffered.indexOf('\\r\\n'));\n            const statusCode = +firstLine.split(' ')[1];\n            debug('got proxy server response: %o', firstLine);\n            resolve({\n                statusCode,\n                buffered\n            });\n        }\n        socket.on('error', onerror);\n        socket.on('close', onclose);\n        socket.on('end', onend);\n        read();\n    });\n}\nexports[\"default\"] = parseProxyResponse;\n//# sourceMappingURL=parse-proxy-response.js.map\n\n//# sourceURL=webpack://thelambda/./node_modules/https-proxy-agent/dist/parse-proxy-response.js?");

/***/ }),

/***/ "./node_modules/inflight/inflight.js":
/*!*******************************************!*\
  !*** ./node_modules/inflight/inflight.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var wrappy = __webpack_require__(/*! wrappy */ \"./node_modules/wrappy/wrappy.js\")\nvar reqs = Object.create(null)\nvar once = __webpack_require__(/*! once */ \"./node_modules/once/once.js\")\n\nmodule.exports = wrappy(inflight)\n\nfunction inflight (key, cb) {\n  if (reqs[key]) {\n    reqs[key].push(cb)\n    return null\n  } else {\n    reqs[key] = [cb]\n    return makeres(key)\n  }\n}\n\nfunction makeres (key) {\n  return once(function RES () {\n    var cbs = reqs[key]\n    var len = cbs.length\n    var args = slice(arguments)\n\n    // XXX It's somewhat ambiguous whether a new callback added in this\n    // pass should be queued for later execution if something in the\n    // list of callbacks throws, or if it should just be discarded.\n    // However, it's such an edge case that it hardly matters, and either\n    // choice is likely as surprising as the other.\n    // As it happens, we do go ahead and schedule it for later execution.\n    try {\n      for (var i = 0; i < len; i++) {\n        cbs[i].apply(null, args)\n      }\n    } finally {\n      if (cbs.length > len) {\n        // added more in the interim.\n        // de-zalgo, just in case, but don't call again.\n        cbs.splice(0, len)\n        process.nextTick(function () {\n          RES.apply(null, args)\n        })\n      } else {\n        delete reqs[key]\n      }\n    }\n  })\n}\n\nfunction slice (args) {\n  var length = args.length\n  var array = []\n\n  for (var i = 0; i < length; i++) array[i] = args[i]\n  return array\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/inflight/inflight.js?");

/***/ }),

/***/ "./node_modules/inherits/inherits_browser.js":
/*!***************************************************!*\
  !*** ./node_modules/inherits/inherits_browser.js ***!
  \***************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "./node_modules/is-fullwidth-code-point/index.js":
/*!*******************************************************!*\
  !*** ./node_modules/is-fullwidth-code-point/index.js ***!
  \*******************************************************/
/***/ ((module) => {

"use strict";
eval("/* eslint-disable yoda */\n\n\nconst isFullwidthCodePoint = codePoint => {\n\tif (Number.isNaN(codePoint)) {\n\t\treturn false;\n\t}\n\n\t// Code points are derived from:\n\t// http://www.unix.org/Public/UNIDATA/EastAsianWidth.txt\n\tif (\n\t\tcodePoint >= 0x1100 && (\n\t\t\tcodePoint <= 0x115F || // Hangul Jamo\n\t\t\tcodePoint === 0x2329 || // LEFT-POINTING ANGLE BRACKET\n\t\t\tcodePoint === 0x232A || // RIGHT-POINTING ANGLE BRACKET\n\t\t\t// CJK Radicals Supplement .. Enclosed CJK Letters and Months\n\t\t\t(0x2E80 <= codePoint && codePoint <= 0x3247 && codePoint !== 0x303F) ||\n\t\t\t// Enclosed CJK Letters and Months .. CJK Unified Ideographs Extension A\n\t\t\t(0x3250 <= codePoint && codePoint <= 0x4DBF) ||\n\t\t\t// CJK Unified Ideographs .. Yi Radicals\n\t\t\t(0x4E00 <= codePoint && codePoint <= 0xA4C6) ||\n\t\t\t// Hangul Jamo Extended-A\n\t\t\t(0xA960 <= codePoint && codePoint <= 0xA97C) ||\n\t\t\t// Hangul Syllables\n\t\t\t(0xAC00 <= codePoint && codePoint <= 0xD7A3) ||\n\t\t\t// CJK Compatibility Ideographs\n\t\t\t(0xF900 <= codePoint && codePoint <= 0xFAFF) ||\n\t\t\t// Vertical Forms\n\t\t\t(0xFE10 <= codePoint && codePoint <= 0xFE19) ||\n\t\t\t// CJK Compatibility Forms .. Small Form Variants\n\t\t\t(0xFE30 <= codePoint && codePoint <= 0xFE6B) ||\n\t\t\t// Halfwidth and Fullwidth Forms\n\t\t\t(0xFF01 <= codePoint && codePoint <= 0xFF60) ||\n\t\t\t(0xFFE0 <= codePoint && codePoint <= 0xFFE6) ||\n\t\t\t// Kana Supplement\n\t\t\t(0x1B000 <= codePoint && codePoint <= 0x1B001) ||\n\t\t\t// Enclosed Ideographic Supplement\n\t\t\t(0x1F200 <= codePoint && codePoint <= 0x1F251) ||\n\t\t\t// CJK Unified Ideographs Extension B .. Tertiary Ideographic Plane\n\t\t\t(0x20000 <= codePoint && codePoint <= 0x3FFFD)\n\t\t)\n\t) {\n\t\treturn true;\n\t}\n\n\treturn false;\n};\n\nmodule.exports = isFullwidthCodePoint;\nmodule.exports[\"default\"] = isFullwidthCodePoint;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/is-fullwidth-code-point/index.js?");

/***/ }),

/***/ "./node_modules/make-dir/index.js":
/*!****************************************!*\
  !*** ./node_modules/make-dir/index.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst fs = __webpack_require__(/*! fs */ \"?f129\");\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\");\nconst {promisify} = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\nconst semver = __webpack_require__(/*! semver */ \"./node_modules/make-dir/node_modules/semver/semver.js\");\n\nconst useNativeRecursiveOption = semver.satisfies(process.version, '>=10.12.0');\n\n// https://github.com/nodejs/node/issues/8987\n// https://github.com/libuv/libuv/pull/1088\nconst checkPath = pth => {\n\tif (process.platform === 'win32') {\n\t\tconst pathHasInvalidWinCharacters = /[<>:\"|?*]/.test(pth.replace(path.parse(pth).root, ''));\n\n\t\tif (pathHasInvalidWinCharacters) {\n\t\t\tconst error = new Error(`Path contains invalid characters: ${pth}`);\n\t\t\terror.code = 'EINVAL';\n\t\t\tthrow error;\n\t\t}\n\t}\n};\n\nconst processOptions = options => {\n\t// https://github.com/sindresorhus/make-dir/issues/18\n\tconst defaults = {\n\t\tmode: 0o777,\n\t\tfs\n\t};\n\n\treturn {\n\t\t...defaults,\n\t\t...options\n\t};\n};\n\nconst permissionError = pth => {\n\t// This replicates the exception of `fs.mkdir` with native the\n\t// `recusive` option when run on an invalid drive under Windows.\n\tconst error = new Error(`operation not permitted, mkdir '${pth}'`);\n\terror.code = 'EPERM';\n\terror.errno = -4048;\n\terror.path = pth;\n\terror.syscall = 'mkdir';\n\treturn error;\n};\n\nconst makeDir = async (input, options) => {\n\tcheckPath(input);\n\toptions = processOptions(options);\n\n\tconst mkdir = promisify(options.fs.mkdir);\n\tconst stat = promisify(options.fs.stat);\n\n\tif (useNativeRecursiveOption && options.fs.mkdir === fs.mkdir) {\n\t\tconst pth = path.resolve(input);\n\n\t\tawait mkdir(pth, {\n\t\t\tmode: options.mode,\n\t\t\trecursive: true\n\t\t});\n\n\t\treturn pth;\n\t}\n\n\tconst make = async pth => {\n\t\ttry {\n\t\t\tawait mkdir(pth, options.mode);\n\n\t\t\treturn pth;\n\t\t} catch (error) {\n\t\t\tif (error.code === 'EPERM') {\n\t\t\t\tthrow error;\n\t\t\t}\n\n\t\t\tif (error.code === 'ENOENT') {\n\t\t\t\tif (path.dirname(pth) === pth) {\n\t\t\t\t\tthrow permissionError(pth);\n\t\t\t\t}\n\n\t\t\t\tif (error.message.includes('null bytes')) {\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\n\t\t\t\tawait make(path.dirname(pth));\n\n\t\t\t\treturn make(pth);\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tconst stats = await stat(pth);\n\t\t\t\tif (!stats.isDirectory()) {\n\t\t\t\t\tthrow new Error('The path is not a directory');\n\t\t\t\t}\n\t\t\t} catch (_) {\n\t\t\t\tthrow error;\n\t\t\t}\n\n\t\t\treturn pth;\n\t\t}\n\t};\n\n\treturn make(path.resolve(input));\n};\n\nmodule.exports = makeDir;\n\nmodule.exports.sync = (input, options) => {\n\tcheckPath(input);\n\toptions = processOptions(options);\n\n\tif (useNativeRecursiveOption && options.fs.mkdirSync === fs.mkdirSync) {\n\t\tconst pth = path.resolve(input);\n\n\t\tfs.mkdirSync(pth, {\n\t\t\tmode: options.mode,\n\t\t\trecursive: true\n\t\t});\n\n\t\treturn pth;\n\t}\n\n\tconst make = pth => {\n\t\ttry {\n\t\t\toptions.fs.mkdirSync(pth, options.mode);\n\t\t} catch (error) {\n\t\t\tif (error.code === 'EPERM') {\n\t\t\t\tthrow error;\n\t\t\t}\n\n\t\t\tif (error.code === 'ENOENT') {\n\t\t\t\tif (path.dirname(pth) === pth) {\n\t\t\t\t\tthrow permissionError(pth);\n\t\t\t\t}\n\n\t\t\t\tif (error.message.includes('null bytes')) {\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\n\t\t\t\tmake(path.dirname(pth));\n\t\t\t\treturn make(pth);\n\t\t\t}\n\n\t\t\ttry {\n\t\t\t\tif (!options.fs.statSync(pth).isDirectory()) {\n\t\t\t\t\tthrow new Error('The path is not a directory');\n\t\t\t\t}\n\t\t\t} catch (_) {\n\t\t\t\tthrow error;\n\t\t\t}\n\t\t}\n\n\t\treturn pth;\n\t};\n\n\treturn make(path.resolve(input));\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/make-dir/index.js?");

/***/ }),

/***/ "./node_modules/make-dir/node_modules/semver/semver.js":
/*!*************************************************************!*\
  !*** ./node_modules/make-dir/node_modules/semver/semver.js ***!
  \*************************************************************/
/***/ ((module, exports) => {

eval("exports = module.exports = SemVer\n\nvar debug\n/* istanbul ignore next */\nif (typeof process === 'object' &&\n    process.env &&\n    process.env.NODE_DEBUG &&\n    /\\bsemver\\b/i.test(process.env.NODE_DEBUG)) {\n  debug = function () {\n    var args = Array.prototype.slice.call(arguments, 0)\n    args.unshift('SEMVER')\n    console.log.apply(console, args)\n  }\n} else {\n  debug = function () {}\n}\n\n// Note: this is the semver.org version of the spec that it implements\n// Not necessarily the package version of this code.\nexports.SEMVER_SPEC_VERSION = '2.0.0'\n\nvar MAX_LENGTH = 256\nvar MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER ||\n  /* istanbul ignore next */ 9007199254740991\n\n// Max safe segment length for coercion.\nvar MAX_SAFE_COMPONENT_LENGTH = 16\n\nvar MAX_SAFE_BUILD_LENGTH = MAX_LENGTH - 6\n\n// The actual regexps go on exports.re\nvar re = exports.re = []\nvar safeRe = exports.safeRe = []\nvar src = exports.src = []\nvar t = exports.tokens = {}\nvar R = 0\n\nfunction tok (n) {\n  t[n] = R++\n}\n\nvar LETTERDASHNUMBER = '[a-zA-Z0-9-]'\n\n// Replace some greedy regex tokens to prevent regex dos issues. These regex are\n// used internally via the safeRe object since all inputs in this library get\n// normalized first to trim and collapse all extra whitespace. The original\n// regexes are exported for userland consumption and lower level usage. A\n// future breaking change could export the safer regex only with a note that\n// all input should have extra whitespace removed.\nvar safeRegexReplacements = [\n  ['\\\\s', 1],\n  ['\\\\d', MAX_LENGTH],\n  [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH],\n]\n\nfunction makeSafeRe (value) {\n  for (var i = 0; i < safeRegexReplacements.length; i++) {\n    var token = safeRegexReplacements[i][0]\n    var max = safeRegexReplacements[i][1]\n    value = value\n      .split(token + '*').join(token + '{0,' + max + '}')\n      .split(token + '+').join(token + '{1,' + max + '}')\n  }\n  return value\n}\n\n// The following Regular Expressions can be used for tokenizing,\n// validating, and parsing SemVer version strings.\n\n// ## Numeric Identifier\n// A single `0`, or a non-zero digit followed by zero or more digits.\n\ntok('NUMERICIDENTIFIER')\nsrc[t.NUMERICIDENTIFIER] = '0|[1-9]\\\\d*'\ntok('NUMERICIDENTIFIERLOOSE')\nsrc[t.NUMERICIDENTIFIERLOOSE] = '\\\\d+'\n\n// ## Non-numeric Identifier\n// Zero or more digits, followed by a letter or hyphen, and then zero or\n// more letters, digits, or hyphens.\n\ntok('NONNUMERICIDENTIFIER')\nsrc[t.NONNUMERICIDENTIFIER] = '\\\\d*[a-zA-Z-]' + LETTERDASHNUMBER + '*'\n\n// ## Main Version\n// Three dot-separated numeric identifiers.\n\ntok('MAINVERSION')\nsrc[t.MAINVERSION] = '(' + src[t.NUMERICIDENTIFIER] + ')\\\\.' +\n                   '(' + src[t.NUMERICIDENTIFIER] + ')\\\\.' +\n                   '(' + src[t.NUMERICIDENTIFIER] + ')'\n\ntok('MAINVERSIONLOOSE')\nsrc[t.MAINVERSIONLOOSE] = '(' + src[t.NUMERICIDENTIFIERLOOSE] + ')\\\\.' +\n                        '(' + src[t.NUMERICIDENTIFIERLOOSE] + ')\\\\.' +\n                        '(' + src[t.NUMERICIDENTIFIERLOOSE] + ')'\n\n// ## Pre-release Version Identifier\n// A numeric identifier, or a non-numeric identifier.\n\ntok('PRERELEASEIDENTIFIER')\nsrc[t.PRERELEASEIDENTIFIER] = '(?:' + src[t.NUMERICIDENTIFIER] +\n                            '|' + src[t.NONNUMERICIDENTIFIER] + ')'\n\ntok('PRERELEASEIDENTIFIERLOOSE')\nsrc[t.PRERELEASEIDENTIFIERLOOSE] = '(?:' + src[t.NUMERICIDENTIFIERLOOSE] +\n                                 '|' + src[t.NONNUMERICIDENTIFIER] + ')'\n\n// ## Pre-release Version\n// Hyphen, followed by one or more dot-separated pre-release version\n// identifiers.\n\ntok('PRERELEASE')\nsrc[t.PRERELEASE] = '(?:-(' + src[t.PRERELEASEIDENTIFIER] +\n                  '(?:\\\\.' + src[t.PRERELEASEIDENTIFIER] + ')*))'\n\ntok('PRERELEASELOOSE')\nsrc[t.PRERELEASELOOSE] = '(?:-?(' + src[t.PRERELEASEIDENTIFIERLOOSE] +\n                       '(?:\\\\.' + src[t.PRERELEASEIDENTIFIERLOOSE] + ')*))'\n\n// ## Build Metadata Identifier\n// Any combination of digits, letters, or hyphens.\n\ntok('BUILDIDENTIFIER')\nsrc[t.BUILDIDENTIFIER] = LETTERDASHNUMBER + '+'\n\n// ## Build Metadata\n// Plus sign, followed by one or more period-separated build metadata\n// identifiers.\n\ntok('BUILD')\nsrc[t.BUILD] = '(?:\\\\+(' + src[t.BUILDIDENTIFIER] +\n             '(?:\\\\.' + src[t.BUILDIDENTIFIER] + ')*))'\n\n// ## Full Version String\n// A main version, followed optionally by a pre-release version and\n// build metadata.\n\n// Note that the only major, minor, patch, and pre-release sections of\n// the version string are capturing groups.  The build metadata is not a\n// capturing group, because it should not ever be used in version\n// comparison.\n\ntok('FULL')\ntok('FULLPLAIN')\nsrc[t.FULLPLAIN] = 'v?' + src[t.MAINVERSION] +\n                  src[t.PRERELEASE] + '?' +\n                  src[t.BUILD] + '?'\n\nsrc[t.FULL] = '^' + src[t.FULLPLAIN] + '$'\n\n// like full, but allows v1.2.3 and =1.2.3, which people do sometimes.\n// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty\n// common in the npm registry.\ntok('LOOSEPLAIN')\nsrc[t.LOOSEPLAIN] = '[v=\\\\s]*' + src[t.MAINVERSIONLOOSE] +\n                  src[t.PRERELEASELOOSE] + '?' +\n                  src[t.BUILD] + '?'\n\ntok('LOOSE')\nsrc[t.LOOSE] = '^' + src[t.LOOSEPLAIN] + '$'\n\ntok('GTLT')\nsrc[t.GTLT] = '((?:<|>)?=?)'\n\n// Something like \"2.*\" or \"1.2.x\".\n// Note that \"x.x\" is a valid xRange identifer, meaning \"any version\"\n// Only the first item is strictly required.\ntok('XRANGEIDENTIFIERLOOSE')\nsrc[t.XRANGEIDENTIFIERLOOSE] = src[t.NUMERICIDENTIFIERLOOSE] + '|x|X|\\\\*'\ntok('XRANGEIDENTIFIER')\nsrc[t.XRANGEIDENTIFIER] = src[t.NUMERICIDENTIFIER] + '|x|X|\\\\*'\n\ntok('XRANGEPLAIN')\nsrc[t.XRANGEPLAIN] = '[v=\\\\s]*(' + src[t.XRANGEIDENTIFIER] + ')' +\n                   '(?:\\\\.(' + src[t.XRANGEIDENTIFIER] + ')' +\n                   '(?:\\\\.(' + src[t.XRANGEIDENTIFIER] + ')' +\n                   '(?:' + src[t.PRERELEASE] + ')?' +\n                   src[t.BUILD] + '?' +\n                   ')?)?'\n\ntok('XRANGEPLAINLOOSE')\nsrc[t.XRANGEPLAINLOOSE] = '[v=\\\\s]*(' + src[t.XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:\\\\.(' + src[t.XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:\\\\.(' + src[t.XRANGEIDENTIFIERLOOSE] + ')' +\n                        '(?:' + src[t.PRERELEASELOOSE] + ')?' +\n                        src[t.BUILD] + '?' +\n                        ')?)?'\n\ntok('XRANGE')\nsrc[t.XRANGE] = '^' + src[t.GTLT] + '\\\\s*' + src[t.XRANGEPLAIN] + '$'\ntok('XRANGELOOSE')\nsrc[t.XRANGELOOSE] = '^' + src[t.GTLT] + '\\\\s*' + src[t.XRANGEPLAINLOOSE] + '$'\n\n// Coercion.\n// Extract anything that could conceivably be a part of a valid semver\ntok('COERCE')\nsrc[t.COERCE] = '(^|[^\\\\d])' +\n              '(\\\\d{1,' + MAX_SAFE_COMPONENT_LENGTH + '})' +\n              '(?:\\\\.(\\\\d{1,' + MAX_SAFE_COMPONENT_LENGTH + '}))?' +\n              '(?:\\\\.(\\\\d{1,' + MAX_SAFE_COMPONENT_LENGTH + '}))?' +\n              '(?:$|[^\\\\d])'\ntok('COERCERTL')\nre[t.COERCERTL] = new RegExp(src[t.COERCE], 'g')\nsafeRe[t.COERCERTL] = new RegExp(makeSafeRe(src[t.COERCE]), 'g')\n\n// Tilde ranges.\n// Meaning is \"reasonably at or greater than\"\ntok('LONETILDE')\nsrc[t.LONETILDE] = '(?:~>?)'\n\ntok('TILDETRIM')\nsrc[t.TILDETRIM] = '(\\\\s*)' + src[t.LONETILDE] + '\\\\s+'\nre[t.TILDETRIM] = new RegExp(src[t.TILDETRIM], 'g')\nsafeRe[t.TILDETRIM] = new RegExp(makeSafeRe(src[t.TILDETRIM]), 'g')\nvar tildeTrimReplace = '$1~'\n\ntok('TILDE')\nsrc[t.TILDE] = '^' + src[t.LONETILDE] + src[t.XRANGEPLAIN] + '$'\ntok('TILDELOOSE')\nsrc[t.TILDELOOSE] = '^' + src[t.LONETILDE] + src[t.XRANGEPLAINLOOSE] + '$'\n\n// Caret ranges.\n// Meaning is \"at least and backwards compatible with\"\ntok('LONECARET')\nsrc[t.LONECARET] = '(?:\\\\^)'\n\ntok('CARETTRIM')\nsrc[t.CARETTRIM] = '(\\\\s*)' + src[t.LONECARET] + '\\\\s+'\nre[t.CARETTRIM] = new RegExp(src[t.CARETTRIM], 'g')\nsafeRe[t.CARETTRIM] = new RegExp(makeSafeRe(src[t.CARETTRIM]), 'g')\nvar caretTrimReplace = '$1^'\n\ntok('CARET')\nsrc[t.CARET] = '^' + src[t.LONECARET] + src[t.XRANGEPLAIN] + '$'\ntok('CARETLOOSE')\nsrc[t.CARETLOOSE] = '^' + src[t.LONECARET] + src[t.XRANGEPLAINLOOSE] + '$'\n\n// A simple gt/lt/eq thing, or just \"\" to indicate \"any version\"\ntok('COMPARATORLOOSE')\nsrc[t.COMPARATORLOOSE] = '^' + src[t.GTLT] + '\\\\s*(' + src[t.LOOSEPLAIN] + ')$|^$'\ntok('COMPARATOR')\nsrc[t.COMPARATOR] = '^' + src[t.GTLT] + '\\\\s*(' + src[t.FULLPLAIN] + ')$|^$'\n\n// An expression to strip any whitespace between the gtlt and the thing\n// it modifies, so that `> 1.2.3` ==> `>1.2.3`\ntok('COMPARATORTRIM')\nsrc[t.COMPARATORTRIM] = '(\\\\s*)' + src[t.GTLT] +\n                      '\\\\s*(' + src[t.LOOSEPLAIN] + '|' + src[t.XRANGEPLAIN] + ')'\n\n// this one has to use the /g flag\nre[t.COMPARATORTRIM] = new RegExp(src[t.COMPARATORTRIM], 'g')\nsafeRe[t.COMPARATORTRIM] = new RegExp(makeSafeRe(src[t.COMPARATORTRIM]), 'g')\nvar comparatorTrimReplace = '$1$2$3'\n\n// Something like `1.2.3 - 1.2.4`\n// Note that these all use the loose form, because they'll be\n// checked against either the strict or loose comparator form\n// later.\ntok('HYPHENRANGE')\nsrc[t.HYPHENRANGE] = '^\\\\s*(' + src[t.XRANGEPLAIN] + ')' +\n                   '\\\\s+-\\\\s+' +\n                   '(' + src[t.XRANGEPLAIN] + ')' +\n                   '\\\\s*$'\n\ntok('HYPHENRANGELOOSE')\nsrc[t.HYPHENRANGELOOSE] = '^\\\\s*(' + src[t.XRANGEPLAINLOOSE] + ')' +\n                        '\\\\s+-\\\\s+' +\n                        '(' + src[t.XRANGEPLAINLOOSE] + ')' +\n                        '\\\\s*$'\n\n// Star ranges basically just allow anything at all.\ntok('STAR')\nsrc[t.STAR] = '(<|>)?=?\\\\s*\\\\*'\n\n// Compile to actual regexp objects.\n// All are flag-free, unless they were created above with a flag.\nfor (var i = 0; i < R; i++) {\n  debug(i, src[i])\n  if (!re[i]) {\n    re[i] = new RegExp(src[i])\n\n    // Replace all greedy whitespace to prevent regex dos issues. These regex are\n    // used internally via the safeRe object since all inputs in this library get\n    // normalized first to trim and collapse all extra whitespace. The original\n    // regexes are exported for userland consumption and lower level usage. A\n    // future breaking change could export the safer regex only with a note that\n    // all input should have extra whitespace removed.\n    safeRe[i] = new RegExp(makeSafeRe(src[i]))\n  }\n}\n\nexports.parse = parse\nfunction parse (version, options) {\n  if (!options || typeof options !== 'object') {\n    options = {\n      loose: !!options,\n      includePrerelease: false\n    }\n  }\n\n  if (version instanceof SemVer) {\n    return version\n  }\n\n  if (typeof version !== 'string') {\n    return null\n  }\n\n  if (version.length > MAX_LENGTH) {\n    return null\n  }\n\n  var r = options.loose ? safeRe[t.LOOSE] : safeRe[t.FULL]\n  if (!r.test(version)) {\n    return null\n  }\n\n  try {\n    return new SemVer(version, options)\n  } catch (er) {\n    return null\n  }\n}\n\nexports.valid = valid\nfunction valid (version, options) {\n  var v = parse(version, options)\n  return v ? v.version : null\n}\n\nexports.clean = clean\nfunction clean (version, options) {\n  var s = parse(version.trim().replace(/^[=v]+/, ''), options)\n  return s ? s.version : null\n}\n\nexports.SemVer = SemVer\n\nfunction SemVer (version, options) {\n  if (!options || typeof options !== 'object') {\n    options = {\n      loose: !!options,\n      includePrerelease: false\n    }\n  }\n  if (version instanceof SemVer) {\n    if (version.loose === options.loose) {\n      return version\n    } else {\n      version = version.version\n    }\n  } else if (typeof version !== 'string') {\n    throw new TypeError('Invalid Version: ' + version)\n  }\n\n  if (version.length > MAX_LENGTH) {\n    throw new TypeError('version is longer than ' + MAX_LENGTH + ' characters')\n  }\n\n  if (!(this instanceof SemVer)) {\n    return new SemVer(version, options)\n  }\n\n  debug('SemVer', version, options)\n  this.options = options\n  this.loose = !!options.loose\n\n  var m = version.trim().match(options.loose ? safeRe[t.LOOSE] : safeRe[t.FULL])\n\n  if (!m) {\n    throw new TypeError('Invalid Version: ' + version)\n  }\n\n  this.raw = version\n\n  // these are actually numbers\n  this.major = +m[1]\n  this.minor = +m[2]\n  this.patch = +m[3]\n\n  if (this.major > MAX_SAFE_INTEGER || this.major < 0) {\n    throw new TypeError('Invalid major version')\n  }\n\n  if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {\n    throw new TypeError('Invalid minor version')\n  }\n\n  if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {\n    throw new TypeError('Invalid patch version')\n  }\n\n  // numberify any prerelease numeric ids\n  if (!m[4]) {\n    this.prerelease = []\n  } else {\n    this.prerelease = m[4].split('.').map(function (id) {\n      if (/^[0-9]+$/.test(id)) {\n        var num = +id\n        if (num >= 0 && num < MAX_SAFE_INTEGER) {\n          return num\n        }\n      }\n      return id\n    })\n  }\n\n  this.build = m[5] ? m[5].split('.') : []\n  this.format()\n}\n\nSemVer.prototype.format = function () {\n  this.version = this.major + '.' + this.minor + '.' + this.patch\n  if (this.prerelease.length) {\n    this.version += '-' + this.prerelease.join('.')\n  }\n  return this.version\n}\n\nSemVer.prototype.toString = function () {\n  return this.version\n}\n\nSemVer.prototype.compare = function (other) {\n  debug('SemVer.compare', this.version, this.options, other)\n  if (!(other instanceof SemVer)) {\n    other = new SemVer(other, this.options)\n  }\n\n  return this.compareMain(other) || this.comparePre(other)\n}\n\nSemVer.prototype.compareMain = function (other) {\n  if (!(other instanceof SemVer)) {\n    other = new SemVer(other, this.options)\n  }\n\n  return compareIdentifiers(this.major, other.major) ||\n         compareIdentifiers(this.minor, other.minor) ||\n         compareIdentifiers(this.patch, other.patch)\n}\n\nSemVer.prototype.comparePre = function (other) {\n  if (!(other instanceof SemVer)) {\n    other = new SemVer(other, this.options)\n  }\n\n  // NOT having a prerelease is > having one\n  if (this.prerelease.length && !other.prerelease.length) {\n    return -1\n  } else if (!this.prerelease.length && other.prerelease.length) {\n    return 1\n  } else if (!this.prerelease.length && !other.prerelease.length) {\n    return 0\n  }\n\n  var i = 0\n  do {\n    var a = this.prerelease[i]\n    var b = other.prerelease[i]\n    debug('prerelease compare', i, a, b)\n    if (a === undefined && b === undefined) {\n      return 0\n    } else if (b === undefined) {\n      return 1\n    } else if (a === undefined) {\n      return -1\n    } else if (a === b) {\n      continue\n    } else {\n      return compareIdentifiers(a, b)\n    }\n  } while (++i)\n}\n\nSemVer.prototype.compareBuild = function (other) {\n  if (!(other instanceof SemVer)) {\n    other = new SemVer(other, this.options)\n  }\n\n  var i = 0\n  do {\n    var a = this.build[i]\n    var b = other.build[i]\n    debug('prerelease compare', i, a, b)\n    if (a === undefined && b === undefined) {\n      return 0\n    } else if (b === undefined) {\n      return 1\n    } else if (a === undefined) {\n      return -1\n    } else if (a === b) {\n      continue\n    } else {\n      return compareIdentifiers(a, b)\n    }\n  } while (++i)\n}\n\n// preminor will bump the version up to the next minor release, and immediately\n// down to pre-release. premajor and prepatch work the same way.\nSemVer.prototype.inc = function (release, identifier) {\n  switch (release) {\n    case 'premajor':\n      this.prerelease.length = 0\n      this.patch = 0\n      this.minor = 0\n      this.major++\n      this.inc('pre', identifier)\n      break\n    case 'preminor':\n      this.prerelease.length = 0\n      this.patch = 0\n      this.minor++\n      this.inc('pre', identifier)\n      break\n    case 'prepatch':\n      // If this is already a prerelease, it will bump to the next version\n      // drop any prereleases that might already exist, since they are not\n      // relevant at this point.\n      this.prerelease.length = 0\n      this.inc('patch', identifier)\n      this.inc('pre', identifier)\n      break\n    // If the input is a non-prerelease version, this acts the same as\n    // prepatch.\n    case 'prerelease':\n      if (this.prerelease.length === 0) {\n        this.inc('patch', identifier)\n      }\n      this.inc('pre', identifier)\n      break\n\n    case 'major':\n      // If this is a pre-major version, bump up to the same major version.\n      // Otherwise increment major.\n      // 1.0.0-5 bumps to 1.0.0\n      // 1.1.0 bumps to 2.0.0\n      if (this.minor !== 0 ||\n          this.patch !== 0 ||\n          this.prerelease.length === 0) {\n        this.major++\n      }\n      this.minor = 0\n      this.patch = 0\n      this.prerelease = []\n      break\n    case 'minor':\n      // If this is a pre-minor version, bump up to the same minor version.\n      // Otherwise increment minor.\n      // 1.2.0-5 bumps to 1.2.0\n      // 1.2.1 bumps to 1.3.0\n      if (this.patch !== 0 || this.prerelease.length === 0) {\n        this.minor++\n      }\n      this.patch = 0\n      this.prerelease = []\n      break\n    case 'patch':\n      // If this is not a pre-release version, it will increment the patch.\n      // If it is a pre-release it will bump up to the same patch version.\n      // 1.2.0-5 patches to 1.2.0\n      // 1.2.0 patches to 1.2.1\n      if (this.prerelease.length === 0) {\n        this.patch++\n      }\n      this.prerelease = []\n      break\n    // This probably shouldn't be used publicly.\n    // 1.0.0 \"pre\" would become 1.0.0-0 which is the wrong direction.\n    case 'pre':\n      if (this.prerelease.length === 0) {\n        this.prerelease = [0]\n      } else {\n        var i = this.prerelease.length\n        while (--i >= 0) {\n          if (typeof this.prerelease[i] === 'number') {\n            this.prerelease[i]++\n            i = -2\n          }\n        }\n        if (i === -1) {\n          // didn't increment anything\n          this.prerelease.push(0)\n        }\n      }\n      if (identifier) {\n        // 1.2.0-beta.1 bumps to 1.2.0-beta.2,\n        // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0\n        if (this.prerelease[0] === identifier) {\n          if (isNaN(this.prerelease[1])) {\n            this.prerelease = [identifier, 0]\n          }\n        } else {\n          this.prerelease = [identifier, 0]\n        }\n      }\n      break\n\n    default:\n      throw new Error('invalid increment argument: ' + release)\n  }\n  this.format()\n  this.raw = this.version\n  return this\n}\n\nexports.inc = inc\nfunction inc (version, release, loose, identifier) {\n  if (typeof (loose) === 'string') {\n    identifier = loose\n    loose = undefined\n  }\n\n  try {\n    return new SemVer(version, loose).inc(release, identifier).version\n  } catch (er) {\n    return null\n  }\n}\n\nexports.diff = diff\nfunction diff (version1, version2) {\n  if (eq(version1, version2)) {\n    return null\n  } else {\n    var v1 = parse(version1)\n    var v2 = parse(version2)\n    var prefix = ''\n    if (v1.prerelease.length || v2.prerelease.length) {\n      prefix = 'pre'\n      var defaultResult = 'prerelease'\n    }\n    for (var key in v1) {\n      if (key === 'major' || key === 'minor' || key === 'patch') {\n        if (v1[key] !== v2[key]) {\n          return prefix + key\n        }\n      }\n    }\n    return defaultResult // may be undefined\n  }\n}\n\nexports.compareIdentifiers = compareIdentifiers\n\nvar numeric = /^[0-9]+$/\nfunction compareIdentifiers (a, b) {\n  var anum = numeric.test(a)\n  var bnum = numeric.test(b)\n\n  if (anum && bnum) {\n    a = +a\n    b = +b\n  }\n\n  return a === b ? 0\n    : (anum && !bnum) ? -1\n    : (bnum && !anum) ? 1\n    : a < b ? -1\n    : 1\n}\n\nexports.rcompareIdentifiers = rcompareIdentifiers\nfunction rcompareIdentifiers (a, b) {\n  return compareIdentifiers(b, a)\n}\n\nexports.major = major\nfunction major (a, loose) {\n  return new SemVer(a, loose).major\n}\n\nexports.minor = minor\nfunction minor (a, loose) {\n  return new SemVer(a, loose).minor\n}\n\nexports.patch = patch\nfunction patch (a, loose) {\n  return new SemVer(a, loose).patch\n}\n\nexports.compare = compare\nfunction compare (a, b, loose) {\n  return new SemVer(a, loose).compare(new SemVer(b, loose))\n}\n\nexports.compareLoose = compareLoose\nfunction compareLoose (a, b) {\n  return compare(a, b, true)\n}\n\nexports.compareBuild = compareBuild\nfunction compareBuild (a, b, loose) {\n  var versionA = new SemVer(a, loose)\n  var versionB = new SemVer(b, loose)\n  return versionA.compare(versionB) || versionA.compareBuild(versionB)\n}\n\nexports.rcompare = rcompare\nfunction rcompare (a, b, loose) {\n  return compare(b, a, loose)\n}\n\nexports.sort = sort\nfunction sort (list, loose) {\n  return list.sort(function (a, b) {\n    return exports.compareBuild(a, b, loose)\n  })\n}\n\nexports.rsort = rsort\nfunction rsort (list, loose) {\n  return list.sort(function (a, b) {\n    return exports.compareBuild(b, a, loose)\n  })\n}\n\nexports.gt = gt\nfunction gt (a, b, loose) {\n  return compare(a, b, loose) > 0\n}\n\nexports.lt = lt\nfunction lt (a, b, loose) {\n  return compare(a, b, loose) < 0\n}\n\nexports.eq = eq\nfunction eq (a, b, loose) {\n  return compare(a, b, loose) === 0\n}\n\nexports.neq = neq\nfunction neq (a, b, loose) {\n  return compare(a, b, loose) !== 0\n}\n\nexports.gte = gte\nfunction gte (a, b, loose) {\n  return compare(a, b, loose) >= 0\n}\n\nexports.lte = lte\nfunction lte (a, b, loose) {\n  return compare(a, b, loose) <= 0\n}\n\nexports.cmp = cmp\nfunction cmp (a, op, b, loose) {\n  switch (op) {\n    case '===':\n      if (typeof a === 'object')\n        a = a.version\n      if (typeof b === 'object')\n        b = b.version\n      return a === b\n\n    case '!==':\n      if (typeof a === 'object')\n        a = a.version\n      if (typeof b === 'object')\n        b = b.version\n      return a !== b\n\n    case '':\n    case '=':\n    case '==':\n      return eq(a, b, loose)\n\n    case '!=':\n      return neq(a, b, loose)\n\n    case '>':\n      return gt(a, b, loose)\n\n    case '>=':\n      return gte(a, b, loose)\n\n    case '<':\n      return lt(a, b, loose)\n\n    case '<=':\n      return lte(a, b, loose)\n\n    default:\n      throw new TypeError('Invalid operator: ' + op)\n  }\n}\n\nexports.Comparator = Comparator\nfunction Comparator (comp, options) {\n  if (!options || typeof options !== 'object') {\n    options = {\n      loose: !!options,\n      includePrerelease: false\n    }\n  }\n\n  if (comp instanceof Comparator) {\n    if (comp.loose === !!options.loose) {\n      return comp\n    } else {\n      comp = comp.value\n    }\n  }\n\n  if (!(this instanceof Comparator)) {\n    return new Comparator(comp, options)\n  }\n\n  comp = comp.trim().split(/\\s+/).join(' ')\n  debug('comparator', comp, options)\n  this.options = options\n  this.loose = !!options.loose\n  this.parse(comp)\n\n  if (this.semver === ANY) {\n    this.value = ''\n  } else {\n    this.value = this.operator + this.semver.version\n  }\n\n  debug('comp', this)\n}\n\nvar ANY = {}\nComparator.prototype.parse = function (comp) {\n  var r = this.options.loose ? safeRe[t.COMPARATORLOOSE] : safeRe[t.COMPARATOR]\n  var m = comp.match(r)\n\n  if (!m) {\n    throw new TypeError('Invalid comparator: ' + comp)\n  }\n\n  this.operator = m[1] !== undefined ? m[1] : ''\n  if (this.operator === '=') {\n    this.operator = ''\n  }\n\n  // if it literally is just '>' or '' then allow anything.\n  if (!m[2]) {\n    this.semver = ANY\n  } else {\n    this.semver = new SemVer(m[2], this.options.loose)\n  }\n}\n\nComparator.prototype.toString = function () {\n  return this.value\n}\n\nComparator.prototype.test = function (version) {\n  debug('Comparator.test', version, this.options.loose)\n\n  if (this.semver === ANY || version === ANY) {\n    return true\n  }\n\n  if (typeof version === 'string') {\n    try {\n      version = new SemVer(version, this.options)\n    } catch (er) {\n      return false\n    }\n  }\n\n  return cmp(version, this.operator, this.semver, this.options)\n}\n\nComparator.prototype.intersects = function (comp, options) {\n  if (!(comp instanceof Comparator)) {\n    throw new TypeError('a Comparator is required')\n  }\n\n  if (!options || typeof options !== 'object') {\n    options = {\n      loose: !!options,\n      includePrerelease: false\n    }\n  }\n\n  var rangeTmp\n\n  if (this.operator === '') {\n    if (this.value === '') {\n      return true\n    }\n    rangeTmp = new Range(comp.value, options)\n    return satisfies(this.value, rangeTmp, options)\n  } else if (comp.operator === '') {\n    if (comp.value === '') {\n      return true\n    }\n    rangeTmp = new Range(this.value, options)\n    return satisfies(comp.semver, rangeTmp, options)\n  }\n\n  var sameDirectionIncreasing =\n    (this.operator === '>=' || this.operator === '>') &&\n    (comp.operator === '>=' || comp.operator === '>')\n  var sameDirectionDecreasing =\n    (this.operator === '<=' || this.operator === '<') &&\n    (comp.operator === '<=' || comp.operator === '<')\n  var sameSemVer = this.semver.version === comp.semver.version\n  var differentDirectionsInclusive =\n    (this.operator === '>=' || this.operator === '<=') &&\n    (comp.operator === '>=' || comp.operator === '<=')\n  var oppositeDirectionsLessThan =\n    cmp(this.semver, '<', comp.semver, options) &&\n    ((this.operator === '>=' || this.operator === '>') &&\n    (comp.operator === '<=' || comp.operator === '<'))\n  var oppositeDirectionsGreaterThan =\n    cmp(this.semver, '>', comp.semver, options) &&\n    ((this.operator === '<=' || this.operator === '<') &&\n    (comp.operator === '>=' || comp.operator === '>'))\n\n  return sameDirectionIncreasing || sameDirectionDecreasing ||\n    (sameSemVer && differentDirectionsInclusive) ||\n    oppositeDirectionsLessThan || oppositeDirectionsGreaterThan\n}\n\nexports.Range = Range\nfunction Range (range, options) {\n  if (!options || typeof options !== 'object') {\n    options = {\n      loose: !!options,\n      includePrerelease: false\n    }\n  }\n\n  if (range instanceof Range) {\n    if (range.loose === !!options.loose &&\n        range.includePrerelease === !!options.includePrerelease) {\n      return range\n    } else {\n      return new Range(range.raw, options)\n    }\n  }\n\n  if (range instanceof Comparator) {\n    return new Range(range.value, options)\n  }\n\n  if (!(this instanceof Range)) {\n    return new Range(range, options)\n  }\n\n  this.options = options\n  this.loose = !!options.loose\n  this.includePrerelease = !!options.includePrerelease\n\n  // First reduce all whitespace as much as possible so we do not have to rely\n  // on potentially slow regexes like \\s*. This is then stored and used for\n  // future error messages as well.\n  this.raw = range\n    .trim()\n    .split(/\\s+/)\n    .join(' ')\n\n  // First, split based on boolean or ||\n  this.set = this.raw.split('||').map(function (range) {\n    return this.parseRange(range.trim())\n  }, this).filter(function (c) {\n    // throw out any that are not relevant for whatever reason\n    return c.length\n  })\n\n  if (!this.set.length) {\n    throw new TypeError('Invalid SemVer Range: ' + this.raw)\n  }\n\n  this.format()\n}\n\nRange.prototype.format = function () {\n  this.range = this.set.map(function (comps) {\n    return comps.join(' ').trim()\n  }).join('||').trim()\n  return this.range\n}\n\nRange.prototype.toString = function () {\n  return this.range\n}\n\nRange.prototype.parseRange = function (range) {\n  var loose = this.options.loose\n  // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`\n  var hr = loose ? safeRe[t.HYPHENRANGELOOSE] : safeRe[t.HYPHENRANGE]\n  range = range.replace(hr, hyphenReplace)\n  debug('hyphen replace', range)\n  // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`\n  range = range.replace(safeRe[t.COMPARATORTRIM], comparatorTrimReplace)\n  debug('comparator trim', range, safeRe[t.COMPARATORTRIM])\n\n  // `~ 1.2.3` => `~1.2.3`\n  range = range.replace(safeRe[t.TILDETRIM], tildeTrimReplace)\n\n  // `^ 1.2.3` => `^1.2.3`\n  range = range.replace(safeRe[t.CARETTRIM], caretTrimReplace)\n\n  // normalize spaces\n  range = range.split(/\\s+/).join(' ')\n\n  // At this point, the range is completely trimmed and\n  // ready to be split into comparators.\n\n  var compRe = loose ? safeRe[t.COMPARATORLOOSE] : safeRe[t.COMPARATOR]\n  var set = range.split(' ').map(function (comp) {\n    return parseComparator(comp, this.options)\n  }, this).join(' ').split(/\\s+/)\n  if (this.options.loose) {\n    // in loose mode, throw out any that are not valid comparators\n    set = set.filter(function (comp) {\n      return !!comp.match(compRe)\n    })\n  }\n  set = set.map(function (comp) {\n    return new Comparator(comp, this.options)\n  }, this)\n\n  return set\n}\n\nRange.prototype.intersects = function (range, options) {\n  if (!(range instanceof Range)) {\n    throw new TypeError('a Range is required')\n  }\n\n  return this.set.some(function (thisComparators) {\n    return (\n      isSatisfiable(thisComparators, options) &&\n      range.set.some(function (rangeComparators) {\n        return (\n          isSatisfiable(rangeComparators, options) &&\n          thisComparators.every(function (thisComparator) {\n            return rangeComparators.every(function (rangeComparator) {\n              return thisComparator.intersects(rangeComparator, options)\n            })\n          })\n        )\n      })\n    )\n  })\n}\n\n// take a set of comparators and determine whether there\n// exists a version which can satisfy it\nfunction isSatisfiable (comparators, options) {\n  var result = true\n  var remainingComparators = comparators.slice()\n  var testComparator = remainingComparators.pop()\n\n  while (result && remainingComparators.length) {\n    result = remainingComparators.every(function (otherComparator) {\n      return testComparator.intersects(otherComparator, options)\n    })\n\n    testComparator = remainingComparators.pop()\n  }\n\n  return result\n}\n\n// Mostly just for testing and legacy API reasons\nexports.toComparators = toComparators\nfunction toComparators (range, options) {\n  return new Range(range, options).set.map(function (comp) {\n    return comp.map(function (c) {\n      return c.value\n    }).join(' ').trim().split(' ')\n  })\n}\n\n// comprised of xranges, tildes, stars, and gtlt's at this point.\n// already replaced the hyphen ranges\n// turn into a set of JUST comparators.\nfunction parseComparator (comp, options) {\n  debug('comp', comp, options)\n  comp = replaceCarets(comp, options)\n  debug('caret', comp)\n  comp = replaceTildes(comp, options)\n  debug('tildes', comp)\n  comp = replaceXRanges(comp, options)\n  debug('xrange', comp)\n  comp = replaceStars(comp, options)\n  debug('stars', comp)\n  return comp\n}\n\nfunction isX (id) {\n  return !id || id.toLowerCase() === 'x' || id === '*'\n}\n\n// ~, ~> --> * (any, kinda silly)\n// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0\n// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0\n// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0\n// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0\n// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0\nfunction replaceTildes (comp, options) {\n  return comp.trim().split(/\\s+/).map(function (comp) {\n    return replaceTilde(comp, options)\n  }).join(' ')\n}\n\nfunction replaceTilde (comp, options) {\n  var r = options.loose ? safeRe[t.TILDELOOSE] : safeRe[t.TILDE]\n  return comp.replace(r, function (_, M, m, p, pr) {\n    debug('tilde', comp, _, M, m, p, pr)\n    var ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0'\n    } else if (isX(p)) {\n      // ~1.2 == >=1.2.0 <1.3.0\n      ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0'\n    } else if (pr) {\n      debug('replaceTilde pr', pr)\n      ret = '>=' + M + '.' + m + '.' + p + '-' + pr +\n            ' <' + M + '.' + (+m + 1) + '.0'\n    } else {\n      // ~1.2.3 == >=1.2.3 <1.3.0\n      ret = '>=' + M + '.' + m + '.' + p +\n            ' <' + M + '.' + (+m + 1) + '.0'\n    }\n\n    debug('tilde return', ret)\n    return ret\n  })\n}\n\n// ^ --> * (any, kinda silly)\n// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0\n// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0\n// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0\n// ^1.2.3 --> >=1.2.3 <2.0.0\n// ^1.2.0 --> >=1.2.0 <2.0.0\nfunction replaceCarets (comp, options) {\n  return comp.trim().split(/\\s+/).map(function (comp) {\n    return replaceCaret(comp, options)\n  }).join(' ')\n}\n\nfunction replaceCaret (comp, options) {\n  debug('caret', comp, options)\n  var r = options.loose ? safeRe[t.CARETLOOSE] : safeRe[t.CARET]\n  return comp.replace(r, function (_, M, m, p, pr) {\n    debug('caret', comp, _, M, m, p, pr)\n    var ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = '>=' + M + '.0.0 <' + (+M + 1) + '.0.0'\n    } else if (isX(p)) {\n      if (M === '0') {\n        ret = '>=' + M + '.' + m + '.0 <' + M + '.' + (+m + 1) + '.0'\n      } else {\n        ret = '>=' + M + '.' + m + '.0 <' + (+M + 1) + '.0.0'\n      }\n    } else if (pr) {\n      debug('replaceCaret pr', pr)\n      if (M === '0') {\n        if (m === '0') {\n          ret = '>=' + M + '.' + m + '.' + p + '-' + pr +\n                ' <' + M + '.' + m + '.' + (+p + 1)\n        } else {\n          ret = '>=' + M + '.' + m + '.' + p + '-' + pr +\n                ' <' + M + '.' + (+m + 1) + '.0'\n        }\n      } else {\n        ret = '>=' + M + '.' + m + '.' + p + '-' + pr +\n              ' <' + (+M + 1) + '.0.0'\n      }\n    } else {\n      debug('no pr')\n      if (M === '0') {\n        if (m === '0') {\n          ret = '>=' + M + '.' + m + '.' + p +\n                ' <' + M + '.' + m + '.' + (+p + 1)\n        } else {\n          ret = '>=' + M + '.' + m + '.' + p +\n                ' <' + M + '.' + (+m + 1) + '.0'\n        }\n      } else {\n        ret = '>=' + M + '.' + m + '.' + p +\n              ' <' + (+M + 1) + '.0.0'\n      }\n    }\n\n    debug('caret return', ret)\n    return ret\n  })\n}\n\nfunction replaceXRanges (comp, options) {\n  debug('replaceXRanges', comp, options)\n  return comp.split(/\\s+/).map(function (comp) {\n    return replaceXRange(comp, options)\n  }).join(' ')\n}\n\nfunction replaceXRange (comp, options) {\n  comp = comp.trim()\n  var r = options.loose ? safeRe[t.XRANGELOOSE] : safeRe[t.XRANGE]\n  return comp.replace(r, function (ret, gtlt, M, m, p, pr) {\n    debug('xRange', comp, ret, gtlt, M, m, p, pr)\n    var xM = isX(M)\n    var xm = xM || isX(m)\n    var xp = xm || isX(p)\n    var anyX = xp\n\n    if (gtlt === '=' && anyX) {\n      gtlt = ''\n    }\n\n    // if we're including prereleases in the match, then we need\n    // to fix this to -0, the lowest possible prerelease value\n    pr = options.includePrerelease ? '-0' : ''\n\n    if (xM) {\n      if (gtlt === '>' || gtlt === '<') {\n        // nothing is allowed\n        ret = '<0.0.0-0'\n      } else {\n        // nothing is forbidden\n        ret = '*'\n      }\n    } else if (gtlt && anyX) {\n      // we know patch is an x, because we have any x at all.\n      // replace X with 0\n      if (xm) {\n        m = 0\n      }\n      p = 0\n\n      if (gtlt === '>') {\n        // >1 => >=2.0.0\n        // >1.2 => >=1.3.0\n        // >1.2.3 => >= 1.2.4\n        gtlt = '>='\n        if (xm) {\n          M = +M + 1\n          m = 0\n          p = 0\n        } else {\n          m = +m + 1\n          p = 0\n        }\n      } else if (gtlt === '<=') {\n        // <=0.7.x is actually <0.8.0, since any 0.7.x should\n        // pass.  Similarly, <=7.x is actually <8.0.0, etc.\n        gtlt = '<'\n        if (xm) {\n          M = +M + 1\n        } else {\n          m = +m + 1\n        }\n      }\n\n      ret = gtlt + M + '.' + m + '.' + p + pr\n    } else if (xm) {\n      ret = '>=' + M + '.0.0' + pr + ' <' + (+M + 1) + '.0.0' + pr\n    } else if (xp) {\n      ret = '>=' + M + '.' + m + '.0' + pr +\n        ' <' + M + '.' + (+m + 1) + '.0' + pr\n    }\n\n    debug('xRange return', ret)\n\n    return ret\n  })\n}\n\n// Because * is AND-ed with everything else in the comparator,\n// and '' means \"any version\", just remove the *s entirely.\nfunction replaceStars (comp, options) {\n  debug('replaceStars', comp, options)\n  // Looseness is ignored here.  star is always as loose as it gets!\n  return comp.trim().replace(safeRe[t.STAR], '')\n}\n\n// This function is passed to string.replace(re[t.HYPHENRANGE])\n// M, m, patch, prerelease, build\n// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5\n// 1.2.3 - 3.4 => >=1.2.0 <3.5.0 Any 3.4.x will do\n// 1.2 - 3.4 => >=1.2.0 <3.5.0\nfunction hyphenReplace ($0,\n  from, fM, fm, fp, fpr, fb,\n  to, tM, tm, tp, tpr, tb) {\n  if (isX(fM)) {\n    from = ''\n  } else if (isX(fm)) {\n    from = '>=' + fM + '.0.0'\n  } else if (isX(fp)) {\n    from = '>=' + fM + '.' + fm + '.0'\n  } else {\n    from = '>=' + from\n  }\n\n  if (isX(tM)) {\n    to = ''\n  } else if (isX(tm)) {\n    to = '<' + (+tM + 1) + '.0.0'\n  } else if (isX(tp)) {\n    to = '<' + tM + '.' + (+tm + 1) + '.0'\n  } else if (tpr) {\n    to = '<=' + tM + '.' + tm + '.' + tp + '-' + tpr\n  } else {\n    to = '<=' + to\n  }\n\n  return (from + ' ' + to).trim()\n}\n\n// if ANY of the sets match ALL of its comparators, then pass\nRange.prototype.test = function (version) {\n  if (!version) {\n    return false\n  }\n\n  if (typeof version === 'string') {\n    try {\n      version = new SemVer(version, this.options)\n    } catch (er) {\n      return false\n    }\n  }\n\n  for (var i = 0; i < this.set.length; i++) {\n    if (testSet(this.set[i], version, this.options)) {\n      return true\n    }\n  }\n  return false\n}\n\nfunction testSet (set, version, options) {\n  for (var i = 0; i < set.length; i++) {\n    if (!set[i].test(version)) {\n      return false\n    }\n  }\n\n  if (version.prerelease.length && !options.includePrerelease) {\n    // Find the set of versions that are allowed to have prereleases\n    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0\n    // That should allow `1.2.3-pr.2` to pass.\n    // However, `1.2.4-alpha.notready` should NOT be allowed,\n    // even though it's within the range set by the comparators.\n    for (i = 0; i < set.length; i++) {\n      debug(set[i].semver)\n      if (set[i].semver === ANY) {\n        continue\n      }\n\n      if (set[i].semver.prerelease.length > 0) {\n        var allowed = set[i].semver\n        if (allowed.major === version.major &&\n            allowed.minor === version.minor &&\n            allowed.patch === version.patch) {\n          return true\n        }\n      }\n    }\n\n    // Version has a -pre, but it's not one of the ones we like.\n    return false\n  }\n\n  return true\n}\n\nexports.satisfies = satisfies\nfunction satisfies (version, range, options) {\n  try {\n    range = new Range(range, options)\n  } catch (er) {\n    return false\n  }\n  return range.test(version)\n}\n\nexports.maxSatisfying = maxSatisfying\nfunction maxSatisfying (versions, range, options) {\n  var max = null\n  var maxSV = null\n  try {\n    var rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach(function (v) {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!max || maxSV.compare(v) === -1) {\n        // compare(max, v, true)\n        max = v\n        maxSV = new SemVer(max, options)\n      }\n    }\n  })\n  return max\n}\n\nexports.minSatisfying = minSatisfying\nfunction minSatisfying (versions, range, options) {\n  var min = null\n  var minSV = null\n  try {\n    var rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach(function (v) {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!min || minSV.compare(v) === 1) {\n        // compare(min, v, true)\n        min = v\n        minSV = new SemVer(min, options)\n      }\n    }\n  })\n  return min\n}\n\nexports.minVersion = minVersion\nfunction minVersion (range, loose) {\n  range = new Range(range, loose)\n\n  var minver = new SemVer('0.0.0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = new SemVer('0.0.0-0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = null\n  for (var i = 0; i < range.set.length; ++i) {\n    var comparators = range.set[i]\n\n    comparators.forEach(function (comparator) {\n      // Clone to avoid manipulating the comparator's semver object.\n      var compver = new SemVer(comparator.semver.version)\n      switch (comparator.operator) {\n        case '>':\n          if (compver.prerelease.length === 0) {\n            compver.patch++\n          } else {\n            compver.prerelease.push(0)\n          }\n          compver.raw = compver.format()\n          /* fallthrough */\n        case '':\n        case '>=':\n          if (!minver || gt(minver, compver)) {\n            minver = compver\n          }\n          break\n        case '<':\n        case '<=':\n          /* Ignore maximum versions */\n          break\n        /* istanbul ignore next */\n        default:\n          throw new Error('Unexpected operation: ' + comparator.operator)\n      }\n    })\n  }\n\n  if (minver && range.test(minver)) {\n    return minver\n  }\n\n  return null\n}\n\nexports.validRange = validRange\nfunction validRange (range, options) {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return new Range(range, options).range || '*'\n  } catch (er) {\n    return null\n  }\n}\n\n// Determine if version is less than all the versions possible in the range\nexports.ltr = ltr\nfunction ltr (version, range, options) {\n  return outside(version, range, '<', options)\n}\n\n// Determine if version is greater than all the versions possible in the range.\nexports.gtr = gtr\nfunction gtr (version, range, options) {\n  return outside(version, range, '>', options)\n}\n\nexports.outside = outside\nfunction outside (version, range, hilo, options) {\n  version = new SemVer(version, options)\n  range = new Range(range, options)\n\n  var gtfn, ltefn, ltfn, comp, ecomp\n  switch (hilo) {\n    case '>':\n      gtfn = gt\n      ltefn = lte\n      ltfn = lt\n      comp = '>'\n      ecomp = '>='\n      break\n    case '<':\n      gtfn = lt\n      ltefn = gte\n      ltfn = gt\n      comp = '<'\n      ecomp = '<='\n      break\n    default:\n      throw new TypeError('Must provide a hilo val of \"<\" or \">\"')\n  }\n\n  // If it satisifes the range it is not outside\n  if (satisfies(version, range, options)) {\n    return false\n  }\n\n  // From now on, variable terms are as if we're in \"gtr\" mode.\n  // but note that everything is flipped for the \"ltr\" function.\n\n  for (var i = 0; i < range.set.length; ++i) {\n    var comparators = range.set[i]\n\n    var high = null\n    var low = null\n\n    comparators.forEach(function (comparator) {\n      if (comparator.semver === ANY) {\n        comparator = new Comparator('>=0.0.0')\n      }\n      high = high || comparator\n      low = low || comparator\n      if (gtfn(comparator.semver, high.semver, options)) {\n        high = comparator\n      } else if (ltfn(comparator.semver, low.semver, options)) {\n        low = comparator\n      }\n    })\n\n    // If the edge version comparator has a operator then our version\n    // isn't outside it\n    if (high.operator === comp || high.operator === ecomp) {\n      return false\n    }\n\n    // If the lowest version comparator has an operator and our version\n    // is less than it then it isn't higher than the range\n    if ((!low.operator || low.operator === comp) &&\n        ltefn(version, low.semver)) {\n      return false\n    } else if (low.operator === ecomp && ltfn(version, low.semver)) {\n      return false\n    }\n  }\n  return true\n}\n\nexports.prerelease = prerelease\nfunction prerelease (version, options) {\n  var parsed = parse(version, options)\n  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null\n}\n\nexports.intersects = intersects\nfunction intersects (r1, r2, options) {\n  r1 = new Range(r1, options)\n  r2 = new Range(r2, options)\n  return r1.intersects(r2)\n}\n\nexports.coerce = coerce\nfunction coerce (version, options) {\n  if (version instanceof SemVer) {\n    return version\n  }\n\n  if (typeof version === 'number') {\n    version = String(version)\n  }\n\n  if (typeof version !== 'string') {\n    return null\n  }\n\n  options = options || {}\n\n  var match = null\n  if (!options.rtl) {\n    match = version.match(safeRe[t.COERCE])\n  } else {\n    // Find the right-most coercible string that does not share\n    // a terminus with a more left-ward coercible string.\n    // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'\n    //\n    // Walk through the string checking with a /g regexp\n    // Manually set the index so as to pick up overlapping matches.\n    // Stop when we get a match that ends at the string end, since no\n    // coercible string can be more right-ward without the same terminus.\n    var next\n    while ((next = safeRe[t.COERCERTL].exec(version)) &&\n      (!match || match.index + match[0].length !== version.length)\n    ) {\n      if (!match ||\n          next.index + next[0].length !== match.index + match[0].length) {\n        match = next\n      }\n      safeRe[t.COERCERTL].lastIndex = next.index + next[1].length + next[2].length\n    }\n    // leave it in a clean state\n    safeRe[t.COERCERTL].lastIndex = -1\n  }\n\n  if (match === null) {\n    return null\n  }\n\n  return parse(match[2] +\n    '.' + (match[3] || '0') +\n    '.' + (match[4] || '0'), options)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/make-dir/node_modules/semver/semver.js?");

/***/ }),

/***/ "./node_modules/minimatch/minimatch.js":
/*!*********************************************!*\
  !*** ./node_modules/minimatch/minimatch.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = minimatch\nminimatch.Minimatch = Minimatch\n\nvar path = (function () { try { return __webpack_require__(/*! path */ \"./node_modules/path/path.js\") } catch (e) {}}()) || {\n  sep: '/'\n}\nminimatch.sep = path.sep\n\nvar GLOBSTAR = minimatch.GLOBSTAR = Minimatch.GLOBSTAR = {}\nvar expand = __webpack_require__(/*! brace-expansion */ \"./node_modules/brace-expansion/index.js\")\n\nvar plTypes = {\n  '!': { open: '(?:(?!(?:', close: '))[^/]*?)'},\n  '?': { open: '(?:', close: ')?' },\n  '+': { open: '(?:', close: ')+' },\n  '*': { open: '(?:', close: ')*' },\n  '@': { open: '(?:', close: ')' }\n}\n\n// any single thing other than /\n// don't need to escape / when using new RegExp()\nvar qmark = '[^/]'\n\n// * => any number of characters\nvar star = qmark + '*?'\n\n// ** when dots are allowed.  Anything goes, except .. and .\n// not (^ or / followed by one or two dots followed by $ or /),\n// followed by anything, any number of times.\nvar twoStarDot = '(?:(?!(?:\\\\\\/|^)(?:\\\\.{1,2})($|\\\\\\/)).)*?'\n\n// not a ^ or / followed by a dot,\n// followed by anything, any number of times.\nvar twoStarNoDot = '(?:(?!(?:\\\\\\/|^)\\\\.).)*?'\n\n// characters that need to be escaped in RegExp.\nvar reSpecials = charSet('().*{}+?[]^$\\\\!')\n\n// \"abc\" -> { a:true, b:true, c:true }\nfunction charSet (s) {\n  return s.split('').reduce(function (set, c) {\n    set[c] = true\n    return set\n  }, {})\n}\n\n// normalizes slashes.\nvar slashSplit = /\\/+/\n\nminimatch.filter = filter\nfunction filter (pattern, options) {\n  options = options || {}\n  return function (p, i, list) {\n    return minimatch(p, pattern, options)\n  }\n}\n\nfunction ext (a, b) {\n  b = b || {}\n  var t = {}\n  Object.keys(a).forEach(function (k) {\n    t[k] = a[k]\n  })\n  Object.keys(b).forEach(function (k) {\n    t[k] = b[k]\n  })\n  return t\n}\n\nminimatch.defaults = function (def) {\n  if (!def || typeof def !== 'object' || !Object.keys(def).length) {\n    return minimatch\n  }\n\n  var orig = minimatch\n\n  var m = function minimatch (p, pattern, options) {\n    return orig(p, pattern, ext(def, options))\n  }\n\n  m.Minimatch = function Minimatch (pattern, options) {\n    return new orig.Minimatch(pattern, ext(def, options))\n  }\n  m.Minimatch.defaults = function defaults (options) {\n    return orig.defaults(ext(def, options)).Minimatch\n  }\n\n  m.filter = function filter (pattern, options) {\n    return orig.filter(pattern, ext(def, options))\n  }\n\n  m.defaults = function defaults (options) {\n    return orig.defaults(ext(def, options))\n  }\n\n  m.makeRe = function makeRe (pattern, options) {\n    return orig.makeRe(pattern, ext(def, options))\n  }\n\n  m.braceExpand = function braceExpand (pattern, options) {\n    return orig.braceExpand(pattern, ext(def, options))\n  }\n\n  m.match = function (list, pattern, options) {\n    return orig.match(list, pattern, ext(def, options))\n  }\n\n  return m\n}\n\nMinimatch.defaults = function (def) {\n  return minimatch.defaults(def).Minimatch\n}\n\nfunction minimatch (p, pattern, options) {\n  assertValidPattern(pattern)\n\n  if (!options) options = {}\n\n  // shortcut: comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    return false\n  }\n\n  return new Minimatch(pattern, options).match(p)\n}\n\nfunction Minimatch (pattern, options) {\n  if (!(this instanceof Minimatch)) {\n    return new Minimatch(pattern, options)\n  }\n\n  assertValidPattern(pattern)\n\n  if (!options) options = {}\n\n  pattern = pattern.trim()\n\n  // windows support: need to use /, not \\\n  if (!options.allowWindowsEscape && path.sep !== '/') {\n    pattern = pattern.split(path.sep).join('/')\n  }\n\n  this.options = options\n  this.set = []\n  this.pattern = pattern\n  this.regexp = null\n  this.negate = false\n  this.comment = false\n  this.empty = false\n  this.partial = !!options.partial\n\n  // make the set of regexps etc.\n  this.make()\n}\n\nMinimatch.prototype.debug = function () {}\n\nMinimatch.prototype.make = make\nfunction make () {\n  var pattern = this.pattern\n  var options = this.options\n\n  // empty patterns and comments match nothing.\n  if (!options.nocomment && pattern.charAt(0) === '#') {\n    this.comment = true\n    return\n  }\n  if (!pattern) {\n    this.empty = true\n    return\n  }\n\n  // step 1: figure out negation, etc.\n  this.parseNegate()\n\n  // step 2: expand braces\n  var set = this.globSet = this.braceExpand()\n\n  if (options.debug) this.debug = function debug() { console.error.apply(console, arguments) }\n\n  this.debug(this.pattern, set)\n\n  // step 3: now we have a set, so turn each one into a series of path-portion\n  // matching patterns.\n  // These will be regexps, except in the case of \"**\", which is\n  // set to the GLOBSTAR object for globstar behavior,\n  // and will not contain any / characters\n  set = this.globParts = set.map(function (s) {\n    return s.split(slashSplit)\n  })\n\n  this.debug(this.pattern, set)\n\n  // glob --> regexps\n  set = set.map(function (s, si, set) {\n    return s.map(this.parse, this)\n  }, this)\n\n  this.debug(this.pattern, set)\n\n  // filter out everything that didn't compile properly.\n  set = set.filter(function (s) {\n    return s.indexOf(false) === -1\n  })\n\n  this.debug(this.pattern, set)\n\n  this.set = set\n}\n\nMinimatch.prototype.parseNegate = parseNegate\nfunction parseNegate () {\n  var pattern = this.pattern\n  var negate = false\n  var options = this.options\n  var negateOffset = 0\n\n  if (options.nonegate) return\n\n  for (var i = 0, l = pattern.length\n    ; i < l && pattern.charAt(i) === '!'\n    ; i++) {\n    negate = !negate\n    negateOffset++\n  }\n\n  if (negateOffset) this.pattern = pattern.substr(negateOffset)\n  this.negate = negate\n}\n\n// Brace expansion:\n// a{b,c}d -> abd acd\n// a{b,}c -> abc ac\n// a{0..3}d -> a0d a1d a2d a3d\n// a{b,c{d,e}f}g -> abg acdfg acefg\n// a{b,c}d{e,f}g -> abdeg acdeg abdeg abdfg\n//\n// Invalid sets are not expanded.\n// a{2..}b -> a{2..}b\n// a{b}c -> a{b}c\nminimatch.braceExpand = function (pattern, options) {\n  return braceExpand(pattern, options)\n}\n\nMinimatch.prototype.braceExpand = braceExpand\n\nfunction braceExpand (pattern, options) {\n  if (!options) {\n    if (this instanceof Minimatch) {\n      options = this.options\n    } else {\n      options = {}\n    }\n  }\n\n  pattern = typeof pattern === 'undefined'\n    ? this.pattern : pattern\n\n  assertValidPattern(pattern)\n\n  // Thanks to Yeting Li <https://github.com/yetingli> for\n  // improving this regexp to avoid a ReDOS vulnerability.\n  if (options.nobrace || !/\\{(?:(?!\\{).)*\\}/.test(pattern)) {\n    // shortcut. no need to expand.\n    return [pattern]\n  }\n\n  return expand(pattern)\n}\n\nvar MAX_PATTERN_LENGTH = 1024 * 64\nvar assertValidPattern = function (pattern) {\n  if (typeof pattern !== 'string') {\n    throw new TypeError('invalid pattern')\n  }\n\n  if (pattern.length > MAX_PATTERN_LENGTH) {\n    throw new TypeError('pattern is too long')\n  }\n}\n\n// parse a component of the expanded set.\n// At this point, no pattern may contain \"/\" in it\n// so we're going to return a 2d array, where each entry is the full\n// pattern, split on '/', and then turned into a regular expression.\n// A regexp is made at the end which joins each array with an\n// escaped /, and another full one which joins each regexp with |.\n//\n// Following the lead of Bash 4.1, note that \"**\" only has special meaning\n// when it is the *only* thing in a path portion.  Otherwise, any series\n// of * is equivalent to a single *.  Globstar behavior is enabled by\n// default, and can be disabled by setting options.noglobstar.\nMinimatch.prototype.parse = parse\nvar SUBPARSE = {}\nfunction parse (pattern, isSub) {\n  assertValidPattern(pattern)\n\n  var options = this.options\n\n  // shortcuts\n  if (pattern === '**') {\n    if (!options.noglobstar)\n      return GLOBSTAR\n    else\n      pattern = '*'\n  }\n  if (pattern === '') return ''\n\n  var re = ''\n  var hasMagic = !!options.nocase\n  var escaping = false\n  // ? => one single character\n  var patternListStack = []\n  var negativeLists = []\n  var stateChar\n  var inClass = false\n  var reClassStart = -1\n  var classStart = -1\n  // . and .. never match anything that doesn't start with .,\n  // even when options.dot is set.\n  var patternStart = pattern.charAt(0) === '.' ? '' // anything\n  // not (start or / followed by . or .. followed by / or end)\n  : options.dot ? '(?!(?:^|\\\\\\/)\\\\.{1,2}(?:$|\\\\\\/))'\n  : '(?!\\\\.)'\n  var self = this\n\n  function clearStateChar () {\n    if (stateChar) {\n      // we had some state-tracking character\n      // that wasn't consumed by this pass.\n      switch (stateChar) {\n        case '*':\n          re += star\n          hasMagic = true\n        break\n        case '?':\n          re += qmark\n          hasMagic = true\n        break\n        default:\n          re += '\\\\' + stateChar\n        break\n      }\n      self.debug('clearStateChar %j %j', stateChar, re)\n      stateChar = false\n    }\n  }\n\n  for (var i = 0, len = pattern.length, c\n    ; (i < len) && (c = pattern.charAt(i))\n    ; i++) {\n    this.debug('%s\\t%s %s %j', pattern, i, re, c)\n\n    // skip over any that are escaped.\n    if (escaping && reSpecials[c]) {\n      re += '\\\\' + c\n      escaping = false\n      continue\n    }\n\n    switch (c) {\n      /* istanbul ignore next */\n      case '/': {\n        // completely not allowed, even escaped.\n        // Should already be path-split by now.\n        return false\n      }\n\n      case '\\\\':\n        clearStateChar()\n        escaping = true\n      continue\n\n      // the various stateChar values\n      // for the \"extglob\" stuff.\n      case '?':\n      case '*':\n      case '+':\n      case '@':\n      case '!':\n        this.debug('%s\\t%s %s %j <-- stateChar', pattern, i, re, c)\n\n        // all of those are literals inside a class, except that\n        // the glob [!a] means [^a] in regexp\n        if (inClass) {\n          this.debug('  in class')\n          if (c === '!' && i === classStart + 1) c = '^'\n          re += c\n          continue\n        }\n\n        // if we already have a stateChar, then it means\n        // that there was something like ** or +? in there.\n        // Handle the stateChar, then proceed with this one.\n        self.debug('call clearStateChar %j', stateChar)\n        clearStateChar()\n        stateChar = c\n        // if extglob is disabled, then +(asdf|foo) isn't a thing.\n        // just clear the statechar *now*, rather than even diving into\n        // the patternList stuff.\n        if (options.noext) clearStateChar()\n      continue\n\n      case '(':\n        if (inClass) {\n          re += '('\n          continue\n        }\n\n        if (!stateChar) {\n          re += '\\\\('\n          continue\n        }\n\n        patternListStack.push({\n          type: stateChar,\n          start: i - 1,\n          reStart: re.length,\n          open: plTypes[stateChar].open,\n          close: plTypes[stateChar].close\n        })\n        // negation is (?:(?!js)[^/]*)\n        re += stateChar === '!' ? '(?:(?!(?:' : '(?:'\n        this.debug('plType %j %j', stateChar, re)\n        stateChar = false\n      continue\n\n      case ')':\n        if (inClass || !patternListStack.length) {\n          re += '\\\\)'\n          continue\n        }\n\n        clearStateChar()\n        hasMagic = true\n        var pl = patternListStack.pop()\n        // negation is (?:(?!js)[^/]*)\n        // The others are (?:<pattern>)<type>\n        re += pl.close\n        if (pl.type === '!') {\n          negativeLists.push(pl)\n        }\n        pl.reEnd = re.length\n      continue\n\n      case '|':\n        if (inClass || !patternListStack.length || escaping) {\n          re += '\\\\|'\n          escaping = false\n          continue\n        }\n\n        clearStateChar()\n        re += '|'\n      continue\n\n      // these are mostly the same in regexp and glob\n      case '[':\n        // swallow any state-tracking char before the [\n        clearStateChar()\n\n        if (inClass) {\n          re += '\\\\' + c\n          continue\n        }\n\n        inClass = true\n        classStart = i\n        reClassStart = re.length\n        re += c\n      continue\n\n      case ']':\n        //  a right bracket shall lose its special\n        //  meaning and represent itself in\n        //  a bracket expression if it occurs\n        //  first in the list.  -- POSIX.2 2.8.3.2\n        if (i === classStart + 1 || !inClass) {\n          re += '\\\\' + c\n          escaping = false\n          continue\n        }\n\n        // handle the case where we left a class open.\n        // \"[z-a]\" is valid, equivalent to \"\\[z-a\\]\"\n        // split where the last [ was, make sure we don't have\n        // an invalid re. if so, re-walk the contents of the\n        // would-be class to re-translate any characters that\n        // were passed through as-is\n        // TODO: It would probably be faster to determine this\n        // without a try/catch and a new RegExp, but it's tricky\n        // to do safely.  For now, this is safe and works.\n        var cs = pattern.substring(classStart + 1, i)\n        try {\n          RegExp('[' + cs + ']')\n        } catch (er) {\n          // not a valid class!\n          var sp = this.parse(cs, SUBPARSE)\n          re = re.substr(0, reClassStart) + '\\\\[' + sp[0] + '\\\\]'\n          hasMagic = hasMagic || sp[1]\n          inClass = false\n          continue\n        }\n\n        // finish up the class.\n        hasMagic = true\n        inClass = false\n        re += c\n      continue\n\n      default:\n        // swallow any state char that wasn't consumed\n        clearStateChar()\n\n        if (escaping) {\n          // no need\n          escaping = false\n        } else if (reSpecials[c]\n          && !(c === '^' && inClass)) {\n          re += '\\\\'\n        }\n\n        re += c\n\n    } // switch\n  } // for\n\n  // handle the case where we left a class open.\n  // \"[abc\" is valid, equivalent to \"\\[abc\"\n  if (inClass) {\n    // split where the last [ was, and escape it\n    // this is a huge pita.  We now have to re-walk\n    // the contents of the would-be class to re-translate\n    // any characters that were passed through as-is\n    cs = pattern.substr(classStart + 1)\n    sp = this.parse(cs, SUBPARSE)\n    re = re.substr(0, reClassStart) + '\\\\[' + sp[0]\n    hasMagic = hasMagic || sp[1]\n  }\n\n  // handle the case where we had a +( thing at the *end*\n  // of the pattern.\n  // each pattern list stack adds 3 chars, and we need to go through\n  // and escape any | chars that were passed through as-is for the regexp.\n  // Go through and escape them, taking care not to double-escape any\n  // | chars that were already escaped.\n  for (pl = patternListStack.pop(); pl; pl = patternListStack.pop()) {\n    var tail = re.slice(pl.reStart + pl.open.length)\n    this.debug('setting tail', re, pl)\n    // maybe some even number of \\, then maybe 1 \\, followed by a |\n    tail = tail.replace(/((?:\\\\{2}){0,64})(\\\\?)\\|/g, function (_, $1, $2) {\n      if (!$2) {\n        // the | isn't already escaped, so escape it.\n        $2 = '\\\\'\n      }\n\n      // need to escape all those slashes *again*, without escaping the\n      // one that we need for escaping the | character.  As it works out,\n      // escaping an even number of slashes can be done by simply repeating\n      // it exactly after itself.  That's why this trick works.\n      //\n      // I am sorry that you have to see this.\n      return $1 + $1 + $2 + '|'\n    })\n\n    this.debug('tail=%j\\n   %s', tail, tail, pl, re)\n    var t = pl.type === '*' ? star\n      : pl.type === '?' ? qmark\n      : '\\\\' + pl.type\n\n    hasMagic = true\n    re = re.slice(0, pl.reStart) + t + '\\\\(' + tail\n  }\n\n  // handle trailing things that only matter at the very end.\n  clearStateChar()\n  if (escaping) {\n    // trailing \\\\\n    re += '\\\\\\\\'\n  }\n\n  // only need to apply the nodot start if the re starts with\n  // something that could conceivably capture a dot\n  var addPatternStart = false\n  switch (re.charAt(0)) {\n    case '[': case '.': case '(': addPatternStart = true\n  }\n\n  // Hack to work around lack of negative lookbehind in JS\n  // A pattern like: *.!(x).!(y|z) needs to ensure that a name\n  // like 'a.xyz.yz' doesn't match.  So, the first negative\n  // lookahead, has to look ALL the way ahead, to the end of\n  // the pattern.\n  for (var n = negativeLists.length - 1; n > -1; n--) {\n    var nl = negativeLists[n]\n\n    var nlBefore = re.slice(0, nl.reStart)\n    var nlFirst = re.slice(nl.reStart, nl.reEnd - 8)\n    var nlLast = re.slice(nl.reEnd - 8, nl.reEnd)\n    var nlAfter = re.slice(nl.reEnd)\n\n    nlLast += nlAfter\n\n    // Handle nested stuff like *(*.js|!(*.json)), where open parens\n    // mean that we should *not* include the ) in the bit that is considered\n    // \"after\" the negated section.\n    var openParensBefore = nlBefore.split('(').length - 1\n    var cleanAfter = nlAfter\n    for (i = 0; i < openParensBefore; i++) {\n      cleanAfter = cleanAfter.replace(/\\)[+*?]?/, '')\n    }\n    nlAfter = cleanAfter\n\n    var dollar = ''\n    if (nlAfter === '' && isSub !== SUBPARSE) {\n      dollar = '$'\n    }\n    var newRe = nlBefore + nlFirst + nlAfter + dollar + nlLast\n    re = newRe\n  }\n\n  // if the re is not \"\" at this point, then we need to make sure\n  // it doesn't match against an empty path part.\n  // Otherwise a/* will match a/, which it should not.\n  if (re !== '' && hasMagic) {\n    re = '(?=.)' + re\n  }\n\n  if (addPatternStart) {\n    re = patternStart + re\n  }\n\n  // parsing just a piece of a larger pattern.\n  if (isSub === SUBPARSE) {\n    return [re, hasMagic]\n  }\n\n  // skip the regexp for non-magical patterns\n  // unescape anything in it, though, so that it'll be\n  // an exact match against a file etc.\n  if (!hasMagic) {\n    return globUnescape(pattern)\n  }\n\n  var flags = options.nocase ? 'i' : ''\n  try {\n    var regExp = new RegExp('^' + re + '$', flags)\n  } catch (er) /* istanbul ignore next - should be impossible */ {\n    // If it was an invalid regular expression, then it can't match\n    // anything.  This trick looks for a character after the end of\n    // the string, which is of course impossible, except in multi-line\n    // mode, but it's not a /m regex.\n    return new RegExp('$.')\n  }\n\n  regExp._glob = pattern\n  regExp._src = re\n\n  return regExp\n}\n\nminimatch.makeRe = function (pattern, options) {\n  return new Minimatch(pattern, options || {}).makeRe()\n}\n\nMinimatch.prototype.makeRe = makeRe\nfunction makeRe () {\n  if (this.regexp || this.regexp === false) return this.regexp\n\n  // at this point, this.set is a 2d array of partial\n  // pattern strings, or \"**\".\n  //\n  // It's better to use .match().  This function shouldn't\n  // be used, really, but it's pretty convenient sometimes,\n  // when you just want to work with a regex.\n  var set = this.set\n\n  if (!set.length) {\n    this.regexp = false\n    return this.regexp\n  }\n  var options = this.options\n\n  var twoStar = options.noglobstar ? star\n    : options.dot ? twoStarDot\n    : twoStarNoDot\n  var flags = options.nocase ? 'i' : ''\n\n  var re = set.map(function (pattern) {\n    return pattern.map(function (p) {\n      return (p === GLOBSTAR) ? twoStar\n      : (typeof p === 'string') ? regExpEscape(p)\n      : p._src\n    }).join('\\\\\\/')\n  }).join('|')\n\n  // must match entire pattern\n  // ending in a * or ** will make it less strict.\n  re = '^(?:' + re + ')$'\n\n  // can match anything, as long as it's not this.\n  if (this.negate) re = '^(?!' + re + ').*$'\n\n  try {\n    this.regexp = new RegExp(re, flags)\n  } catch (ex) /* istanbul ignore next - should be impossible */ {\n    this.regexp = false\n  }\n  return this.regexp\n}\n\nminimatch.match = function (list, pattern, options) {\n  options = options || {}\n  var mm = new Minimatch(pattern, options)\n  list = list.filter(function (f) {\n    return mm.match(f)\n  })\n  if (mm.options.nonull && !list.length) {\n    list.push(pattern)\n  }\n  return list\n}\n\nMinimatch.prototype.match = function match (f, partial) {\n  if (typeof partial === 'undefined') partial = this.partial\n  this.debug('match', f, this.pattern)\n  // short-circuit in the case of busted things.\n  // comments, etc.\n  if (this.comment) return false\n  if (this.empty) return f === ''\n\n  if (f === '/' && partial) return true\n\n  var options = this.options\n\n  // windows: need to use /, not \\\n  if (path.sep !== '/') {\n    f = f.split(path.sep).join('/')\n  }\n\n  // treat the test path as a set of pathparts.\n  f = f.split(slashSplit)\n  this.debug(this.pattern, 'split', f)\n\n  // just ONE of the pattern sets in this.set needs to match\n  // in order for it to be valid.  If negating, then just one\n  // match means that we have failed.\n  // Either way, return on the first hit.\n\n  var set = this.set\n  this.debug(this.pattern, 'set', set)\n\n  // Find the basename of the path by looking for the last non-empty segment\n  var filename\n  var i\n  for (i = f.length - 1; i >= 0; i--) {\n    filename = f[i]\n    if (filename) break\n  }\n\n  for (i = 0; i < set.length; i++) {\n    var pattern = set[i]\n    var file = f\n    if (options.matchBase && pattern.length === 1) {\n      file = [filename]\n    }\n    var hit = this.matchOne(file, pattern, partial)\n    if (hit) {\n      if (options.flipNegate) return true\n      return !this.negate\n    }\n  }\n\n  // didn't get any hits.  this is success if it's a negative\n  // pattern, failure otherwise.\n  if (options.flipNegate) return false\n  return this.negate\n}\n\n// set partial to true to test if, for example,\n// \"/a/b\" matches the start of \"/*/b/*/d\"\n// Partial means, if you run out of file before you run\n// out of pattern, then that's fine, as long as all\n// the parts match.\nMinimatch.prototype.matchOne = function (file, pattern, partial) {\n  var options = this.options\n\n  this.debug('matchOne',\n    { 'this': this, file: file, pattern: pattern })\n\n  this.debug('matchOne', file.length, pattern.length)\n\n  for (var fi = 0,\n      pi = 0,\n      fl = file.length,\n      pl = pattern.length\n      ; (fi < fl) && (pi < pl)\n      ; fi++, pi++) {\n    this.debug('matchOne loop')\n    var p = pattern[pi]\n    var f = file[fi]\n\n    this.debug(pattern, p, f)\n\n    // should be impossible.\n    // some invalid regexp stuff in the set.\n    /* istanbul ignore if */\n    if (p === false) return false\n\n    if (p === GLOBSTAR) {\n      this.debug('GLOBSTAR', [pattern, p, f])\n\n      // \"**\"\n      // a/**/b/**/c would match the following:\n      // a/b/x/y/z/c\n      // a/x/y/z/b/c\n      // a/b/x/b/x/c\n      // a/b/c\n      // To do this, take the rest of the pattern after\n      // the **, and see if it would match the file remainder.\n      // If so, return success.\n      // If not, the ** \"swallows\" a segment, and try again.\n      // This is recursively awful.\n      //\n      // a/**/b/**/c matching a/b/x/y/z/c\n      // - a matches a\n      // - doublestar\n      //   - matchOne(b/x/y/z/c, b/**/c)\n      //     - b matches b\n      //     - doublestar\n      //       - matchOne(x/y/z/c, c) -> no\n      //       - matchOne(y/z/c, c) -> no\n      //       - matchOne(z/c, c) -> no\n      //       - matchOne(c, c) yes, hit\n      var fr = fi\n      var pr = pi + 1\n      if (pr === pl) {\n        this.debug('** at the end')\n        // a ** at the end will just swallow the rest.\n        // We have found a match.\n        // however, it will not swallow /.x, unless\n        // options.dot is set.\n        // . and .. are *never* matched by **, for explosively\n        // exponential reasons.\n        for (; fi < fl; fi++) {\n          if (file[fi] === '.' || file[fi] === '..' ||\n            (!options.dot && file[fi].charAt(0) === '.')) return false\n        }\n        return true\n      }\n\n      // ok, let's see if we can swallow whatever we can.\n      while (fr < fl) {\n        var swallowee = file[fr]\n\n        this.debug('\\nglobstar while', file, fr, pattern, pr, swallowee)\n\n        // XXX remove this slice.  Just pass the start index.\n        if (this.matchOne(file.slice(fr), pattern.slice(pr), partial)) {\n          this.debug('globstar found match!', fr, fl, swallowee)\n          // found a match.\n          return true\n        } else {\n          // can't swallow \".\" or \"..\" ever.\n          // can only swallow \".foo\" when explicitly asked.\n          if (swallowee === '.' || swallowee === '..' ||\n            (!options.dot && swallowee.charAt(0) === '.')) {\n            this.debug('dot detected!', file, fr, pattern, pr)\n            break\n          }\n\n          // ** swallows a segment, and continue.\n          this.debug('globstar swallow a segment, and continue')\n          fr++\n        }\n      }\n\n      // no match was found.\n      // However, in partial mode, we can't say this is necessarily over.\n      // If there's more *pattern* left, then\n      /* istanbul ignore if */\n      if (partial) {\n        // ran out of file\n        this.debug('\\n>>> no match, partial?', file, fr, pattern, pr)\n        if (fr === fl) return true\n      }\n      return false\n    }\n\n    // something other than **\n    // non-magic patterns just have to match exactly\n    // patterns with magic have been turned into regexps.\n    var hit\n    if (typeof p === 'string') {\n      hit = f === p\n      this.debug('string match', p, f, hit)\n    } else {\n      hit = f.match(p)\n      this.debug('pattern match', p, f, hit)\n    }\n\n    if (!hit) return false\n  }\n\n  // Note: ending in / means that we'll get a final \"\"\n  // at the end of the pattern.  This can only match a\n  // corresponding \"\" at the end of the file.\n  // If the file ends in /, then it can only match a\n  // a pattern that ends in /, unless the pattern just\n  // doesn't have any more for it. But, a/b/ should *not*\n  // match \"a/b/*\", even though \"\" matches against the\n  // [^/]*? pattern, except in partial mode, where it might\n  // simply not be reached yet.\n  // However, a/b/ should still satisfy a/*\n\n  // now either we fell off the end of the pattern, or we're done.\n  if (fi === fl && pi === pl) {\n    // ran out of pattern and filename at the same time.\n    // an exact hit!\n    return true\n  } else if (fi === fl) {\n    // ran out of file, but still had pattern left.\n    // this is ok if we're doing the match as part of\n    // a glob fs traversal.\n    return partial\n  } else /* istanbul ignore else */ if (pi === pl) {\n    // ran out of pattern, still have file left.\n    // this is only acceptable if we're on the very last\n    // empty segment of a file with a trailing slash.\n    // a/* should match a/b/\n    return (fi === fl - 1) && (file[fi] === '')\n  }\n\n  // should be unreachable.\n  /* istanbul ignore next */\n  throw new Error('wtf?')\n}\n\n// replace stuff like \\* with *\nfunction globUnescape (s) {\n  return s.replace(/\\\\(.)/g, '$1')\n}\n\nfunction regExpEscape (s) {\n  return s.replace(/[-[\\]{}()*+?.,\\\\^$|#\\s]/g, '\\\\$&')\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/minimatch/minimatch.js?");

/***/ }),

/***/ "./node_modules/minipass/index.js":
/*!****************************************!*\
  !*** ./node_modules/minipass/index.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nconst proc =\n  typeof process === 'object' && process\n    ? process\n    : {\n        stdout: null,\n        stderr: null,\n      }\nconst EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst Stream = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst stringdecoder = __webpack_require__(/*! string_decoder */ \"./node_modules/string_decoder/lib/string_decoder.js\")\nconst SD = stringdecoder.StringDecoder\n\nconst EOF = Symbol('EOF')\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd')\nconst EMITTED_END = Symbol('emittedEnd')\nconst EMITTING_END = Symbol('emittingEnd')\nconst EMITTED_ERROR = Symbol('emittedError')\nconst CLOSED = Symbol('closed')\nconst READ = Symbol('read')\nconst FLUSH = Symbol('flush')\nconst FLUSHCHUNK = Symbol('flushChunk')\nconst ENCODING = Symbol('encoding')\nconst DECODER = Symbol('decoder')\nconst FLOWING = Symbol('flowing')\nconst PAUSED = Symbol('paused')\nconst RESUME = Symbol('resume')\nconst BUFFER = Symbol('buffer')\nconst PIPES = Symbol('pipes')\nconst BUFFERLENGTH = Symbol('bufferLength')\nconst BUFFERPUSH = Symbol('bufferPush')\nconst BUFFERSHIFT = Symbol('bufferShift')\nconst OBJECTMODE = Symbol('objectMode')\n// internal event when stream is destroyed\nconst DESTROYED = Symbol('destroyed')\n// internal event when stream has an error\nconst ERROR = Symbol('error')\nconst EMITDATA = Symbol('emitData')\nconst EMITEND = Symbol('emitEnd')\nconst EMITEND2 = Symbol('emitEnd2')\nconst ASYNC = Symbol('async')\nconst ABORT = Symbol('abort')\nconst ABORTED = Symbol('aborted')\nconst SIGNAL = Symbol('signal')\n\nconst defer = fn => Promise.resolve().then(fn)\n\n// TODO remove when Node v8 support drops\nconst doIter = __webpack_require__.g._MP_NO_ITERATOR_SYMBOLS_ !== '1'\nconst ASYNCITERATOR =\n  (doIter && Symbol.asyncIterator) || Symbol('asyncIterator not implemented')\nconst ITERATOR =\n  (doIter && Symbol.iterator) || Symbol('iterator not implemented')\n\n// events that mean 'the stream is over'\n// these are treated specially, and re-emitted\n// if they are listened for after emitting.\nconst isEndish = ev => ev === 'end' || ev === 'finish' || ev === 'prefinish'\n\nconst isArrayBuffer = b =>\n  b instanceof ArrayBuffer ||\n  (typeof b === 'object' &&\n    b.constructor &&\n    b.constructor.name === 'ArrayBuffer' &&\n    b.byteLength >= 0)\n\nconst isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)\n\nclass Pipe {\n  constructor(src, dest, opts) {\n    this.src = src\n    this.dest = dest\n    this.opts = opts\n    this.ondrain = () => src[RESUME]()\n    dest.on('drain', this.ondrain)\n  }\n  unpipe() {\n    this.dest.removeListener('drain', this.ondrain)\n  }\n  // istanbul ignore next - only here for the prototype\n  proxyErrors() {}\n  end() {\n    this.unpipe()\n    if (this.opts.end) this.dest.end()\n  }\n}\n\nclass PipeProxyErrors extends Pipe {\n  unpipe() {\n    this.src.removeListener('error', this.proxyErrors)\n    super.unpipe()\n  }\n  constructor(src, dest, opts) {\n    super(src, dest, opts)\n    this.proxyErrors = er => dest.emit('error', er)\n    src.on('error', this.proxyErrors)\n  }\n}\n\nclass Minipass extends Stream {\n  constructor(options) {\n    super()\n    this[FLOWING] = false\n    // whether we're explicitly paused\n    this[PAUSED] = false\n    this[PIPES] = []\n    this[BUFFER] = []\n    this[OBJECTMODE] = (options && options.objectMode) || false\n    if (this[OBJECTMODE]) this[ENCODING] = null\n    else this[ENCODING] = (options && options.encoding) || null\n    if (this[ENCODING] === 'buffer') this[ENCODING] = null\n    this[ASYNC] = (options && !!options.async) || false\n    this[DECODER] = this[ENCODING] ? new SD(this[ENCODING]) : null\n    this[EOF] = false\n    this[EMITTED_END] = false\n    this[EMITTING_END] = false\n    this[CLOSED] = false\n    this[EMITTED_ERROR] = null\n    this.writable = true\n    this.readable = true\n    this[BUFFERLENGTH] = 0\n    this[DESTROYED] = false\n    if (options && options.debugExposeBuffer === true) {\n      Object.defineProperty(this, 'buffer', { get: () => this[BUFFER] })\n    }\n    if (options && options.debugExposePipes === true) {\n      Object.defineProperty(this, 'pipes', { get: () => this[PIPES] })\n    }\n    this[SIGNAL] = options && options.signal\n    this[ABORTED] = false\n    if (this[SIGNAL]) {\n      this[SIGNAL].addEventListener('abort', () => this[ABORT]())\n      if (this[SIGNAL].aborted) {\n        this[ABORT]()\n      }\n    }\n  }\n\n  get bufferLength() {\n    return this[BUFFERLENGTH]\n  }\n\n  get encoding() {\n    return this[ENCODING]\n  }\n  set encoding(enc) {\n    if (this[OBJECTMODE]) throw new Error('cannot set encoding in objectMode')\n\n    if (\n      this[ENCODING] &&\n      enc !== this[ENCODING] &&\n      ((this[DECODER] && this[DECODER].lastNeed) || this[BUFFERLENGTH])\n    )\n      throw new Error('cannot change encoding')\n\n    if (this[ENCODING] !== enc) {\n      this[DECODER] = enc ? new SD(enc) : null\n      if (this[BUFFER].length)\n        this[BUFFER] = this[BUFFER].map(chunk => this[DECODER].write(chunk))\n    }\n\n    this[ENCODING] = enc\n  }\n\n  setEncoding(enc) {\n    this.encoding = enc\n  }\n\n  get objectMode() {\n    return this[OBJECTMODE]\n  }\n  set objectMode(om) {\n    this[OBJECTMODE] = this[OBJECTMODE] || !!om\n  }\n\n  get ['async']() {\n    return this[ASYNC]\n  }\n  set ['async'](a) {\n    this[ASYNC] = this[ASYNC] || !!a\n  }\n\n  // drop everything and get out of the flow completely\n  [ABORT]() {\n    this[ABORTED] = true\n    this.emit('abort', this[SIGNAL].reason)\n    this.destroy(this[SIGNAL].reason)\n  }\n\n  get aborted() {\n    return this[ABORTED]\n  }\n  set aborted(_) {}\n\n  write(chunk, encoding, cb) {\n    if (this[ABORTED]) return false\n    if (this[EOF]) throw new Error('write after end')\n\n    if (this[DESTROYED]) {\n      this.emit(\n        'error',\n        Object.assign(\n          new Error('Cannot call write after a stream was destroyed'),\n          { code: 'ERR_STREAM_DESTROYED' }\n        )\n      )\n      return true\n    }\n\n    if (typeof encoding === 'function') (cb = encoding), (encoding = 'utf8')\n\n    if (!encoding) encoding = 'utf8'\n\n    const fn = this[ASYNC] ? defer : f => f()\n\n    // convert array buffers and typed array views into buffers\n    // at some point in the future, we may want to do the opposite!\n    // leave strings and buffers as-is\n    // anything else switches us into object mode\n    if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n      if (isArrayBufferView(chunk))\n        chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n      else if (isArrayBuffer(chunk)) chunk = Buffer.from(chunk)\n      else if (typeof chunk !== 'string')\n        // use the setter so we throw if we have encoding set\n        this.objectMode = true\n    }\n\n    // handle object mode up front, since it's simpler\n    // this yields better performance, fewer checks later.\n    if (this[OBJECTMODE]) {\n      /* istanbul ignore if - maybe impossible? */\n      if (this.flowing && this[BUFFERLENGTH] !== 0) this[FLUSH](true)\n\n      if (this.flowing) this.emit('data', chunk)\n      else this[BUFFERPUSH](chunk)\n\n      if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n\n      if (cb) fn(cb)\n\n      return this.flowing\n    }\n\n    // at this point the chunk is a buffer or string\n    // don't buffer it up or send it to the decoder\n    if (!chunk.length) {\n      if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n      if (cb) fn(cb)\n      return this.flowing\n    }\n\n    // fast-path writing strings of same encoding to a stream with\n    // an empty buffer, skipping the buffer/decoder dance\n    if (\n      typeof chunk === 'string' &&\n      // unless it is a string already ready for us to use\n      !(encoding === this[ENCODING] && !this[DECODER].lastNeed)\n    ) {\n      chunk = Buffer.from(chunk, encoding)\n    }\n\n    if (Buffer.isBuffer(chunk) && this[ENCODING])\n      chunk = this[DECODER].write(chunk)\n\n    // Note: flushing CAN potentially switch us into not-flowing mode\n    if (this.flowing && this[BUFFERLENGTH] !== 0) this[FLUSH](true)\n\n    if (this.flowing) this.emit('data', chunk)\n    else this[BUFFERPUSH](chunk)\n\n    if (this[BUFFERLENGTH] !== 0) this.emit('readable')\n\n    if (cb) fn(cb)\n\n    return this.flowing\n  }\n\n  read(n) {\n    if (this[DESTROYED]) return null\n\n    if (this[BUFFERLENGTH] === 0 || n === 0 || n > this[BUFFERLENGTH]) {\n      this[MAYBE_EMIT_END]()\n      return null\n    }\n\n    if (this[OBJECTMODE]) n = null\n\n    if (this[BUFFER].length > 1 && !this[OBJECTMODE]) {\n      if (this.encoding) this[BUFFER] = [this[BUFFER].join('')]\n      else this[BUFFER] = [Buffer.concat(this[BUFFER], this[BUFFERLENGTH])]\n    }\n\n    const ret = this[READ](n || null, this[BUFFER][0])\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [READ](n, chunk) {\n    if (n === chunk.length || n === null) this[BUFFERSHIFT]()\n    else {\n      this[BUFFER][0] = chunk.slice(n)\n      chunk = chunk.slice(0, n)\n      this[BUFFERLENGTH] -= n\n    }\n\n    this.emit('data', chunk)\n\n    if (!this[BUFFER].length && !this[EOF]) this.emit('drain')\n\n    return chunk\n  }\n\n  end(chunk, encoding, cb) {\n    if (typeof chunk === 'function') (cb = chunk), (chunk = null)\n    if (typeof encoding === 'function') (cb = encoding), (encoding = 'utf8')\n    if (chunk) this.write(chunk, encoding)\n    if (cb) this.once('end', cb)\n    this[EOF] = true\n    this.writable = false\n\n    // if we haven't written anything, then go ahead and emit,\n    // even if we're not reading.\n    // we'll re-emit if a new 'end' listener is added anyway.\n    // This makes MP more suitable to write-only use cases.\n    if (this.flowing || !this[PAUSED]) this[MAYBE_EMIT_END]()\n    return this\n  }\n\n  // don't let the internal resume be overwritten\n  [RESUME]() {\n    if (this[DESTROYED]) return\n\n    this[PAUSED] = false\n    this[FLOWING] = true\n    this.emit('resume')\n    if (this[BUFFER].length) this[FLUSH]()\n    else if (this[EOF]) this[MAYBE_EMIT_END]()\n    else this.emit('drain')\n  }\n\n  resume() {\n    return this[RESUME]()\n  }\n\n  pause() {\n    this[FLOWING] = false\n    this[PAUSED] = true\n  }\n\n  get destroyed() {\n    return this[DESTROYED]\n  }\n\n  get flowing() {\n    return this[FLOWING]\n  }\n\n  get paused() {\n    return this[PAUSED]\n  }\n\n  [BUFFERPUSH](chunk) {\n    if (this[OBJECTMODE]) this[BUFFERLENGTH] += 1\n    else this[BUFFERLENGTH] += chunk.length\n    this[BUFFER].push(chunk)\n  }\n\n  [BUFFERSHIFT]() {\n    if (this[OBJECTMODE]) this[BUFFERLENGTH] -= 1\n    else this[BUFFERLENGTH] -= this[BUFFER][0].length\n    return this[BUFFER].shift()\n  }\n\n  [FLUSH](noDrain) {\n    do {} while (this[FLUSHCHUNK](this[BUFFERSHIFT]()) && this[BUFFER].length)\n\n    if (!noDrain && !this[BUFFER].length && !this[EOF]) this.emit('drain')\n  }\n\n  [FLUSHCHUNK](chunk) {\n    this.emit('data', chunk)\n    return this.flowing\n  }\n\n  pipe(dest, opts) {\n    if (this[DESTROYED]) return\n\n    const ended = this[EMITTED_END]\n    opts = opts || {}\n    if (dest === proc.stdout || dest === proc.stderr) opts.end = false\n    else opts.end = opts.end !== false\n    opts.proxyErrors = !!opts.proxyErrors\n\n    // piping an ended stream ends immediately\n    if (ended) {\n      if (opts.end) dest.end()\n    } else {\n      this[PIPES].push(\n        !opts.proxyErrors\n          ? new Pipe(this, dest, opts)\n          : new PipeProxyErrors(this, dest, opts)\n      )\n      if (this[ASYNC]) defer(() => this[RESUME]())\n      else this[RESUME]()\n    }\n\n    return dest\n  }\n\n  unpipe(dest) {\n    const p = this[PIPES].find(p => p.dest === dest)\n    if (p) {\n      this[PIPES].splice(this[PIPES].indexOf(p), 1)\n      p.unpipe()\n    }\n  }\n\n  addListener(ev, fn) {\n    return this.on(ev, fn)\n  }\n\n  on(ev, fn) {\n    const ret = super.on(ev, fn)\n    if (ev === 'data' && !this[PIPES].length && !this.flowing) this[RESUME]()\n    else if (ev === 'readable' && this[BUFFERLENGTH] !== 0)\n      super.emit('readable')\n    else if (isEndish(ev) && this[EMITTED_END]) {\n      super.emit(ev)\n      this.removeAllListeners(ev)\n    } else if (ev === 'error' && this[EMITTED_ERROR]) {\n      if (this[ASYNC]) defer(() => fn.call(this, this[EMITTED_ERROR]))\n      else fn.call(this, this[EMITTED_ERROR])\n    }\n    return ret\n  }\n\n  get emittedEnd() {\n    return this[EMITTED_END]\n  }\n\n  [MAYBE_EMIT_END]() {\n    if (\n      !this[EMITTING_END] &&\n      !this[EMITTED_END] &&\n      !this[DESTROYED] &&\n      this[BUFFER].length === 0 &&\n      this[EOF]\n    ) {\n      this[EMITTING_END] = true\n      this.emit('end')\n      this.emit('prefinish')\n      this.emit('finish')\n      if (this[CLOSED]) this.emit('close')\n      this[EMITTING_END] = false\n    }\n  }\n\n  emit(ev, data, ...extra) {\n    // error and close are only events allowed after calling destroy()\n    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && this[DESTROYED])\n      return\n    else if (ev === 'data') {\n      return !this[OBJECTMODE] && !data\n        ? false\n        : this[ASYNC]\n        ? defer(() => this[EMITDATA](data))\n        : this[EMITDATA](data)\n    } else if (ev === 'end') {\n      return this[EMITEND]()\n    } else if (ev === 'close') {\n      this[CLOSED] = true\n      // don't emit close before 'end' and 'finish'\n      if (!this[EMITTED_END] && !this[DESTROYED]) return\n      const ret = super.emit('close')\n      this.removeAllListeners('close')\n      return ret\n    } else if (ev === 'error') {\n      this[EMITTED_ERROR] = data\n      super.emit(ERROR, data)\n      const ret =\n        !this[SIGNAL] || this.listeners('error').length\n          ? super.emit('error', data)\n          : false\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'resume') {\n      const ret = super.emit('resume')\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'finish' || ev === 'prefinish') {\n      const ret = super.emit(ev)\n      this.removeAllListeners(ev)\n      return ret\n    }\n\n    // Some other unknown event\n    const ret = super.emit(ev, data, ...extra)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITDATA](data) {\n    for (const p of this[PIPES]) {\n      if (p.dest.write(data) === false) this.pause()\n    }\n    const ret = super.emit('data', data)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITEND]() {\n    if (this[EMITTED_END]) return\n\n    this[EMITTED_END] = true\n    this.readable = false\n    if (this[ASYNC]) defer(() => this[EMITEND2]())\n    else this[EMITEND2]()\n  }\n\n  [EMITEND2]() {\n    if (this[DECODER]) {\n      const data = this[DECODER].end()\n      if (data) {\n        for (const p of this[PIPES]) {\n          p.dest.write(data)\n        }\n        super.emit('data', data)\n      }\n    }\n\n    for (const p of this[PIPES]) {\n      p.end()\n    }\n    const ret = super.emit('end')\n    this.removeAllListeners('end')\n    return ret\n  }\n\n  // const all = await stream.collect()\n  collect() {\n    const buf = []\n    if (!this[OBJECTMODE]) buf.dataLength = 0\n    // set the promise first, in case an error is raised\n    // by triggering the flow here.\n    const p = this.promise()\n    this.on('data', c => {\n      buf.push(c)\n      if (!this[OBJECTMODE]) buf.dataLength += c.length\n    })\n    return p.then(() => buf)\n  }\n\n  // const data = await stream.concat()\n  concat() {\n    return this[OBJECTMODE]\n      ? Promise.reject(new Error('cannot concat in objectMode'))\n      : this.collect().then(buf =>\n          this[OBJECTMODE]\n            ? Promise.reject(new Error('cannot concat in objectMode'))\n            : this[ENCODING]\n            ? buf.join('')\n            : Buffer.concat(buf, buf.dataLength)\n        )\n  }\n\n  // stream.promise().then(() => done, er => emitted error)\n  promise() {\n    return new Promise((resolve, reject) => {\n      this.on(DESTROYED, () => reject(new Error('stream destroyed')))\n      this.on('error', er => reject(er))\n      this.on('end', () => resolve())\n    })\n  }\n\n  // for await (let chunk of stream)\n  [ASYNCITERATOR]() {\n    let stopped = false\n    const stop = () => {\n      this.pause()\n      stopped = true\n      return Promise.resolve({ done: true })\n    }\n    const next = () => {\n      if (stopped) return stop()\n      const res = this.read()\n      if (res !== null) return Promise.resolve({ done: false, value: res })\n\n      if (this[EOF]) return stop()\n\n      let resolve = null\n      let reject = null\n      const onerr = er => {\n        this.removeListener('data', ondata)\n        this.removeListener('end', onend)\n        this.removeListener(DESTROYED, ondestroy)\n        stop()\n        reject(er)\n      }\n      const ondata = value => {\n        this.removeListener('error', onerr)\n        this.removeListener('end', onend)\n        this.removeListener(DESTROYED, ondestroy)\n        this.pause()\n        resolve({ value: value, done: !!this[EOF] })\n      }\n      const onend = () => {\n        this.removeListener('error', onerr)\n        this.removeListener('data', ondata)\n        this.removeListener(DESTROYED, ondestroy)\n        stop()\n        resolve({ done: true })\n      }\n      const ondestroy = () => onerr(new Error('stream destroyed'))\n      return new Promise((res, rej) => {\n        reject = rej\n        resolve = res\n        this.once(DESTROYED, ondestroy)\n        this.once('error', onerr)\n        this.once('end', onend)\n        this.once('data', ondata)\n      })\n    }\n\n    return {\n      next,\n      throw: stop,\n      return: stop,\n      [ASYNCITERATOR]() {\n        return this\n      },\n    }\n  }\n\n  // for (let chunk of stream)\n  [ITERATOR]() {\n    let stopped = false\n    const stop = () => {\n      this.pause()\n      this.removeListener(ERROR, stop)\n      this.removeListener(DESTROYED, stop)\n      this.removeListener('end', stop)\n      stopped = true\n      return { done: true }\n    }\n\n    const next = () => {\n      if (stopped) return stop()\n      const value = this.read()\n      return value === null ? stop() : { value }\n    }\n    this.once('end', stop)\n    this.once(ERROR, stop)\n    this.once(DESTROYED, stop)\n\n    return {\n      next,\n      throw: stop,\n      return: stop,\n      [ITERATOR]() {\n        return this\n      },\n    }\n  }\n\n  destroy(er) {\n    if (this[DESTROYED]) {\n      if (er) this.emit('error', er)\n      else this.emit(DESTROYED)\n      return this\n    }\n\n    this[DESTROYED] = true\n\n    // throw away all buffered data, it's never coming out\n    this[BUFFER].length = 0\n    this[BUFFERLENGTH] = 0\n\n    if (typeof this.close === 'function' && !this[CLOSED]) this.close()\n\n    if (er) this.emit('error', er)\n    // if no error to emit, still reject pending promises\n    else this.emit(DESTROYED)\n\n    return this\n  }\n\n  static isStream(s) {\n    return (\n      !!s &&\n      (s instanceof Minipass ||\n        s instanceof Stream ||\n        (s instanceof EE &&\n          // readable\n          (typeof s.pipe === 'function' ||\n            // writable\n            (typeof s.write === 'function' && typeof s.end === 'function'))))\n    )\n  }\n}\n\nexports.Minipass = Minipass\n\n\n//# sourceURL=webpack://thelambda/./node_modules/minipass/index.js?");

/***/ }),

/***/ "./node_modules/minizlib/constants.js":
/*!********************************************!*\
  !*** ./node_modules/minizlib/constants.js ***!
  \********************************************/
/***/ ((module) => {

eval("// Update with any zlib constants that are added or changed in the future.\n// Node v6 didn't export this, so we just hard code the version and rely\n// on all the other hard-coded values from zlib v4736.  When node v6\n// support drops, we can just export the realZlibConstants object.\nconst realZlibConstants = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'zlib'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()) ||\n  /* istanbul ignore next */ { ZLIB_VERNUM: 4736 }\n\nmodule.exports = Object.freeze(Object.assign(Object.create(null), {\n  Z_NO_FLUSH: 0,\n  Z_PARTIAL_FLUSH: 1,\n  Z_SYNC_FLUSH: 2,\n  Z_FULL_FLUSH: 3,\n  Z_FINISH: 4,\n  Z_BLOCK: 5,\n  Z_OK: 0,\n  Z_STREAM_END: 1,\n  Z_NEED_DICT: 2,\n  Z_ERRNO: -1,\n  Z_STREAM_ERROR: -2,\n  Z_DATA_ERROR: -3,\n  Z_MEM_ERROR: -4,\n  Z_BUF_ERROR: -5,\n  Z_VERSION_ERROR: -6,\n  Z_NO_COMPRESSION: 0,\n  Z_BEST_SPEED: 1,\n  Z_BEST_COMPRESSION: 9,\n  Z_DEFAULT_COMPRESSION: -1,\n  Z_FILTERED: 1,\n  Z_HUFFMAN_ONLY: 2,\n  Z_RLE: 3,\n  Z_FIXED: 4,\n  Z_DEFAULT_STRATEGY: 0,\n  DEFLATE: 1,\n  INFLATE: 2,\n  GZIP: 3,\n  GUNZIP: 4,\n  DEFLATERAW: 5,\n  INFLATERAW: 6,\n  UNZIP: 7,\n  BROTLI_DECODE: 8,\n  BROTLI_ENCODE: 9,\n  Z_MIN_WINDOWBITS: 8,\n  Z_MAX_WINDOWBITS: 15,\n  Z_DEFAULT_WINDOWBITS: 15,\n  Z_MIN_CHUNK: 64,\n  Z_MAX_CHUNK: Infinity,\n  Z_DEFAULT_CHUNK: 16384,\n  Z_MIN_MEMLEVEL: 1,\n  Z_MAX_MEMLEVEL: 9,\n  Z_DEFAULT_MEMLEVEL: 8,\n  Z_MIN_LEVEL: -1,\n  Z_MAX_LEVEL: 9,\n  Z_DEFAULT_LEVEL: -1,\n  BROTLI_OPERATION_PROCESS: 0,\n  BROTLI_OPERATION_FLUSH: 1,\n  BROTLI_OPERATION_FINISH: 2,\n  BROTLI_OPERATION_EMIT_METADATA: 3,\n  BROTLI_MODE_GENERIC: 0,\n  BROTLI_MODE_TEXT: 1,\n  BROTLI_MODE_FONT: 2,\n  BROTLI_DEFAULT_MODE: 0,\n  BROTLI_MIN_QUALITY: 0,\n  BROTLI_MAX_QUALITY: 11,\n  BROTLI_DEFAULT_QUALITY: 11,\n  BROTLI_MIN_WINDOW_BITS: 10,\n  BROTLI_MAX_WINDOW_BITS: 24,\n  BROTLI_LARGE_MAX_WINDOW_BITS: 30,\n  BROTLI_DEFAULT_WINDOW: 22,\n  BROTLI_MIN_INPUT_BLOCK_BITS: 16,\n  BROTLI_MAX_INPUT_BLOCK_BITS: 24,\n  BROTLI_PARAM_MODE: 0,\n  BROTLI_PARAM_QUALITY: 1,\n  BROTLI_PARAM_LGWIN: 2,\n  BROTLI_PARAM_LGBLOCK: 3,\n  BROTLI_PARAM_DISABLE_LITERAL_CONTEXT_MODELING: 4,\n  BROTLI_PARAM_SIZE_HINT: 5,\n  BROTLI_PARAM_LARGE_WINDOW: 6,\n  BROTLI_PARAM_NPOSTFIX: 7,\n  BROTLI_PARAM_NDIRECT: 8,\n  BROTLI_DECODER_RESULT_ERROR: 0,\n  BROTLI_DECODER_RESULT_SUCCESS: 1,\n  BROTLI_DECODER_RESULT_NEEDS_MORE_INPUT: 2,\n  BROTLI_DECODER_RESULT_NEEDS_MORE_OUTPUT: 3,\n  BROTLI_DECODER_PARAM_DISABLE_RING_BUFFER_REALLOCATION: 0,\n  BROTLI_DECODER_PARAM_LARGE_WINDOW: 1,\n  BROTLI_DECODER_NO_ERROR: 0,\n  BROTLI_DECODER_SUCCESS: 1,\n  BROTLI_DECODER_NEEDS_MORE_INPUT: 2,\n  BROTLI_DECODER_NEEDS_MORE_OUTPUT: 3,\n  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_NIBBLE: -1,\n  BROTLI_DECODER_ERROR_FORMAT_RESERVED: -2,\n  BROTLI_DECODER_ERROR_FORMAT_EXUBERANT_META_NIBBLE: -3,\n  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_ALPHABET: -4,\n  BROTLI_DECODER_ERROR_FORMAT_SIMPLE_HUFFMAN_SAME: -5,\n  BROTLI_DECODER_ERROR_FORMAT_CL_SPACE: -6,\n  BROTLI_DECODER_ERROR_FORMAT_HUFFMAN_SPACE: -7,\n  BROTLI_DECODER_ERROR_FORMAT_CONTEXT_MAP_REPEAT: -8,\n  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_1: -9,\n  BROTLI_DECODER_ERROR_FORMAT_BLOCK_LENGTH_2: -10,\n  BROTLI_DECODER_ERROR_FORMAT_TRANSFORM: -11,\n  BROTLI_DECODER_ERROR_FORMAT_DICTIONARY: -12,\n  BROTLI_DECODER_ERROR_FORMAT_WINDOW_BITS: -13,\n  BROTLI_DECODER_ERROR_FORMAT_PADDING_1: -14,\n  BROTLI_DECODER_ERROR_FORMAT_PADDING_2: -15,\n  BROTLI_DECODER_ERROR_FORMAT_DISTANCE: -16,\n  BROTLI_DECODER_ERROR_DICTIONARY_NOT_SET: -19,\n  BROTLI_DECODER_ERROR_INVALID_ARGUMENTS: -20,\n  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MODES: -21,\n  BROTLI_DECODER_ERROR_ALLOC_TREE_GROUPS: -22,\n  BROTLI_DECODER_ERROR_ALLOC_CONTEXT_MAP: -25,\n  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_1: -26,\n  BROTLI_DECODER_ERROR_ALLOC_RING_BUFFER_2: -27,\n  BROTLI_DECODER_ERROR_ALLOC_BLOCK_TYPE_TREES: -30,\n  BROTLI_DECODER_ERROR_UNREACHABLE: -31,\n}, realZlibConstants))\n\n\n//# sourceURL=webpack://thelambda/./node_modules/minizlib/constants.js?");

/***/ }),

/***/ "./node_modules/minizlib/index.js":
/*!****************************************!*\
  !*** ./node_modules/minizlib/index.js ***!
  \****************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\nconst assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst Buffer = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())\nconst realZlib = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'zlib'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\n\nconst constants = exports.constants = __webpack_require__(/*! ./constants.js */ \"./node_modules/minizlib/constants.js\")\nconst Minipass = __webpack_require__(/*! minipass */ \"./node_modules/minizlib/node_modules/minipass/index.js\")\n\nconst OriginalBufferConcat = Buffer.concat\n\nconst _superWrite = Symbol('_superWrite')\nclass ZlibError extends Error {\n  constructor (err) {\n    super('zlib: ' + err.message)\n    this.code = err.code\n    this.errno = err.errno\n    /* istanbul ignore if */\n    if (!this.code)\n      this.code = 'ZLIB_ERROR'\n\n    this.message = 'zlib: ' + err.message\n    Error.captureStackTrace(this, this.constructor)\n  }\n\n  get name () {\n    return 'ZlibError'\n  }\n}\n\n// the Zlib class they all inherit from\n// This thing manages the queue of requests, and returns\n// true or false if there is anything in the queue when\n// you call the .write() method.\nconst _opts = Symbol('opts')\nconst _flushFlag = Symbol('flushFlag')\nconst _finishFlushFlag = Symbol('finishFlushFlag')\nconst _fullFlushFlag = Symbol('fullFlushFlag')\nconst _handle = Symbol('handle')\nconst _onError = Symbol('onError')\nconst _sawError = Symbol('sawError')\nconst _level = Symbol('level')\nconst _strategy = Symbol('strategy')\nconst _ended = Symbol('ended')\nconst _defaultFullFlush = Symbol('_defaultFullFlush')\n\nclass ZlibBase extends Minipass {\n  constructor (opts, mode) {\n    if (!opts || typeof opts !== 'object')\n      throw new TypeError('invalid options for ZlibBase constructor')\n\n    super(opts)\n    this[_sawError] = false\n    this[_ended] = false\n    this[_opts] = opts\n\n    this[_flushFlag] = opts.flush\n    this[_finishFlushFlag] = opts.finishFlush\n    // this will throw if any options are invalid for the class selected\n    try {\n      this[_handle] = new realZlib[mode](opts)\n    } catch (er) {\n      // make sure that all errors get decorated properly\n      throw new ZlibError(er)\n    }\n\n    this[_onError] = (err) => {\n      // no sense raising multiple errors, since we abort on the first one.\n      if (this[_sawError])\n        return\n\n      this[_sawError] = true\n\n      // there is no way to cleanly recover.\n      // continuing only obscures problems.\n      this.close()\n      this.emit('error', err)\n    }\n\n    this[_handle].on('error', er => this[_onError](new ZlibError(er)))\n    this.once('end', () => this.close)\n  }\n\n  close () {\n    if (this[_handle]) {\n      this[_handle].close()\n      this[_handle] = null\n      this.emit('close')\n    }\n  }\n\n  reset () {\n    if (!this[_sawError]) {\n      assert(this[_handle], 'zlib binding closed')\n      return this[_handle].reset()\n    }\n  }\n\n  flush (flushFlag) {\n    if (this.ended)\n      return\n\n    if (typeof flushFlag !== 'number')\n      flushFlag = this[_fullFlushFlag]\n    this.write(Object.assign(Buffer.alloc(0), { [_flushFlag]: flushFlag }))\n  }\n\n  end (chunk, encoding, cb) {\n    if (chunk)\n      this.write(chunk, encoding)\n    this.flush(this[_finishFlushFlag])\n    this[_ended] = true\n    return super.end(null, null, cb)\n  }\n\n  get ended () {\n    return this[_ended]\n  }\n\n  write (chunk, encoding, cb) {\n    // process the chunk using the sync process\n    // then super.write() all the outputted chunks\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n\n    if (typeof chunk === 'string')\n      chunk = Buffer.from(chunk, encoding)\n\n    if (this[_sawError])\n      return\n    assert(this[_handle], 'zlib binding closed')\n\n    // _processChunk tries to .close() the native handle after it's done, so we\n    // intercept that by temporarily making it a no-op.\n    const nativeHandle = this[_handle]._handle\n    const originalNativeClose = nativeHandle.close\n    nativeHandle.close = () => {}\n    const originalClose = this[_handle].close\n    this[_handle].close = () => {}\n    // It also calls `Buffer.concat()` at the end, which may be convenient\n    // for some, but which we are not interested in as it slows us down.\n    Buffer.concat = (args) => args\n    let result\n    try {\n      const flushFlag = typeof chunk[_flushFlag] === 'number'\n        ? chunk[_flushFlag] : this[_flushFlag]\n      result = this[_handle]._processChunk(chunk, flushFlag)\n      // if we don't throw, reset it back how it was\n      Buffer.concat = OriginalBufferConcat\n    } catch (err) {\n      // or if we do, put Buffer.concat() back before we emit error\n      // Error events call into user code, which may call Buffer.concat()\n      Buffer.concat = OriginalBufferConcat\n      this[_onError](new ZlibError(err))\n    } finally {\n      if (this[_handle]) {\n        // Core zlib resets `_handle` to null after attempting to close the\n        // native handle. Our no-op handler prevented actual closure, but we\n        // need to restore the `._handle` property.\n        this[_handle]._handle = nativeHandle\n        nativeHandle.close = originalNativeClose\n        this[_handle].close = originalClose\n        // `_processChunk()` adds an 'error' listener. If we don't remove it\n        // after each call, these handlers start piling up.\n        this[_handle].removeAllListeners('error')\n        // make sure OUR error listener is still attached tho\n      }\n    }\n\n    if (this[_handle])\n      this[_handle].on('error', er => this[_onError](new ZlibError(er)))\n\n    let writeReturn\n    if (result) {\n      if (Array.isArray(result) && result.length > 0) {\n        // The first buffer is always `handle._outBuffer`, which would be\n        // re-used for later invocations; so, we always have to copy that one.\n        writeReturn = this[_superWrite](Buffer.from(result[0]))\n        for (let i = 1; i < result.length; i++) {\n          writeReturn = this[_superWrite](result[i])\n        }\n      } else {\n        writeReturn = this[_superWrite](Buffer.from(result))\n      }\n    }\n\n    if (cb)\n      cb()\n    return writeReturn\n  }\n\n  [_superWrite] (data) {\n    return super.write(data)\n  }\n}\n\nclass Zlib extends ZlibBase {\n  constructor (opts, mode) {\n    opts = opts || {}\n\n    opts.flush = opts.flush || constants.Z_NO_FLUSH\n    opts.finishFlush = opts.finishFlush || constants.Z_FINISH\n    super(opts, mode)\n\n    this[_fullFlushFlag] = constants.Z_FULL_FLUSH\n    this[_level] = opts.level\n    this[_strategy] = opts.strategy\n  }\n\n  params (level, strategy) {\n    if (this[_sawError])\n      return\n\n    if (!this[_handle])\n      throw new Error('cannot switch params when binding is closed')\n\n    // no way to test this without also not supporting params at all\n    /* istanbul ignore if */\n    if (!this[_handle].params)\n      throw new Error('not supported in this implementation')\n\n    if (this[_level] !== level || this[_strategy] !== strategy) {\n      this.flush(constants.Z_SYNC_FLUSH)\n      assert(this[_handle], 'zlib binding closed')\n      // .params() calls .flush(), but the latter is always async in the\n      // core zlib. We override .flush() temporarily to intercept that and\n      // flush synchronously.\n      const origFlush = this[_handle].flush\n      this[_handle].flush = (flushFlag, cb) => {\n        this.flush(flushFlag)\n        cb()\n      }\n      try {\n        this[_handle].params(level, strategy)\n      } finally {\n        this[_handle].flush = origFlush\n      }\n      /* istanbul ignore else */\n      if (this[_handle]) {\n        this[_level] = level\n        this[_strategy] = strategy\n      }\n    }\n  }\n}\n\n// minimal 2-byte header\nclass Deflate extends Zlib {\n  constructor (opts) {\n    super(opts, 'Deflate')\n  }\n}\n\nclass Inflate extends Zlib {\n  constructor (opts) {\n    super(opts, 'Inflate')\n  }\n}\n\n// gzip - bigger header, same deflate compression\nconst _portable = Symbol('_portable')\nclass Gzip extends Zlib {\n  constructor (opts) {\n    super(opts, 'Gzip')\n    this[_portable] = opts && !!opts.portable\n  }\n\n  [_superWrite] (data) {\n    if (!this[_portable])\n      return super[_superWrite](data)\n\n    // we'll always get the header emitted in one first chunk\n    // overwrite the OS indicator byte with 0xFF\n    this[_portable] = false\n    data[9] = 255\n    return super[_superWrite](data)\n  }\n}\n\nclass Gunzip extends Zlib {\n  constructor (opts) {\n    super(opts, 'Gunzip')\n  }\n}\n\n// raw - no header\nclass DeflateRaw extends Zlib {\n  constructor (opts) {\n    super(opts, 'DeflateRaw')\n  }\n}\n\nclass InflateRaw extends Zlib {\n  constructor (opts) {\n    super(opts, 'InflateRaw')\n  }\n}\n\n// auto-detect header.\nclass Unzip extends Zlib {\n  constructor (opts) {\n    super(opts, 'Unzip')\n  }\n}\n\nclass Brotli extends ZlibBase {\n  constructor (opts, mode) {\n    opts = opts || {}\n\n    opts.flush = opts.flush || constants.BROTLI_OPERATION_PROCESS\n    opts.finishFlush = opts.finishFlush || constants.BROTLI_OPERATION_FINISH\n\n    super(opts, mode)\n\n    this[_fullFlushFlag] = constants.BROTLI_OPERATION_FLUSH\n  }\n}\n\nclass BrotliCompress extends Brotli {\n  constructor (opts) {\n    super(opts, 'BrotliCompress')\n  }\n}\n\nclass BrotliDecompress extends Brotli {\n  constructor (opts) {\n    super(opts, 'BrotliDecompress')\n  }\n}\n\nexports.Deflate = Deflate\nexports.Inflate = Inflate\nexports.Gzip = Gzip\nexports.Gunzip = Gunzip\nexports.DeflateRaw = DeflateRaw\nexports.InflateRaw = InflateRaw\nexports.Unzip = Unzip\n/* istanbul ignore else */\nif (typeof realZlib.BrotliCompress === 'function') {\n  exports.BrotliCompress = BrotliCompress\n  exports.BrotliDecompress = BrotliDecompress\n} else {\n  exports.BrotliCompress = exports.BrotliDecompress = class {\n    constructor () {\n      throw new Error('Brotli is not supported in this version of Node.js')\n    }\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/minizlib/index.js?");

/***/ }),

/***/ "./node_modules/minizlib/node_modules/minipass/index.js":
/*!**************************************************************!*\
  !*** ./node_modules/minizlib/node_modules/minipass/index.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst proc = typeof process === 'object' && process ? process : {\n  stdout: null,\n  stderr: null,\n}\nconst EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst Stream = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst SD = (__webpack_require__(/*! string_decoder */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder)\n\nconst EOF = Symbol('EOF')\nconst MAYBE_EMIT_END = Symbol('maybeEmitEnd')\nconst EMITTED_END = Symbol('emittedEnd')\nconst EMITTING_END = Symbol('emittingEnd')\nconst EMITTED_ERROR = Symbol('emittedError')\nconst CLOSED = Symbol('closed')\nconst READ = Symbol('read')\nconst FLUSH = Symbol('flush')\nconst FLUSHCHUNK = Symbol('flushChunk')\nconst ENCODING = Symbol('encoding')\nconst DECODER = Symbol('decoder')\nconst FLOWING = Symbol('flowing')\nconst PAUSED = Symbol('paused')\nconst RESUME = Symbol('resume')\nconst BUFFERLENGTH = Symbol('bufferLength')\nconst BUFFERPUSH = Symbol('bufferPush')\nconst BUFFERSHIFT = Symbol('bufferShift')\nconst OBJECTMODE = Symbol('objectMode')\nconst DESTROYED = Symbol('destroyed')\nconst EMITDATA = Symbol('emitData')\nconst EMITEND = Symbol('emitEnd')\nconst EMITEND2 = Symbol('emitEnd2')\nconst ASYNC = Symbol('async')\n\nconst defer = fn => Promise.resolve().then(fn)\n\n// TODO remove when Node v8 support drops\nconst doIter = __webpack_require__.g._MP_NO_ITERATOR_SYMBOLS_  !== '1'\nconst ASYNCITERATOR = doIter && Symbol.asyncIterator\n  || Symbol('asyncIterator not implemented')\nconst ITERATOR = doIter && Symbol.iterator\n  || Symbol('iterator not implemented')\n\n// events that mean 'the stream is over'\n// these are treated specially, and re-emitted\n// if they are listened for after emitting.\nconst isEndish = ev =>\n  ev === 'end' ||\n  ev === 'finish' ||\n  ev === 'prefinish'\n\nconst isArrayBuffer = b => b instanceof ArrayBuffer ||\n  typeof b === 'object' &&\n  b.constructor &&\n  b.constructor.name === 'ArrayBuffer' &&\n  b.byteLength >= 0\n\nconst isArrayBufferView = b => !Buffer.isBuffer(b) && ArrayBuffer.isView(b)\n\nclass Pipe {\n  constructor (src, dest, opts) {\n    this.src = src\n    this.dest = dest\n    this.opts = opts\n    this.ondrain = () => src[RESUME]()\n    dest.on('drain', this.ondrain)\n  }\n  unpipe () {\n    this.dest.removeListener('drain', this.ondrain)\n  }\n  // istanbul ignore next - only here for the prototype\n  proxyErrors () {}\n  end () {\n    this.unpipe()\n    if (this.opts.end)\n      this.dest.end()\n  }\n}\n\nclass PipeProxyErrors extends Pipe {\n  unpipe () {\n    this.src.removeListener('error', this.proxyErrors)\n    super.unpipe()\n  }\n  constructor (src, dest, opts) {\n    super(src, dest, opts)\n    this.proxyErrors = er => dest.emit('error', er)\n    src.on('error', this.proxyErrors)\n  }\n}\n\nmodule.exports = class Minipass extends Stream {\n  constructor (options) {\n    super()\n    this[FLOWING] = false\n    // whether we're explicitly paused\n    this[PAUSED] = false\n    this.pipes = []\n    this.buffer = []\n    this[OBJECTMODE] = options && options.objectMode || false\n    if (this[OBJECTMODE])\n      this[ENCODING] = null\n    else\n      this[ENCODING] = options && options.encoding || null\n    if (this[ENCODING] === 'buffer')\n      this[ENCODING] = null\n    this[ASYNC] = options && !!options.async || false\n    this[DECODER] = this[ENCODING] ? new SD(this[ENCODING]) : null\n    this[EOF] = false\n    this[EMITTED_END] = false\n    this[EMITTING_END] = false\n    this[CLOSED] = false\n    this[EMITTED_ERROR] = null\n    this.writable = true\n    this.readable = true\n    this[BUFFERLENGTH] = 0\n    this[DESTROYED] = false\n  }\n\n  get bufferLength () { return this[BUFFERLENGTH] }\n\n  get encoding () { return this[ENCODING] }\n  set encoding (enc) {\n    if (this[OBJECTMODE])\n      throw new Error('cannot set encoding in objectMode')\n\n    if (this[ENCODING] && enc !== this[ENCODING] &&\n        (this[DECODER] && this[DECODER].lastNeed || this[BUFFERLENGTH]))\n      throw new Error('cannot change encoding')\n\n    if (this[ENCODING] !== enc) {\n      this[DECODER] = enc ? new SD(enc) : null\n      if (this.buffer.length)\n        this.buffer = this.buffer.map(chunk => this[DECODER].write(chunk))\n    }\n\n    this[ENCODING] = enc\n  }\n\n  setEncoding (enc) {\n    this.encoding = enc\n  }\n\n  get objectMode () { return this[OBJECTMODE] }\n  set objectMode (om) { this[OBJECTMODE] = this[OBJECTMODE] || !!om }\n\n  get ['async'] () { return this[ASYNC] }\n  set ['async'] (a) { this[ASYNC] = this[ASYNC] || !!a }\n\n  write (chunk, encoding, cb) {\n    if (this[EOF])\n      throw new Error('write after end')\n\n    if (this[DESTROYED]) {\n      this.emit('error', Object.assign(\n        new Error('Cannot call write after a stream was destroyed'),\n        { code: 'ERR_STREAM_DESTROYED' }\n      ))\n      return true\n    }\n\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n\n    if (!encoding)\n      encoding = 'utf8'\n\n    const fn = this[ASYNC] ? defer : f => f()\n\n    // convert array buffers and typed array views into buffers\n    // at some point in the future, we may want to do the opposite!\n    // leave strings and buffers as-is\n    // anything else switches us into object mode\n    if (!this[OBJECTMODE] && !Buffer.isBuffer(chunk)) {\n      if (isArrayBufferView(chunk))\n        chunk = Buffer.from(chunk.buffer, chunk.byteOffset, chunk.byteLength)\n      else if (isArrayBuffer(chunk))\n        chunk = Buffer.from(chunk)\n      else if (typeof chunk !== 'string')\n        // use the setter so we throw if we have encoding set\n        this.objectMode = true\n    }\n\n    // handle object mode up front, since it's simpler\n    // this yields better performance, fewer checks later.\n    if (this[OBJECTMODE]) {\n      /* istanbul ignore if - maybe impossible? */\n      if (this.flowing && this[BUFFERLENGTH] !== 0)\n        this[FLUSH](true)\n\n      if (this.flowing)\n        this.emit('data', chunk)\n      else\n        this[BUFFERPUSH](chunk)\n\n      if (this[BUFFERLENGTH] !== 0)\n        this.emit('readable')\n\n      if (cb)\n        fn(cb)\n\n      return this.flowing\n    }\n\n    // at this point the chunk is a buffer or string\n    // don't buffer it up or send it to the decoder\n    if (!chunk.length) {\n      if (this[BUFFERLENGTH] !== 0)\n        this.emit('readable')\n      if (cb)\n        fn(cb)\n      return this.flowing\n    }\n\n    // fast-path writing strings of same encoding to a stream with\n    // an empty buffer, skipping the buffer/decoder dance\n    if (typeof chunk === 'string' &&\n        // unless it is a string already ready for us to use\n        !(encoding === this[ENCODING] && !this[DECODER].lastNeed)) {\n      chunk = Buffer.from(chunk, encoding)\n    }\n\n    if (Buffer.isBuffer(chunk) && this[ENCODING])\n      chunk = this[DECODER].write(chunk)\n\n    // Note: flushing CAN potentially switch us into not-flowing mode\n    if (this.flowing && this[BUFFERLENGTH] !== 0)\n      this[FLUSH](true)\n\n    if (this.flowing)\n      this.emit('data', chunk)\n    else\n      this[BUFFERPUSH](chunk)\n\n    if (this[BUFFERLENGTH] !== 0)\n      this.emit('readable')\n\n    if (cb)\n      fn(cb)\n\n    return this.flowing\n  }\n\n  read (n) {\n    if (this[DESTROYED])\n      return null\n\n    if (this[BUFFERLENGTH] === 0 || n === 0 || n > this[BUFFERLENGTH]) {\n      this[MAYBE_EMIT_END]()\n      return null\n    }\n\n    if (this[OBJECTMODE])\n      n = null\n\n    if (this.buffer.length > 1 && !this[OBJECTMODE]) {\n      if (this.encoding)\n        this.buffer = [this.buffer.join('')]\n      else\n        this.buffer = [Buffer.concat(this.buffer, this[BUFFERLENGTH])]\n    }\n\n    const ret = this[READ](n || null, this.buffer[0])\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [READ] (n, chunk) {\n    if (n === chunk.length || n === null)\n      this[BUFFERSHIFT]()\n    else {\n      this.buffer[0] = chunk.slice(n)\n      chunk = chunk.slice(0, n)\n      this[BUFFERLENGTH] -= n\n    }\n\n    this.emit('data', chunk)\n\n    if (!this.buffer.length && !this[EOF])\n      this.emit('drain')\n\n    return chunk\n  }\n\n  end (chunk, encoding, cb) {\n    if (typeof chunk === 'function')\n      cb = chunk, chunk = null\n    if (typeof encoding === 'function')\n      cb = encoding, encoding = 'utf8'\n    if (chunk)\n      this.write(chunk, encoding)\n    if (cb)\n      this.once('end', cb)\n    this[EOF] = true\n    this.writable = false\n\n    // if we haven't written anything, then go ahead and emit,\n    // even if we're not reading.\n    // we'll re-emit if a new 'end' listener is added anyway.\n    // This makes MP more suitable to write-only use cases.\n    if (this.flowing || !this[PAUSED])\n      this[MAYBE_EMIT_END]()\n    return this\n  }\n\n  // don't let the internal resume be overwritten\n  [RESUME] () {\n    if (this[DESTROYED])\n      return\n\n    this[PAUSED] = false\n    this[FLOWING] = true\n    this.emit('resume')\n    if (this.buffer.length)\n      this[FLUSH]()\n    else if (this[EOF])\n      this[MAYBE_EMIT_END]()\n    else\n      this.emit('drain')\n  }\n\n  resume () {\n    return this[RESUME]()\n  }\n\n  pause () {\n    this[FLOWING] = false\n    this[PAUSED] = true\n  }\n\n  get destroyed () {\n    return this[DESTROYED]\n  }\n\n  get flowing () {\n    return this[FLOWING]\n  }\n\n  get paused () {\n    return this[PAUSED]\n  }\n\n  [BUFFERPUSH] (chunk) {\n    if (this[OBJECTMODE])\n      this[BUFFERLENGTH] += 1\n    else\n      this[BUFFERLENGTH] += chunk.length\n    this.buffer.push(chunk)\n  }\n\n  [BUFFERSHIFT] () {\n    if (this.buffer.length) {\n      if (this[OBJECTMODE])\n        this[BUFFERLENGTH] -= 1\n      else\n        this[BUFFERLENGTH] -= this.buffer[0].length\n    }\n    return this.buffer.shift()\n  }\n\n  [FLUSH] (noDrain) {\n    do {} while (this[FLUSHCHUNK](this[BUFFERSHIFT]()))\n\n    if (!noDrain && !this.buffer.length && !this[EOF])\n      this.emit('drain')\n  }\n\n  [FLUSHCHUNK] (chunk) {\n    return chunk ? (this.emit('data', chunk), this.flowing) : false\n  }\n\n  pipe (dest, opts) {\n    if (this[DESTROYED])\n      return\n\n    const ended = this[EMITTED_END]\n    opts = opts || {}\n    if (dest === proc.stdout || dest === proc.stderr)\n      opts.end = false\n    else\n      opts.end = opts.end !== false\n    opts.proxyErrors = !!opts.proxyErrors\n\n    // piping an ended stream ends immediately\n    if (ended) {\n      if (opts.end)\n        dest.end()\n    } else {\n      this.pipes.push(!opts.proxyErrors ? new Pipe(this, dest, opts)\n        : new PipeProxyErrors(this, dest, opts))\n      if (this[ASYNC])\n        defer(() => this[RESUME]())\n      else\n        this[RESUME]()\n    }\n\n    return dest\n  }\n\n  unpipe (dest) {\n    const p = this.pipes.find(p => p.dest === dest)\n    if (p) {\n      this.pipes.splice(this.pipes.indexOf(p), 1)\n      p.unpipe()\n    }\n  }\n\n  addListener (ev, fn) {\n    return this.on(ev, fn)\n  }\n\n  on (ev, fn) {\n    const ret = super.on(ev, fn)\n    if (ev === 'data' && !this.pipes.length && !this.flowing)\n      this[RESUME]()\n    else if (ev === 'readable' && this[BUFFERLENGTH] !== 0)\n      super.emit('readable')\n    else if (isEndish(ev) && this[EMITTED_END]) {\n      super.emit(ev)\n      this.removeAllListeners(ev)\n    } else if (ev === 'error' && this[EMITTED_ERROR]) {\n      if (this[ASYNC])\n        defer(() => fn.call(this, this[EMITTED_ERROR]))\n      else\n        fn.call(this, this[EMITTED_ERROR])\n    }\n    return ret\n  }\n\n  get emittedEnd () {\n    return this[EMITTED_END]\n  }\n\n  [MAYBE_EMIT_END] () {\n    if (!this[EMITTING_END] &&\n        !this[EMITTED_END] &&\n        !this[DESTROYED] &&\n        this.buffer.length === 0 &&\n        this[EOF]) {\n      this[EMITTING_END] = true\n      this.emit('end')\n      this.emit('prefinish')\n      this.emit('finish')\n      if (this[CLOSED])\n        this.emit('close')\n      this[EMITTING_END] = false\n    }\n  }\n\n  emit (ev, data, ...extra) {\n    // error and close are only events allowed after calling destroy()\n    if (ev !== 'error' && ev !== 'close' && ev !== DESTROYED && this[DESTROYED])\n      return\n    else if (ev === 'data') {\n      return !data ? false\n        : this[ASYNC] ? defer(() => this[EMITDATA](data))\n        : this[EMITDATA](data)\n    } else if (ev === 'end') {\n      return this[EMITEND]()\n    } else if (ev === 'close') {\n      this[CLOSED] = true\n      // don't emit close before 'end' and 'finish'\n      if (!this[EMITTED_END] && !this[DESTROYED])\n        return\n      const ret = super.emit('close')\n      this.removeAllListeners('close')\n      return ret\n    } else if (ev === 'error') {\n      this[EMITTED_ERROR] = data\n      const ret = super.emit('error', data)\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'resume') {\n      const ret = super.emit('resume')\n      this[MAYBE_EMIT_END]()\n      return ret\n    } else if (ev === 'finish' || ev === 'prefinish') {\n      const ret = super.emit(ev)\n      this.removeAllListeners(ev)\n      return ret\n    }\n\n    // Some other unknown event\n    const ret = super.emit(ev, data, ...extra)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITDATA] (data) {\n    for (const p of this.pipes) {\n      if (p.dest.write(data) === false)\n        this.pause()\n    }\n    const ret = super.emit('data', data)\n    this[MAYBE_EMIT_END]()\n    return ret\n  }\n\n  [EMITEND] () {\n    if (this[EMITTED_END])\n      return\n\n    this[EMITTED_END] = true\n    this.readable = false\n    if (this[ASYNC])\n      defer(() => this[EMITEND2]())\n    else\n      this[EMITEND2]()\n  }\n\n  [EMITEND2] () {\n    if (this[DECODER]) {\n      const data = this[DECODER].end()\n      if (data) {\n        for (const p of this.pipes) {\n          p.dest.write(data)\n        }\n        super.emit('data', data)\n      }\n    }\n\n    for (const p of this.pipes) {\n      p.end()\n    }\n    const ret = super.emit('end')\n    this.removeAllListeners('end')\n    return ret\n  }\n\n  // const all = await stream.collect()\n  collect () {\n    const buf = []\n    if (!this[OBJECTMODE])\n      buf.dataLength = 0\n    // set the promise first, in case an error is raised\n    // by triggering the flow here.\n    const p = this.promise()\n    this.on('data', c => {\n      buf.push(c)\n      if (!this[OBJECTMODE])\n        buf.dataLength += c.length\n    })\n    return p.then(() => buf)\n  }\n\n  // const data = await stream.concat()\n  concat () {\n    return this[OBJECTMODE]\n      ? Promise.reject(new Error('cannot concat in objectMode'))\n      : this.collect().then(buf =>\n          this[OBJECTMODE]\n            ? Promise.reject(new Error('cannot concat in objectMode'))\n            : this[ENCODING] ? buf.join('') : Buffer.concat(buf, buf.dataLength))\n  }\n\n  // stream.promise().then(() => done, er => emitted error)\n  promise () {\n    return new Promise((resolve, reject) => {\n      this.on(DESTROYED, () => reject(new Error('stream destroyed')))\n      this.on('error', er => reject(er))\n      this.on('end', () => resolve())\n    })\n  }\n\n  // for await (let chunk of stream)\n  [ASYNCITERATOR] () {\n    const next = () => {\n      const res = this.read()\n      if (res !== null)\n        return Promise.resolve({ done: false, value: res })\n\n      if (this[EOF])\n        return Promise.resolve({ done: true })\n\n      let resolve = null\n      let reject = null\n      const onerr = er => {\n        this.removeListener('data', ondata)\n        this.removeListener('end', onend)\n        reject(er)\n      }\n      const ondata = value => {\n        this.removeListener('error', onerr)\n        this.removeListener('end', onend)\n        this.pause()\n        resolve({ value: value, done: !!this[EOF] })\n      }\n      const onend = () => {\n        this.removeListener('error', onerr)\n        this.removeListener('data', ondata)\n        resolve({ done: true })\n      }\n      const ondestroy = () => onerr(new Error('stream destroyed'))\n      return new Promise((res, rej) => {\n        reject = rej\n        resolve = res\n        this.once(DESTROYED, ondestroy)\n        this.once('error', onerr)\n        this.once('end', onend)\n        this.once('data', ondata)\n      })\n    }\n\n    return { next }\n  }\n\n  // for (let chunk of stream)\n  [ITERATOR] () {\n    const next = () => {\n      const value = this.read()\n      const done = value === null\n      return { value, done }\n    }\n    return { next }\n  }\n\n  destroy (er) {\n    if (this[DESTROYED]) {\n      if (er)\n        this.emit('error', er)\n      else\n        this.emit(DESTROYED)\n      return this\n    }\n\n    this[DESTROYED] = true\n\n    // throw away all buffered data, it's never coming out\n    this.buffer.length = 0\n    this[BUFFERLENGTH] = 0\n\n    if (typeof this.close === 'function' && !this[CLOSED])\n      this.close()\n\n    if (er)\n      this.emit('error', er)\n    else // if no error to emit, still reject pending promises\n      this.emit(DESTROYED)\n\n    return this\n  }\n\n  static isStream (s) {\n    return !!s && (s instanceof Minipass || s instanceof Stream ||\n      s instanceof EE && (\n        typeof s.pipe === 'function' || // readable\n        (typeof s.write === 'function' && typeof s.end === 'function') // writable\n      ))\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/minizlib/node_modules/minipass/index.js?");

/***/ }),

/***/ "./node_modules/mkdirp/index.js":
/*!**************************************!*\
  !*** ./node_modules/mkdirp/index.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const optsArg = __webpack_require__(/*! ./lib/opts-arg.js */ \"./node_modules/mkdirp/lib/opts-arg.js\")\nconst pathArg = __webpack_require__(/*! ./lib/path-arg.js */ \"./node_modules/mkdirp/lib/path-arg.js\")\n\nconst {mkdirpNative, mkdirpNativeSync} = __webpack_require__(/*! ./lib/mkdirp-native.js */ \"./node_modules/mkdirp/lib/mkdirp-native.js\")\nconst {mkdirpManual, mkdirpManualSync} = __webpack_require__(/*! ./lib/mkdirp-manual.js */ \"./node_modules/mkdirp/lib/mkdirp-manual.js\")\nconst {useNative, useNativeSync} = __webpack_require__(/*! ./lib/use-native.js */ \"./node_modules/mkdirp/lib/use-native.js\")\n\n\nconst mkdirp = (path, opts) => {\n  path = pathArg(path)\n  opts = optsArg(opts)\n  return useNative(opts)\n    ? mkdirpNative(path, opts)\n    : mkdirpManual(path, opts)\n}\n\nconst mkdirpSync = (path, opts) => {\n  path = pathArg(path)\n  opts = optsArg(opts)\n  return useNativeSync(opts)\n    ? mkdirpNativeSync(path, opts)\n    : mkdirpManualSync(path, opts)\n}\n\nmkdirp.sync = mkdirpSync\nmkdirp.native = (path, opts) => mkdirpNative(pathArg(path), optsArg(opts))\nmkdirp.manual = (path, opts) => mkdirpManual(pathArg(path), optsArg(opts))\nmkdirp.nativeSync = (path, opts) => mkdirpNativeSync(pathArg(path), optsArg(opts))\nmkdirp.manualSync = (path, opts) => mkdirpManualSync(pathArg(path), optsArg(opts))\n\nmodule.exports = mkdirp\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/index.js?");

/***/ }),

/***/ "./node_modules/mkdirp/lib/find-made.js":
/*!**********************************************!*\
  !*** ./node_modules/mkdirp/lib/find-made.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const {dirname} = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\nconst findMade = (opts, parent, path = undefined) => {\n  // we never want the 'made' return value to be a root directory\n  if (path === parent)\n    return Promise.resolve()\n\n  return opts.statAsync(parent).then(\n    st => st.isDirectory() ? path : undefined, // will fail later\n    er => er.code === 'ENOENT'\n      ? findMade(opts, dirname(parent), parent)\n      : undefined\n  )\n}\n\nconst findMadeSync = (opts, parent, path = undefined) => {\n  if (path === parent)\n    return undefined\n\n  try {\n    return opts.statSync(parent).isDirectory() ? path : undefined\n  } catch (er) {\n    return er.code === 'ENOENT'\n      ? findMadeSync(opts, dirname(parent), parent)\n      : undefined\n  }\n}\n\nmodule.exports = {findMade, findMadeSync}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/lib/find-made.js?");

/***/ }),

/***/ "./node_modules/mkdirp/lib/mkdirp-manual.js":
/*!**************************************************!*\
  !*** ./node_modules/mkdirp/lib/mkdirp-manual.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const {dirname} = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\nconst mkdirpManual = (path, opts, made) => {\n  opts.recursive = false\n  const parent = dirname(path)\n  if (parent === path) {\n    return opts.mkdirAsync(path, opts).catch(er => {\n      // swallowed by recursive implementation on posix systems\n      // any other error is a failure\n      if (er.code !== 'EISDIR')\n        throw er\n    })\n  }\n\n  return opts.mkdirAsync(path, opts).then(() => made || path, er => {\n    if (er.code === 'ENOENT')\n      return mkdirpManual(parent, opts)\n        .then(made => mkdirpManual(path, opts, made))\n    if (er.code !== 'EEXIST' && er.code !== 'EROFS')\n      throw er\n    return opts.statAsync(path).then(st => {\n      if (st.isDirectory())\n        return made\n      else\n        throw er\n    }, () => { throw er })\n  })\n}\n\nconst mkdirpManualSync = (path, opts, made) => {\n  const parent = dirname(path)\n  opts.recursive = false\n\n  if (parent === path) {\n    try {\n      return opts.mkdirSync(path, opts)\n    } catch (er) {\n      // swallowed by recursive implementation on posix systems\n      // any other error is a failure\n      if (er.code !== 'EISDIR')\n        throw er\n      else\n        return\n    }\n  }\n\n  try {\n    opts.mkdirSync(path, opts)\n    return made || path\n  } catch (er) {\n    if (er.code === 'ENOENT')\n      return mkdirpManualSync(path, opts, mkdirpManualSync(parent, opts, made))\n    if (er.code !== 'EEXIST' && er.code !== 'EROFS')\n      throw er\n    try {\n      if (!opts.statSync(path).isDirectory())\n        throw er\n    } catch (_) {\n      throw er\n    }\n  }\n}\n\nmodule.exports = {mkdirpManual, mkdirpManualSync}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/lib/mkdirp-manual.js?");

/***/ }),

/***/ "./node_modules/mkdirp/lib/mkdirp-native.js":
/*!**************************************************!*\
  !*** ./node_modules/mkdirp/lib/mkdirp-native.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const {dirname} = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst {findMade, findMadeSync} = __webpack_require__(/*! ./find-made.js */ \"./node_modules/mkdirp/lib/find-made.js\")\nconst {mkdirpManual, mkdirpManualSync} = __webpack_require__(/*! ./mkdirp-manual.js */ \"./node_modules/mkdirp/lib/mkdirp-manual.js\")\n\nconst mkdirpNative = (path, opts) => {\n  opts.recursive = true\n  const parent = dirname(path)\n  if (parent === path)\n    return opts.mkdirAsync(path, opts)\n\n  return findMade(opts, path).then(made =>\n    opts.mkdirAsync(path, opts).then(() => made)\n    .catch(er => {\n      if (er.code === 'ENOENT')\n        return mkdirpManual(path, opts)\n      else\n        throw er\n    }))\n}\n\nconst mkdirpNativeSync = (path, opts) => {\n  opts.recursive = true\n  const parent = dirname(path)\n  if (parent === path)\n    return opts.mkdirSync(path, opts)\n\n  const made = findMadeSync(opts, path)\n  try {\n    opts.mkdirSync(path, opts)\n    return made\n  } catch (er) {\n    if (er.code === 'ENOENT')\n      return mkdirpManualSync(path, opts)\n    else\n      throw er\n  }\n}\n\nmodule.exports = {mkdirpNative, mkdirpNativeSync}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/lib/mkdirp-native.js?");

/***/ }),

/***/ "./node_modules/mkdirp/lib/opts-arg.js":
/*!*********************************************!*\
  !*** ./node_modules/mkdirp/lib/opts-arg.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { promisify } = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\nconst fs = __webpack_require__(/*! fs */ \"?c311\")\nconst optsArg = opts => {\n  if (!opts)\n    opts = { mode: 0o777, fs }\n  else if (typeof opts === 'object')\n    opts = { mode: 0o777, fs, ...opts }\n  else if (typeof opts === 'number')\n    opts = { mode: opts, fs }\n  else if (typeof opts === 'string')\n    opts = { mode: parseInt(opts, 8), fs }\n  else\n    throw new TypeError('invalid options argument')\n\n  opts.mkdir = opts.mkdir || opts.fs.mkdir || fs.mkdir\n  opts.mkdirAsync = promisify(opts.mkdir)\n  opts.stat = opts.stat || opts.fs.stat || fs.stat\n  opts.statAsync = promisify(opts.stat)\n  opts.statSync = opts.statSync || opts.fs.statSync || fs.statSync\n  opts.mkdirSync = opts.mkdirSync || opts.fs.mkdirSync || fs.mkdirSync\n  return opts\n}\nmodule.exports = optsArg\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/lib/opts-arg.js?");

/***/ }),

/***/ "./node_modules/mkdirp/lib/path-arg.js":
/*!*********************************************!*\
  !*** ./node_modules/mkdirp/lib/path-arg.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const platform = process.env.__TESTING_MKDIRP_PLATFORM__ || process.platform\nconst { resolve, parse } = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst pathArg = path => {\n  if (/\\0/.test(path)) {\n    // simulate same failure that node raises\n    throw Object.assign(\n      new TypeError('path must be a string without null bytes'),\n      {\n        path,\n        code: 'ERR_INVALID_ARG_VALUE',\n      }\n    )\n  }\n\n  path = resolve(path)\n  if (platform === 'win32') {\n    const badWinChars = /[*|\"<>?:]/\n    const {root} = parse(path)\n    if (badWinChars.test(path.substr(root.length))) {\n      throw Object.assign(new Error('Illegal characters in path.'), {\n        path,\n        code: 'EINVAL',\n      })\n    }\n  }\n\n  return path\n}\nmodule.exports = pathArg\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/lib/path-arg.js?");

/***/ }),

/***/ "./node_modules/mkdirp/lib/use-native.js":
/*!***********************************************!*\
  !*** ./node_modules/mkdirp/lib/use-native.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const fs = __webpack_require__(/*! fs */ \"?c311\")\n\nconst version = process.env.__TESTING_MKDIRP_NODE_VERSION__ || process.version\nconst versArr = version.replace(/^v/, '').split('.')\nconst hasNative = +versArr[0] > 10 || +versArr[0] === 10 && +versArr[1] >= 12\n\nconst useNative = !hasNative ? () => false : opts => opts.mkdir === fs.mkdir\nconst useNativeSync = !hasNative ? () => false : opts => opts.mkdirSync === fs.mkdirSync\n\nmodule.exports = {useNative, useNativeSync}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/mkdirp/lib/use-native.js?");

/***/ }),

/***/ "./node_modules/ms/index.js":
/*!**********************************!*\
  !*** ./node_modules/ms/index.js ***!
  \**********************************/
/***/ ((module) => {

eval("/**\n * Helpers.\n */\n\nvar s = 1000;\nvar m = s * 60;\nvar h = m * 60;\nvar d = h * 24;\nvar w = d * 7;\nvar y = d * 365.25;\n\n/**\n * Parse or format the given `val`.\n *\n * Options:\n *\n *  - `long` verbose formatting [false]\n *\n * @param {String|Number} val\n * @param {Object} [options]\n * @throws {Error} throw an error if val is not a non-empty string or a number\n * @return {String|Number}\n * @api public\n */\n\nmodule.exports = function(val, options) {\n  options = options || {};\n  var type = typeof val;\n  if (type === 'string' && val.length > 0) {\n    return parse(val);\n  } else if (type === 'number' && isFinite(val)) {\n    return options.long ? fmtLong(val) : fmtShort(val);\n  }\n  throw new Error(\n    'val is not a non-empty string or a valid number. val=' +\n      JSON.stringify(val)\n  );\n};\n\n/**\n * Parse the given `str` and return milliseconds.\n *\n * @param {String} str\n * @return {Number}\n * @api private\n */\n\nfunction parse(str) {\n  str = String(str);\n  if (str.length > 100) {\n    return;\n  }\n  var match = /^(-?(?:\\d+)?\\.?\\d+) *(milliseconds?|msecs?|ms|seconds?|secs?|s|minutes?|mins?|m|hours?|hrs?|h|days?|d|weeks?|w|years?|yrs?|y)?$/i.exec(\n    str\n  );\n  if (!match) {\n    return;\n  }\n  var n = parseFloat(match[1]);\n  var type = (match[2] || 'ms').toLowerCase();\n  switch (type) {\n    case 'years':\n    case 'year':\n    case 'yrs':\n    case 'yr':\n    case 'y':\n      return n * y;\n    case 'weeks':\n    case 'week':\n    case 'w':\n      return n * w;\n    case 'days':\n    case 'day':\n    case 'd':\n      return n * d;\n    case 'hours':\n    case 'hour':\n    case 'hrs':\n    case 'hr':\n    case 'h':\n      return n * h;\n    case 'minutes':\n    case 'minute':\n    case 'mins':\n    case 'min':\n    case 'm':\n      return n * m;\n    case 'seconds':\n    case 'second':\n    case 'secs':\n    case 'sec':\n    case 's':\n      return n * s;\n    case 'milliseconds':\n    case 'millisecond':\n    case 'msecs':\n    case 'msec':\n    case 'ms':\n      return n;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Short format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtShort(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return Math.round(ms / d) + 'd';\n  }\n  if (msAbs >= h) {\n    return Math.round(ms / h) + 'h';\n  }\n  if (msAbs >= m) {\n    return Math.round(ms / m) + 'm';\n  }\n  if (msAbs >= s) {\n    return Math.round(ms / s) + 's';\n  }\n  return ms + 'ms';\n}\n\n/**\n * Long format for `ms`.\n *\n * @param {Number} ms\n * @return {String}\n * @api private\n */\n\nfunction fmtLong(ms) {\n  var msAbs = Math.abs(ms);\n  if (msAbs >= d) {\n    return plural(ms, msAbs, d, 'day');\n  }\n  if (msAbs >= h) {\n    return plural(ms, msAbs, h, 'hour');\n  }\n  if (msAbs >= m) {\n    return plural(ms, msAbs, m, 'minute');\n  }\n  if (msAbs >= s) {\n    return plural(ms, msAbs, s, 'second');\n  }\n  return ms + ' ms';\n}\n\n/**\n * Pluralization helper.\n */\n\nfunction plural(ms, msAbs, n, name) {\n  var isPlural = msAbs >= n * 1.5;\n  return Math.round(ms / n) + ' ' + name + (isPlural ? 's' : '');\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/ms/index.js?");

/***/ }),

/***/ "./node_modules/node-fetch/browser.js":
/*!********************************************!*\
  !*** ./node_modules/node-fetch/browser.js ***!
  \********************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\n\n// ref: https://github.com/tc39/proposal-global\nvar getGlobal = function () {\n\t// the only reliable means to get the global object is\n\t// `Function('return this')()`\n\t// However, this causes CSP violations in Chrome apps.\n\tif (typeof self !== 'undefined') { return self; }\n\tif (typeof window !== 'undefined') { return window; }\n\tif (typeof __webpack_require__.g !== 'undefined') { return __webpack_require__.g; }\n\tthrow new Error('unable to locate global object');\n}\n\nvar globalObject = getGlobal();\n\nmodule.exports = exports = globalObject.fetch;\n\n// Needed for TypeScript and Webpack.\nif (globalObject.fetch) {\n\texports[\"default\"] = globalObject.fetch.bind(globalObject);\n}\n\nexports.Headers = globalObject.Headers;\nexports.Request = globalObject.Request;\nexports.Response = globalObject.Response;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/node-fetch/browser.js?");

/***/ }),

/***/ "./node_modules/nopt/lib/nopt.js":
/*!***************************************!*\
  !*** ./node_modules/nopt/lib/nopt.js ***!
  \***************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("// info about each config option.\n\nvar debug = process.env.DEBUG_NOPT || process.env.NOPT_DEBUG\n  ? function () { console.error.apply(console, arguments) }\n  : function () {}\n\nvar url = __webpack_require__(/*! url */ \"./node_modules/url/url.js\")\n  , path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n  , Stream = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'stream'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())\n  , abbrev = __webpack_require__(/*! abbrev */ \"./node_modules/abbrev/abbrev.js\")\n  , os = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'os'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\n\nmodule.exports = exports = nopt\nexports.clean = clean\n\nexports.typeDefs =\n  { String  : { type: String,  validate: validateString  }\n  , Boolean : { type: Boolean, validate: validateBoolean }\n  , url     : { type: url,     validate: validateUrl     }\n  , Number  : { type: Number,  validate: validateNumber  }\n  , path    : { type: path,    validate: validatePath    }\n  , Stream  : { type: Stream,  validate: validateStream  }\n  , Date    : { type: Date,    validate: validateDate    }\n  }\n\nfunction nopt (types, shorthands, args, slice) {\n  args = args || process.argv\n  types = types || {}\n  shorthands = shorthands || {}\n  if (typeof slice !== \"number\") slice = 2\n\n  debug(types, shorthands, args, slice)\n\n  args = args.slice(slice)\n  var data = {}\n    , key\n    , argv = {\n        remain: [],\n        cooked: args,\n        original: args.slice(0)\n      }\n\n  parse(args, data, argv.remain, types, shorthands)\n  // now data is full\n  clean(data, types, exports.typeDefs)\n  data.argv = argv\n  Object.defineProperty(data.argv, 'toString', { value: function () {\n    return this.original.map(JSON.stringify).join(\" \")\n  }, enumerable: false })\n  return data\n}\n\nfunction clean (data, types, typeDefs) {\n  typeDefs = typeDefs || exports.typeDefs\n  var remove = {}\n    , typeDefault = [false, true, null, String, Array]\n\n  Object.keys(data).forEach(function (k) {\n    if (k === \"argv\") return\n    var val = data[k]\n      , isArray = Array.isArray(val)\n      , type = types[k]\n    if (!isArray) val = [val]\n    if (!type) type = typeDefault\n    if (type === Array) type = typeDefault.concat(Array)\n    if (!Array.isArray(type)) type = [type]\n\n    debug(\"val=%j\", val)\n    debug(\"types=\", type)\n    val = val.map(function (val) {\n      // if it's an unknown value, then parse false/true/null/numbers/dates\n      if (typeof val === \"string\") {\n        debug(\"string %j\", val)\n        val = val.trim()\n        if ((val === \"null\" && ~type.indexOf(null))\n            || (val === \"true\" &&\n               (~type.indexOf(true) || ~type.indexOf(Boolean)))\n            || (val === \"false\" &&\n               (~type.indexOf(false) || ~type.indexOf(Boolean)))) {\n          val = JSON.parse(val)\n          debug(\"jsonable %j\", val)\n        } else if (~type.indexOf(Number) && !isNaN(val)) {\n          debug(\"convert to number\", val)\n          val = +val\n        } else if (~type.indexOf(Date) && !isNaN(Date.parse(val))) {\n          debug(\"convert to date\", val)\n          val = new Date(val)\n        }\n      }\n\n      if (!types.hasOwnProperty(k)) {\n        return val\n      }\n\n      // allow `--no-blah` to set 'blah' to null if null is allowed\n      if (val === false && ~type.indexOf(null) &&\n          !(~type.indexOf(false) || ~type.indexOf(Boolean))) {\n        val = null\n      }\n\n      var d = {}\n      d[k] = val\n      debug(\"prevalidated val\", d, val, types[k])\n      if (!validate(d, k, val, types[k], typeDefs)) {\n        if (exports.invalidHandler) {\n          exports.invalidHandler(k, val, types[k], data)\n        } else if (exports.invalidHandler !== false) {\n          debug(\"invalid: \"+k+\"=\"+val, types[k])\n        }\n        return remove\n      }\n      debug(\"validated val\", d, val, types[k])\n      return d[k]\n    }).filter(function (val) { return val !== remove })\n\n    // if we allow Array specifically, then an empty array is how we\n    // express 'no value here', not null.  Allow it.\n    if (!val.length && type.indexOf(Array) === -1) {\n      debug('VAL HAS NO LENGTH, DELETE IT', val, k, type.indexOf(Array))\n      delete data[k]\n    }\n    else if (isArray) {\n      debug(isArray, data[k], val)\n      data[k] = val\n    } else data[k] = val[0]\n\n    debug(\"k=%s val=%j\", k, val, data[k])\n  })\n}\n\nfunction validateString (data, k, val) {\n  data[k] = String(val)\n}\n\nfunction validatePath (data, k, val) {\n  if (val === true) return false\n  if (val === null) return true\n\n  val = String(val)\n\n  var isWin       = process.platform === 'win32'\n    , homePattern = isWin ? /^~(\\/|\\\\)/ : /^~\\//\n    , home        = os.homedir()\n\n  if (home && val.match(homePattern)) {\n    data[k] = path.resolve(home, val.substr(2))\n  } else {\n    data[k] = path.resolve(val)\n  }\n  return true\n}\n\nfunction validateNumber (data, k, val) {\n  debug(\"validate Number %j %j %j\", k, val, isNaN(val))\n  if (isNaN(val)) return false\n  data[k] = +val\n}\n\nfunction validateDate (data, k, val) {\n  var s = Date.parse(val)\n  debug(\"validate Date %j %j %j\", k, val, s)\n  if (isNaN(s)) return false\n  data[k] = new Date(val)\n}\n\nfunction validateBoolean (data, k, val) {\n  if (val instanceof Boolean) val = val.valueOf()\n  else if (typeof val === \"string\") {\n    if (!isNaN(val)) val = !!(+val)\n    else if (val === \"null\" || val === \"false\") val = false\n    else val = true\n  } else val = !!val\n  data[k] = val\n}\n\nfunction validateUrl (data, k, val) {\n  val = url.parse(String(val))\n  if (!val.host) return false\n  data[k] = val.href\n}\n\nfunction validateStream (data, k, val) {\n  if (!(val instanceof Stream)) return false\n  data[k] = val\n}\n\nfunction validate (data, k, val, type, typeDefs) {\n  // arrays are lists of types.\n  if (Array.isArray(type)) {\n    for (var i = 0, l = type.length; i < l; i ++) {\n      if (type[i] === Array) continue\n      if (validate(data, k, val, type[i], typeDefs)) return true\n    }\n    delete data[k]\n    return false\n  }\n\n  // an array of anything?\n  if (type === Array) return true\n\n  // NaN is poisonous.  Means that something is not allowed.\n  if (type !== type) {\n    debug(\"Poison NaN\", k, val, type)\n    delete data[k]\n    return false\n  }\n\n  // explicit list of values\n  if (val === type) {\n    debug(\"Explicitly allowed %j\", val)\n    // if (isArray) (data[k] = data[k] || []).push(val)\n    // else data[k] = val\n    data[k] = val\n    return true\n  }\n\n  // now go through the list of typeDefs, validate against each one.\n  var ok = false\n    , types = Object.keys(typeDefs)\n  for (var i = 0, l = types.length; i < l; i ++) {\n    debug(\"test type %j %j %j\", k, val, types[i])\n    var t = typeDefs[types[i]]\n    if (t &&\n      ((type && type.name && t.type && t.type.name) ? (type.name === t.type.name) : (type === t.type))) {\n      var d = {}\n      ok = false !== t.validate(d, k, val)\n      val = d[k]\n      if (ok) {\n        // if (isArray) (data[k] = data[k] || []).push(val)\n        // else data[k] = val\n        data[k] = val\n        break\n      }\n    }\n  }\n  debug(\"OK? %j (%j %j %j)\", ok, k, val, types[i])\n\n  if (!ok) delete data[k]\n  return ok\n}\n\nfunction parse (args, data, remain, types, shorthands) {\n  debug(\"parse\", args, data, remain)\n\n  var key = null\n    , abbrevs = abbrev(Object.keys(types))\n    , shortAbbr = abbrev(Object.keys(shorthands))\n\n  for (var i = 0; i < args.length; i ++) {\n    var arg = args[i]\n    debug(\"arg\", arg)\n\n    if (arg.match(/^-{2,}$/)) {\n      // done with keys.\n      // the rest are args.\n      remain.push.apply(remain, args.slice(i + 1))\n      args[i] = \"--\"\n      break\n    }\n    var hadEq = false\n    if (arg.charAt(0) === \"-\" && arg.length > 1) {\n      var at = arg.indexOf('=')\n      if (at > -1) {\n        hadEq = true\n        var v = arg.substr(at + 1)\n        arg = arg.substr(0, at)\n        args.splice(i, 1, arg, v)\n      }\n\n      // see if it's a shorthand\n      // if so, splice and back up to re-parse it.\n      var shRes = resolveShort(arg, shorthands, shortAbbr, abbrevs)\n      debug(\"arg=%j shRes=%j\", arg, shRes)\n      if (shRes) {\n        debug(arg, shRes)\n        args.splice.apply(args, [i, 1].concat(shRes))\n        if (arg !== shRes[0]) {\n          i --\n          continue\n        }\n      }\n      arg = arg.replace(/^-+/, \"\")\n      var no = null\n      while (arg.toLowerCase().indexOf(\"no-\") === 0) {\n        no = !no\n        arg = arg.substr(3)\n      }\n\n      if (abbrevs[arg]) arg = abbrevs[arg]\n\n      var argType = types[arg]\n      var isTypeArray = Array.isArray(argType)\n      if (isTypeArray && argType.length === 1) {\n        isTypeArray = false\n        argType = argType[0]\n      }\n\n      var isArray = argType === Array ||\n        isTypeArray && argType.indexOf(Array) !== -1\n\n      // allow unknown things to be arrays if specified multiple times.\n      if (!types.hasOwnProperty(arg) && data.hasOwnProperty(arg)) {\n        if (!Array.isArray(data[arg]))\n          data[arg] = [data[arg]]\n        isArray = true\n      }\n\n      var val\n        , la = args[i + 1]\n\n      var isBool = typeof no === 'boolean' ||\n        argType === Boolean ||\n        isTypeArray && argType.indexOf(Boolean) !== -1 ||\n        (typeof argType === 'undefined' && !hadEq) ||\n        (la === \"false\" &&\n         (argType === null ||\n          isTypeArray && ~argType.indexOf(null)))\n\n      if (isBool) {\n        // just set and move along\n        val = !no\n        // however, also support --bool true or --bool false\n        if (la === \"true\" || la === \"false\") {\n          val = JSON.parse(la)\n          la = null\n          if (no) val = !val\n          i ++\n        }\n\n        // also support \"foo\":[Boolean, \"bar\"] and \"--foo bar\"\n        if (isTypeArray && la) {\n          if (~argType.indexOf(la)) {\n            // an explicit type\n            val = la\n            i ++\n          } else if ( la === \"null\" && ~argType.indexOf(null) ) {\n            // null allowed\n            val = null\n            i ++\n          } else if ( !la.match(/^-{2,}[^-]/) &&\n                      !isNaN(la) &&\n                      ~argType.indexOf(Number) ) {\n            // number\n            val = +la\n            i ++\n          } else if ( !la.match(/^-[^-]/) && ~argType.indexOf(String) ) {\n            // string\n            val = la\n            i ++\n          }\n        }\n\n        if (isArray) (data[arg] = data[arg] || []).push(val)\n        else data[arg] = val\n\n        continue\n      }\n\n      if (argType === String) {\n        if (la === undefined) {\n          la = \"\"\n        } else if (la.match(/^-{1,2}[^-]+/)) {\n          la = \"\"\n          i --\n        }\n      }\n\n      if (la && la.match(/^-{2,}$/)) {\n        la = undefined\n        i --\n      }\n\n      val = la === undefined ? true : la\n      if (isArray) (data[arg] = data[arg] || []).push(val)\n      else data[arg] = val\n\n      i ++\n      continue\n    }\n    remain.push(arg)\n  }\n}\n\nfunction resolveShort (arg, shorthands, shortAbbr, abbrevs) {\n  // handle single-char shorthands glommed together, like\n  // npm ls -glp, but only if there is one dash, and only if\n  // all of the chars are single-char shorthands, and it's\n  // not a match to some other abbrev.\n  arg = arg.replace(/^-+/, '')\n\n  // if it's an exact known option, then don't go any further\n  if (abbrevs[arg] === arg)\n    return null\n\n  // if it's an exact known shortopt, same deal\n  if (shorthands[arg]) {\n    // make it an array, if it's a list of words\n    if (shorthands[arg] && !Array.isArray(shorthands[arg]))\n      shorthands[arg] = shorthands[arg].split(/\\s+/)\n\n    return shorthands[arg]\n  }\n\n  // first check to see if this arg is a set of single-char shorthands\n  var singles = shorthands.___singles\n  if (!singles) {\n    singles = Object.keys(shorthands).filter(function (s) {\n      return s.length === 1\n    }).reduce(function (l,r) {\n      l[r] = true\n      return l\n    }, {})\n    shorthands.___singles = singles\n    debug('shorthand singles', singles)\n  }\n\n  var chrs = arg.split(\"\").filter(function (c) {\n    return singles[c]\n  })\n\n  if (chrs.join(\"\") === arg) return chrs.map(function (c) {\n    return shorthands[c]\n  }).reduce(function (l, r) {\n    return l.concat(r)\n  }, [])\n\n\n  // if it's an arg abbrev, and not a literal shorthand, then prefer the arg\n  if (abbrevs[arg] && !shorthands[arg])\n    return null\n\n  // if it's an abbr for a shorthand, then use that\n  if (shortAbbr[arg])\n    arg = shortAbbr[arg]\n\n  // make it an array, if it's a list of words\n  if (shorthands[arg] && !Array.isArray(shorthands[arg]))\n    shorthands[arg] = shorthands[arg].split(/\\s+/)\n\n  return shorthands[arg]\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/nopt/lib/nopt.js?");

/***/ }),

/***/ "./node_modules/npmlog/log.js":
/*!************************************!*\
  !*** ./node_modules/npmlog/log.js ***!
  \************************************/
/***/ ((module, exports, __webpack_require__) => {

"use strict";
eval("\nvar Progress = __webpack_require__(/*! are-we-there-yet */ \"./node_modules/are-we-there-yet/lib/index.js\")\nvar Gauge = __webpack_require__(/*! gauge */ \"./node_modules/gauge/index.js\")\nvar EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter)\nvar log = exports = module.exports = new EE()\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\")\n\nvar setBlocking = __webpack_require__(/*! set-blocking */ \"./node_modules/set-blocking/index.js\")\nvar consoleControl = __webpack_require__(/*! console-control-strings */ \"./node_modules/console-control-strings/index.js\")\n\nsetBlocking(true)\nvar stream = process.stderr\nObject.defineProperty(log, 'stream', {\n  set: function (newStream) {\n    stream = newStream\n    if (this.gauge) {\n      this.gauge.setWriteTo(stream, stream)\n    }\n  },\n  get: function () {\n    return stream\n  },\n})\n\n// by default, decide based on tty-ness.\nvar colorEnabled\nlog.useColor = function () {\n  return colorEnabled != null ? colorEnabled : stream.isTTY\n}\n\nlog.enableColor = function () {\n  colorEnabled = true\n  this.gauge.setTheme({hasColor: colorEnabled, hasUnicode: unicodeEnabled})\n}\nlog.disableColor = function () {\n  colorEnabled = false\n  this.gauge.setTheme({hasColor: colorEnabled, hasUnicode: unicodeEnabled})\n}\n\n// default level\nlog.level = 'info'\n\nlog.gauge = new Gauge(stream, {\n  enabled: false, // no progress bars unless asked\n  theme: {hasColor: log.useColor()},\n  template: [\n    {type: 'progressbar', length: 20},\n    {type: 'activityIndicator', kerning: 1, length: 1},\n    {type: 'section', default: ''},\n    ':',\n    {type: 'logline', kerning: 1, default: ''},\n  ],\n})\n\nlog.tracker = new Progress.TrackerGroup()\n\n// we track this separately as we may need to temporarily disable the\n// display of the status bar for our own loggy purposes.\nlog.progressEnabled = log.gauge.isEnabled()\n\nvar unicodeEnabled\n\nlog.enableUnicode = function () {\n  unicodeEnabled = true\n  this.gauge.setTheme({hasColor: this.useColor(), hasUnicode: unicodeEnabled})\n}\n\nlog.disableUnicode = function () {\n  unicodeEnabled = false\n  this.gauge.setTheme({hasColor: this.useColor(), hasUnicode: unicodeEnabled})\n}\n\nlog.setGaugeThemeset = function (themes) {\n  this.gauge.setThemeset(themes)\n}\n\nlog.setGaugeTemplate = function (template) {\n  this.gauge.setTemplate(template)\n}\n\nlog.enableProgress = function () {\n  if (this.progressEnabled) {\n    return\n  }\n\n  this.progressEnabled = true\n  this.tracker.on('change', this.showProgress)\n  if (this._paused) {\n    return\n  }\n\n  this.gauge.enable()\n}\n\nlog.disableProgress = function () {\n  if (!this.progressEnabled) {\n    return\n  }\n  this.progressEnabled = false\n  this.tracker.removeListener('change', this.showProgress)\n  this.gauge.disable()\n}\n\nvar trackerConstructors = ['newGroup', 'newItem', 'newStream']\n\nvar mixinLog = function (tracker) {\n  // mixin the public methods from log into the tracker\n  // (except: conflicts and one's we handle specially)\n  Object.keys(log).forEach(function (P) {\n    if (P[0] === '_') {\n      return\n    }\n\n    if (trackerConstructors.filter(function (C) {\n      return C === P\n    }).length) {\n      return\n    }\n\n    if (tracker[P]) {\n      return\n    }\n\n    if (typeof log[P] !== 'function') {\n      return\n    }\n\n    var func = log[P]\n    tracker[P] = function () {\n      return func.apply(log, arguments)\n    }\n  })\n  // if the new tracker is a group, make sure any subtrackers get\n  // mixed in too\n  if (tracker instanceof Progress.TrackerGroup) {\n    trackerConstructors.forEach(function (C) {\n      var func = tracker[C]\n      tracker[C] = function () {\n        return mixinLog(func.apply(tracker, arguments))\n      }\n    })\n  }\n  return tracker\n}\n\n// Add tracker constructors to the top level log object\ntrackerConstructors.forEach(function (C) {\n  log[C] = function () {\n    return mixinLog(this.tracker[C].apply(this.tracker, arguments))\n  }\n})\n\nlog.clearProgress = function (cb) {\n  if (!this.progressEnabled) {\n    return cb && process.nextTick(cb)\n  }\n\n  this.gauge.hide(cb)\n}\n\nlog.showProgress = function (name, completed) {\n  if (!this.progressEnabled) {\n    return\n  }\n\n  var values = {}\n  if (name) {\n    values.section = name\n  }\n\n  var last = log.record[log.record.length - 1]\n  if (last) {\n    values.subsection = last.prefix\n    var disp = log.disp[last.level] || last.level\n    var logline = this._format(disp, log.style[last.level])\n    if (last.prefix) {\n      logline += ' ' + this._format(last.prefix, this.prefixStyle)\n    }\n\n    logline += ' ' + last.message.split(/\\r?\\n/)[0]\n    values.logline = logline\n  }\n  values.completed = completed || this.tracker.completed()\n  this.gauge.show(values)\n}.bind(log) // bind for use in tracker's on-change listener\n\n// temporarily stop emitting, but don't drop\nlog.pause = function () {\n  this._paused = true\n  if (this.progressEnabled) {\n    this.gauge.disable()\n  }\n}\n\nlog.resume = function () {\n  if (!this._paused) {\n    return\n  }\n\n  this._paused = false\n\n  var b = this._buffer\n  this._buffer = []\n  b.forEach(function (m) {\n    this.emitLog(m)\n  }, this)\n  if (this.progressEnabled) {\n    this.gauge.enable()\n  }\n}\n\nlog._buffer = []\n\nvar id = 0\nlog.record = []\nlog.maxRecordSize = 10000\nlog.log = function (lvl, prefix, message) {\n  var l = this.levels[lvl]\n  if (l === undefined) {\n    return this.emit('error', new Error(util.format(\n      'Undefined log level: %j', lvl)))\n  }\n\n  var a = new Array(arguments.length - 2)\n  var stack = null\n  for (var i = 2; i < arguments.length; i++) {\n    var arg = a[i - 2] = arguments[i]\n\n    // resolve stack traces to a plain string.\n    if (typeof arg === 'object' && arg instanceof Error && arg.stack) {\n      Object.defineProperty(arg, 'stack', {\n        value: stack = arg.stack + '',\n        enumerable: true,\n        writable: true,\n      })\n    }\n  }\n  if (stack) {\n    a.unshift(stack + '\\n')\n  }\n  message = util.format.apply(util, a)\n\n  var m = {\n    id: id++,\n    level: lvl,\n    prefix: String(prefix || ''),\n    message: message,\n    messageRaw: a,\n  }\n\n  this.emit('log', m)\n  this.emit('log.' + lvl, m)\n  if (m.prefix) {\n    this.emit(m.prefix, m)\n  }\n\n  this.record.push(m)\n  var mrs = this.maxRecordSize\n  var n = this.record.length - mrs\n  if (n > mrs / 10) {\n    var newSize = Math.floor(mrs * 0.9)\n    this.record = this.record.slice(-1 * newSize)\n  }\n\n  this.emitLog(m)\n}.bind(log)\n\nlog.emitLog = function (m) {\n  if (this._paused) {\n    this._buffer.push(m)\n    return\n  }\n  if (this.progressEnabled) {\n    this.gauge.pulse(m.prefix)\n  }\n\n  var l = this.levels[m.level]\n  if (l === undefined) {\n    return\n  }\n\n  if (l < this.levels[this.level]) {\n    return\n  }\n\n  if (l > 0 && !isFinite(l)) {\n    return\n  }\n\n  // If 'disp' is null or undefined, use the lvl as a default\n  // Allows: '', 0 as valid disp\n  var disp = log.disp[m.level] != null ? log.disp[m.level] : m.level\n  this.clearProgress()\n  m.message.split(/\\r?\\n/).forEach(function (line) {\n    if (this.heading) {\n      this.write(this.heading, this.headingStyle)\n      this.write(' ')\n    }\n    this.write(disp, log.style[m.level])\n    var p = m.prefix || ''\n    if (p) {\n      this.write(' ')\n    }\n\n    this.write(p, this.prefixStyle)\n    this.write(' ' + line + '\\n')\n  }, this)\n  this.showProgress()\n}\n\nlog._format = function (msg, style) {\n  if (!stream) {\n    return\n  }\n\n  var output = ''\n  if (this.useColor()) {\n    style = style || {}\n    var settings = []\n    if (style.fg) {\n      settings.push(style.fg)\n    }\n\n    if (style.bg) {\n      settings.push('bg' + style.bg[0].toUpperCase() + style.bg.slice(1))\n    }\n\n    if (style.bold) {\n      settings.push('bold')\n    }\n\n    if (style.underline) {\n      settings.push('underline')\n    }\n\n    if (style.inverse) {\n      settings.push('inverse')\n    }\n\n    if (settings.length) {\n      output += consoleControl.color(settings)\n    }\n\n    if (style.beep) {\n      output += consoleControl.beep()\n    }\n  }\n  output += msg\n  if (this.useColor()) {\n    output += consoleControl.color('reset')\n  }\n\n  return output\n}\n\nlog.write = function (msg, style) {\n  if (!stream) {\n    return\n  }\n\n  stream.write(this._format(msg, style))\n}\n\nlog.addLevel = function (lvl, n, style, disp) {\n  // If 'disp' is null or undefined, use the lvl as a default\n  if (disp == null) {\n    disp = lvl\n  }\n\n  this.levels[lvl] = n\n  this.style[lvl] = style\n  if (!this[lvl]) {\n    this[lvl] = function () {\n      var a = new Array(arguments.length + 1)\n      a[0] = lvl\n      for (var i = 0; i < arguments.length; i++) {\n        a[i + 1] = arguments[i]\n      }\n\n      return this.log.apply(this, a)\n    }.bind(this)\n  }\n  this.disp[lvl] = disp\n}\n\nlog.prefixStyle = { fg: 'magenta' }\nlog.headingStyle = { fg: 'white', bg: 'black' }\n\nlog.style = {}\nlog.levels = {}\nlog.disp = {}\nlog.addLevel('silly', -Infinity, { inverse: true }, 'sill')\nlog.addLevel('verbose', 1000, { fg: 'blue', bg: 'black' }, 'verb')\nlog.addLevel('info', 2000, { fg: 'green' })\nlog.addLevel('timing', 2500, { fg: 'green', bg: 'black' })\nlog.addLevel('http', 3000, { fg: 'green', bg: 'black' })\nlog.addLevel('notice', 3500, { fg: 'blue', bg: 'black' })\nlog.addLevel('warn', 4000, { fg: 'black', bg: 'yellow' }, 'WARN')\nlog.addLevel('error', 5000, { fg: 'red', bg: 'black' }, 'ERR!')\nlog.addLevel('silent', Infinity)\n\n// allow 'error' prefix\nlog.on('error', function () {})\n\n\n//# sourceURL=webpack://thelambda/./node_modules/npmlog/log.js?");

/***/ }),

/***/ "./node_modules/object-assign/index.js":
/*!*********************************************!*\
  !*** ./node_modules/object-assign/index.js ***!
  \*********************************************/
/***/ ((module) => {

"use strict";
eval("/*\nobject-assign\n(c) Sindre Sorhus\n@license MIT\n*/\n\n\n/* eslint-disable no-unused-vars */\nvar getOwnPropertySymbols = Object.getOwnPropertySymbols;\nvar hasOwnProperty = Object.prototype.hasOwnProperty;\nvar propIsEnumerable = Object.prototype.propertyIsEnumerable;\n\nfunction toObject(val) {\n\tif (val === null || val === undefined) {\n\t\tthrow new TypeError('Object.assign cannot be called with null or undefined');\n\t}\n\n\treturn Object(val);\n}\n\nfunction shouldUseNative() {\n\ttry {\n\t\tif (!Object.assign) {\n\t\t\treturn false;\n\t\t}\n\n\t\t// Detect buggy property enumeration order in older V8 versions.\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=4118\n\t\tvar test1 = new String('abc');  // eslint-disable-line no-new-wrappers\n\t\ttest1[5] = 'de';\n\t\tif (Object.getOwnPropertyNames(test1)[0] === '5') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test2 = {};\n\t\tfor (var i = 0; i < 10; i++) {\n\t\t\ttest2['_' + String.fromCharCode(i)] = i;\n\t\t}\n\t\tvar order2 = Object.getOwnPropertyNames(test2).map(function (n) {\n\t\t\treturn test2[n];\n\t\t});\n\t\tif (order2.join('') !== '0123456789') {\n\t\t\treturn false;\n\t\t}\n\n\t\t// https://bugs.chromium.org/p/v8/issues/detail?id=3056\n\t\tvar test3 = {};\n\t\t'abcdefghijklmnopqrst'.split('').forEach(function (letter) {\n\t\t\ttest3[letter] = letter;\n\t\t});\n\t\tif (Object.keys(Object.assign({}, test3)).join('') !==\n\t\t\t\t'abcdefghijklmnopqrst') {\n\t\t\treturn false;\n\t\t}\n\n\t\treturn true;\n\t} catch (err) {\n\t\t// We don't expect any of the above to throw, but better to be safe.\n\t\treturn false;\n\t}\n}\n\nmodule.exports = shouldUseNative() ? Object.assign : function (target, source) {\n\tvar from;\n\tvar to = toObject(target);\n\tvar symbols;\n\n\tfor (var s = 1; s < arguments.length; s++) {\n\t\tfrom = Object(arguments[s]);\n\n\t\tfor (var key in from) {\n\t\t\tif (hasOwnProperty.call(from, key)) {\n\t\t\t\tto[key] = from[key];\n\t\t\t}\n\t\t}\n\n\t\tif (getOwnPropertySymbols) {\n\t\t\tsymbols = getOwnPropertySymbols(from);\n\t\t\tfor (var i = 0; i < symbols.length; i++) {\n\t\t\t\tif (propIsEnumerable.call(from, symbols[i])) {\n\t\t\t\t\tto[symbols[i]] = from[symbols[i]];\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn to;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/object-assign/index.js?");

/***/ }),

/***/ "./node_modules/object-inspect/index.js":
/*!**********************************************!*\
  !*** ./node_modules/object-inspect/index.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var hasMap = typeof Map === 'function' && Map.prototype;\nvar mapSizeDescriptor = Object.getOwnPropertyDescriptor && hasMap ? Object.getOwnPropertyDescriptor(Map.prototype, 'size') : null;\nvar mapSize = hasMap && mapSizeDescriptor && typeof mapSizeDescriptor.get === 'function' ? mapSizeDescriptor.get : null;\nvar mapForEach = hasMap && Map.prototype.forEach;\nvar hasSet = typeof Set === 'function' && Set.prototype;\nvar setSizeDescriptor = Object.getOwnPropertyDescriptor && hasSet ? Object.getOwnPropertyDescriptor(Set.prototype, 'size') : null;\nvar setSize = hasSet && setSizeDescriptor && typeof setSizeDescriptor.get === 'function' ? setSizeDescriptor.get : null;\nvar setForEach = hasSet && Set.prototype.forEach;\nvar hasWeakMap = typeof WeakMap === 'function' && WeakMap.prototype;\nvar weakMapHas = hasWeakMap ? WeakMap.prototype.has : null;\nvar hasWeakSet = typeof WeakSet === 'function' && WeakSet.prototype;\nvar weakSetHas = hasWeakSet ? WeakSet.prototype.has : null;\nvar hasWeakRef = typeof WeakRef === 'function' && WeakRef.prototype;\nvar weakRefDeref = hasWeakRef ? WeakRef.prototype.deref : null;\nvar booleanValueOf = Boolean.prototype.valueOf;\nvar objectToString = Object.prototype.toString;\nvar functionToString = Function.prototype.toString;\nvar $match = String.prototype.match;\nvar $slice = String.prototype.slice;\nvar $replace = String.prototype.replace;\nvar $toUpperCase = String.prototype.toUpperCase;\nvar $toLowerCase = String.prototype.toLowerCase;\nvar $test = RegExp.prototype.test;\nvar $concat = Array.prototype.concat;\nvar $join = Array.prototype.join;\nvar $arrSlice = Array.prototype.slice;\nvar $floor = Math.floor;\nvar bigIntValueOf = typeof BigInt === 'function' ? BigInt.prototype.valueOf : null;\nvar gOPS = Object.getOwnPropertySymbols;\nvar symToString = typeof Symbol === 'function' && typeof Symbol.iterator === 'symbol' ? Symbol.prototype.toString : null;\nvar hasShammedSymbols = typeof Symbol === 'function' && typeof Symbol.iterator === 'object';\n// ie, `has-tostringtag/shams\nvar toStringTag = typeof Symbol === 'function' && Symbol.toStringTag && (typeof Symbol.toStringTag === hasShammedSymbols ? 'object' : 'symbol')\n    ? Symbol.toStringTag\n    : null;\nvar isEnumerable = Object.prototype.propertyIsEnumerable;\n\nvar gPO = (typeof Reflect === 'function' ? Reflect.getPrototypeOf : Object.getPrototypeOf) || (\n    [].__proto__ === Array.prototype // eslint-disable-line no-proto\n        ? function (O) {\n            return O.__proto__; // eslint-disable-line no-proto\n        }\n        : null\n);\n\nfunction addNumericSeparator(num, str) {\n    if (\n        num === Infinity\n        || num === -Infinity\n        || num !== num\n        || (num && num > -1000 && num < 1000)\n        || $test.call(/e/, str)\n    ) {\n        return str;\n    }\n    var sepRegex = /[0-9](?=(?:[0-9]{3})+(?![0-9]))/g;\n    if (typeof num === 'number') {\n        var int = num < 0 ? -$floor(-num) : $floor(num); // trunc(num)\n        if (int !== num) {\n            var intStr = String(int);\n            var dec = $slice.call(str, intStr.length + 1);\n            return $replace.call(intStr, sepRegex, '$&_') + '.' + $replace.call($replace.call(dec, /([0-9]{3})/g, '$&_'), /_$/, '');\n        }\n    }\n    return $replace.call(str, sepRegex, '$&_');\n}\n\nvar utilInspect = __webpack_require__(/*! ./util.inspect */ \"?4f7e\");\nvar inspectCustom = utilInspect.custom;\nvar inspectSymbol = isSymbol(inspectCustom) ? inspectCustom : null;\n\nmodule.exports = function inspect_(obj, options, depth, seen) {\n    var opts = options || {};\n\n    if (has(opts, 'quoteStyle') && (opts.quoteStyle !== 'single' && opts.quoteStyle !== 'double')) {\n        throw new TypeError('option \"quoteStyle\" must be \"single\" or \"double\"');\n    }\n    if (\n        has(opts, 'maxStringLength') && (typeof opts.maxStringLength === 'number'\n            ? opts.maxStringLength < 0 && opts.maxStringLength !== Infinity\n            : opts.maxStringLength !== null\n        )\n    ) {\n        throw new TypeError('option \"maxStringLength\", if provided, must be a positive integer, Infinity, or `null`');\n    }\n    var customInspect = has(opts, 'customInspect') ? opts.customInspect : true;\n    if (typeof customInspect !== 'boolean' && customInspect !== 'symbol') {\n        throw new TypeError('option \"customInspect\", if provided, must be `true`, `false`, or `\\'symbol\\'`');\n    }\n\n    if (\n        has(opts, 'indent')\n        && opts.indent !== null\n        && opts.indent !== '\\t'\n        && !(parseInt(opts.indent, 10) === opts.indent && opts.indent > 0)\n    ) {\n        throw new TypeError('option \"indent\" must be \"\\\\t\", an integer > 0, or `null`');\n    }\n    if (has(opts, 'numericSeparator') && typeof opts.numericSeparator !== 'boolean') {\n        throw new TypeError('option \"numericSeparator\", if provided, must be `true` or `false`');\n    }\n    var numericSeparator = opts.numericSeparator;\n\n    if (typeof obj === 'undefined') {\n        return 'undefined';\n    }\n    if (obj === null) {\n        return 'null';\n    }\n    if (typeof obj === 'boolean') {\n        return obj ? 'true' : 'false';\n    }\n\n    if (typeof obj === 'string') {\n        return inspectString(obj, opts);\n    }\n    if (typeof obj === 'number') {\n        if (obj === 0) {\n            return Infinity / obj > 0 ? '0' : '-0';\n        }\n        var str = String(obj);\n        return numericSeparator ? addNumericSeparator(obj, str) : str;\n    }\n    if (typeof obj === 'bigint') {\n        var bigIntStr = String(obj) + 'n';\n        return numericSeparator ? addNumericSeparator(obj, bigIntStr) : bigIntStr;\n    }\n\n    var maxDepth = typeof opts.depth === 'undefined' ? 5 : opts.depth;\n    if (typeof depth === 'undefined') { depth = 0; }\n    if (depth >= maxDepth && maxDepth > 0 && typeof obj === 'object') {\n        return isArray(obj) ? '[Array]' : '[Object]';\n    }\n\n    var indent = getIndent(opts, depth);\n\n    if (typeof seen === 'undefined') {\n        seen = [];\n    } else if (indexOf(seen, obj) >= 0) {\n        return '[Circular]';\n    }\n\n    function inspect(value, from, noIndent) {\n        if (from) {\n            seen = $arrSlice.call(seen);\n            seen.push(from);\n        }\n        if (noIndent) {\n            var newOpts = {\n                depth: opts.depth\n            };\n            if (has(opts, 'quoteStyle')) {\n                newOpts.quoteStyle = opts.quoteStyle;\n            }\n            return inspect_(value, newOpts, depth + 1, seen);\n        }\n        return inspect_(value, opts, depth + 1, seen);\n    }\n\n    if (typeof obj === 'function' && !isRegExp(obj)) { // in older engines, regexes are callable\n        var name = nameOf(obj);\n        var keys = arrObjKeys(obj, inspect);\n        return '[Function' + (name ? ': ' + name : ' (anonymous)') + ']' + (keys.length > 0 ? ' { ' + $join.call(keys, ', ') + ' }' : '');\n    }\n    if (isSymbol(obj)) {\n        var symString = hasShammedSymbols ? $replace.call(String(obj), /^(Symbol\\(.*\\))_[^)]*$/, '$1') : symToString.call(obj);\n        return typeof obj === 'object' && !hasShammedSymbols ? markBoxed(symString) : symString;\n    }\n    if (isElement(obj)) {\n        var s = '<' + $toLowerCase.call(String(obj.nodeName));\n        var attrs = obj.attributes || [];\n        for (var i = 0; i < attrs.length; i++) {\n            s += ' ' + attrs[i].name + '=' + wrapQuotes(quote(attrs[i].value), 'double', opts);\n        }\n        s += '>';\n        if (obj.childNodes && obj.childNodes.length) { s += '...'; }\n        s += '</' + $toLowerCase.call(String(obj.nodeName)) + '>';\n        return s;\n    }\n    if (isArray(obj)) {\n        if (obj.length === 0) { return '[]'; }\n        var xs = arrObjKeys(obj, inspect);\n        if (indent && !singleLineValues(xs)) {\n            return '[' + indentedJoin(xs, indent) + ']';\n        }\n        return '[ ' + $join.call(xs, ', ') + ' ]';\n    }\n    if (isError(obj)) {\n        var parts = arrObjKeys(obj, inspect);\n        if (!('cause' in Error.prototype) && 'cause' in obj && !isEnumerable.call(obj, 'cause')) {\n            return '{ [' + String(obj) + '] ' + $join.call($concat.call('[cause]: ' + inspect(obj.cause), parts), ', ') + ' }';\n        }\n        if (parts.length === 0) { return '[' + String(obj) + ']'; }\n        return '{ [' + String(obj) + '] ' + $join.call(parts, ', ') + ' }';\n    }\n    if (typeof obj === 'object' && customInspect) {\n        if (inspectSymbol && typeof obj[inspectSymbol] === 'function' && utilInspect) {\n            return utilInspect(obj, { depth: maxDepth - depth });\n        } else if (customInspect !== 'symbol' && typeof obj.inspect === 'function') {\n            return obj.inspect();\n        }\n    }\n    if (isMap(obj)) {\n        var mapParts = [];\n        if (mapForEach) {\n            mapForEach.call(obj, function (value, key) {\n                mapParts.push(inspect(key, obj, true) + ' => ' + inspect(value, obj));\n            });\n        }\n        return collectionOf('Map', mapSize.call(obj), mapParts, indent);\n    }\n    if (isSet(obj)) {\n        var setParts = [];\n        if (setForEach) {\n            setForEach.call(obj, function (value) {\n                setParts.push(inspect(value, obj));\n            });\n        }\n        return collectionOf('Set', setSize.call(obj), setParts, indent);\n    }\n    if (isWeakMap(obj)) {\n        return weakCollectionOf('WeakMap');\n    }\n    if (isWeakSet(obj)) {\n        return weakCollectionOf('WeakSet');\n    }\n    if (isWeakRef(obj)) {\n        return weakCollectionOf('WeakRef');\n    }\n    if (isNumber(obj)) {\n        return markBoxed(inspect(Number(obj)));\n    }\n    if (isBigInt(obj)) {\n        return markBoxed(inspect(bigIntValueOf.call(obj)));\n    }\n    if (isBoolean(obj)) {\n        return markBoxed(booleanValueOf.call(obj));\n    }\n    if (isString(obj)) {\n        return markBoxed(inspect(String(obj)));\n    }\n    // note: in IE 8, sometimes `global !== window` but both are the prototypes of each other\n    /* eslint-env browser */\n    if (typeof window !== 'undefined' && obj === window) {\n        return '{ [object Window] }';\n    }\n    if (\n        (typeof globalThis !== 'undefined' && obj === globalThis)\n        || (typeof __webpack_require__.g !== 'undefined' && obj === __webpack_require__.g)\n    ) {\n        return '{ [object globalThis] }';\n    }\n    if (!isDate(obj) && !isRegExp(obj)) {\n        var ys = arrObjKeys(obj, inspect);\n        var isPlainObject = gPO ? gPO(obj) === Object.prototype : obj instanceof Object || obj.constructor === Object;\n        var protoTag = obj instanceof Object ? '' : 'null prototype';\n        var stringTag = !isPlainObject && toStringTag && Object(obj) === obj && toStringTag in obj ? $slice.call(toStr(obj), 8, -1) : protoTag ? 'Object' : '';\n        var constructorTag = isPlainObject || typeof obj.constructor !== 'function' ? '' : obj.constructor.name ? obj.constructor.name + ' ' : '';\n        var tag = constructorTag + (stringTag || protoTag ? '[' + $join.call($concat.call([], stringTag || [], protoTag || []), ': ') + '] ' : '');\n        if (ys.length === 0) { return tag + '{}'; }\n        if (indent) {\n            return tag + '{' + indentedJoin(ys, indent) + '}';\n        }\n        return tag + '{ ' + $join.call(ys, ', ') + ' }';\n    }\n    return String(obj);\n};\n\nfunction wrapQuotes(s, defaultStyle, opts) {\n    var quoteChar = (opts.quoteStyle || defaultStyle) === 'double' ? '\"' : \"'\";\n    return quoteChar + s + quoteChar;\n}\n\nfunction quote(s) {\n    return $replace.call(String(s), /\"/g, '&quot;');\n}\n\nfunction isArray(obj) { return toStr(obj) === '[object Array]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\nfunction isDate(obj) { return toStr(obj) === '[object Date]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\nfunction isRegExp(obj) { return toStr(obj) === '[object RegExp]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\nfunction isError(obj) { return toStr(obj) === '[object Error]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\nfunction isString(obj) { return toStr(obj) === '[object String]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\nfunction isNumber(obj) { return toStr(obj) === '[object Number]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\nfunction isBoolean(obj) { return toStr(obj) === '[object Boolean]' && (!toStringTag || !(typeof obj === 'object' && toStringTag in obj)); }\n\n// Symbol and BigInt do have Symbol.toStringTag by spec, so that can't be used to eliminate false positives\nfunction isSymbol(obj) {\n    if (hasShammedSymbols) {\n        return obj && typeof obj === 'object' && obj instanceof Symbol;\n    }\n    if (typeof obj === 'symbol') {\n        return true;\n    }\n    if (!obj || typeof obj !== 'object' || !symToString) {\n        return false;\n    }\n    try {\n        symToString.call(obj);\n        return true;\n    } catch (e) {}\n    return false;\n}\n\nfunction isBigInt(obj) {\n    if (!obj || typeof obj !== 'object' || !bigIntValueOf) {\n        return false;\n    }\n    try {\n        bigIntValueOf.call(obj);\n        return true;\n    } catch (e) {}\n    return false;\n}\n\nvar hasOwn = Object.prototype.hasOwnProperty || function (key) { return key in this; };\nfunction has(obj, key) {\n    return hasOwn.call(obj, key);\n}\n\nfunction toStr(obj) {\n    return objectToString.call(obj);\n}\n\nfunction nameOf(f) {\n    if (f.name) { return f.name; }\n    var m = $match.call(functionToString.call(f), /^function\\s*([\\w$]+)/);\n    if (m) { return m[1]; }\n    return null;\n}\n\nfunction indexOf(xs, x) {\n    if (xs.indexOf) { return xs.indexOf(x); }\n    for (var i = 0, l = xs.length; i < l; i++) {\n        if (xs[i] === x) { return i; }\n    }\n    return -1;\n}\n\nfunction isMap(x) {\n    if (!mapSize || !x || typeof x !== 'object') {\n        return false;\n    }\n    try {\n        mapSize.call(x);\n        try {\n            setSize.call(x);\n        } catch (s) {\n            return true;\n        }\n        return x instanceof Map; // core-js workaround, pre-v2.5.0\n    } catch (e) {}\n    return false;\n}\n\nfunction isWeakMap(x) {\n    if (!weakMapHas || !x || typeof x !== 'object') {\n        return false;\n    }\n    try {\n        weakMapHas.call(x, weakMapHas);\n        try {\n            weakSetHas.call(x, weakSetHas);\n        } catch (s) {\n            return true;\n        }\n        return x instanceof WeakMap; // core-js workaround, pre-v2.5.0\n    } catch (e) {}\n    return false;\n}\n\nfunction isWeakRef(x) {\n    if (!weakRefDeref || !x || typeof x !== 'object') {\n        return false;\n    }\n    try {\n        weakRefDeref.call(x);\n        return true;\n    } catch (e) {}\n    return false;\n}\n\nfunction isSet(x) {\n    if (!setSize || !x || typeof x !== 'object') {\n        return false;\n    }\n    try {\n        setSize.call(x);\n        try {\n            mapSize.call(x);\n        } catch (m) {\n            return true;\n        }\n        return x instanceof Set; // core-js workaround, pre-v2.5.0\n    } catch (e) {}\n    return false;\n}\n\nfunction isWeakSet(x) {\n    if (!weakSetHas || !x || typeof x !== 'object') {\n        return false;\n    }\n    try {\n        weakSetHas.call(x, weakSetHas);\n        try {\n            weakMapHas.call(x, weakMapHas);\n        } catch (s) {\n            return true;\n        }\n        return x instanceof WeakSet; // core-js workaround, pre-v2.5.0\n    } catch (e) {}\n    return false;\n}\n\nfunction isElement(x) {\n    if (!x || typeof x !== 'object') { return false; }\n    if (typeof HTMLElement !== 'undefined' && x instanceof HTMLElement) {\n        return true;\n    }\n    return typeof x.nodeName === 'string' && typeof x.getAttribute === 'function';\n}\n\nfunction inspectString(str, opts) {\n    if (str.length > opts.maxStringLength) {\n        var remaining = str.length - opts.maxStringLength;\n        var trailer = '... ' + remaining + ' more character' + (remaining > 1 ? 's' : '');\n        return inspectString($slice.call(str, 0, opts.maxStringLength), opts) + trailer;\n    }\n    // eslint-disable-next-line no-control-regex\n    var s = $replace.call($replace.call(str, /(['\\\\])/g, '\\\\$1'), /[\\x00-\\x1f]/g, lowbyte);\n    return wrapQuotes(s, 'single', opts);\n}\n\nfunction lowbyte(c) {\n    var n = c.charCodeAt(0);\n    var x = {\n        8: 'b',\n        9: 't',\n        10: 'n',\n        12: 'f',\n        13: 'r'\n    }[n];\n    if (x) { return '\\\\' + x; }\n    return '\\\\x' + (n < 0x10 ? '0' : '') + $toUpperCase.call(n.toString(16));\n}\n\nfunction markBoxed(str) {\n    return 'Object(' + str + ')';\n}\n\nfunction weakCollectionOf(type) {\n    return type + ' { ? }';\n}\n\nfunction collectionOf(type, size, entries, indent) {\n    var joinedEntries = indent ? indentedJoin(entries, indent) : $join.call(entries, ', ');\n    return type + ' (' + size + ') {' + joinedEntries + '}';\n}\n\nfunction singleLineValues(xs) {\n    for (var i = 0; i < xs.length; i++) {\n        if (indexOf(xs[i], '\\n') >= 0) {\n            return false;\n        }\n    }\n    return true;\n}\n\nfunction getIndent(opts, depth) {\n    var baseIndent;\n    if (opts.indent === '\\t') {\n        baseIndent = '\\t';\n    } else if (typeof opts.indent === 'number' && opts.indent > 0) {\n        baseIndent = $join.call(Array(opts.indent + 1), ' ');\n    } else {\n        return null;\n    }\n    return {\n        base: baseIndent,\n        prev: $join.call(Array(depth + 1), baseIndent)\n    };\n}\n\nfunction indentedJoin(xs, indent) {\n    if (xs.length === 0) { return ''; }\n    var lineJoiner = '\\n' + indent.prev + indent.base;\n    return lineJoiner + $join.call(xs, ',' + lineJoiner) + '\\n' + indent.prev;\n}\n\nfunction arrObjKeys(obj, inspect) {\n    var isArr = isArray(obj);\n    var xs = [];\n    if (isArr) {\n        xs.length = obj.length;\n        for (var i = 0; i < obj.length; i++) {\n            xs[i] = has(obj, i) ? inspect(obj[i], obj) : '';\n        }\n    }\n    var syms = typeof gOPS === 'function' ? gOPS(obj) : [];\n    var symMap;\n    if (hasShammedSymbols) {\n        symMap = {};\n        for (var k = 0; k < syms.length; k++) {\n            symMap['$' + syms[k]] = syms[k];\n        }\n    }\n\n    for (var key in obj) { // eslint-disable-line no-restricted-syntax\n        if (!has(obj, key)) { continue; } // eslint-disable-line no-restricted-syntax, no-continue\n        if (isArr && String(Number(key)) === key && key < obj.length) { continue; } // eslint-disable-line no-restricted-syntax, no-continue\n        if (hasShammedSymbols && symMap['$' + key] instanceof Symbol) {\n            // this is to prevent shammed Symbols, which are stored as strings, from being included in the string key section\n            continue; // eslint-disable-line no-restricted-syntax, no-continue\n        } else if ($test.call(/[^\\w$]/, key)) {\n            xs.push(inspect(key, obj) + ': ' + inspect(obj[key], obj));\n        } else {\n            xs.push(key + ': ' + inspect(obj[key], obj));\n        }\n    }\n    if (typeof gOPS === 'function') {\n        for (var j = 0; j < syms.length; j++) {\n            if (isEnumerable.call(obj, syms[j])) {\n                xs.push('[' + inspect(syms[j]) + ']: ' + inspect(obj[syms[j]], obj));\n            }\n        }\n    }\n    return xs;\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/object-inspect/index.js?");

/***/ }),

/***/ "./node_modules/once/once.js":
/*!***********************************!*\
  !*** ./node_modules/once/once.js ***!
  \***********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var wrappy = __webpack_require__(/*! wrappy */ \"./node_modules/wrappy/wrappy.js\")\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/once/once.js?");

/***/ }),

/***/ "./node_modules/path-is-absolute/index.js":
/*!************************************************!*\
  !*** ./node_modules/path-is-absolute/index.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction posix(path) {\n\treturn path.charAt(0) === '/';\n}\n\nfunction win32(path) {\n\t// https://github.com/nodejs/node/blob/b3fcc245fb25539909ef1d5eaa01dbf92e168633/lib/path.js#L56\n\tvar splitDeviceRe = /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\n\tvar result = splitDeviceRe.exec(path);\n\tvar device = result[1] || '';\n\tvar isUnc = Boolean(device && device.charAt(1) !== ':');\n\n\t// UNC paths are always absolute\n\treturn Boolean(result[2] || isUnc);\n}\n\nmodule.exports = process.platform === 'win32' ? win32 : posix;\nmodule.exports.posix = posix;\nmodule.exports.win32 = win32;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/path-is-absolute/index.js?");

/***/ }),

/***/ "./node_modules/path/path.js":
/*!***********************************!*\
  !*** ./node_modules/path/path.js ***!
  \***********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\r\n//\r\n// Permission is hereby granted, free of charge, to any person obtaining a\r\n// copy of this software and associated documentation files (the\r\n// \"Software\"), to deal in the Software without restriction, including\r\n// without limitation the rights to use, copy, modify, merge, publish,\r\n// distribute, sublicense, and/or sell copies of the Software, and to permit\r\n// persons to whom the Software is furnished to do so, subject to the\r\n// following conditions:\r\n//\r\n// The above copyright notice and this permission notice shall be included\r\n// in all copies or substantial portions of the Software.\r\n//\r\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\r\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\r\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\r\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\r\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\r\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\r\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\r\n\r\n\r\n\r\n\r\nvar isWindows = process.platform === 'win32';\r\nvar util = __webpack_require__(/*! util */ \"./node_modules/util/util.js\");\r\n\r\n\r\n// resolves . and .. elements in a path array with directory names there\r\n// must be no slashes or device names (c:\\) in the array\r\n// (so also no leading and trailing slashes - it does not distinguish\r\n// relative and absolute paths)\r\nfunction normalizeArray(parts, allowAboveRoot) {\r\n  var res = [];\r\n  for (var i = 0; i < parts.length; i++) {\r\n    var p = parts[i];\r\n\r\n    // ignore empty parts\r\n    if (!p || p === '.')\r\n      continue;\r\n\r\n    if (p === '..') {\r\n      if (res.length && res[res.length - 1] !== '..') {\r\n        res.pop();\r\n      } else if (allowAboveRoot) {\r\n        res.push('..');\r\n      }\r\n    } else {\r\n      res.push(p);\r\n    }\r\n  }\r\n\r\n  return res;\r\n}\r\n\r\n// returns an array with empty elements removed from either end of the input\r\n// array or the original array if no elements need to be removed\r\nfunction trimArray(arr) {\r\n  var lastIndex = arr.length - 1;\r\n  var start = 0;\r\n  for (; start <= lastIndex; start++) {\r\n    if (arr[start])\r\n      break;\r\n  }\r\n\r\n  var end = lastIndex;\r\n  for (; end >= 0; end--) {\r\n    if (arr[end])\r\n      break;\r\n  }\r\n\r\n  if (start === 0 && end === lastIndex)\r\n    return arr;\r\n  if (start > end)\r\n    return [];\r\n  return arr.slice(start, end + 1);\r\n}\r\n\r\n// Regex to split a windows path into three parts: [*, device, slash,\r\n// tail] windows-only\r\nvar splitDeviceRe =\r\n    /^([a-zA-Z]:|[\\\\\\/]{2}[^\\\\\\/]+[\\\\\\/]+[^\\\\\\/]+)?([\\\\\\/])?([\\s\\S]*?)$/;\r\n\r\n// Regex to split the tail part of the above into [*, dir, basename, ext]\r\nvar splitTailRe =\r\n    /^([\\s\\S]*?)((?:\\.{1,2}|[^\\\\\\/]+?|)(\\.[^.\\/\\\\]*|))(?:[\\\\\\/]*)$/;\r\n\r\nvar win32 = {};\r\n\r\n// Function to split a filename into [root, dir, basename, ext]\r\nfunction win32SplitPath(filename) {\r\n  // Separate device+slash from tail\r\n  var result = splitDeviceRe.exec(filename),\r\n      device = (result[1] || '') + (result[2] || ''),\r\n      tail = result[3] || '';\r\n  // Split the tail into dir, basename and extension\r\n  var result2 = splitTailRe.exec(tail),\r\n      dir = result2[1],\r\n      basename = result2[2],\r\n      ext = result2[3];\r\n  return [device, dir, basename, ext];\r\n}\r\n\r\nfunction win32StatPath(path) {\r\n  var result = splitDeviceRe.exec(path),\r\n      device = result[1] || '',\r\n      isUnc = !!device && device[1] !== ':';\r\n  return {\r\n    device: device,\r\n    isUnc: isUnc,\r\n    isAbsolute: isUnc || !!result[2], // UNC paths are always absolute\r\n    tail: result[3]\r\n  };\r\n}\r\n\r\nfunction normalizeUNCRoot(device) {\r\n  return '\\\\\\\\' + device.replace(/^[\\\\\\/]+/, '').replace(/[\\\\\\/]+/g, '\\\\');\r\n}\r\n\r\n// path.resolve([from ...], to)\r\nwin32.resolve = function() {\r\n  var resolvedDevice = '',\r\n      resolvedTail = '',\r\n      resolvedAbsolute = false;\r\n\r\n  for (var i = arguments.length - 1; i >= -1; i--) {\r\n    var path;\r\n    if (i >= 0) {\r\n      path = arguments[i];\r\n    } else if (!resolvedDevice) {\r\n      path = process.cwd();\r\n    } else {\r\n      // Windows has the concept of drive-specific current working\r\n      // directories. If we've resolved a drive letter but not yet an\r\n      // absolute path, get cwd for that drive. We're sure the device is not\r\n      // an unc path at this points, because unc paths are always absolute.\r\n      path = process.env['=' + resolvedDevice];\r\n      // Verify that a drive-local cwd was found and that it actually points\r\n      // to our drive. If not, default to the drive's root.\r\n      if (!path || path.substr(0, 3).toLowerCase() !==\r\n          resolvedDevice.toLowerCase() + '\\\\') {\r\n        path = resolvedDevice + '\\\\';\r\n      }\r\n    }\r\n\r\n    // Skip empty and invalid entries\r\n    if (!util.isString(path)) {\r\n      throw new TypeError('Arguments to path.resolve must be strings');\r\n    } else if (!path) {\r\n      continue;\r\n    }\r\n\r\n    var result = win32StatPath(path),\r\n        device = result.device,\r\n        isUnc = result.isUnc,\r\n        isAbsolute = result.isAbsolute,\r\n        tail = result.tail;\r\n\r\n    if (device &&\r\n        resolvedDevice &&\r\n        device.toLowerCase() !== resolvedDevice.toLowerCase()) {\r\n      // This path points to another device so it is not applicable\r\n      continue;\r\n    }\r\n\r\n    if (!resolvedDevice) {\r\n      resolvedDevice = device;\r\n    }\r\n    if (!resolvedAbsolute) {\r\n      resolvedTail = tail + '\\\\' + resolvedTail;\r\n      resolvedAbsolute = isAbsolute;\r\n    }\r\n\r\n    if (resolvedDevice && resolvedAbsolute) {\r\n      break;\r\n    }\r\n  }\r\n\r\n  // Convert slashes to backslashes when `resolvedDevice` points to an UNC\r\n  // root. Also squash multiple slashes into a single one where appropriate.\r\n  if (isUnc) {\r\n    resolvedDevice = normalizeUNCRoot(resolvedDevice);\r\n  }\r\n\r\n  // At this point the path should be resolved to a full absolute path,\r\n  // but handle relative paths to be safe (might happen when process.cwd()\r\n  // fails)\r\n\r\n  // Normalize the tail path\r\n  resolvedTail = normalizeArray(resolvedTail.split(/[\\\\\\/]+/),\r\n                                !resolvedAbsolute).join('\\\\');\r\n\r\n  return (resolvedDevice + (resolvedAbsolute ? '\\\\' : '') + resolvedTail) ||\r\n         '.';\r\n};\r\n\r\n\r\nwin32.normalize = function(path) {\r\n  var result = win32StatPath(path),\r\n      device = result.device,\r\n      isUnc = result.isUnc,\r\n      isAbsolute = result.isAbsolute,\r\n      tail = result.tail,\r\n      trailingSlash = /[\\\\\\/]$/.test(tail);\r\n\r\n  // Normalize the tail path\r\n  tail = normalizeArray(tail.split(/[\\\\\\/]+/), !isAbsolute).join('\\\\');\r\n\r\n  if (!tail && !isAbsolute) {\r\n    tail = '.';\r\n  }\r\n  if (tail && trailingSlash) {\r\n    tail += '\\\\';\r\n  }\r\n\r\n  // Convert slashes to backslashes when `device` points to an UNC root.\r\n  // Also squash multiple slashes into a single one where appropriate.\r\n  if (isUnc) {\r\n    device = normalizeUNCRoot(device);\r\n  }\r\n\r\n  return device + (isAbsolute ? '\\\\' : '') + tail;\r\n};\r\n\r\n\r\nwin32.isAbsolute = function(path) {\r\n  return win32StatPath(path).isAbsolute;\r\n};\r\n\r\nwin32.join = function() {\r\n  var paths = [];\r\n  for (var i = 0; i < arguments.length; i++) {\r\n    var arg = arguments[i];\r\n    if (!util.isString(arg)) {\r\n      throw new TypeError('Arguments to path.join must be strings');\r\n    }\r\n    if (arg) {\r\n      paths.push(arg);\r\n    }\r\n  }\r\n\r\n  var joined = paths.join('\\\\');\r\n\r\n  // Make sure that the joined path doesn't start with two slashes, because\r\n  // normalize() will mistake it for an UNC path then.\r\n  //\r\n  // This step is skipped when it is very clear that the user actually\r\n  // intended to point at an UNC path. This is assumed when the first\r\n  // non-empty string arguments starts with exactly two slashes followed by\r\n  // at least one more non-slash character.\r\n  //\r\n  // Note that for normalize() to treat a path as an UNC path it needs to\r\n  // have at least 2 components, so we don't filter for that here.\r\n  // This means that the user can use join to construct UNC paths from\r\n  // a server name and a share name; for example:\r\n  //   path.join('//server', 'share') -> '\\\\\\\\server\\\\share\\')\r\n  if (!/^[\\\\\\/]{2}[^\\\\\\/]/.test(paths[0])) {\r\n    joined = joined.replace(/^[\\\\\\/]{2,}/, '\\\\');\r\n  }\r\n\r\n  return win32.normalize(joined);\r\n};\r\n\r\n\r\n// path.relative(from, to)\r\n// it will solve the relative path from 'from' to 'to', for instance:\r\n// from = 'C:\\\\orandea\\\\test\\\\aaa'\r\n// to = 'C:\\\\orandea\\\\impl\\\\bbb'\r\n// The output of the function should be: '..\\\\..\\\\impl\\\\bbb'\r\nwin32.relative = function(from, to) {\r\n  from = win32.resolve(from);\r\n  to = win32.resolve(to);\r\n\r\n  // windows is not case sensitive\r\n  var lowerFrom = from.toLowerCase();\r\n  var lowerTo = to.toLowerCase();\r\n\r\n  var toParts = trimArray(to.split('\\\\'));\r\n\r\n  var lowerFromParts = trimArray(lowerFrom.split('\\\\'));\r\n  var lowerToParts = trimArray(lowerTo.split('\\\\'));\r\n\r\n  var length = Math.min(lowerFromParts.length, lowerToParts.length);\r\n  var samePartsLength = length;\r\n  for (var i = 0; i < length; i++) {\r\n    if (lowerFromParts[i] !== lowerToParts[i]) {\r\n      samePartsLength = i;\r\n      break;\r\n    }\r\n  }\r\n\r\n  if (samePartsLength == 0) {\r\n    return to;\r\n  }\r\n\r\n  var outputParts = [];\r\n  for (var i = samePartsLength; i < lowerFromParts.length; i++) {\r\n    outputParts.push('..');\r\n  }\r\n\r\n  outputParts = outputParts.concat(toParts.slice(samePartsLength));\r\n\r\n  return outputParts.join('\\\\');\r\n};\r\n\r\n\r\nwin32._makeLong = function(path) {\r\n  // Note: this will *probably* throw somewhere.\r\n  if (!util.isString(path))\r\n    return path;\r\n\r\n  if (!path) {\r\n    return '';\r\n  }\r\n\r\n  var resolvedPath = win32.resolve(path);\r\n\r\n  if (/^[a-zA-Z]\\:\\\\/.test(resolvedPath)) {\r\n    // path is local filesystem path, which needs to be converted\r\n    // to long UNC path.\r\n    return '\\\\\\\\?\\\\' + resolvedPath;\r\n  } else if (/^\\\\\\\\[^?.]/.test(resolvedPath)) {\r\n    // path is network UNC path, which needs to be converted\r\n    // to long UNC path.\r\n    return '\\\\\\\\?\\\\UNC\\\\' + resolvedPath.substring(2);\r\n  }\r\n\r\n  return path;\r\n};\r\n\r\n\r\nwin32.dirname = function(path) {\r\n  var result = win32SplitPath(path),\r\n      root = result[0],\r\n      dir = result[1];\r\n\r\n  if (!root && !dir) {\r\n    // No dirname whatsoever\r\n    return '.';\r\n  }\r\n\r\n  if (dir) {\r\n    // It has a dirname, strip trailing slash\r\n    dir = dir.substr(0, dir.length - 1);\r\n  }\r\n\r\n  return root + dir;\r\n};\r\n\r\n\r\nwin32.basename = function(path, ext) {\r\n  var f = win32SplitPath(path)[2];\r\n  // TODO: make this comparison case-insensitive on windows?\r\n  if (ext && f.substr(-1 * ext.length) === ext) {\r\n    f = f.substr(0, f.length - ext.length);\r\n  }\r\n  return f;\r\n};\r\n\r\n\r\nwin32.extname = function(path) {\r\n  return win32SplitPath(path)[3];\r\n};\r\n\r\n\r\nwin32.format = function(pathObject) {\r\n  if (!util.isObject(pathObject)) {\r\n    throw new TypeError(\r\n        \"Parameter 'pathObject' must be an object, not \" + typeof pathObject\r\n    );\r\n  }\r\n\r\n  var root = pathObject.root || '';\r\n\r\n  if (!util.isString(root)) {\r\n    throw new TypeError(\r\n        \"'pathObject.root' must be a string or undefined, not \" +\r\n        typeof pathObject.root\r\n    );\r\n  }\r\n\r\n  var dir = pathObject.dir;\r\n  var base = pathObject.base || '';\r\n  if (!dir) {\r\n    return base;\r\n  }\r\n  if (dir[dir.length - 1] === win32.sep) {\r\n    return dir + base;\r\n  }\r\n  return dir + win32.sep + base;\r\n};\r\n\r\n\r\nwin32.parse = function(pathString) {\r\n  if (!util.isString(pathString)) {\r\n    throw new TypeError(\r\n        \"Parameter 'pathString' must be a string, not \" + typeof pathString\r\n    );\r\n  }\r\n  var allParts = win32SplitPath(pathString);\r\n  if (!allParts || allParts.length !== 4) {\r\n    throw new TypeError(\"Invalid path '\" + pathString + \"'\");\r\n  }\r\n  return {\r\n    root: allParts[0],\r\n    dir: allParts[0] + allParts[1].slice(0, -1),\r\n    base: allParts[2],\r\n    ext: allParts[3],\r\n    name: allParts[2].slice(0, allParts[2].length - allParts[3].length)\r\n  };\r\n};\r\n\r\n\r\nwin32.sep = '\\\\';\r\nwin32.delimiter = ';';\r\n\r\n\r\n// Split a filename into [root, dir, basename, ext], unix version\r\n// 'root' is just a slash, or nothing.\r\nvar splitPathRe =\r\n    /^(\\/?|)([\\s\\S]*?)((?:\\.{1,2}|[^\\/]+?|)(\\.[^.\\/]*|))(?:[\\/]*)$/;\r\nvar posix = {};\r\n\r\n\r\nfunction posixSplitPath(filename) {\r\n  return splitPathRe.exec(filename).slice(1);\r\n}\r\n\r\n\r\n// path.resolve([from ...], to)\r\n// posix version\r\nposix.resolve = function() {\r\n  var resolvedPath = '',\r\n      resolvedAbsolute = false;\r\n\r\n  for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {\r\n    var path = (i >= 0) ? arguments[i] : process.cwd();\r\n\r\n    // Skip empty and invalid entries\r\n    if (!util.isString(path)) {\r\n      throw new TypeError('Arguments to path.resolve must be strings');\r\n    } else if (!path) {\r\n      continue;\r\n    }\r\n\r\n    resolvedPath = path + '/' + resolvedPath;\r\n    resolvedAbsolute = path[0] === '/';\r\n  }\r\n\r\n  // At this point the path should be resolved to a full absolute path, but\r\n  // handle relative paths to be safe (might happen when process.cwd() fails)\r\n\r\n  // Normalize the path\r\n  resolvedPath = normalizeArray(resolvedPath.split('/'),\r\n                                !resolvedAbsolute).join('/');\r\n\r\n  return ((resolvedAbsolute ? '/' : '') + resolvedPath) || '.';\r\n};\r\n\r\n// path.normalize(path)\r\n// posix version\r\nposix.normalize = function(path) {\r\n  var isAbsolute = posix.isAbsolute(path),\r\n      trailingSlash = path && path[path.length - 1] === '/';\r\n\r\n  // Normalize the path\r\n  path = normalizeArray(path.split('/'), !isAbsolute).join('/');\r\n\r\n  if (!path && !isAbsolute) {\r\n    path = '.';\r\n  }\r\n  if (path && trailingSlash) {\r\n    path += '/';\r\n  }\r\n\r\n  return (isAbsolute ? '/' : '') + path;\r\n};\r\n\r\n// posix version\r\nposix.isAbsolute = function(path) {\r\n  return path.charAt(0) === '/';\r\n};\r\n\r\n// posix version\r\nposix.join = function() {\r\n  var path = '';\r\n  for (var i = 0; i < arguments.length; i++) {\r\n    var segment = arguments[i];\r\n    if (!util.isString(segment)) {\r\n      throw new TypeError('Arguments to path.join must be strings');\r\n    }\r\n    if (segment) {\r\n      if (!path) {\r\n        path += segment;\r\n      } else {\r\n        path += '/' + segment;\r\n      }\r\n    }\r\n  }\r\n  return posix.normalize(path);\r\n};\r\n\r\n\r\n// path.relative(from, to)\r\n// posix version\r\nposix.relative = function(from, to) {\r\n  from = posix.resolve(from).substr(1);\r\n  to = posix.resolve(to).substr(1);\r\n\r\n  var fromParts = trimArray(from.split('/'));\r\n  var toParts = trimArray(to.split('/'));\r\n\r\n  var length = Math.min(fromParts.length, toParts.length);\r\n  var samePartsLength = length;\r\n  for (var i = 0; i < length; i++) {\r\n    if (fromParts[i] !== toParts[i]) {\r\n      samePartsLength = i;\r\n      break;\r\n    }\r\n  }\r\n\r\n  var outputParts = [];\r\n  for (var i = samePartsLength; i < fromParts.length; i++) {\r\n    outputParts.push('..');\r\n  }\r\n\r\n  outputParts = outputParts.concat(toParts.slice(samePartsLength));\r\n\r\n  return outputParts.join('/');\r\n};\r\n\r\n\r\nposix._makeLong = function(path) {\r\n  return path;\r\n};\r\n\r\n\r\nposix.dirname = function(path) {\r\n  var result = posixSplitPath(path),\r\n      root = result[0],\r\n      dir = result[1];\r\n\r\n  if (!root && !dir) {\r\n    // No dirname whatsoever\r\n    return '.';\r\n  }\r\n\r\n  if (dir) {\r\n    // It has a dirname, strip trailing slash\r\n    dir = dir.substr(0, dir.length - 1);\r\n  }\r\n\r\n  return root + dir;\r\n};\r\n\r\n\r\nposix.basename = function(path, ext) {\r\n  var f = posixSplitPath(path)[2];\r\n  // TODO: make this comparison case-insensitive on windows?\r\n  if (ext && f.substr(-1 * ext.length) === ext) {\r\n    f = f.substr(0, f.length - ext.length);\r\n  }\r\n  return f;\r\n};\r\n\r\n\r\nposix.extname = function(path) {\r\n  return posixSplitPath(path)[3];\r\n};\r\n\r\n\r\nposix.format = function(pathObject) {\r\n  if (!util.isObject(pathObject)) {\r\n    throw new TypeError(\r\n        \"Parameter 'pathObject' must be an object, not \" + typeof pathObject\r\n    );\r\n  }\r\n\r\n  var root = pathObject.root || '';\r\n\r\n  if (!util.isString(root)) {\r\n    throw new TypeError(\r\n        \"'pathObject.root' must be a string or undefined, not \" +\r\n        typeof pathObject.root\r\n    );\r\n  }\r\n\r\n  var dir = pathObject.dir ? pathObject.dir + posix.sep : '';\r\n  var base = pathObject.base || '';\r\n  return dir + base;\r\n};\r\n\r\n\r\nposix.parse = function(pathString) {\r\n  if (!util.isString(pathString)) {\r\n    throw new TypeError(\r\n        \"Parameter 'pathString' must be a string, not \" + typeof pathString\r\n    );\r\n  }\r\n  var allParts = posixSplitPath(pathString);\r\n  if (!allParts || allParts.length !== 4) {\r\n    throw new TypeError(\"Invalid path '\" + pathString + \"'\");\r\n  }\r\n  allParts[1] = allParts[1] || '';\r\n  allParts[2] = allParts[2] || '';\r\n  allParts[3] = allParts[3] || '';\r\n\r\n  return {\r\n    root: allParts[0],\r\n    dir: allParts[0] + allParts[1].slice(0, -1),\r\n    base: allParts[2],\r\n    ext: allParts[3],\r\n    name: allParts[2].slice(0, allParts[2].length - allParts[3].length)\r\n  };\r\n};\r\n\r\n\r\nposix.sep = '/';\r\nposix.delimiter = ':';\r\n\r\n\r\nif (isWindows)\r\n  module.exports = win32;\r\nelse /* posix */\r\n  module.exports = posix;\r\n\r\nmodule.exports.posix = posix;\r\nmodule.exports.win32 = win32;\r\n\n\n//# sourceURL=webpack://thelambda/./node_modules/path/path.js?");

/***/ }),

/***/ "./node_modules/process/browser.js":
/*!*****************************************!*\
  !*** ./node_modules/process/browser.js ***!
  \*****************************************/
/***/ ((module) => {

eval("// shim for using process in browser\nvar process = module.exports = {};\n\n// cached from whatever global is present so that test runners that stub it\n// don't break things.  But we need to wrap it in a try catch in case it is\n// wrapped in strict mode code which doesn't define any globals.  It's inside a\n// function because try/catches deoptimize in certain engines.\n\nvar cachedSetTimeout;\nvar cachedClearTimeout;\n\nfunction defaultSetTimout() {\n    throw new Error('setTimeout has not been defined');\n}\nfunction defaultClearTimeout () {\n    throw new Error('clearTimeout has not been defined');\n}\n(function () {\n    try {\n        if (typeof setTimeout === 'function') {\n            cachedSetTimeout = setTimeout;\n        } else {\n            cachedSetTimeout = defaultSetTimout;\n        }\n    } catch (e) {\n        cachedSetTimeout = defaultSetTimout;\n    }\n    try {\n        if (typeof clearTimeout === 'function') {\n            cachedClearTimeout = clearTimeout;\n        } else {\n            cachedClearTimeout = defaultClearTimeout;\n        }\n    } catch (e) {\n        cachedClearTimeout = defaultClearTimeout;\n    }\n} ())\nfunction runTimeout(fun) {\n    if (cachedSetTimeout === setTimeout) {\n        //normal enviroments in sane situations\n        return setTimeout(fun, 0);\n    }\n    // if setTimeout wasn't available but was latter defined\n    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {\n        cachedSetTimeout = setTimeout;\n        return setTimeout(fun, 0);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedSetTimeout(fun, 0);\n    } catch(e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally\n            return cachedSetTimeout.call(null, fun, 0);\n        } catch(e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error\n            return cachedSetTimeout.call(this, fun, 0);\n        }\n    }\n\n\n}\nfunction runClearTimeout(marker) {\n    if (cachedClearTimeout === clearTimeout) {\n        //normal enviroments in sane situations\n        return clearTimeout(marker);\n    }\n    // if clearTimeout wasn't available but was latter defined\n    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {\n        cachedClearTimeout = clearTimeout;\n        return clearTimeout(marker);\n    }\n    try {\n        // when when somebody has screwed with setTimeout but no I.E. maddness\n        return cachedClearTimeout(marker);\n    } catch (e){\n        try {\n            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally\n            return cachedClearTimeout.call(null, marker);\n        } catch (e){\n            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.\n            // Some versions of I.E. have different rules for clearTimeout vs setTimeout\n            return cachedClearTimeout.call(this, marker);\n        }\n    }\n\n\n\n}\nvar queue = [];\nvar draining = false;\nvar currentQueue;\nvar queueIndex = -1;\n\nfunction cleanUpNextTick() {\n    if (!draining || !currentQueue) {\n        return;\n    }\n    draining = false;\n    if (currentQueue.length) {\n        queue = currentQueue.concat(queue);\n    } else {\n        queueIndex = -1;\n    }\n    if (queue.length) {\n        drainQueue();\n    }\n}\n\nfunction drainQueue() {\n    if (draining) {\n        return;\n    }\n    var timeout = runTimeout(cleanUpNextTick);\n    draining = true;\n\n    var len = queue.length;\n    while(len) {\n        currentQueue = queue;\n        queue = [];\n        while (++queueIndex < len) {\n            if (currentQueue) {\n                currentQueue[queueIndex].run();\n            }\n        }\n        queueIndex = -1;\n        len = queue.length;\n    }\n    currentQueue = null;\n    draining = false;\n    runClearTimeout(timeout);\n}\n\nprocess.nextTick = function (fun) {\n    var args = new Array(arguments.length - 1);\n    if (arguments.length > 1) {\n        for (var i = 1; i < arguments.length; i++) {\n            args[i - 1] = arguments[i];\n        }\n    }\n    queue.push(new Item(fun, args));\n    if (queue.length === 1 && !draining) {\n        runTimeout(drainQueue);\n    }\n};\n\n// v8 likes predictible objects\nfunction Item(fun, array) {\n    this.fun = fun;\n    this.array = array;\n}\nItem.prototype.run = function () {\n    this.fun.apply(null, this.array);\n};\nprocess.title = 'browser';\nprocess.browser = true;\nprocess.env = {};\nprocess.argv = [];\nprocess.version = ''; // empty string to avoid regexp issues\nprocess.versions = {};\n\nfunction noop() {}\n\nprocess.on = noop;\nprocess.addListener = noop;\nprocess.once = noop;\nprocess.off = noop;\nprocess.removeListener = noop;\nprocess.removeAllListeners = noop;\nprocess.emit = noop;\nprocess.prependListener = noop;\nprocess.prependOnceListener = noop;\n\nprocess.listeners = function (name) { return [] }\n\nprocess.binding = function (name) {\n    throw new Error('process.binding is not supported');\n};\n\nprocess.cwd = function () { return '/' };\nprocess.chdir = function (dir) {\n    throw new Error('process.chdir is not supported');\n};\nprocess.umask = function() { return 0; };\n\n\n//# sourceURL=webpack://thelambda/./node_modules/process/browser.js?");

/***/ }),

/***/ "./node_modules/qs/lib/formats.js":
/*!****************************************!*\
  !*** ./node_modules/qs/lib/formats.js ***!
  \****************************************/
/***/ ((module) => {

"use strict";
eval("\n\nvar replace = String.prototype.replace;\nvar percentTwenties = /%20/g;\n\nvar Format = {\n    RFC1738: 'RFC1738',\n    RFC3986: 'RFC3986'\n};\n\nmodule.exports = {\n    'default': Format.RFC3986,\n    formatters: {\n        RFC1738: function (value) {\n            return replace.call(value, percentTwenties, '+');\n        },\n        RFC3986: function (value) {\n            return String(value);\n        }\n    },\n    RFC1738: Format.RFC1738,\n    RFC3986: Format.RFC3986\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/qs/lib/formats.js?");

/***/ }),

/***/ "./node_modules/qs/lib/index.js":
/*!**************************************!*\
  !*** ./node_modules/qs/lib/index.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar stringify = __webpack_require__(/*! ./stringify */ \"./node_modules/qs/lib/stringify.js\");\nvar parse = __webpack_require__(/*! ./parse */ \"./node_modules/qs/lib/parse.js\");\nvar formats = __webpack_require__(/*! ./formats */ \"./node_modules/qs/lib/formats.js\");\n\nmodule.exports = {\n    formats: formats,\n    parse: parse,\n    stringify: stringify\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/qs/lib/index.js?");

/***/ }),

/***/ "./node_modules/qs/lib/parse.js":
/*!**************************************!*\
  !*** ./node_modules/qs/lib/parse.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/qs/lib/utils.js\");\n\nvar has = Object.prototype.hasOwnProperty;\nvar isArray = Array.isArray;\n\nvar defaults = {\n    allowDots: false,\n    allowEmptyArrays: false,\n    allowPrototypes: false,\n    allowSparse: false,\n    arrayLimit: 20,\n    charset: 'utf-8',\n    charsetSentinel: false,\n    comma: false,\n    decodeDotInKeys: false,\n    decoder: utils.decode,\n    delimiter: '&',\n    depth: 5,\n    duplicates: 'combine',\n    ignoreQueryPrefix: false,\n    interpretNumericEntities: false,\n    parameterLimit: 1000,\n    parseArrays: true,\n    plainObjects: false,\n    strictDepth: false,\n    strictNullHandling: false\n};\n\nvar interpretNumericEntities = function (str) {\n    return str.replace(/&#(\\d+);/g, function ($0, numberStr) {\n        return String.fromCharCode(parseInt(numberStr, 10));\n    });\n};\n\nvar parseArrayValue = function (val, options) {\n    if (val && typeof val === 'string' && options.comma && val.indexOf(',') > -1) {\n        return val.split(',');\n    }\n\n    return val;\n};\n\n// This is what browsers will submit when the  character occurs in an\n// application/x-www-form-urlencoded body and the encoding of the page containing\n// the form is iso-8859-1, or when the submitted form has an accept-charset\n// attribute of iso-8859-1. Presumably also with other charsets that do not contain\n// the  character, such as us-ascii.\nvar isoSentinel = 'utf8=%26%2310003%3B'; // encodeURIComponent('&#10003;')\n\n// These are the percent-encoded utf-8 octets representing a checkmark, indicating that the request actually is utf-8 encoded.\nvar charsetSentinel = 'utf8=%E2%9C%93'; // encodeURIComponent('')\n\nvar parseValues = function parseQueryStringValues(str, options) {\n    var obj = { __proto__: null };\n\n    var cleanStr = options.ignoreQueryPrefix ? str.replace(/^\\?/, '') : str;\n    cleanStr = cleanStr.replace(/%5B/gi, '[').replace(/%5D/gi, ']');\n    var limit = options.parameterLimit === Infinity ? undefined : options.parameterLimit;\n    var parts = cleanStr.split(options.delimiter, limit);\n    var skipIndex = -1; // Keep track of where the utf8 sentinel was found\n    var i;\n\n    var charset = options.charset;\n    if (options.charsetSentinel) {\n        for (i = 0; i < parts.length; ++i) {\n            if (parts[i].indexOf('utf8=') === 0) {\n                if (parts[i] === charsetSentinel) {\n                    charset = 'utf-8';\n                } else if (parts[i] === isoSentinel) {\n                    charset = 'iso-8859-1';\n                }\n                skipIndex = i;\n                i = parts.length; // The eslint settings do not allow break;\n            }\n        }\n    }\n\n    for (i = 0; i < parts.length; ++i) {\n        if (i === skipIndex) {\n            continue;\n        }\n        var part = parts[i];\n\n        var bracketEqualsPos = part.indexOf(']=');\n        var pos = bracketEqualsPos === -1 ? part.indexOf('=') : bracketEqualsPos + 1;\n\n        var key, val;\n        if (pos === -1) {\n            key = options.decoder(part, defaults.decoder, charset, 'key');\n            val = options.strictNullHandling ? null : '';\n        } else {\n            key = options.decoder(part.slice(0, pos), defaults.decoder, charset, 'key');\n            val = utils.maybeMap(\n                parseArrayValue(part.slice(pos + 1), options),\n                function (encodedVal) {\n                    return options.decoder(encodedVal, defaults.decoder, charset, 'value');\n                }\n            );\n        }\n\n        if (val && options.interpretNumericEntities && charset === 'iso-8859-1') {\n            val = interpretNumericEntities(val);\n        }\n\n        if (part.indexOf('[]=') > -1) {\n            val = isArray(val) ? [val] : val;\n        }\n\n        var existing = has.call(obj, key);\n        if (existing && options.duplicates === 'combine') {\n            obj[key] = utils.combine(obj[key], val);\n        } else if (!existing || options.duplicates === 'last') {\n            obj[key] = val;\n        }\n    }\n\n    return obj;\n};\n\nvar parseObject = function (chain, val, options, valuesParsed) {\n    var leaf = valuesParsed ? val : parseArrayValue(val, options);\n\n    for (var i = chain.length - 1; i >= 0; --i) {\n        var obj;\n        var root = chain[i];\n\n        if (root === '[]' && options.parseArrays) {\n            obj = options.allowEmptyArrays && (leaf === '' || (options.strictNullHandling && leaf === null))\n                ? []\n                : [].concat(leaf);\n        } else {\n            obj = options.plainObjects ? Object.create(null) : {};\n            var cleanRoot = root.charAt(0) === '[' && root.charAt(root.length - 1) === ']' ? root.slice(1, -1) : root;\n            var decodedRoot = options.decodeDotInKeys ? cleanRoot.replace(/%2E/g, '.') : cleanRoot;\n            var index = parseInt(decodedRoot, 10);\n            if (!options.parseArrays && decodedRoot === '') {\n                obj = { 0: leaf };\n            } else if (\n                !isNaN(index)\n                && root !== decodedRoot\n                && String(index) === decodedRoot\n                && index >= 0\n                && (options.parseArrays && index <= options.arrayLimit)\n            ) {\n                obj = [];\n                obj[index] = leaf;\n            } else if (decodedRoot !== '__proto__') {\n                obj[decodedRoot] = leaf;\n            }\n        }\n\n        leaf = obj;\n    }\n\n    return leaf;\n};\n\nvar parseKeys = function parseQueryStringKeys(givenKey, val, options, valuesParsed) {\n    if (!givenKey) {\n        return;\n    }\n\n    // Transform dot notation to bracket notation\n    var key = options.allowDots ? givenKey.replace(/\\.([^.[]+)/g, '[$1]') : givenKey;\n\n    // The regex chunks\n\n    var brackets = /(\\[[^[\\]]*])/;\n    var child = /(\\[[^[\\]]*])/g;\n\n    // Get the parent\n\n    var segment = options.depth > 0 && brackets.exec(key);\n    var parent = segment ? key.slice(0, segment.index) : key;\n\n    // Stash the parent if it exists\n\n    var keys = [];\n    if (parent) {\n        // If we aren't using plain objects, optionally prefix keys that would overwrite object prototype properties\n        if (!options.plainObjects && has.call(Object.prototype, parent)) {\n            if (!options.allowPrototypes) {\n                return;\n            }\n        }\n\n        keys.push(parent);\n    }\n\n    // Loop through children appending to the array until we hit depth\n\n    var i = 0;\n    while (options.depth > 0 && (segment = child.exec(key)) !== null && i < options.depth) {\n        i += 1;\n        if (!options.plainObjects && has.call(Object.prototype, segment[1].slice(1, -1))) {\n            if (!options.allowPrototypes) {\n                return;\n            }\n        }\n        keys.push(segment[1]);\n    }\n\n    // If there's a remainder, check strictDepth option for throw, else just add whatever is left\n\n    if (segment) {\n        if (options.strictDepth === true) {\n            throw new RangeError('Input depth exceeded depth option of ' + options.depth + ' and strictDepth is true');\n        }\n        keys.push('[' + key.slice(segment.index) + ']');\n    }\n\n    return parseObject(keys, val, options, valuesParsed);\n};\n\nvar normalizeParseOptions = function normalizeParseOptions(opts) {\n    if (!opts) {\n        return defaults;\n    }\n\n    if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n        throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n    }\n\n    if (typeof opts.decodeDotInKeys !== 'undefined' && typeof opts.decodeDotInKeys !== 'boolean') {\n        throw new TypeError('`decodeDotInKeys` option can only be `true` or `false`, when provided');\n    }\n\n    if (opts.decoder !== null && typeof opts.decoder !== 'undefined' && typeof opts.decoder !== 'function') {\n        throw new TypeError('Decoder has to be a function.');\n    }\n\n    if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n        throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n    }\n    var charset = typeof opts.charset === 'undefined' ? defaults.charset : opts.charset;\n\n    var duplicates = typeof opts.duplicates === 'undefined' ? defaults.duplicates : opts.duplicates;\n\n    if (duplicates !== 'combine' && duplicates !== 'first' && duplicates !== 'last') {\n        throw new TypeError('The duplicates option must be either combine, first, or last');\n    }\n\n    var allowDots = typeof opts.allowDots === 'undefined' ? opts.decodeDotInKeys === true ? true : defaults.allowDots : !!opts.allowDots;\n\n    return {\n        allowDots: allowDots,\n        allowEmptyArrays: typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n        allowPrototypes: typeof opts.allowPrototypes === 'boolean' ? opts.allowPrototypes : defaults.allowPrototypes,\n        allowSparse: typeof opts.allowSparse === 'boolean' ? opts.allowSparse : defaults.allowSparse,\n        arrayLimit: typeof opts.arrayLimit === 'number' ? opts.arrayLimit : defaults.arrayLimit,\n        charset: charset,\n        charsetSentinel: typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n        comma: typeof opts.comma === 'boolean' ? opts.comma : defaults.comma,\n        decodeDotInKeys: typeof opts.decodeDotInKeys === 'boolean' ? opts.decodeDotInKeys : defaults.decodeDotInKeys,\n        decoder: typeof opts.decoder === 'function' ? opts.decoder : defaults.decoder,\n        delimiter: typeof opts.delimiter === 'string' || utils.isRegExp(opts.delimiter) ? opts.delimiter : defaults.delimiter,\n        // eslint-disable-next-line no-implicit-coercion, no-extra-parens\n        depth: (typeof opts.depth === 'number' || opts.depth === false) ? +opts.depth : defaults.depth,\n        duplicates: duplicates,\n        ignoreQueryPrefix: opts.ignoreQueryPrefix === true,\n        interpretNumericEntities: typeof opts.interpretNumericEntities === 'boolean' ? opts.interpretNumericEntities : defaults.interpretNumericEntities,\n        parameterLimit: typeof opts.parameterLimit === 'number' ? opts.parameterLimit : defaults.parameterLimit,\n        parseArrays: opts.parseArrays !== false,\n        plainObjects: typeof opts.plainObjects === 'boolean' ? opts.plainObjects : defaults.plainObjects,\n        strictDepth: typeof opts.strictDepth === 'boolean' ? !!opts.strictDepth : defaults.strictDepth,\n        strictNullHandling: typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling\n    };\n};\n\nmodule.exports = function (str, opts) {\n    var options = normalizeParseOptions(opts);\n\n    if (str === '' || str === null || typeof str === 'undefined') {\n        return options.plainObjects ? Object.create(null) : {};\n    }\n\n    var tempObj = typeof str === 'string' ? parseValues(str, options) : str;\n    var obj = options.plainObjects ? Object.create(null) : {};\n\n    // Iterate over the keys and setup the new object\n\n    var keys = Object.keys(tempObj);\n    for (var i = 0; i < keys.length; ++i) {\n        var key = keys[i];\n        var newObj = parseKeys(key, tempObj[key], options, typeof str === 'string');\n        obj = utils.merge(obj, newObj, options);\n    }\n\n    if (options.allowSparse === true) {\n        return obj;\n    }\n\n    return utils.compact(obj);\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/qs/lib/parse.js?");

/***/ }),

/***/ "./node_modules/qs/lib/stringify.js":
/*!******************************************!*\
  !*** ./node_modules/qs/lib/stringify.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar getSideChannel = __webpack_require__(/*! side-channel */ \"./node_modules/side-channel/index.js\");\nvar utils = __webpack_require__(/*! ./utils */ \"./node_modules/qs/lib/utils.js\");\nvar formats = __webpack_require__(/*! ./formats */ \"./node_modules/qs/lib/formats.js\");\nvar has = Object.prototype.hasOwnProperty;\n\nvar arrayPrefixGenerators = {\n    brackets: function brackets(prefix) {\n        return prefix + '[]';\n    },\n    comma: 'comma',\n    indices: function indices(prefix, key) {\n        return prefix + '[' + key + ']';\n    },\n    repeat: function repeat(prefix) {\n        return prefix;\n    }\n};\n\nvar isArray = Array.isArray;\nvar push = Array.prototype.push;\nvar pushToArray = function (arr, valueOrArray) {\n    push.apply(arr, isArray(valueOrArray) ? valueOrArray : [valueOrArray]);\n};\n\nvar toISO = Date.prototype.toISOString;\n\nvar defaultFormat = formats['default'];\nvar defaults = {\n    addQueryPrefix: false,\n    allowDots: false,\n    allowEmptyArrays: false,\n    arrayFormat: 'indices',\n    charset: 'utf-8',\n    charsetSentinel: false,\n    delimiter: '&',\n    encode: true,\n    encodeDotInKeys: false,\n    encoder: utils.encode,\n    encodeValuesOnly: false,\n    format: defaultFormat,\n    formatter: formats.formatters[defaultFormat],\n    // deprecated\n    indices: false,\n    serializeDate: function serializeDate(date) {\n        return toISO.call(date);\n    },\n    skipNulls: false,\n    strictNullHandling: false\n};\n\nvar isNonNullishPrimitive = function isNonNullishPrimitive(v) {\n    return typeof v === 'string'\n        || typeof v === 'number'\n        || typeof v === 'boolean'\n        || typeof v === 'symbol'\n        || typeof v === 'bigint';\n};\n\nvar sentinel = {};\n\nvar stringify = function stringify(\n    object,\n    prefix,\n    generateArrayPrefix,\n    commaRoundTrip,\n    allowEmptyArrays,\n    strictNullHandling,\n    skipNulls,\n    encodeDotInKeys,\n    encoder,\n    filter,\n    sort,\n    allowDots,\n    serializeDate,\n    format,\n    formatter,\n    encodeValuesOnly,\n    charset,\n    sideChannel\n) {\n    var obj = object;\n\n    var tmpSc = sideChannel;\n    var step = 0;\n    var findFlag = false;\n    while ((tmpSc = tmpSc.get(sentinel)) !== void undefined && !findFlag) {\n        // Where object last appeared in the ref tree\n        var pos = tmpSc.get(object);\n        step += 1;\n        if (typeof pos !== 'undefined') {\n            if (pos === step) {\n                throw new RangeError('Cyclic object value');\n            } else {\n                findFlag = true; // Break while\n            }\n        }\n        if (typeof tmpSc.get(sentinel) === 'undefined') {\n            step = 0;\n        }\n    }\n\n    if (typeof filter === 'function') {\n        obj = filter(prefix, obj);\n    } else if (obj instanceof Date) {\n        obj = serializeDate(obj);\n    } else if (generateArrayPrefix === 'comma' && isArray(obj)) {\n        obj = utils.maybeMap(obj, function (value) {\n            if (value instanceof Date) {\n                return serializeDate(value);\n            }\n            return value;\n        });\n    }\n\n    if (obj === null) {\n        if (strictNullHandling) {\n            return encoder && !encodeValuesOnly ? encoder(prefix, defaults.encoder, charset, 'key', format) : prefix;\n        }\n\n        obj = '';\n    }\n\n    if (isNonNullishPrimitive(obj) || utils.isBuffer(obj)) {\n        if (encoder) {\n            var keyValue = encodeValuesOnly ? prefix : encoder(prefix, defaults.encoder, charset, 'key', format);\n            return [formatter(keyValue) + '=' + formatter(encoder(obj, defaults.encoder, charset, 'value', format))];\n        }\n        return [formatter(prefix) + '=' + formatter(String(obj))];\n    }\n\n    var values = [];\n\n    if (typeof obj === 'undefined') {\n        return values;\n    }\n\n    var objKeys;\n    if (generateArrayPrefix === 'comma' && isArray(obj)) {\n        // we need to join elements in\n        if (encodeValuesOnly && encoder) {\n            obj = utils.maybeMap(obj, encoder);\n        }\n        objKeys = [{ value: obj.length > 0 ? obj.join(',') || null : void undefined }];\n    } else if (isArray(filter)) {\n        objKeys = filter;\n    } else {\n        var keys = Object.keys(obj);\n        objKeys = sort ? keys.sort(sort) : keys;\n    }\n\n    var encodedPrefix = encodeDotInKeys ? prefix.replace(/\\./g, '%2E') : prefix;\n\n    var adjustedPrefix = commaRoundTrip && isArray(obj) && obj.length === 1 ? encodedPrefix + '[]' : encodedPrefix;\n\n    if (allowEmptyArrays && isArray(obj) && obj.length === 0) {\n        return adjustedPrefix + '[]';\n    }\n\n    for (var j = 0; j < objKeys.length; ++j) {\n        var key = objKeys[j];\n        var value = typeof key === 'object' && typeof key.value !== 'undefined' ? key.value : obj[key];\n\n        if (skipNulls && value === null) {\n            continue;\n        }\n\n        var encodedKey = allowDots && encodeDotInKeys ? key.replace(/\\./g, '%2E') : key;\n        var keyPrefix = isArray(obj)\n            ? typeof generateArrayPrefix === 'function' ? generateArrayPrefix(adjustedPrefix, encodedKey) : adjustedPrefix\n            : adjustedPrefix + (allowDots ? '.' + encodedKey : '[' + encodedKey + ']');\n\n        sideChannel.set(object, step);\n        var valueSideChannel = getSideChannel();\n        valueSideChannel.set(sentinel, sideChannel);\n        pushToArray(values, stringify(\n            value,\n            keyPrefix,\n            generateArrayPrefix,\n            commaRoundTrip,\n            allowEmptyArrays,\n            strictNullHandling,\n            skipNulls,\n            encodeDotInKeys,\n            generateArrayPrefix === 'comma' && encodeValuesOnly && isArray(obj) ? null : encoder,\n            filter,\n            sort,\n            allowDots,\n            serializeDate,\n            format,\n            formatter,\n            encodeValuesOnly,\n            charset,\n            valueSideChannel\n        ));\n    }\n\n    return values;\n};\n\nvar normalizeStringifyOptions = function normalizeStringifyOptions(opts) {\n    if (!opts) {\n        return defaults;\n    }\n\n    if (typeof opts.allowEmptyArrays !== 'undefined' && typeof opts.allowEmptyArrays !== 'boolean') {\n        throw new TypeError('`allowEmptyArrays` option can only be `true` or `false`, when provided');\n    }\n\n    if (typeof opts.encodeDotInKeys !== 'undefined' && typeof opts.encodeDotInKeys !== 'boolean') {\n        throw new TypeError('`encodeDotInKeys` option can only be `true` or `false`, when provided');\n    }\n\n    if (opts.encoder !== null && typeof opts.encoder !== 'undefined' && typeof opts.encoder !== 'function') {\n        throw new TypeError('Encoder has to be a function.');\n    }\n\n    var charset = opts.charset || defaults.charset;\n    if (typeof opts.charset !== 'undefined' && opts.charset !== 'utf-8' && opts.charset !== 'iso-8859-1') {\n        throw new TypeError('The charset option must be either utf-8, iso-8859-1, or undefined');\n    }\n\n    var format = formats['default'];\n    if (typeof opts.format !== 'undefined') {\n        if (!has.call(formats.formatters, opts.format)) {\n            throw new TypeError('Unknown format option provided.');\n        }\n        format = opts.format;\n    }\n    var formatter = formats.formatters[format];\n\n    var filter = defaults.filter;\n    if (typeof opts.filter === 'function' || isArray(opts.filter)) {\n        filter = opts.filter;\n    }\n\n    var arrayFormat;\n    if (opts.arrayFormat in arrayPrefixGenerators) {\n        arrayFormat = opts.arrayFormat;\n    } else if ('indices' in opts) {\n        arrayFormat = opts.indices ? 'indices' : 'repeat';\n    } else {\n        arrayFormat = defaults.arrayFormat;\n    }\n\n    if ('commaRoundTrip' in opts && typeof opts.commaRoundTrip !== 'boolean') {\n        throw new TypeError('`commaRoundTrip` must be a boolean, or absent');\n    }\n\n    var allowDots = typeof opts.allowDots === 'undefined' ? opts.encodeDotInKeys === true ? true : defaults.allowDots : !!opts.allowDots;\n\n    return {\n        addQueryPrefix: typeof opts.addQueryPrefix === 'boolean' ? opts.addQueryPrefix : defaults.addQueryPrefix,\n        allowDots: allowDots,\n        allowEmptyArrays: typeof opts.allowEmptyArrays === 'boolean' ? !!opts.allowEmptyArrays : defaults.allowEmptyArrays,\n        arrayFormat: arrayFormat,\n        charset: charset,\n        charsetSentinel: typeof opts.charsetSentinel === 'boolean' ? opts.charsetSentinel : defaults.charsetSentinel,\n        commaRoundTrip: opts.commaRoundTrip,\n        delimiter: typeof opts.delimiter === 'undefined' ? defaults.delimiter : opts.delimiter,\n        encode: typeof opts.encode === 'boolean' ? opts.encode : defaults.encode,\n        encodeDotInKeys: typeof opts.encodeDotInKeys === 'boolean' ? opts.encodeDotInKeys : defaults.encodeDotInKeys,\n        encoder: typeof opts.encoder === 'function' ? opts.encoder : defaults.encoder,\n        encodeValuesOnly: typeof opts.encodeValuesOnly === 'boolean' ? opts.encodeValuesOnly : defaults.encodeValuesOnly,\n        filter: filter,\n        format: format,\n        formatter: formatter,\n        serializeDate: typeof opts.serializeDate === 'function' ? opts.serializeDate : defaults.serializeDate,\n        skipNulls: typeof opts.skipNulls === 'boolean' ? opts.skipNulls : defaults.skipNulls,\n        sort: typeof opts.sort === 'function' ? opts.sort : null,\n        strictNullHandling: typeof opts.strictNullHandling === 'boolean' ? opts.strictNullHandling : defaults.strictNullHandling\n    };\n};\n\nmodule.exports = function (object, opts) {\n    var obj = object;\n    var options = normalizeStringifyOptions(opts);\n\n    var objKeys;\n    var filter;\n\n    if (typeof options.filter === 'function') {\n        filter = options.filter;\n        obj = filter('', obj);\n    } else if (isArray(options.filter)) {\n        filter = options.filter;\n        objKeys = filter;\n    }\n\n    var keys = [];\n\n    if (typeof obj !== 'object' || obj === null) {\n        return '';\n    }\n\n    var generateArrayPrefix = arrayPrefixGenerators[options.arrayFormat];\n    var commaRoundTrip = generateArrayPrefix === 'comma' && options.commaRoundTrip;\n\n    if (!objKeys) {\n        objKeys = Object.keys(obj);\n    }\n\n    if (options.sort) {\n        objKeys.sort(options.sort);\n    }\n\n    var sideChannel = getSideChannel();\n    for (var i = 0; i < objKeys.length; ++i) {\n        var key = objKeys[i];\n\n        if (options.skipNulls && obj[key] === null) {\n            continue;\n        }\n        pushToArray(keys, stringify(\n            obj[key],\n            key,\n            generateArrayPrefix,\n            commaRoundTrip,\n            options.allowEmptyArrays,\n            options.strictNullHandling,\n            options.skipNulls,\n            options.encodeDotInKeys,\n            options.encode ? options.encoder : null,\n            options.filter,\n            options.sort,\n            options.allowDots,\n            options.serializeDate,\n            options.format,\n            options.formatter,\n            options.encodeValuesOnly,\n            options.charset,\n            sideChannel\n        ));\n    }\n\n    var joined = keys.join(options.delimiter);\n    var prefix = options.addQueryPrefix === true ? '?' : '';\n\n    if (options.charsetSentinel) {\n        if (options.charset === 'iso-8859-1') {\n            // encodeURIComponent('&#10003;'), the \"numeric entity\" representation of a checkmark\n            prefix += 'utf8=%26%2310003%3B&';\n        } else {\n            // encodeURIComponent('')\n            prefix += 'utf8=%E2%9C%93&';\n        }\n    }\n\n    return joined.length > 0 ? prefix + joined : '';\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/qs/lib/stringify.js?");

/***/ }),

/***/ "./node_modules/qs/lib/utils.js":
/*!**************************************!*\
  !*** ./node_modules/qs/lib/utils.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar formats = __webpack_require__(/*! ./formats */ \"./node_modules/qs/lib/formats.js\");\n\nvar has = Object.prototype.hasOwnProperty;\nvar isArray = Array.isArray;\n\nvar hexTable = (function () {\n    var array = [];\n    for (var i = 0; i < 256; ++i) {\n        array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());\n    }\n\n    return array;\n}());\n\nvar compactQueue = function compactQueue(queue) {\n    while (queue.length > 1) {\n        var item = queue.pop();\n        var obj = item.obj[item.prop];\n\n        if (isArray(obj)) {\n            var compacted = [];\n\n            for (var j = 0; j < obj.length; ++j) {\n                if (typeof obj[j] !== 'undefined') {\n                    compacted.push(obj[j]);\n                }\n            }\n\n            item.obj[item.prop] = compacted;\n        }\n    }\n};\n\nvar arrayToObject = function arrayToObject(source, options) {\n    var obj = options && options.plainObjects ? Object.create(null) : {};\n    for (var i = 0; i < source.length; ++i) {\n        if (typeof source[i] !== 'undefined') {\n            obj[i] = source[i];\n        }\n    }\n\n    return obj;\n};\n\nvar merge = function merge(target, source, options) {\n    /* eslint no-param-reassign: 0 */\n    if (!source) {\n        return target;\n    }\n\n    if (typeof source !== 'object') {\n        if (isArray(target)) {\n            target.push(source);\n        } else if (target && typeof target === 'object') {\n            if ((options && (options.plainObjects || options.allowPrototypes)) || !has.call(Object.prototype, source)) {\n                target[source] = true;\n            }\n        } else {\n            return [target, source];\n        }\n\n        return target;\n    }\n\n    if (!target || typeof target !== 'object') {\n        return [target].concat(source);\n    }\n\n    var mergeTarget = target;\n    if (isArray(target) && !isArray(source)) {\n        mergeTarget = arrayToObject(target, options);\n    }\n\n    if (isArray(target) && isArray(source)) {\n        source.forEach(function (item, i) {\n            if (has.call(target, i)) {\n                var targetItem = target[i];\n                if (targetItem && typeof targetItem === 'object' && item && typeof item === 'object') {\n                    target[i] = merge(targetItem, item, options);\n                } else {\n                    target.push(item);\n                }\n            } else {\n                target[i] = item;\n            }\n        });\n        return target;\n    }\n\n    return Object.keys(source).reduce(function (acc, key) {\n        var value = source[key];\n\n        if (has.call(acc, key)) {\n            acc[key] = merge(acc[key], value, options);\n        } else {\n            acc[key] = value;\n        }\n        return acc;\n    }, mergeTarget);\n};\n\nvar assign = function assignSingleSource(target, source) {\n    return Object.keys(source).reduce(function (acc, key) {\n        acc[key] = source[key];\n        return acc;\n    }, target);\n};\n\nvar decode = function (str, decoder, charset) {\n    var strWithoutPlus = str.replace(/\\+/g, ' ');\n    if (charset === 'iso-8859-1') {\n        // unescape never throws, no try...catch needed:\n        return strWithoutPlus.replace(/%[0-9a-f]{2}/gi, unescape);\n    }\n    // utf-8\n    try {\n        return decodeURIComponent(strWithoutPlus);\n    } catch (e) {\n        return strWithoutPlus;\n    }\n};\n\nvar limit = 1024;\n\n/* eslint operator-linebreak: [2, \"before\"] */\n\nvar encode = function encode(str, defaultEncoder, charset, kind, format) {\n    // This code was originally written by Brian White (mscdex) for the io.js core querystring library.\n    // It has been adapted here for stricter adherence to RFC 3986\n    if (str.length === 0) {\n        return str;\n    }\n\n    var string = str;\n    if (typeof str === 'symbol') {\n        string = Symbol.prototype.toString.call(str);\n    } else if (typeof str !== 'string') {\n        string = String(str);\n    }\n\n    if (charset === 'iso-8859-1') {\n        return escape(string).replace(/%u[0-9a-f]{4}/gi, function ($0) {\n            return '%26%23' + parseInt($0.slice(2), 16) + '%3B';\n        });\n    }\n\n    var out = '';\n    for (var j = 0; j < string.length; j += limit) {\n        var segment = string.length >= limit ? string.slice(j, j + limit) : string;\n        var arr = [];\n\n        for (var i = 0; i < segment.length; ++i) {\n            var c = segment.charCodeAt(i);\n            if (\n                c === 0x2D // -\n                || c === 0x2E // .\n                || c === 0x5F // _\n                || c === 0x7E // ~\n                || (c >= 0x30 && c <= 0x39) // 0-9\n                || (c >= 0x41 && c <= 0x5A) // a-z\n                || (c >= 0x61 && c <= 0x7A) // A-Z\n                || (format === formats.RFC1738 && (c === 0x28 || c === 0x29)) // ( )\n            ) {\n                arr[arr.length] = segment.charAt(i);\n                continue;\n            }\n\n            if (c < 0x80) {\n                arr[arr.length] = hexTable[c];\n                continue;\n            }\n\n            if (c < 0x800) {\n                arr[arr.length] = hexTable[0xC0 | (c >> 6)]\n                    + hexTable[0x80 | (c & 0x3F)];\n                continue;\n            }\n\n            if (c < 0xD800 || c >= 0xE000) {\n                arr[arr.length] = hexTable[0xE0 | (c >> 12)]\n                    + hexTable[0x80 | ((c >> 6) & 0x3F)]\n                    + hexTable[0x80 | (c & 0x3F)];\n                continue;\n            }\n\n            i += 1;\n            c = 0x10000 + (((c & 0x3FF) << 10) | (segment.charCodeAt(i) & 0x3FF));\n\n            arr[arr.length] = hexTable[0xF0 | (c >> 18)]\n                + hexTable[0x80 | ((c >> 12) & 0x3F)]\n                + hexTable[0x80 | ((c >> 6) & 0x3F)]\n                + hexTable[0x80 | (c & 0x3F)];\n        }\n\n        out += arr.join('');\n    }\n\n    return out;\n};\n\nvar compact = function compact(value) {\n    var queue = [{ obj: { o: value }, prop: 'o' }];\n    var refs = [];\n\n    for (var i = 0; i < queue.length; ++i) {\n        var item = queue[i];\n        var obj = item.obj[item.prop];\n\n        var keys = Object.keys(obj);\n        for (var j = 0; j < keys.length; ++j) {\n            var key = keys[j];\n            var val = obj[key];\n            if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {\n                queue.push({ obj: obj, prop: key });\n                refs.push(val);\n            }\n        }\n    }\n\n    compactQueue(queue);\n\n    return value;\n};\n\nvar isRegExp = function isRegExp(obj) {\n    return Object.prototype.toString.call(obj) === '[object RegExp]';\n};\n\nvar isBuffer = function isBuffer(obj) {\n    if (!obj || typeof obj !== 'object') {\n        return false;\n    }\n\n    return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));\n};\n\nvar combine = function combine(a, b) {\n    return [].concat(a, b);\n};\n\nvar maybeMap = function maybeMap(val, fn) {\n    if (isArray(val)) {\n        var mapped = [];\n        for (var i = 0; i < val.length; i += 1) {\n            mapped.push(fn(val[i]));\n        }\n        return mapped;\n    }\n    return fn(val);\n};\n\nmodule.exports = {\n    arrayToObject: arrayToObject,\n    assign: assign,\n    combine: combine,\n    compact: compact,\n    decode: decode,\n    encode: encode,\n    isBuffer: isBuffer,\n    isRegExp: isRegExp,\n    maybeMap: maybeMap,\n    merge: merge\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/qs/lib/utils.js?");

/***/ }),

/***/ "./node_modules/readable-stream/errors-browser.js":
/*!********************************************************!*\
  !*** ./node_modules/readable-stream/errors-browser.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/errors-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_duplex.js":
/*!************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_duplex.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n\n\n/*<replacement>*/\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n  for (var key in obj) keys.push(key);\n  return keys;\n};\n/*</replacement>*/\n\nmodule.exports = Duplex;\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Duplex, Readable);\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\n// the no-half-open enforcer\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return;\n\n  // no more data can be written.\n  // But allow more writes to happen in this tick.\n  process.nextTick(onEndNT, this);\n}\nfunction onEndNT(self) {\n  self.end();\n}\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_passthrough.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\n\nmodule.exports = PassThrough;\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(PassThrough, Transform);\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_readable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_readable.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\nmodule.exports = Readable;\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n\n/*<replacement>*/\nvar EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter);\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\nvar Buffer = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\nvar OurUint8Array = (typeof __webpack_require__.g !== 'undefined' ? __webpack_require__.g : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : {}).Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\n/*<replacement>*/\nvar debugUtil = __webpack_require__(/*! util */ \"?d17e\");\nvar debug;\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/buffer_list */ \"./node_modules/readable-stream/lib/internal/streams/buffer_list.js\");\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\"),\n  getHighWaterMark = _require.getHighWaterMark;\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n  ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n  ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT;\n\n// Lazy loaded to improve the startup performance.\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Readable, Stream);\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn);\n\n  // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex;\n\n  // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode;\n\n  // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex);\n\n  // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false;\n\n  // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n  this.sync = true;\n\n  // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true;\n\n  // Should close be emitted on destroy. Defaults to true.\n  this.emitClose = options.emitClose !== false;\n\n  // Should .destroy() be called after 'end' (and potentially 'finish')\n  this.autoDestroy = !!options.autoDestroy;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // the number of writers that are awaiting a drain event in .pipe()s\n  this.awaitDrain = 0;\n\n  // if true, a maybeReadMore has been scheduled\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  if (!(this instanceof Readable)) return new Readable(options);\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex);\n\n  // legacy\n  this.readable = true;\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n  Stream.call(this);\n}\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n// Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n};\n\n// Unshift should *always* be something directly out of read()\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  }\n\n  // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n  maybeReadMore(stream, state);\n}\nfunction chunkInvalid(state, chunk) {\n  var er;\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n  return er;\n}\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n};\n\n// backwards compatibility.\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder;\n  // If setEncoding(null), decoder.encoding equals utf8\n  this._readableState.encoding = this._readableState.decoder.encoding;\n\n  // Iterate over current buffer to convert already stored Buffers:\n  var p = this._readableState.buffer.head;\n  var content = '';\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n  this._readableState.buffer.clear();\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n};\n\n// Don't raise the hwm > 1GB\nvar MAX_HWM = 0x40000000;\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n  return n;\n}\n\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  }\n  // If we're asking for more than the current hwm, then raise the hwm.\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n;\n  // Don't have enough\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n  return state.length;\n}\n\n// you can override either this method, or the async _read(n) below.\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false;\n\n  // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n  n = howMuchToRead(n, state);\n\n  // if we've ended, and we're now clear, then finish it up.\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  }\n\n  // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n\n  // if we need a readable event, then we need to do some reading.\n  var doRead = state.needReadable;\n  debug('need readable', doRead);\n\n  // if we currently have less than the highWaterMark, then also read some\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  }\n\n  // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true;\n    // if the length is currently zero, then we *need* a readable event.\n    if (state.length === 0) state.needReadable = true;\n    // call internal read method\n    this._read(state.highWaterMark);\n    state.sync = false;\n    // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true;\n\n    // If we tried to read() past the EOF, then emit end on the next tick.\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n  state.ended = true;\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n}\n\n// Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  }\n\n  // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n}\n\n// at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length)\n      // didn't get any data, stop spinning.\n      break;\n  }\n  state.readingMore = false;\n}\n\n// abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n  function onend() {\n    debug('onend');\n    dest.end();\n  }\n\n  // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n  function cleanup() {\n    debug('cleanup');\n    // cleanup event handlers once the pipe is broken\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true;\n\n    // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n  src.on('data', ondata);\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n      src.pause();\n    }\n  }\n\n  // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  }\n\n  // Make sure our error handler is attached before userland ones.\n  prependListener(dest, 'error', onerror);\n\n  // Both close and finish should trigger unpipe, but only once.\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n  dest.once('close', onclose);\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n  dest.once('finish', onfinish);\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  }\n\n  // tell the dest that it's being piped to\n  dest.emit('pipe', src);\n\n  // start the flow if it hasn't been started already.\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n  return dest;\n};\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  };\n\n  // if we're not piping anywhere, then do nothing.\n  if (state.pipesCount === 0) return this;\n\n  // just one destination.  most common case.\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes;\n\n    // got a match.\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  }\n\n  // slow case. multiple pipe destinations.\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    for (var i = 0; i < len; i++) dests[i].emit('unpipe', this, {\n      hasUnpiped: false\n    });\n    return this;\n  }\n\n  // try to find the right one.\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n};\n\n// set up data events if they are asked for\n// Ensure readable listeners eventually get something\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0;\n\n    // Try start flowing on next tick if stream isn't explicitly paused\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n  return res;\n};\nReadable.prototype.addListener = Readable.prototype.on;\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n  return res;\n};\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n  return res;\n};\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true;\n\n    // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n}\n\n// pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n  if (!state.flowing) {\n    debug('resume');\n    // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n  state.paused = false;\n  return this;\n};\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n  if (!state.reading) {\n    stream.read(0);\n  }\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n  this._readableState.paused = true;\n  return this;\n};\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n  while (state.flowing && stream.read() !== null);\n}\n\n// wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk);\n\n    // don't skip over falsy values in objectMode\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n    var ret = _this.push(chunk);\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  });\n\n  // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  }\n\n  // proxy certain important events.\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  }\n\n  // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n  this._read = function (n) {\n    debug('wrapped _read', n);\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n  return this;\n};\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = __webpack_require__(/*! ./internal/streams/async_iterator */ \"./node_modules/readable-stream/lib/internal/streams/async_iterator.js\");\n    }\n    return createReadableStreamAsyncIterator(this);\n  };\n}\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n});\n\n// exposed for testing purposes only.\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n});\n\n// Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length);\n\n  // Check that we didn't get one last unshift.\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = __webpack_require__(/*! ./internal/streams/from */ \"./node_modules/readable-stream/lib/internal/streams/from-browser.js\");\n    }\n    return from(Readable, iterable, opts);\n  };\n}\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n  return -1;\n}\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_transform.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_transform.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\n\nmodule.exports = Transform;\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n  ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n  ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Transform, Duplex);\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null)\n    // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  };\n\n  // start out asking for a readable event once data is transformed.\n  this._readableState.needReadable = true;\n\n  // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n  this._readableState.sync = false;\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  }\n\n  // When the writable side finishes, then flush out anything remaining.\n  this.on('prefinish', prefinish);\n}\nfunction prefinish() {\n  var _this = this;\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n};\n\n// This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n};\n\n// Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null)\n    // single equals check for both `null` and `undefined`\n    stream.push(data);\n\n  // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_writable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_writable.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\n\nmodule.exports = Writable;\n\n/* <replacement> */\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n}\n\n// It seems a linked list but it is not\n// there will be only 2 of these for each stream\nfunction CorkedRequest(state) {\n  var _this = this;\n  this.next = null;\n  this.entry = null;\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n\n/*<replacement>*/\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"./node_modules/util-deprecate/browser.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\nvar Buffer = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\nvar OurUint8Array = (typeof __webpack_require__.g !== 'undefined' ? __webpack_require__.g : typeof window !== 'undefined' ? window : typeof self !== 'undefined' ? self : {}).Uint8Array || function () {};\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\"),\n  getHighWaterMark = _require.getHighWaterMark;\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n  ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n  ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n  ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n  ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n  ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n  ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n  ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Writable, Stream);\nfunction nop() {}\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {};\n\n  // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex;\n\n  // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode;\n\n  // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex);\n\n  // if _final has been called\n  this.finalCalled = false;\n\n  // drain event flag.\n  this.needDrain = false;\n  // at the start of calling end()\n  this.ending = false;\n  // when end() has been called, and returned\n  this.ended = false;\n  // when 'finish' is emitted\n  this.finished = false;\n\n  // has it been destroyed\n  this.destroyed = false;\n\n  // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode;\n\n  // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n  this.defaultEncoding = options.defaultEncoding || 'utf8';\n\n  // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n  this.length = 0;\n\n  // a flag to see when we're in the middle of a write.\n  this.writing = false;\n\n  // when true all writes will be buffered until .uncork() call\n  this.corked = 0;\n\n  // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n  this.sync = true;\n\n  // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n  this.bufferProcessing = false;\n\n  // the callback that's passed to _write(chunk,cb)\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  };\n\n  // the callback that the user supplies to write(chunk,encoding,cb)\n  this.writecb = null;\n\n  // the amount that is being written when _write is called.\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null;\n\n  // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n  this.pendingcb = 0;\n\n  // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n  this.prefinished = false;\n\n  // True if the error was already emitted and should not be thrown again\n  this.errorEmitted = false;\n\n  // Should close be emitted on destroy. Defaults to true.\n  this.emitClose = options.emitClose !== false;\n\n  // Should .destroy() be called after 'finish' (and potentially 'end')\n  this.autoDestroy = !!options.autoDestroy;\n\n  // count buffered requests\n  this.bufferedRequestCount = 0;\n\n  // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n  return out;\n};\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})();\n\n// Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\nvar realHasInstance;\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n  // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex);\n\n  // legacy.\n  this.writable = true;\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n  Stream.call(this);\n}\n\n// Otherwise people can pipe Writable streams, which is just wrong.\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END();\n  // TODO: defer error events consistently everywhere, not just the cb\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n}\n\n// Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n  return true;\n}\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n  return chunk;\n}\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\n\n// if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark;\n  // we must ensure that previous needDrain will not be reset to false.\n  if (!ret) state.needDrain = true;\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n  return ret;\n}\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er);\n    // this can emit finish, and it will always happen\n    // after error\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n    // this can emit finish, but finish must\n    // always follow error\n    finishMaybe(stream, state);\n  }\n}\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n}\n\n// Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n}\n\n// if there's something in the buffer waiting, then process it\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish);\n\n    // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--;\n      // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n      if (state.writing) {\n        break;\n      }\n    }\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\nWritable.prototype._writev = null;\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding);\n\n  // .end() fully uncorks\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  }\n\n  // ignore unnecessary end() calls.\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n  if (need) {\n    prefinish(stream, state);\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n  return need;\n}\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n  state.ended = true;\n  stream.writable = false;\n}\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  }\n\n  // reuse the free corkReq.\n  state.corkedRequestsFree.next = corkReq;\n}\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    }\n\n    // backward compatibility, the user is explicitly\n    // managing destroyed\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/async_iterator.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/async_iterator.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _Object$setPrototypeO;\nfunction _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\nfunction _toPropertyKey(arg) { var key = _toPrimitive(arg, \"string\"); return typeof key === \"symbol\" ? key : String(key); }\nfunction _toPrimitive(input, hint) { if (typeof input !== \"object\" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || \"default\"); if (typeof res !== \"object\") return res; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (hint === \"string\" ? String : Number)(input); }\nvar finished = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n  if (resolve !== null) {\n    var data = iter[kStream].read();\n    // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n  next: function next() {\n    var _this = this;\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    }\n\n    // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n    var lastPromise = this[kLastPromise];\n    var promise;\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n      promise = new Promise(this[kHandlePromise]);\n    }\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject];\n      // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n      iterator[kError] = err;\n      return;\n    }\n    var resolve = iterator[kLastResolve];\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\nmodule.exports = createReadableStreamAsyncIterator;\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/async_iterator.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/buffer_list.js":
/*!**************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/buffer_list.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); enumerableOnly && (symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; })), keys.push.apply(keys, symbols); } return keys; }\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = null != arguments[i] ? arguments[i] : {}; i % 2 ? ownKeys(Object(source), !0).forEach(function (key) { _defineProperty(target, key, source[key]); }) : Object.getOwnPropertyDescriptors ? Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)) : ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } return target; }\nfunction _defineProperty(obj, key, value) { key = _toPropertyKey(key); if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, _toPropertyKey(descriptor.key), descriptor); } }\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); Object.defineProperty(Constructor, \"prototype\", { writable: false }); return Constructor; }\nfunction _toPropertyKey(arg) { var key = _toPrimitive(arg, \"string\"); return typeof key === \"symbol\" ? key : String(key); }\nfunction _toPrimitive(input, hint) { if (typeof input !== \"object\" || input === null) return input; var prim = input[Symbol.toPrimitive]; if (prim !== undefined) { var res = prim.call(input, hint || \"default\"); if (typeof res !== \"object\") return res; throw new TypeError(\"@@toPrimitive must return a primitive value.\"); } return (hint === \"string\" ? String : Number)(input); }\nvar _require = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())),\n  Buffer = _require.Buffer;\nvar _require2 = __webpack_require__(/*! util */ \"?ed1b\"),\n  inspect = _require2.inspect;\nvar custom = inspect && inspect.custom || 'inspect';\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\nmodule.exports = /*#__PURE__*/function () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n      while (p = p.next) ret += s + p.data;\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n      return ret;\n    }\n\n    // Consumes a specified amount of bytes or characters from the buffered data.\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    }\n\n    // Consumes a specified amount of characters from the buffered data.\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n          break;\n        }\n        ++c;\n      }\n      this.length -= c;\n      return ret;\n    }\n\n    // Consumes a specified amount of bytes from the buffered data.\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n          break;\n        }\n        ++c;\n      }\n      this.length -= c;\n      return ret;\n    }\n\n    // Make sure the linked list only shows the minimal necessary information.\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread(_objectSpread({}, options), {}, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n  return BufferList;\n}();\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/buffer_list.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// undocumented cb() API, needed for core, not for public API\nfunction destroy(err, cb) {\n  var _this = this;\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n    return this;\n  }\n\n  // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  }\n\n  // if this is a duplex stream mark the writable part as destroyed as well\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n  return this;\n}\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/end-of-stream.js":
/*!****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/end-of-stream.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\n\nvar ERR_STREAM_PREMATURE_CLOSE = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes).ERR_STREAM_PREMATURE_CLOSE;\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n    callback.apply(this, args);\n  };\n}\nfunction noop() {}\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n  var writableEnded = stream._writableState && stream._writableState.finished;\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n  var onclose = function onclose() {\n    var err;\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\nmodule.exports = eos;\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/end-of-stream.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/from-browser.js":
/*!***************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/from-browser.js ***!
  \***************************************************************************/
/***/ ((module) => {

eval("module.exports = function () {\n  throw new Error('Readable.from is not available in the browser')\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/from-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/pipeline.js":
/*!***********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/pipeline.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\n\nvar eos;\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\nvar _require$codes = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n  ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n  ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true;\n\n    // request.destroy just do .end - .abort is what we want\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\nfunction call(fn) {\n  fn();\n}\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\nmodule.exports = pipeline;\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/pipeline.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/state.js":
/*!********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/state.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ERR_INVALID_OPT_VALUE = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes).ERR_INVALID_OPT_VALUE;\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n    return Math.floor(hwm);\n  }\n\n  // Default value\n  return state.objectMode ? 16 : 16 * 1024;\n}\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/state.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/lib/internal/streams/stream-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/readable-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/readable-browser.js ***!
  \**********************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\nexports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\nexports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\nexports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"./node_modules/readable-stream/lib/_stream_passthrough.js\");\nexports.finished = __webpack_require__(/*! ./lib/internal/streams/end-of-stream.js */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\nexports.pipeline = __webpack_require__(/*! ./lib/internal/streams/pipeline.js */ \"./node_modules/readable-stream/lib/internal/streams/pipeline.js\");\n\n\n//# sourceURL=webpack://thelambda/./node_modules/readable-stream/readable-browser.js?");

/***/ }),

/***/ "./node_modules/rimraf/rimraf.js":
/*!***************************************!*\
  !*** ./node_modules/rimraf/rimraf.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst fs = __webpack_require__(/*! fs */ \"?3e89\")\nlet glob = undefined\ntry {\n  glob = __webpack_require__(/*! glob */ \"./node_modules/glob/glob.js\")\n} catch (_err) {\n  // treat glob as optional.\n}\n\nconst defaultGlobOpts = {\n  nosort: true,\n  silent: true\n}\n\n// for EMFILE handling\nlet timeout = 0\n\nconst isWindows = (process.platform === \"win32\")\n\nconst defaults = options => {\n  const methods = [\n    'unlink',\n    'chmod',\n    'stat',\n    'lstat',\n    'rmdir',\n    'readdir'\n  ]\n  methods.forEach(m => {\n    options[m] = options[m] || fs[m]\n    m = m + 'Sync'\n    options[m] = options[m] || fs[m]\n  })\n\n  options.maxBusyTries = options.maxBusyTries || 3\n  options.emfileWait = options.emfileWait || 1000\n  if (options.glob === false) {\n    options.disableGlob = true\n  }\n  if (options.disableGlob !== true && glob === undefined) {\n    throw Error('glob dependency not found, set `options.disableGlob = true` if intentional')\n  }\n  options.disableGlob = options.disableGlob || false\n  options.glob = options.glob || defaultGlobOpts\n}\n\nconst rimraf = (p, options, cb) => {\n  if (typeof options === 'function') {\n    cb = options\n    options = {}\n  }\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert.equal(typeof cb, 'function', 'rimraf: callback function required')\n  assert(options, 'rimraf: invalid options argument provided')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  defaults(options)\n\n  let busyTries = 0\n  let errState = null\n  let n = 0\n\n  const next = (er) => {\n    errState = errState || er\n    if (--n === 0)\n      cb(errState)\n  }\n\n  const afterGlob = (er, results) => {\n    if (er)\n      return cb(er)\n\n    n = results.length\n    if (n === 0)\n      return cb()\n\n    results.forEach(p => {\n      const CB = (er) => {\n        if (er) {\n          if ((er.code === \"EBUSY\" || er.code === \"ENOTEMPTY\" || er.code === \"EPERM\") &&\n              busyTries < options.maxBusyTries) {\n            busyTries ++\n            // try again, with the same exact callback as this one.\n            return setTimeout(() => rimraf_(p, options, CB), busyTries * 100)\n          }\n\n          // this one won't happen if graceful-fs is used.\n          if (er.code === \"EMFILE\" && timeout < options.emfileWait) {\n            return setTimeout(() => rimraf_(p, options, CB), timeout ++)\n          }\n\n          // already gone\n          if (er.code === \"ENOENT\") er = null\n        }\n\n        timeout = 0\n        next(er)\n      }\n      rimraf_(p, options, CB)\n    })\n  }\n\n  if (options.disableGlob || !glob.hasMagic(p))\n    return afterGlob(null, [p])\n\n  options.lstat(p, (er, stat) => {\n    if (!er)\n      return afterGlob(null, [p])\n\n    glob(p, options.glob, afterGlob)\n  })\n\n}\n\n// Two possible strategies.\n// 1. Assume it's a file.  unlink it, then do the dir stuff on EPERM or EISDIR\n// 2. Assume it's a directory.  readdir, then do the file stuff on ENOTDIR\n//\n// Both result in an extra syscall when you guess wrong.  However, there\n// are likely far more normal files in the world than directories.  This\n// is based on the assumption that a the average number of files per\n// directory is >= 1.\n//\n// If anyone ever complains about this, then I guess the strategy could\n// be made configurable somehow.  But until then, YAGNI.\nconst rimraf_ = (p, options, cb) => {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // sunos lets the root user unlink directories, which is... weird.\n  // so we have to lstat here and make sure it's not a dir.\n  options.lstat(p, (er, st) => {\n    if (er && er.code === \"ENOENT\")\n      return cb(null)\n\n    // Windows can EPERM on stat.  Life is suffering.\n    if (er && er.code === \"EPERM\" && isWindows)\n      fixWinEPERM(p, options, er, cb)\n\n    if (st && st.isDirectory())\n      return rmdir(p, options, er, cb)\n\n    options.unlink(p, er => {\n      if (er) {\n        if (er.code === \"ENOENT\")\n          return cb(null)\n        if (er.code === \"EPERM\")\n          return (isWindows)\n            ? fixWinEPERM(p, options, er, cb)\n            : rmdir(p, options, er, cb)\n        if (er.code === \"EISDIR\")\n          return rmdir(p, options, er, cb)\n      }\n      return cb(er)\n    })\n  })\n}\n\nconst fixWinEPERM = (p, options, er, cb) => {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.chmod(p, 0o666, er2 => {\n    if (er2)\n      cb(er2.code === \"ENOENT\" ? null : er)\n    else\n      options.stat(p, (er3, stats) => {\n        if (er3)\n          cb(er3.code === \"ENOENT\" ? null : er)\n        else if (stats.isDirectory())\n          rmdir(p, options, er, cb)\n        else\n          options.unlink(p, cb)\n      })\n  })\n}\n\nconst fixWinEPERMSync = (p, options, er) => {\n  assert(p)\n  assert(options)\n\n  try {\n    options.chmodSync(p, 0o666)\n  } catch (er2) {\n    if (er2.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  let stats\n  try {\n    stats = options.statSync(p)\n  } catch (er3) {\n    if (er3.code === \"ENOENT\")\n      return\n    else\n      throw er\n  }\n\n  if (stats.isDirectory())\n    rmdirSync(p, options, er)\n  else\n    options.unlinkSync(p)\n}\n\nconst rmdir = (p, options, originalEr, cb) => {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  // try to rmdir first, and only readdir on ENOTEMPTY or EEXIST (SunOS)\n  // if we guessed wrong, and it's not a directory, then\n  // raise the original error.\n  options.rmdir(p, er => {\n    if (er && (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\"))\n      rmkids(p, options, cb)\n    else if (er && er.code === \"ENOTDIR\")\n      cb(originalEr)\n    else\n      cb(er)\n  })\n}\n\nconst rmkids = (p, options, cb) => {\n  assert(p)\n  assert(options)\n  assert(typeof cb === 'function')\n\n  options.readdir(p, (er, files) => {\n    if (er)\n      return cb(er)\n    let n = files.length\n    if (n === 0)\n      return options.rmdir(p, cb)\n    let errState\n    files.forEach(f => {\n      rimraf(path.join(p, f), options, er => {\n        if (errState)\n          return\n        if (er)\n          return cb(errState = er)\n        if (--n === 0)\n          options.rmdir(p, cb)\n      })\n    })\n  })\n}\n\n// this looks simpler, and is strictly *faster*, but will\n// tie up the JavaScript thread and fail on excessively\n// deep directory trees.\nconst rimrafSync = (p, options) => {\n  options = options || {}\n  defaults(options)\n\n  assert(p, 'rimraf: missing path')\n  assert.equal(typeof p, 'string', 'rimraf: path should be a string')\n  assert(options, 'rimraf: missing options')\n  assert.equal(typeof options, 'object', 'rimraf: options should be object')\n\n  let results\n\n  if (options.disableGlob || !glob.hasMagic(p)) {\n    results = [p]\n  } else {\n    try {\n      options.lstatSync(p)\n      results = [p]\n    } catch (er) {\n      results = glob.sync(p, options.glob)\n    }\n  }\n\n  if (!results.length)\n    return\n\n  for (let i = 0; i < results.length; i++) {\n    const p = results[i]\n\n    let st\n    try {\n      st = options.lstatSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n\n      // Windows can EPERM on stat.  Life is suffering.\n      if (er.code === \"EPERM\" && isWindows)\n        fixWinEPERMSync(p, options, er)\n    }\n\n    try {\n      // sunos lets the root user unlink directories, which is... weird.\n      if (st && st.isDirectory())\n        rmdirSync(p, options, null)\n      else\n        options.unlinkSync(p)\n    } catch (er) {\n      if (er.code === \"ENOENT\")\n        return\n      if (er.code === \"EPERM\")\n        return isWindows ? fixWinEPERMSync(p, options, er) : rmdirSync(p, options, er)\n      if (er.code !== \"EISDIR\")\n        throw er\n\n      rmdirSync(p, options, er)\n    }\n  }\n}\n\nconst rmdirSync = (p, options, originalEr) => {\n  assert(p)\n  assert(options)\n\n  try {\n    options.rmdirSync(p)\n  } catch (er) {\n    if (er.code === \"ENOENT\")\n      return\n    if (er.code === \"ENOTDIR\")\n      throw originalEr\n    if (er.code === \"ENOTEMPTY\" || er.code === \"EEXIST\" || er.code === \"EPERM\")\n      rmkidsSync(p, options)\n  }\n}\n\nconst rmkidsSync = (p, options) => {\n  assert(p)\n  assert(options)\n  options.readdirSync(p).forEach(f => rimrafSync(path.join(p, f), options))\n\n  // We only end up here once we got ENOTEMPTY at least once, and\n  // at this point, we are guaranteed to have removed all the kids.\n  // So, we know that it won't be ENOENT or ENOTDIR or anything else.\n  // try really hard to delete stuff on windows, because it has a\n  // PROFOUNDLY annoying habit of not closing handles promptly when\n  // files are deleted, resulting in spurious ENOTEMPTY errors.\n  const retries = isWindows ? 100 : 1\n  let i = 0\n  do {\n    let threw = true\n    try {\n      const ret = options.rmdirSync(p, options)\n      threw = false\n      return ret\n    } finally {\n      if (++i < retries && threw)\n        continue\n    }\n  } while (true)\n}\n\nmodule.exports = rimraf\nrimraf.sync = rimrafSync\n\n\n//# sourceURL=webpack://thelambda/./node_modules/rimraf/rimraf.js?");

/***/ }),

/***/ "./node_modules/safe-buffer/index.js":
/*!*******************************************!*\
  !*** ./node_modules/safe-buffer/index.js ***!
  \*******************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/safe-buffer/index.js?");

/***/ }),

/***/ "./node_modules/semver/classes/comparator.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/classes/comparator.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const ANY = Symbol('SemVer ANY')\n// hoisted class for cyclic dependency\nclass Comparator {\n  static get ANY () {\n    return ANY\n  }\n\n  constructor (comp, options) {\n    options = parseOptions(options)\n\n    if (comp instanceof Comparator) {\n      if (comp.loose === !!options.loose) {\n        return comp\n      } else {\n        comp = comp.value\n      }\n    }\n\n    comp = comp.trim().split(/\\s+/).join(' ')\n    debug('comparator', comp, options)\n    this.options = options\n    this.loose = !!options.loose\n    this.parse(comp)\n\n    if (this.semver === ANY) {\n      this.value = ''\n    } else {\n      this.value = this.operator + this.semver.version\n    }\n\n    debug('comp', this)\n  }\n\n  parse (comp) {\n    const r = this.options.loose ? re[t.COMPARATORLOOSE] : re[t.COMPARATOR]\n    const m = comp.match(r)\n\n    if (!m) {\n      throw new TypeError(`Invalid comparator: ${comp}`)\n    }\n\n    this.operator = m[1] !== undefined ? m[1] : ''\n    if (this.operator === '=') {\n      this.operator = ''\n    }\n\n    // if it literally is just '>' or '' then allow anything.\n    if (!m[2]) {\n      this.semver = ANY\n    } else {\n      this.semver = new SemVer(m[2], this.options.loose)\n    }\n  }\n\n  toString () {\n    return this.value\n  }\n\n  test (version) {\n    debug('Comparator.test', version, this.options.loose)\n\n    if (this.semver === ANY || version === ANY) {\n      return true\n    }\n\n    if (typeof version === 'string') {\n      try {\n        version = new SemVer(version, this.options)\n      } catch (er) {\n        return false\n      }\n    }\n\n    return cmp(version, this.operator, this.semver, this.options)\n  }\n\n  intersects (comp, options) {\n    if (!(comp instanceof Comparator)) {\n      throw new TypeError('a Comparator is required')\n    }\n\n    if (this.operator === '') {\n      if (this.value === '') {\n        return true\n      }\n      return new Range(comp.value, options).test(this.value)\n    } else if (comp.operator === '') {\n      if (comp.value === '') {\n        return true\n      }\n      return new Range(this.value, options).test(comp.semver)\n    }\n\n    options = parseOptions(options)\n\n    // Special cases where nothing can possibly be lower\n    if (options.includePrerelease &&\n      (this.value === '<0.0.0-0' || comp.value === '<0.0.0-0')) {\n      return false\n    }\n    if (!options.includePrerelease &&\n      (this.value.startsWith('<0.0.0') || comp.value.startsWith('<0.0.0'))) {\n      return false\n    }\n\n    // Same direction increasing (> or >=)\n    if (this.operator.startsWith('>') && comp.operator.startsWith('>')) {\n      return true\n    }\n    // Same direction decreasing (< or <=)\n    if (this.operator.startsWith('<') && comp.operator.startsWith('<')) {\n      return true\n    }\n    // same SemVer and both sides are inclusive (<= or >=)\n    if (\n      (this.semver.version === comp.semver.version) &&\n      this.operator.includes('=') && comp.operator.includes('=')) {\n      return true\n    }\n    // opposite directions less than\n    if (cmp(this.semver, '<', comp.semver, options) &&\n      this.operator.startsWith('>') && comp.operator.startsWith('<')) {\n      return true\n    }\n    // opposite directions greater than\n    if (cmp(this.semver, '>', comp.semver, options) &&\n      this.operator.startsWith('<') && comp.operator.startsWith('>')) {\n      return true\n    }\n    return false\n  }\n}\n\nmodule.exports = Comparator\n\nconst parseOptions = __webpack_require__(/*! ../internal/parse-options */ \"./node_modules/semver/internal/parse-options.js\")\nconst { safeRe: re, t } = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\nconst cmp = __webpack_require__(/*! ../functions/cmp */ \"./node_modules/semver/functions/cmp.js\")\nconst debug = __webpack_require__(/*! ../internal/debug */ \"./node_modules/semver/internal/debug.js\")\nconst SemVer = __webpack_require__(/*! ./semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ./range */ \"./node_modules/semver/classes/range.js\")\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/classes/comparator.js?");

/***/ }),

/***/ "./node_modules/semver/classes/range.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/classes/range.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SPACE_CHARACTERS = /\\s+/g\n\n// hoisted class for cyclic dependency\nclass Range {\n  constructor (range, options) {\n    options = parseOptions(options)\n\n    if (range instanceof Range) {\n      if (\n        range.loose === !!options.loose &&\n        range.includePrerelease === !!options.includePrerelease\n      ) {\n        return range\n      } else {\n        return new Range(range.raw, options)\n      }\n    }\n\n    if (range instanceof Comparator) {\n      // just put it in the set and return\n      this.raw = range.value\n      this.set = [[range]]\n      this.formatted = undefined\n      return this\n    }\n\n    this.options = options\n    this.loose = !!options.loose\n    this.includePrerelease = !!options.includePrerelease\n\n    // First reduce all whitespace as much as possible so we do not have to rely\n    // on potentially slow regexes like \\s*. This is then stored and used for\n    // future error messages as well.\n    this.raw = range.trim().replace(SPACE_CHARACTERS, ' ')\n\n    // First, split on ||\n    this.set = this.raw\n      .split('||')\n      // map the range to a 2d array of comparators\n      .map(r => this.parseRange(r.trim()))\n      // throw out any comparator lists that are empty\n      // this generally means that it was not a valid range, which is allowed\n      // in loose mode, but will still throw if the WHOLE range is invalid.\n      .filter(c => c.length)\n\n    if (!this.set.length) {\n      throw new TypeError(`Invalid SemVer Range: ${this.raw}`)\n    }\n\n    // if we have any that are not the null set, throw out null sets.\n    if (this.set.length > 1) {\n      // keep the first one, in case they're all null sets\n      const first = this.set[0]\n      this.set = this.set.filter(c => !isNullSet(c[0]))\n      if (this.set.length === 0) {\n        this.set = [first]\n      } else if (this.set.length > 1) {\n        // if we have any that are *, then the range is just *\n        for (const c of this.set) {\n          if (c.length === 1 && isAny(c[0])) {\n            this.set = [c]\n            break\n          }\n        }\n      }\n    }\n\n    this.formatted = undefined\n  }\n\n  get range () {\n    if (this.formatted === undefined) {\n      this.formatted = ''\n      for (let i = 0; i < this.set.length; i++) {\n        if (i > 0) {\n          this.formatted += '||'\n        }\n        const comps = this.set[i]\n        for (let k = 0; k < comps.length; k++) {\n          if (k > 0) {\n            this.formatted += ' '\n          }\n          this.formatted += comps[k].toString().trim()\n        }\n      }\n    }\n    return this.formatted\n  }\n\n  format () {\n    return this.range\n  }\n\n  toString () {\n    return this.range\n  }\n\n  parseRange (range) {\n    // memoize range parsing for performance.\n    // this is a very hot path, and fully deterministic.\n    const memoOpts =\n      (this.options.includePrerelease && FLAG_INCLUDE_PRERELEASE) |\n      (this.options.loose && FLAG_LOOSE)\n    const memoKey = memoOpts + ':' + range\n    const cached = cache.get(memoKey)\n    if (cached) {\n      return cached\n    }\n\n    const loose = this.options.loose\n    // `1.2.3 - 1.2.4` => `>=1.2.3 <=1.2.4`\n    const hr = loose ? re[t.HYPHENRANGELOOSE] : re[t.HYPHENRANGE]\n    range = range.replace(hr, hyphenReplace(this.options.includePrerelease))\n    debug('hyphen replace', range)\n\n    // `> 1.2.3 < 1.2.5` => `>1.2.3 <1.2.5`\n    range = range.replace(re[t.COMPARATORTRIM], comparatorTrimReplace)\n    debug('comparator trim', range)\n\n    // `~ 1.2.3` => `~1.2.3`\n    range = range.replace(re[t.TILDETRIM], tildeTrimReplace)\n    debug('tilde trim', range)\n\n    // `^ 1.2.3` => `^1.2.3`\n    range = range.replace(re[t.CARETTRIM], caretTrimReplace)\n    debug('caret trim', range)\n\n    // At this point, the range is completely trimmed and\n    // ready to be split into comparators.\n\n    let rangeList = range\n      .split(' ')\n      .map(comp => parseComparator(comp, this.options))\n      .join(' ')\n      .split(/\\s+/)\n      // >=0.0.0 is equivalent to *\n      .map(comp => replaceGTE0(comp, this.options))\n\n    if (loose) {\n      // in loose mode, throw out any that are not valid comparators\n      rangeList = rangeList.filter(comp => {\n        debug('loose invalid filter', comp, this.options)\n        return !!comp.match(re[t.COMPARATORLOOSE])\n      })\n    }\n    debug('range list', rangeList)\n\n    // if any comparators are the null set, then replace with JUST null set\n    // if more than one comparator, remove any * comparators\n    // also, don't include the same comparator more than once\n    const rangeMap = new Map()\n    const comparators = rangeList.map(comp => new Comparator(comp, this.options))\n    for (const comp of comparators) {\n      if (isNullSet(comp)) {\n        return [comp]\n      }\n      rangeMap.set(comp.value, comp)\n    }\n    if (rangeMap.size > 1 && rangeMap.has('')) {\n      rangeMap.delete('')\n    }\n\n    const result = [...rangeMap.values()]\n    cache.set(memoKey, result)\n    return result\n  }\n\n  intersects (range, options) {\n    if (!(range instanceof Range)) {\n      throw new TypeError('a Range is required')\n    }\n\n    return this.set.some((thisComparators) => {\n      return (\n        isSatisfiable(thisComparators, options) &&\n        range.set.some((rangeComparators) => {\n          return (\n            isSatisfiable(rangeComparators, options) &&\n            thisComparators.every((thisComparator) => {\n              return rangeComparators.every((rangeComparator) => {\n                return thisComparator.intersects(rangeComparator, options)\n              })\n            })\n          )\n        })\n      )\n    })\n  }\n\n  // if ANY of the sets match ALL of its comparators, then pass\n  test (version) {\n    if (!version) {\n      return false\n    }\n\n    if (typeof version === 'string') {\n      try {\n        version = new SemVer(version, this.options)\n      } catch (er) {\n        return false\n      }\n    }\n\n    for (let i = 0; i < this.set.length; i++) {\n      if (testSet(this.set[i], version, this.options)) {\n        return true\n      }\n    }\n    return false\n  }\n}\n\nmodule.exports = Range\n\nconst LRU = __webpack_require__(/*! ../internal/lrucache */ \"./node_modules/semver/internal/lrucache.js\")\nconst cache = new LRU()\n\nconst parseOptions = __webpack_require__(/*! ../internal/parse-options */ \"./node_modules/semver/internal/parse-options.js\")\nconst Comparator = __webpack_require__(/*! ./comparator */ \"./node_modules/semver/classes/comparator.js\")\nconst debug = __webpack_require__(/*! ../internal/debug */ \"./node_modules/semver/internal/debug.js\")\nconst SemVer = __webpack_require__(/*! ./semver */ \"./node_modules/semver/classes/semver.js\")\nconst {\n  safeRe: re,\n  t,\n  comparatorTrimReplace,\n  tildeTrimReplace,\n  caretTrimReplace,\n} = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\nconst { FLAG_INCLUDE_PRERELEASE, FLAG_LOOSE } = __webpack_require__(/*! ../internal/constants */ \"./node_modules/semver/internal/constants.js\")\n\nconst isNullSet = c => c.value === '<0.0.0-0'\nconst isAny = c => c.value === ''\n\n// take a set of comparators and determine whether there\n// exists a version which can satisfy it\nconst isSatisfiable = (comparators, options) => {\n  let result = true\n  const remainingComparators = comparators.slice()\n  let testComparator = remainingComparators.pop()\n\n  while (result && remainingComparators.length) {\n    result = remainingComparators.every((otherComparator) => {\n      return testComparator.intersects(otherComparator, options)\n    })\n\n    testComparator = remainingComparators.pop()\n  }\n\n  return result\n}\n\n// comprised of xranges, tildes, stars, and gtlt's at this point.\n// already replaced the hyphen ranges\n// turn into a set of JUST comparators.\nconst parseComparator = (comp, options) => {\n  debug('comp', comp, options)\n  comp = replaceCarets(comp, options)\n  debug('caret', comp)\n  comp = replaceTildes(comp, options)\n  debug('tildes', comp)\n  comp = replaceXRanges(comp, options)\n  debug('xrange', comp)\n  comp = replaceStars(comp, options)\n  debug('stars', comp)\n  return comp\n}\n\nconst isX = id => !id || id.toLowerCase() === 'x' || id === '*'\n\n// ~, ~> --> * (any, kinda silly)\n// ~2, ~2.x, ~2.x.x, ~>2, ~>2.x ~>2.x.x --> >=2.0.0 <3.0.0-0\n// ~2.0, ~2.0.x, ~>2.0, ~>2.0.x --> >=2.0.0 <2.1.0-0\n// ~1.2, ~1.2.x, ~>1.2, ~>1.2.x --> >=1.2.0 <1.3.0-0\n// ~1.2.3, ~>1.2.3 --> >=1.2.3 <1.3.0-0\n// ~1.2.0, ~>1.2.0 --> >=1.2.0 <1.3.0-0\n// ~0.0.1 --> >=0.0.1 <0.1.0-0\nconst replaceTildes = (comp, options) => {\n  return comp\n    .trim()\n    .split(/\\s+/)\n    .map((c) => replaceTilde(c, options))\n    .join(' ')\n}\n\nconst replaceTilde = (comp, options) => {\n  const r = options.loose ? re[t.TILDELOOSE] : re[t.TILDE]\n  return comp.replace(r, (_, M, m, p, pr) => {\n    debug('tilde', comp, _, M, m, p, pr)\n    let ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = `>=${M}.0.0 <${+M + 1}.0.0-0`\n    } else if (isX(p)) {\n      // ~1.2 == >=1.2.0 <1.3.0-0\n      ret = `>=${M}.${m}.0 <${M}.${+m + 1}.0-0`\n    } else if (pr) {\n      debug('replaceTilde pr', pr)\n      ret = `>=${M}.${m}.${p}-${pr\n      } <${M}.${+m + 1}.0-0`\n    } else {\n      // ~1.2.3 == >=1.2.3 <1.3.0-0\n      ret = `>=${M}.${m}.${p\n      } <${M}.${+m + 1}.0-0`\n    }\n\n    debug('tilde return', ret)\n    return ret\n  })\n}\n\n// ^ --> * (any, kinda silly)\n// ^2, ^2.x, ^2.x.x --> >=2.0.0 <3.0.0-0\n// ^2.0, ^2.0.x --> >=2.0.0 <3.0.0-0\n// ^1.2, ^1.2.x --> >=1.2.0 <2.0.0-0\n// ^1.2.3 --> >=1.2.3 <2.0.0-0\n// ^1.2.0 --> >=1.2.0 <2.0.0-0\n// ^0.0.1 --> >=0.0.1 <0.0.2-0\n// ^0.1.0 --> >=0.1.0 <0.2.0-0\nconst replaceCarets = (comp, options) => {\n  return comp\n    .trim()\n    .split(/\\s+/)\n    .map((c) => replaceCaret(c, options))\n    .join(' ')\n}\n\nconst replaceCaret = (comp, options) => {\n  debug('caret', comp, options)\n  const r = options.loose ? re[t.CARETLOOSE] : re[t.CARET]\n  const z = options.includePrerelease ? '-0' : ''\n  return comp.replace(r, (_, M, m, p, pr) => {\n    debug('caret', comp, _, M, m, p, pr)\n    let ret\n\n    if (isX(M)) {\n      ret = ''\n    } else if (isX(m)) {\n      ret = `>=${M}.0.0${z} <${+M + 1}.0.0-0`\n    } else if (isX(p)) {\n      if (M === '0') {\n        ret = `>=${M}.${m}.0${z} <${M}.${+m + 1}.0-0`\n      } else {\n        ret = `>=${M}.${m}.0${z} <${+M + 1}.0.0-0`\n      }\n    } else if (pr) {\n      debug('replaceCaret pr', pr)\n      if (M === '0') {\n        if (m === '0') {\n          ret = `>=${M}.${m}.${p}-${pr\n          } <${M}.${m}.${+p + 1}-0`\n        } else {\n          ret = `>=${M}.${m}.${p}-${pr\n          } <${M}.${+m + 1}.0-0`\n        }\n      } else {\n        ret = `>=${M}.${m}.${p}-${pr\n        } <${+M + 1}.0.0-0`\n      }\n    } else {\n      debug('no pr')\n      if (M === '0') {\n        if (m === '0') {\n          ret = `>=${M}.${m}.${p\n          }${z} <${M}.${m}.${+p + 1}-0`\n        } else {\n          ret = `>=${M}.${m}.${p\n          }${z} <${M}.${+m + 1}.0-0`\n        }\n      } else {\n        ret = `>=${M}.${m}.${p\n        } <${+M + 1}.0.0-0`\n      }\n    }\n\n    debug('caret return', ret)\n    return ret\n  })\n}\n\nconst replaceXRanges = (comp, options) => {\n  debug('replaceXRanges', comp, options)\n  return comp\n    .split(/\\s+/)\n    .map((c) => replaceXRange(c, options))\n    .join(' ')\n}\n\nconst replaceXRange = (comp, options) => {\n  comp = comp.trim()\n  const r = options.loose ? re[t.XRANGELOOSE] : re[t.XRANGE]\n  return comp.replace(r, (ret, gtlt, M, m, p, pr) => {\n    debug('xRange', comp, ret, gtlt, M, m, p, pr)\n    const xM = isX(M)\n    const xm = xM || isX(m)\n    const xp = xm || isX(p)\n    const anyX = xp\n\n    if (gtlt === '=' && anyX) {\n      gtlt = ''\n    }\n\n    // if we're including prereleases in the match, then we need\n    // to fix this to -0, the lowest possible prerelease value\n    pr = options.includePrerelease ? '-0' : ''\n\n    if (xM) {\n      if (gtlt === '>' || gtlt === '<') {\n        // nothing is allowed\n        ret = '<0.0.0-0'\n      } else {\n        // nothing is forbidden\n        ret = '*'\n      }\n    } else if (gtlt && anyX) {\n      // we know patch is an x, because we have any x at all.\n      // replace X with 0\n      if (xm) {\n        m = 0\n      }\n      p = 0\n\n      if (gtlt === '>') {\n        // >1 => >=2.0.0\n        // >1.2 => >=1.3.0\n        gtlt = '>='\n        if (xm) {\n          M = +M + 1\n          m = 0\n          p = 0\n        } else {\n          m = +m + 1\n          p = 0\n        }\n      } else if (gtlt === '<=') {\n        // <=0.7.x is actually <0.8.0, since any 0.7.x should\n        // pass.  Similarly, <=7.x is actually <8.0.0, etc.\n        gtlt = '<'\n        if (xm) {\n          M = +M + 1\n        } else {\n          m = +m + 1\n        }\n      }\n\n      if (gtlt === '<') {\n        pr = '-0'\n      }\n\n      ret = `${gtlt + M}.${m}.${p}${pr}`\n    } else if (xm) {\n      ret = `>=${M}.0.0${pr} <${+M + 1}.0.0-0`\n    } else if (xp) {\n      ret = `>=${M}.${m}.0${pr\n      } <${M}.${+m + 1}.0-0`\n    }\n\n    debug('xRange return', ret)\n\n    return ret\n  })\n}\n\n// Because * is AND-ed with everything else in the comparator,\n// and '' means \"any version\", just remove the *s entirely.\nconst replaceStars = (comp, options) => {\n  debug('replaceStars', comp, options)\n  // Looseness is ignored here.  star is always as loose as it gets!\n  return comp\n    .trim()\n    .replace(re[t.STAR], '')\n}\n\nconst replaceGTE0 = (comp, options) => {\n  debug('replaceGTE0', comp, options)\n  return comp\n    .trim()\n    .replace(re[options.includePrerelease ? t.GTE0PRE : t.GTE0], '')\n}\n\n// This function is passed to string.replace(re[t.HYPHENRANGE])\n// M, m, patch, prerelease, build\n// 1.2 - 3.4.5 => >=1.2.0 <=3.4.5\n// 1.2.3 - 3.4 => >=1.2.0 <3.5.0-0 Any 3.4.x will do\n// 1.2 - 3.4 => >=1.2.0 <3.5.0-0\n// TODO build?\nconst hyphenReplace = incPr => ($0,\n  from, fM, fm, fp, fpr, fb,\n  to, tM, tm, tp, tpr) => {\n  if (isX(fM)) {\n    from = ''\n  } else if (isX(fm)) {\n    from = `>=${fM}.0.0${incPr ? '-0' : ''}`\n  } else if (isX(fp)) {\n    from = `>=${fM}.${fm}.0${incPr ? '-0' : ''}`\n  } else if (fpr) {\n    from = `>=${from}`\n  } else {\n    from = `>=${from}${incPr ? '-0' : ''}`\n  }\n\n  if (isX(tM)) {\n    to = ''\n  } else if (isX(tm)) {\n    to = `<${+tM + 1}.0.0-0`\n  } else if (isX(tp)) {\n    to = `<${tM}.${+tm + 1}.0-0`\n  } else if (tpr) {\n    to = `<=${tM}.${tm}.${tp}-${tpr}`\n  } else if (incPr) {\n    to = `<${tM}.${tm}.${+tp + 1}-0`\n  } else {\n    to = `<=${to}`\n  }\n\n  return `${from} ${to}`.trim()\n}\n\nconst testSet = (set, version, options) => {\n  for (let i = 0; i < set.length; i++) {\n    if (!set[i].test(version)) {\n      return false\n    }\n  }\n\n  if (version.prerelease.length && !options.includePrerelease) {\n    // Find the set of versions that are allowed to have prereleases\n    // For example, ^1.2.3-pr.1 desugars to >=1.2.3-pr.1 <2.0.0\n    // That should allow `1.2.3-pr.2` to pass.\n    // However, `1.2.4-alpha.notready` should NOT be allowed,\n    // even though it's within the range set by the comparators.\n    for (let i = 0; i < set.length; i++) {\n      debug(set[i].semver)\n      if (set[i].semver === Comparator.ANY) {\n        continue\n      }\n\n      if (set[i].semver.prerelease.length > 0) {\n        const allowed = set[i].semver\n        if (allowed.major === version.major &&\n            allowed.minor === version.minor &&\n            allowed.patch === version.patch) {\n          return true\n        }\n      }\n    }\n\n    // Version has a -pre, but it's not one of the ones we like.\n    return false\n  }\n\n  return true\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/classes/range.js?");

/***/ }),

/***/ "./node_modules/semver/classes/semver.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/classes/semver.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const debug = __webpack_require__(/*! ../internal/debug */ \"./node_modules/semver/internal/debug.js\")\nconst { MAX_LENGTH, MAX_SAFE_INTEGER } = __webpack_require__(/*! ../internal/constants */ \"./node_modules/semver/internal/constants.js\")\nconst { safeRe: re, t } = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\n\nconst parseOptions = __webpack_require__(/*! ../internal/parse-options */ \"./node_modules/semver/internal/parse-options.js\")\nconst { compareIdentifiers } = __webpack_require__(/*! ../internal/identifiers */ \"./node_modules/semver/internal/identifiers.js\")\nclass SemVer {\n  constructor (version, options) {\n    options = parseOptions(options)\n\n    if (version instanceof SemVer) {\n      if (version.loose === !!options.loose &&\n          version.includePrerelease === !!options.includePrerelease) {\n        return version\n      } else {\n        version = version.version\n      }\n    } else if (typeof version !== 'string') {\n      throw new TypeError(`Invalid version. Must be a string. Got type \"${typeof version}\".`)\n    }\n\n    if (version.length > MAX_LENGTH) {\n      throw new TypeError(\n        `version is longer than ${MAX_LENGTH} characters`\n      )\n    }\n\n    debug('SemVer', version, options)\n    this.options = options\n    this.loose = !!options.loose\n    // this isn't actually relevant for versions, but keep it so that we\n    // don't run into trouble passing this.options around.\n    this.includePrerelease = !!options.includePrerelease\n\n    const m = version.trim().match(options.loose ? re[t.LOOSE] : re[t.FULL])\n\n    if (!m) {\n      throw new TypeError(`Invalid Version: ${version}`)\n    }\n\n    this.raw = version\n\n    // these are actually numbers\n    this.major = +m[1]\n    this.minor = +m[2]\n    this.patch = +m[3]\n\n    if (this.major > MAX_SAFE_INTEGER || this.major < 0) {\n      throw new TypeError('Invalid major version')\n    }\n\n    if (this.minor > MAX_SAFE_INTEGER || this.minor < 0) {\n      throw new TypeError('Invalid minor version')\n    }\n\n    if (this.patch > MAX_SAFE_INTEGER || this.patch < 0) {\n      throw new TypeError('Invalid patch version')\n    }\n\n    // numberify any prerelease numeric ids\n    if (!m[4]) {\n      this.prerelease = []\n    } else {\n      this.prerelease = m[4].split('.').map((id) => {\n        if (/^[0-9]+$/.test(id)) {\n          const num = +id\n          if (num >= 0 && num < MAX_SAFE_INTEGER) {\n            return num\n          }\n        }\n        return id\n      })\n    }\n\n    this.build = m[5] ? m[5].split('.') : []\n    this.format()\n  }\n\n  format () {\n    this.version = `${this.major}.${this.minor}.${this.patch}`\n    if (this.prerelease.length) {\n      this.version += `-${this.prerelease.join('.')}`\n    }\n    return this.version\n  }\n\n  toString () {\n    return this.version\n  }\n\n  compare (other) {\n    debug('SemVer.compare', this.version, this.options, other)\n    if (!(other instanceof SemVer)) {\n      if (typeof other === 'string' && other === this.version) {\n        return 0\n      }\n      other = new SemVer(other, this.options)\n    }\n\n    if (other.version === this.version) {\n      return 0\n    }\n\n    return this.compareMain(other) || this.comparePre(other)\n  }\n\n  compareMain (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    return (\n      compareIdentifiers(this.major, other.major) ||\n      compareIdentifiers(this.minor, other.minor) ||\n      compareIdentifiers(this.patch, other.patch)\n    )\n  }\n\n  comparePre (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    // NOT having a prerelease is > having one\n    if (this.prerelease.length && !other.prerelease.length) {\n      return -1\n    } else if (!this.prerelease.length && other.prerelease.length) {\n      return 1\n    } else if (!this.prerelease.length && !other.prerelease.length) {\n      return 0\n    }\n\n    let i = 0\n    do {\n      const a = this.prerelease[i]\n      const b = other.prerelease[i]\n      debug('prerelease compare', i, a, b)\n      if (a === undefined && b === undefined) {\n        return 0\n      } else if (b === undefined) {\n        return 1\n      } else if (a === undefined) {\n        return -1\n      } else if (a === b) {\n        continue\n      } else {\n        return compareIdentifiers(a, b)\n      }\n    } while (++i)\n  }\n\n  compareBuild (other) {\n    if (!(other instanceof SemVer)) {\n      other = new SemVer(other, this.options)\n    }\n\n    let i = 0\n    do {\n      const a = this.build[i]\n      const b = other.build[i]\n      debug('build compare', i, a, b)\n      if (a === undefined && b === undefined) {\n        return 0\n      } else if (b === undefined) {\n        return 1\n      } else if (a === undefined) {\n        return -1\n      } else if (a === b) {\n        continue\n      } else {\n        return compareIdentifiers(a, b)\n      }\n    } while (++i)\n  }\n\n  // preminor will bump the version up to the next minor release, and immediately\n  // down to pre-release. premajor and prepatch work the same way.\n  inc (release, identifier, identifierBase) {\n    switch (release) {\n      case 'premajor':\n        this.prerelease.length = 0\n        this.patch = 0\n        this.minor = 0\n        this.major++\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'preminor':\n        this.prerelease.length = 0\n        this.patch = 0\n        this.minor++\n        this.inc('pre', identifier, identifierBase)\n        break\n      case 'prepatch':\n        // If this is already a prerelease, it will bump to the next version\n        // drop any prereleases that might already exist, since they are not\n        // relevant at this point.\n        this.prerelease.length = 0\n        this.inc('patch', identifier, identifierBase)\n        this.inc('pre', identifier, identifierBase)\n        break\n      // If the input is a non-prerelease version, this acts the same as\n      // prepatch.\n      case 'prerelease':\n        if (this.prerelease.length === 0) {\n          this.inc('patch', identifier, identifierBase)\n        }\n        this.inc('pre', identifier, identifierBase)\n        break\n\n      case 'major':\n        // If this is a pre-major version, bump up to the same major version.\n        // Otherwise increment major.\n        // 1.0.0-5 bumps to 1.0.0\n        // 1.1.0 bumps to 2.0.0\n        if (\n          this.minor !== 0 ||\n          this.patch !== 0 ||\n          this.prerelease.length === 0\n        ) {\n          this.major++\n        }\n        this.minor = 0\n        this.patch = 0\n        this.prerelease = []\n        break\n      case 'minor':\n        // If this is a pre-minor version, bump up to the same minor version.\n        // Otherwise increment minor.\n        // 1.2.0-5 bumps to 1.2.0\n        // 1.2.1 bumps to 1.3.0\n        if (this.patch !== 0 || this.prerelease.length === 0) {\n          this.minor++\n        }\n        this.patch = 0\n        this.prerelease = []\n        break\n      case 'patch':\n        // If this is not a pre-release version, it will increment the patch.\n        // If it is a pre-release it will bump up to the same patch version.\n        // 1.2.0-5 patches to 1.2.0\n        // 1.2.0 patches to 1.2.1\n        if (this.prerelease.length === 0) {\n          this.patch++\n        }\n        this.prerelease = []\n        break\n      // This probably shouldn't be used publicly.\n      // 1.0.0 'pre' would become 1.0.0-0 which is the wrong direction.\n      case 'pre': {\n        const base = Number(identifierBase) ? 1 : 0\n\n        if (!identifier && identifierBase === false) {\n          throw new Error('invalid increment argument: identifier is empty')\n        }\n\n        if (this.prerelease.length === 0) {\n          this.prerelease = [base]\n        } else {\n          let i = this.prerelease.length\n          while (--i >= 0) {\n            if (typeof this.prerelease[i] === 'number') {\n              this.prerelease[i]++\n              i = -2\n            }\n          }\n          if (i === -1) {\n            // didn't increment anything\n            if (identifier === this.prerelease.join('.') && identifierBase === false) {\n              throw new Error('invalid increment argument: identifier already exists')\n            }\n            this.prerelease.push(base)\n          }\n        }\n        if (identifier) {\n          // 1.2.0-beta.1 bumps to 1.2.0-beta.2,\n          // 1.2.0-beta.fooblz or 1.2.0-beta bumps to 1.2.0-beta.0\n          let prerelease = [identifier, base]\n          if (identifierBase === false) {\n            prerelease = [identifier]\n          }\n          if (compareIdentifiers(this.prerelease[0], identifier) === 0) {\n            if (isNaN(this.prerelease[1])) {\n              this.prerelease = prerelease\n            }\n          } else {\n            this.prerelease = prerelease\n          }\n        }\n        break\n      }\n      default:\n        throw new Error(`invalid increment argument: ${release}`)\n    }\n    this.raw = this.format()\n    if (this.build.length) {\n      this.raw += `+${this.build.join('.')}`\n    }\n    return this\n  }\n}\n\nmodule.exports = SemVer\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/classes/semver.js?");

/***/ }),

/***/ "./node_modules/semver/functions/clean.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/clean.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst clean = (version, options) => {\n  const s = parse(version.trim().replace(/^[=v]+/, ''), options)\n  return s ? s.version : null\n}\nmodule.exports = clean\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/clean.js?");

/***/ }),

/***/ "./node_modules/semver/functions/cmp.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/cmp.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const eq = __webpack_require__(/*! ./eq */ \"./node_modules/semver/functions/eq.js\")\nconst neq = __webpack_require__(/*! ./neq */ \"./node_modules/semver/functions/neq.js\")\nconst gt = __webpack_require__(/*! ./gt */ \"./node_modules/semver/functions/gt.js\")\nconst gte = __webpack_require__(/*! ./gte */ \"./node_modules/semver/functions/gte.js\")\nconst lt = __webpack_require__(/*! ./lt */ \"./node_modules/semver/functions/lt.js\")\nconst lte = __webpack_require__(/*! ./lte */ \"./node_modules/semver/functions/lte.js\")\n\nconst cmp = (a, op, b, loose) => {\n  switch (op) {\n    case '===':\n      if (typeof a === 'object') {\n        a = a.version\n      }\n      if (typeof b === 'object') {\n        b = b.version\n      }\n      return a === b\n\n    case '!==':\n      if (typeof a === 'object') {\n        a = a.version\n      }\n      if (typeof b === 'object') {\n        b = b.version\n      }\n      return a !== b\n\n    case '':\n    case '=':\n    case '==':\n      return eq(a, b, loose)\n\n    case '!=':\n      return neq(a, b, loose)\n\n    case '>':\n      return gt(a, b, loose)\n\n    case '>=':\n      return gte(a, b, loose)\n\n    case '<':\n      return lt(a, b, loose)\n\n    case '<=':\n      return lte(a, b, loose)\n\n    default:\n      throw new TypeError(`Invalid operator: ${op}`)\n  }\n}\nmodule.exports = cmp\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/cmp.js?");

/***/ }),

/***/ "./node_modules/semver/functions/coerce.js":
/*!*************************************************!*\
  !*** ./node_modules/semver/functions/coerce.js ***!
  \*************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst { safeRe: re, t } = __webpack_require__(/*! ../internal/re */ \"./node_modules/semver/internal/re.js\")\n\nconst coerce = (version, options) => {\n  if (version instanceof SemVer) {\n    return version\n  }\n\n  if (typeof version === 'number') {\n    version = String(version)\n  }\n\n  if (typeof version !== 'string') {\n    return null\n  }\n\n  options = options || {}\n\n  let match = null\n  if (!options.rtl) {\n    match = version.match(options.includePrerelease ? re[t.COERCEFULL] : re[t.COERCE])\n  } else {\n    // Find the right-most coercible string that does not share\n    // a terminus with a more left-ward coercible string.\n    // Eg, '1.2.3.4' wants to coerce '2.3.4', not '3.4' or '4'\n    // With includePrerelease option set, '1.2.3.4-rc' wants to coerce '2.3.4-rc', not '2.3.4'\n    //\n    // Walk through the string checking with a /g regexp\n    // Manually set the index so as to pick up overlapping matches.\n    // Stop when we get a match that ends at the string end, since no\n    // coercible string can be more right-ward without the same terminus.\n    const coerceRtlRegex = options.includePrerelease ? re[t.COERCERTLFULL] : re[t.COERCERTL]\n    let next\n    while ((next = coerceRtlRegex.exec(version)) &&\n        (!match || match.index + match[0].length !== version.length)\n    ) {\n      if (!match ||\n            next.index + next[0].length !== match.index + match[0].length) {\n        match = next\n      }\n      coerceRtlRegex.lastIndex = next.index + next[1].length + next[2].length\n    }\n    // leave it in a clean state\n    coerceRtlRegex.lastIndex = -1\n  }\n\n  if (match === null) {\n    return null\n  }\n\n  const major = match[2]\n  const minor = match[3] || '0'\n  const patch = match[4] || '0'\n  const prerelease = options.includePrerelease && match[5] ? `-${match[5]}` : ''\n  const build = options.includePrerelease && match[6] ? `+${match[6]}` : ''\n\n  return parse(`${major}.${minor}.${patch}${prerelease}${build}`, options)\n}\nmodule.exports = coerce\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/coerce.js?");

/***/ }),

/***/ "./node_modules/semver/functions/compare-build.js":
/*!********************************************************!*\
  !*** ./node_modules/semver/functions/compare-build.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst compareBuild = (a, b, loose) => {\n  const versionA = new SemVer(a, loose)\n  const versionB = new SemVer(b, loose)\n  return versionA.compare(versionB) || versionA.compareBuild(versionB)\n}\nmodule.exports = compareBuild\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/compare-build.js?");

/***/ }),

/***/ "./node_modules/semver/functions/compare-loose.js":
/*!********************************************************!*\
  !*** ./node_modules/semver/functions/compare-loose.js ***!
  \********************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst compareLoose = (a, b) => compare(a, b, true)\nmodule.exports = compareLoose\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/compare-loose.js?");

/***/ }),

/***/ "./node_modules/semver/functions/compare.js":
/*!**************************************************!*\
  !*** ./node_modules/semver/functions/compare.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst compare = (a, b, loose) =>\n  new SemVer(a, loose).compare(new SemVer(b, loose))\n\nmodule.exports = compare\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/compare.js?");

/***/ }),

/***/ "./node_modules/semver/functions/diff.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/functions/diff.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse.js */ \"./node_modules/semver/functions/parse.js\")\n\nconst diff = (version1, version2) => {\n  const v1 = parse(version1, null, true)\n  const v2 = parse(version2, null, true)\n  const comparison = v1.compare(v2)\n\n  if (comparison === 0) {\n    return null\n  }\n\n  const v1Higher = comparison > 0\n  const highVersion = v1Higher ? v1 : v2\n  const lowVersion = v1Higher ? v2 : v1\n  const highHasPre = !!highVersion.prerelease.length\n  const lowHasPre = !!lowVersion.prerelease.length\n\n  if (lowHasPre && !highHasPre) {\n    // Going from prerelease -> no prerelease requires some special casing\n\n    // If the low version has only a major, then it will always be a major\n    // Some examples:\n    // 1.0.0-1 -> 1.0.0\n    // 1.0.0-1 -> 1.1.1\n    // 1.0.0-1 -> 2.0.0\n    if (!lowVersion.patch && !lowVersion.minor) {\n      return 'major'\n    }\n\n    // Otherwise it can be determined by checking the high version\n\n    if (highVersion.patch) {\n      // anything higher than a patch bump would result in the wrong version\n      return 'patch'\n    }\n\n    if (highVersion.minor) {\n      // anything higher than a minor bump would result in the wrong version\n      return 'minor'\n    }\n\n    // bumping major/minor/patch all have same result\n    return 'major'\n  }\n\n  // add the `pre` prefix if we are going to a prerelease version\n  const prefix = highHasPre ? 'pre' : ''\n\n  if (v1.major !== v2.major) {\n    return prefix + 'major'\n  }\n\n  if (v1.minor !== v2.minor) {\n    return prefix + 'minor'\n  }\n\n  if (v1.patch !== v2.patch) {\n    return prefix + 'patch'\n  }\n\n  // high and low are preleases\n  return 'prerelease'\n}\n\nmodule.exports = diff\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/diff.js?");

/***/ }),

/***/ "./node_modules/semver/functions/eq.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/functions/eq.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst eq = (a, b, loose) => compare(a, b, loose) === 0\nmodule.exports = eq\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/eq.js?");

/***/ }),

/***/ "./node_modules/semver/functions/gt.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/functions/gt.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst gt = (a, b, loose) => compare(a, b, loose) > 0\nmodule.exports = gt\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/gt.js?");

/***/ }),

/***/ "./node_modules/semver/functions/gte.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/gte.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst gte = (a, b, loose) => compare(a, b, loose) >= 0\nmodule.exports = gte\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/gte.js?");

/***/ }),

/***/ "./node_modules/semver/functions/inc.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/inc.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\n\nconst inc = (version, release, options, identifier, identifierBase) => {\n  if (typeof (options) === 'string') {\n    identifierBase = identifier\n    identifier = options\n    options = undefined\n  }\n\n  try {\n    return new SemVer(\n      version instanceof SemVer ? version.version : version,\n      options\n    ).inc(release, identifier, identifierBase).version\n  } catch (er) {\n    return null\n  }\n}\nmodule.exports = inc\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/inc.js?");

/***/ }),

/***/ "./node_modules/semver/functions/lt.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/functions/lt.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst lt = (a, b, loose) => compare(a, b, loose) < 0\nmodule.exports = lt\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/lt.js?");

/***/ }),

/***/ "./node_modules/semver/functions/lte.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/lte.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst lte = (a, b, loose) => compare(a, b, loose) <= 0\nmodule.exports = lte\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/lte.js?");

/***/ }),

/***/ "./node_modules/semver/functions/major.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/major.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst major = (a, loose) => new SemVer(a, loose).major\nmodule.exports = major\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/major.js?");

/***/ }),

/***/ "./node_modules/semver/functions/minor.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/minor.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst minor = (a, loose) => new SemVer(a, loose).minor\nmodule.exports = minor\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/minor.js?");

/***/ }),

/***/ "./node_modules/semver/functions/neq.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/functions/neq.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst neq = (a, b, loose) => compare(a, b, loose) !== 0\nmodule.exports = neq\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/neq.js?");

/***/ }),

/***/ "./node_modules/semver/functions/parse.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/parse.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst parse = (version, options, throwErrors = false) => {\n  if (version instanceof SemVer) {\n    return version\n  }\n  try {\n    return new SemVer(version, options)\n  } catch (er) {\n    if (!throwErrors) {\n      return null\n    }\n    throw er\n  }\n}\n\nmodule.exports = parse\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/parse.js?");

/***/ }),

/***/ "./node_modules/semver/functions/patch.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/patch.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst patch = (a, loose) => new SemVer(a, loose).patch\nmodule.exports = patch\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/patch.js?");

/***/ }),

/***/ "./node_modules/semver/functions/prerelease.js":
/*!*****************************************************!*\
  !*** ./node_modules/semver/functions/prerelease.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst prerelease = (version, options) => {\n  const parsed = parse(version, options)\n  return (parsed && parsed.prerelease.length) ? parsed.prerelease : null\n}\nmodule.exports = prerelease\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/prerelease.js?");

/***/ }),

/***/ "./node_modules/semver/functions/rcompare.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/functions/rcompare.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compare = __webpack_require__(/*! ./compare */ \"./node_modules/semver/functions/compare.js\")\nconst rcompare = (a, b, loose) => compare(b, a, loose)\nmodule.exports = rcompare\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/rcompare.js?");

/***/ }),

/***/ "./node_modules/semver/functions/rsort.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/rsort.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compareBuild = __webpack_require__(/*! ./compare-build */ \"./node_modules/semver/functions/compare-build.js\")\nconst rsort = (list, loose) => list.sort((a, b) => compareBuild(b, a, loose))\nmodule.exports = rsort\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/rsort.js?");

/***/ }),

/***/ "./node_modules/semver/functions/satisfies.js":
/*!****************************************************!*\
  !*** ./node_modules/semver/functions/satisfies.js ***!
  \****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst satisfies = (version, range, options) => {\n  try {\n    range = new Range(range, options)\n  } catch (er) {\n    return false\n  }\n  return range.test(version)\n}\nmodule.exports = satisfies\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/satisfies.js?");

/***/ }),

/***/ "./node_modules/semver/functions/sort.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/functions/sort.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const compareBuild = __webpack_require__(/*! ./compare-build */ \"./node_modules/semver/functions/compare-build.js\")\nconst sort = (list, loose) => list.sort((a, b) => compareBuild(a, b, loose))\nmodule.exports = sort\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/sort.js?");

/***/ }),

/***/ "./node_modules/semver/functions/valid.js":
/*!************************************************!*\
  !*** ./node_modules/semver/functions/valid.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const parse = __webpack_require__(/*! ./parse */ \"./node_modules/semver/functions/parse.js\")\nconst valid = (version, options) => {\n  const v = parse(version, options)\n  return v ? v.version : null\n}\nmodule.exports = valid\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/functions/valid.js?");

/***/ }),

/***/ "./node_modules/semver/index.js":
/*!**************************************!*\
  !*** ./node_modules/semver/index.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// just pre-load all the stuff that index.js lazily exports\nconst internalRe = __webpack_require__(/*! ./internal/re */ \"./node_modules/semver/internal/re.js\")\nconst constants = __webpack_require__(/*! ./internal/constants */ \"./node_modules/semver/internal/constants.js\")\nconst SemVer = __webpack_require__(/*! ./classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst identifiers = __webpack_require__(/*! ./internal/identifiers */ \"./node_modules/semver/internal/identifiers.js\")\nconst parse = __webpack_require__(/*! ./functions/parse */ \"./node_modules/semver/functions/parse.js\")\nconst valid = __webpack_require__(/*! ./functions/valid */ \"./node_modules/semver/functions/valid.js\")\nconst clean = __webpack_require__(/*! ./functions/clean */ \"./node_modules/semver/functions/clean.js\")\nconst inc = __webpack_require__(/*! ./functions/inc */ \"./node_modules/semver/functions/inc.js\")\nconst diff = __webpack_require__(/*! ./functions/diff */ \"./node_modules/semver/functions/diff.js\")\nconst major = __webpack_require__(/*! ./functions/major */ \"./node_modules/semver/functions/major.js\")\nconst minor = __webpack_require__(/*! ./functions/minor */ \"./node_modules/semver/functions/minor.js\")\nconst patch = __webpack_require__(/*! ./functions/patch */ \"./node_modules/semver/functions/patch.js\")\nconst prerelease = __webpack_require__(/*! ./functions/prerelease */ \"./node_modules/semver/functions/prerelease.js\")\nconst compare = __webpack_require__(/*! ./functions/compare */ \"./node_modules/semver/functions/compare.js\")\nconst rcompare = __webpack_require__(/*! ./functions/rcompare */ \"./node_modules/semver/functions/rcompare.js\")\nconst compareLoose = __webpack_require__(/*! ./functions/compare-loose */ \"./node_modules/semver/functions/compare-loose.js\")\nconst compareBuild = __webpack_require__(/*! ./functions/compare-build */ \"./node_modules/semver/functions/compare-build.js\")\nconst sort = __webpack_require__(/*! ./functions/sort */ \"./node_modules/semver/functions/sort.js\")\nconst rsort = __webpack_require__(/*! ./functions/rsort */ \"./node_modules/semver/functions/rsort.js\")\nconst gt = __webpack_require__(/*! ./functions/gt */ \"./node_modules/semver/functions/gt.js\")\nconst lt = __webpack_require__(/*! ./functions/lt */ \"./node_modules/semver/functions/lt.js\")\nconst eq = __webpack_require__(/*! ./functions/eq */ \"./node_modules/semver/functions/eq.js\")\nconst neq = __webpack_require__(/*! ./functions/neq */ \"./node_modules/semver/functions/neq.js\")\nconst gte = __webpack_require__(/*! ./functions/gte */ \"./node_modules/semver/functions/gte.js\")\nconst lte = __webpack_require__(/*! ./functions/lte */ \"./node_modules/semver/functions/lte.js\")\nconst cmp = __webpack_require__(/*! ./functions/cmp */ \"./node_modules/semver/functions/cmp.js\")\nconst coerce = __webpack_require__(/*! ./functions/coerce */ \"./node_modules/semver/functions/coerce.js\")\nconst Comparator = __webpack_require__(/*! ./classes/comparator */ \"./node_modules/semver/classes/comparator.js\")\nconst Range = __webpack_require__(/*! ./classes/range */ \"./node_modules/semver/classes/range.js\")\nconst satisfies = __webpack_require__(/*! ./functions/satisfies */ \"./node_modules/semver/functions/satisfies.js\")\nconst toComparators = __webpack_require__(/*! ./ranges/to-comparators */ \"./node_modules/semver/ranges/to-comparators.js\")\nconst maxSatisfying = __webpack_require__(/*! ./ranges/max-satisfying */ \"./node_modules/semver/ranges/max-satisfying.js\")\nconst minSatisfying = __webpack_require__(/*! ./ranges/min-satisfying */ \"./node_modules/semver/ranges/min-satisfying.js\")\nconst minVersion = __webpack_require__(/*! ./ranges/min-version */ \"./node_modules/semver/ranges/min-version.js\")\nconst validRange = __webpack_require__(/*! ./ranges/valid */ \"./node_modules/semver/ranges/valid.js\")\nconst outside = __webpack_require__(/*! ./ranges/outside */ \"./node_modules/semver/ranges/outside.js\")\nconst gtr = __webpack_require__(/*! ./ranges/gtr */ \"./node_modules/semver/ranges/gtr.js\")\nconst ltr = __webpack_require__(/*! ./ranges/ltr */ \"./node_modules/semver/ranges/ltr.js\")\nconst intersects = __webpack_require__(/*! ./ranges/intersects */ \"./node_modules/semver/ranges/intersects.js\")\nconst simplifyRange = __webpack_require__(/*! ./ranges/simplify */ \"./node_modules/semver/ranges/simplify.js\")\nconst subset = __webpack_require__(/*! ./ranges/subset */ \"./node_modules/semver/ranges/subset.js\")\nmodule.exports = {\n  parse,\n  valid,\n  clean,\n  inc,\n  diff,\n  major,\n  minor,\n  patch,\n  prerelease,\n  compare,\n  rcompare,\n  compareLoose,\n  compareBuild,\n  sort,\n  rsort,\n  gt,\n  lt,\n  eq,\n  neq,\n  gte,\n  lte,\n  cmp,\n  coerce,\n  Comparator,\n  Range,\n  satisfies,\n  toComparators,\n  maxSatisfying,\n  minSatisfying,\n  minVersion,\n  validRange,\n  outside,\n  gtr,\n  ltr,\n  intersects,\n  simplifyRange,\n  subset,\n  SemVer,\n  re: internalRe.re,\n  src: internalRe.src,\n  tokens: internalRe.t,\n  SEMVER_SPEC_VERSION: constants.SEMVER_SPEC_VERSION,\n  RELEASE_TYPES: constants.RELEASE_TYPES,\n  compareIdentifiers: identifiers.compareIdentifiers,\n  rcompareIdentifiers: identifiers.rcompareIdentifiers,\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/index.js?");

/***/ }),

/***/ "./node_modules/semver/internal/constants.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/internal/constants.js ***!
  \***************************************************/
/***/ ((module) => {

eval("// Note: this is the semver.org version of the spec that it implements\n// Not necessarily the package version of this code.\nconst SEMVER_SPEC_VERSION = '2.0.0'\n\nconst MAX_LENGTH = 256\nconst MAX_SAFE_INTEGER = Number.MAX_SAFE_INTEGER ||\n/* istanbul ignore next */ 9007199254740991\n\n// Max safe segment length for coercion.\nconst MAX_SAFE_COMPONENT_LENGTH = 16\n\n// Max safe length for a build identifier. The max length minus 6 characters for\n// the shortest version with a build 0.0.0+BUILD.\nconst MAX_SAFE_BUILD_LENGTH = MAX_LENGTH - 6\n\nconst RELEASE_TYPES = [\n  'major',\n  'premajor',\n  'minor',\n  'preminor',\n  'patch',\n  'prepatch',\n  'prerelease',\n]\n\nmodule.exports = {\n  MAX_LENGTH,\n  MAX_SAFE_COMPONENT_LENGTH,\n  MAX_SAFE_BUILD_LENGTH,\n  MAX_SAFE_INTEGER,\n  RELEASE_TYPES,\n  SEMVER_SPEC_VERSION,\n  FLAG_INCLUDE_PRERELEASE: 0b001,\n  FLAG_LOOSE: 0b010,\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/internal/constants.js?");

/***/ }),

/***/ "./node_modules/semver/internal/debug.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/internal/debug.js ***!
  \***********************************************/
/***/ ((module) => {

eval("const debug = (\n  typeof process === 'object' &&\n  process.env &&\n  process.env.NODE_DEBUG &&\n  /\\bsemver\\b/i.test(process.env.NODE_DEBUG)\n) ? (...args) => console.error('SEMVER', ...args)\n  : () => {}\n\nmodule.exports = debug\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/internal/debug.js?");

/***/ }),

/***/ "./node_modules/semver/internal/identifiers.js":
/*!*****************************************************!*\
  !*** ./node_modules/semver/internal/identifiers.js ***!
  \*****************************************************/
/***/ ((module) => {

eval("const numeric = /^[0-9]+$/\nconst compareIdentifiers = (a, b) => {\n  const anum = numeric.test(a)\n  const bnum = numeric.test(b)\n\n  if (anum && bnum) {\n    a = +a\n    b = +b\n  }\n\n  return a === b ? 0\n    : (anum && !bnum) ? -1\n    : (bnum && !anum) ? 1\n    : a < b ? -1\n    : 1\n}\n\nconst rcompareIdentifiers = (a, b) => compareIdentifiers(b, a)\n\nmodule.exports = {\n  compareIdentifiers,\n  rcompareIdentifiers,\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/internal/identifiers.js?");

/***/ }),

/***/ "./node_modules/semver/internal/lrucache.js":
/*!**************************************************!*\
  !*** ./node_modules/semver/internal/lrucache.js ***!
  \**************************************************/
/***/ ((module) => {

eval("class LRUCache {\n  constructor () {\n    this.max = 1000\n    this.map = new Map()\n  }\n\n  get (key) {\n    const value = this.map.get(key)\n    if (value === undefined) {\n      return undefined\n    } else {\n      // Remove the key from the map and add it to the end\n      this.map.delete(key)\n      this.map.set(key, value)\n      return value\n    }\n  }\n\n  delete (key) {\n    return this.map.delete(key)\n  }\n\n  set (key, value) {\n    const deleted = this.delete(key)\n\n    if (!deleted && value !== undefined) {\n      // If cache is full, delete the least recently used item\n      if (this.map.size >= this.max) {\n        const firstKey = this.map.keys().next().value\n        this.delete(firstKey)\n      }\n\n      this.map.set(key, value)\n    }\n\n    return this\n  }\n}\n\nmodule.exports = LRUCache\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/internal/lrucache.js?");

/***/ }),

/***/ "./node_modules/semver/internal/parse-options.js":
/*!*******************************************************!*\
  !*** ./node_modules/semver/internal/parse-options.js ***!
  \*******************************************************/
/***/ ((module) => {

eval("// parse out just the options we care about\nconst looseOption = Object.freeze({ loose: true })\nconst emptyOpts = Object.freeze({ })\nconst parseOptions = options => {\n  if (!options) {\n    return emptyOpts\n  }\n\n  if (typeof options !== 'object') {\n    return looseOption\n  }\n\n  return options\n}\nmodule.exports = parseOptions\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/internal/parse-options.js?");

/***/ }),

/***/ "./node_modules/semver/internal/re.js":
/*!********************************************!*\
  !*** ./node_modules/semver/internal/re.js ***!
  \********************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("const {\n  MAX_SAFE_COMPONENT_LENGTH,\n  MAX_SAFE_BUILD_LENGTH,\n  MAX_LENGTH,\n} = __webpack_require__(/*! ./constants */ \"./node_modules/semver/internal/constants.js\")\nconst debug = __webpack_require__(/*! ./debug */ \"./node_modules/semver/internal/debug.js\")\nexports = module.exports = {}\n\n// The actual regexps go on exports.re\nconst re = exports.re = []\nconst safeRe = exports.safeRe = []\nconst src = exports.src = []\nconst t = exports.t = {}\nlet R = 0\n\nconst LETTERDASHNUMBER = '[a-zA-Z0-9-]'\n\n// Replace some greedy regex tokens to prevent regex dos issues. These regex are\n// used internally via the safeRe object since all inputs in this library get\n// normalized first to trim and collapse all extra whitespace. The original\n// regexes are exported for userland consumption and lower level usage. A\n// future breaking change could export the safer regex only with a note that\n// all input should have extra whitespace removed.\nconst safeRegexReplacements = [\n  ['\\\\s', 1],\n  ['\\\\d', MAX_LENGTH],\n  [LETTERDASHNUMBER, MAX_SAFE_BUILD_LENGTH],\n]\n\nconst makeSafeRegex = (value) => {\n  for (const [token, max] of safeRegexReplacements) {\n    value = value\n      .split(`${token}*`).join(`${token}{0,${max}}`)\n      .split(`${token}+`).join(`${token}{1,${max}}`)\n  }\n  return value\n}\n\nconst createToken = (name, value, isGlobal) => {\n  const safe = makeSafeRegex(value)\n  const index = R++\n  debug(name, index, value)\n  t[name] = index\n  src[index] = value\n  re[index] = new RegExp(value, isGlobal ? 'g' : undefined)\n  safeRe[index] = new RegExp(safe, isGlobal ? 'g' : undefined)\n}\n\n// The following Regular Expressions can be used for tokenizing,\n// validating, and parsing SemVer version strings.\n\n// ## Numeric Identifier\n// A single `0`, or a non-zero digit followed by zero or more digits.\n\ncreateToken('NUMERICIDENTIFIER', '0|[1-9]\\\\d*')\ncreateToken('NUMERICIDENTIFIERLOOSE', '\\\\d+')\n\n// ## Non-numeric Identifier\n// Zero or more digits, followed by a letter or hyphen, and then zero or\n// more letters, digits, or hyphens.\n\ncreateToken('NONNUMERICIDENTIFIER', `\\\\d*[a-zA-Z-]${LETTERDASHNUMBER}*`)\n\n// ## Main Version\n// Three dot-separated numeric identifiers.\n\ncreateToken('MAINVERSION', `(${src[t.NUMERICIDENTIFIER]})\\\\.` +\n                   `(${src[t.NUMERICIDENTIFIER]})\\\\.` +\n                   `(${src[t.NUMERICIDENTIFIER]})`)\n\ncreateToken('MAINVERSIONLOOSE', `(${src[t.NUMERICIDENTIFIERLOOSE]})\\\\.` +\n                        `(${src[t.NUMERICIDENTIFIERLOOSE]})\\\\.` +\n                        `(${src[t.NUMERICIDENTIFIERLOOSE]})`)\n\n// ## Pre-release Version Identifier\n// A numeric identifier, or a non-numeric identifier.\n\ncreateToken('PRERELEASEIDENTIFIER', `(?:${src[t.NUMERICIDENTIFIER]\n}|${src[t.NONNUMERICIDENTIFIER]})`)\n\ncreateToken('PRERELEASEIDENTIFIERLOOSE', `(?:${src[t.NUMERICIDENTIFIERLOOSE]\n}|${src[t.NONNUMERICIDENTIFIER]})`)\n\n// ## Pre-release Version\n// Hyphen, followed by one or more dot-separated pre-release version\n// identifiers.\n\ncreateToken('PRERELEASE', `(?:-(${src[t.PRERELEASEIDENTIFIER]\n}(?:\\\\.${src[t.PRERELEASEIDENTIFIER]})*))`)\n\ncreateToken('PRERELEASELOOSE', `(?:-?(${src[t.PRERELEASEIDENTIFIERLOOSE]\n}(?:\\\\.${src[t.PRERELEASEIDENTIFIERLOOSE]})*))`)\n\n// ## Build Metadata Identifier\n// Any combination of digits, letters, or hyphens.\n\ncreateToken('BUILDIDENTIFIER', `${LETTERDASHNUMBER}+`)\n\n// ## Build Metadata\n// Plus sign, followed by one or more period-separated build metadata\n// identifiers.\n\ncreateToken('BUILD', `(?:\\\\+(${src[t.BUILDIDENTIFIER]\n}(?:\\\\.${src[t.BUILDIDENTIFIER]})*))`)\n\n// ## Full Version String\n// A main version, followed optionally by a pre-release version and\n// build metadata.\n\n// Note that the only major, minor, patch, and pre-release sections of\n// the version string are capturing groups.  The build metadata is not a\n// capturing group, because it should not ever be used in version\n// comparison.\n\ncreateToken('FULLPLAIN', `v?${src[t.MAINVERSION]\n}${src[t.PRERELEASE]}?${\n  src[t.BUILD]}?`)\n\ncreateToken('FULL', `^${src[t.FULLPLAIN]}$`)\n\n// like full, but allows v1.2.3 and =1.2.3, which people do sometimes.\n// also, 1.0.0alpha1 (prerelease without the hyphen) which is pretty\n// common in the npm registry.\ncreateToken('LOOSEPLAIN', `[v=\\\\s]*${src[t.MAINVERSIONLOOSE]\n}${src[t.PRERELEASELOOSE]}?${\n  src[t.BUILD]}?`)\n\ncreateToken('LOOSE', `^${src[t.LOOSEPLAIN]}$`)\n\ncreateToken('GTLT', '((?:<|>)?=?)')\n\n// Something like \"2.*\" or \"1.2.x\".\n// Note that \"x.x\" is a valid xRange identifer, meaning \"any version\"\n// Only the first item is strictly required.\ncreateToken('XRANGEIDENTIFIERLOOSE', `${src[t.NUMERICIDENTIFIERLOOSE]}|x|X|\\\\*`)\ncreateToken('XRANGEIDENTIFIER', `${src[t.NUMERICIDENTIFIER]}|x|X|\\\\*`)\n\ncreateToken('XRANGEPLAIN', `[v=\\\\s]*(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:\\\\.(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:\\\\.(${src[t.XRANGEIDENTIFIER]})` +\n                   `(?:${src[t.PRERELEASE]})?${\n                     src[t.BUILD]}?` +\n                   `)?)?`)\n\ncreateToken('XRANGEPLAINLOOSE', `[v=\\\\s]*(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:\\\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:\\\\.(${src[t.XRANGEIDENTIFIERLOOSE]})` +\n                        `(?:${src[t.PRERELEASELOOSE]})?${\n                          src[t.BUILD]}?` +\n                        `)?)?`)\n\ncreateToken('XRANGE', `^${src[t.GTLT]}\\\\s*${src[t.XRANGEPLAIN]}$`)\ncreateToken('XRANGELOOSE', `^${src[t.GTLT]}\\\\s*${src[t.XRANGEPLAINLOOSE]}$`)\n\n// Coercion.\n// Extract anything that could conceivably be a part of a valid semver\ncreateToken('COERCEPLAIN', `${'(^|[^\\\\d])' +\n              '(\\\\d{1,'}${MAX_SAFE_COMPONENT_LENGTH}})` +\n              `(?:\\\\.(\\\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?` +\n              `(?:\\\\.(\\\\d{1,${MAX_SAFE_COMPONENT_LENGTH}}))?`)\ncreateToken('COERCE', `${src[t.COERCEPLAIN]}(?:$|[^\\\\d])`)\ncreateToken('COERCEFULL', src[t.COERCEPLAIN] +\n              `(?:${src[t.PRERELEASE]})?` +\n              `(?:${src[t.BUILD]})?` +\n              `(?:$|[^\\\\d])`)\ncreateToken('COERCERTL', src[t.COERCE], true)\ncreateToken('COERCERTLFULL', src[t.COERCEFULL], true)\n\n// Tilde ranges.\n// Meaning is \"reasonably at or greater than\"\ncreateToken('LONETILDE', '(?:~>?)')\n\ncreateToken('TILDETRIM', `(\\\\s*)${src[t.LONETILDE]}\\\\s+`, true)\nexports.tildeTrimReplace = '$1~'\n\ncreateToken('TILDE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAIN]}$`)\ncreateToken('TILDELOOSE', `^${src[t.LONETILDE]}${src[t.XRANGEPLAINLOOSE]}$`)\n\n// Caret ranges.\n// Meaning is \"at least and backwards compatible with\"\ncreateToken('LONECARET', '(?:\\\\^)')\n\ncreateToken('CARETTRIM', `(\\\\s*)${src[t.LONECARET]}\\\\s+`, true)\nexports.caretTrimReplace = '$1^'\n\ncreateToken('CARET', `^${src[t.LONECARET]}${src[t.XRANGEPLAIN]}$`)\ncreateToken('CARETLOOSE', `^${src[t.LONECARET]}${src[t.XRANGEPLAINLOOSE]}$`)\n\n// A simple gt/lt/eq thing, or just \"\" to indicate \"any version\"\ncreateToken('COMPARATORLOOSE', `^${src[t.GTLT]}\\\\s*(${src[t.LOOSEPLAIN]})$|^$`)\ncreateToken('COMPARATOR', `^${src[t.GTLT]}\\\\s*(${src[t.FULLPLAIN]})$|^$`)\n\n// An expression to strip any whitespace between the gtlt and the thing\n// it modifies, so that `> 1.2.3` ==> `>1.2.3`\ncreateToken('COMPARATORTRIM', `(\\\\s*)${src[t.GTLT]\n}\\\\s*(${src[t.LOOSEPLAIN]}|${src[t.XRANGEPLAIN]})`, true)\nexports.comparatorTrimReplace = '$1$2$3'\n\n// Something like `1.2.3 - 1.2.4`\n// Note that these all use the loose form, because they'll be\n// checked against either the strict or loose comparator form\n// later.\ncreateToken('HYPHENRANGE', `^\\\\s*(${src[t.XRANGEPLAIN]})` +\n                   `\\\\s+-\\\\s+` +\n                   `(${src[t.XRANGEPLAIN]})` +\n                   `\\\\s*$`)\n\ncreateToken('HYPHENRANGELOOSE', `^\\\\s*(${src[t.XRANGEPLAINLOOSE]})` +\n                        `\\\\s+-\\\\s+` +\n                        `(${src[t.XRANGEPLAINLOOSE]})` +\n                        `\\\\s*$`)\n\n// Star ranges basically just allow anything at all.\ncreateToken('STAR', '(<|>)?=?\\\\s*\\\\*')\n// >=0.0.0 is like a star\ncreateToken('GTE0', '^\\\\s*>=\\\\s*0\\\\.0\\\\.0\\\\s*$')\ncreateToken('GTE0PRE', '^\\\\s*>=\\\\s*0\\\\.0\\\\.0-0\\\\s*$')\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/internal/re.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/gtr.js":
/*!*******************************************!*\
  !*** ./node_modules/semver/ranges/gtr.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Determine if version is greater than all the versions possible in the range.\nconst outside = __webpack_require__(/*! ./outside */ \"./node_modules/semver/ranges/outside.js\")\nconst gtr = (version, range, options) => outside(version, range, '>', options)\nmodule.exports = gtr\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/gtr.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/intersects.js":
/*!**************************************************!*\
  !*** ./node_modules/semver/ranges/intersects.js ***!
  \**************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst intersects = (r1, r2, options) => {\n  r1 = new Range(r1, options)\n  r2 = new Range(r2, options)\n  return r1.intersects(r2, options)\n}\nmodule.exports = intersects\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/intersects.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/ltr.js":
/*!*******************************************!*\
  !*** ./node_modules/semver/ranges/ltr.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const outside = __webpack_require__(/*! ./outside */ \"./node_modules/semver/ranges/outside.js\")\n// Determine if version is less than all the versions possible in the range\nconst ltr = (version, range, options) => outside(version, range, '<', options)\nmodule.exports = ltr\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/ltr.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/max-satisfying.js":
/*!******************************************************!*\
  !*** ./node_modules/semver/ranges/max-satisfying.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\n\nconst maxSatisfying = (versions, range, options) => {\n  let max = null\n  let maxSV = null\n  let rangeObj = null\n  try {\n    rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach((v) => {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!max || maxSV.compare(v) === -1) {\n        // compare(max, v, true)\n        max = v\n        maxSV = new SemVer(max, options)\n      }\n    }\n  })\n  return max\n}\nmodule.exports = maxSatisfying\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/max-satisfying.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/min-satisfying.js":
/*!******************************************************!*\
  !*** ./node_modules/semver/ranges/min-satisfying.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst minSatisfying = (versions, range, options) => {\n  let min = null\n  let minSV = null\n  let rangeObj = null\n  try {\n    rangeObj = new Range(range, options)\n  } catch (er) {\n    return null\n  }\n  versions.forEach((v) => {\n    if (rangeObj.test(v)) {\n      // satisfies(v, range, options)\n      if (!min || minSV.compare(v) === 1) {\n        // compare(min, v, true)\n        min = v\n        minSV = new SemVer(min, options)\n      }\n    }\n  })\n  return min\n}\nmodule.exports = minSatisfying\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/min-satisfying.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/min-version.js":
/*!***************************************************!*\
  !*** ./node_modules/semver/ranges/min-version.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst gt = __webpack_require__(/*! ../functions/gt */ \"./node_modules/semver/functions/gt.js\")\n\nconst minVersion = (range, loose) => {\n  range = new Range(range, loose)\n\n  let minver = new SemVer('0.0.0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = new SemVer('0.0.0-0')\n  if (range.test(minver)) {\n    return minver\n  }\n\n  minver = null\n  for (let i = 0; i < range.set.length; ++i) {\n    const comparators = range.set[i]\n\n    let setMin = null\n    comparators.forEach((comparator) => {\n      // Clone to avoid manipulating the comparator's semver object.\n      const compver = new SemVer(comparator.semver.version)\n      switch (comparator.operator) {\n        case '>':\n          if (compver.prerelease.length === 0) {\n            compver.patch++\n          } else {\n            compver.prerelease.push(0)\n          }\n          compver.raw = compver.format()\n          /* fallthrough */\n        case '':\n        case '>=':\n          if (!setMin || gt(compver, setMin)) {\n            setMin = compver\n          }\n          break\n        case '<':\n        case '<=':\n          /* Ignore maximum versions */\n          break\n        /* istanbul ignore next */\n        default:\n          throw new Error(`Unexpected operation: ${comparator.operator}`)\n      }\n    })\n    if (setMin && (!minver || gt(minver, setMin))) {\n      minver = setMin\n    }\n  }\n\n  if (minver && range.test(minver)) {\n    return minver\n  }\n\n  return null\n}\nmodule.exports = minVersion\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/min-version.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/outside.js":
/*!***********************************************!*\
  !*** ./node_modules/semver/ranges/outside.js ***!
  \***********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const SemVer = __webpack_require__(/*! ../classes/semver */ \"./node_modules/semver/classes/semver.js\")\nconst Comparator = __webpack_require__(/*! ../classes/comparator */ \"./node_modules/semver/classes/comparator.js\")\nconst { ANY } = Comparator\nconst Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst satisfies = __webpack_require__(/*! ../functions/satisfies */ \"./node_modules/semver/functions/satisfies.js\")\nconst gt = __webpack_require__(/*! ../functions/gt */ \"./node_modules/semver/functions/gt.js\")\nconst lt = __webpack_require__(/*! ../functions/lt */ \"./node_modules/semver/functions/lt.js\")\nconst lte = __webpack_require__(/*! ../functions/lte */ \"./node_modules/semver/functions/lte.js\")\nconst gte = __webpack_require__(/*! ../functions/gte */ \"./node_modules/semver/functions/gte.js\")\n\nconst outside = (version, range, hilo, options) => {\n  version = new SemVer(version, options)\n  range = new Range(range, options)\n\n  let gtfn, ltefn, ltfn, comp, ecomp\n  switch (hilo) {\n    case '>':\n      gtfn = gt\n      ltefn = lte\n      ltfn = lt\n      comp = '>'\n      ecomp = '>='\n      break\n    case '<':\n      gtfn = lt\n      ltefn = gte\n      ltfn = gt\n      comp = '<'\n      ecomp = '<='\n      break\n    default:\n      throw new TypeError('Must provide a hilo val of \"<\" or \">\"')\n  }\n\n  // If it satisfies the range it is not outside\n  if (satisfies(version, range, options)) {\n    return false\n  }\n\n  // From now on, variable terms are as if we're in \"gtr\" mode.\n  // but note that everything is flipped for the \"ltr\" function.\n\n  for (let i = 0; i < range.set.length; ++i) {\n    const comparators = range.set[i]\n\n    let high = null\n    let low = null\n\n    comparators.forEach((comparator) => {\n      if (comparator.semver === ANY) {\n        comparator = new Comparator('>=0.0.0')\n      }\n      high = high || comparator\n      low = low || comparator\n      if (gtfn(comparator.semver, high.semver, options)) {\n        high = comparator\n      } else if (ltfn(comparator.semver, low.semver, options)) {\n        low = comparator\n      }\n    })\n\n    // If the edge version comparator has a operator then our version\n    // isn't outside it\n    if (high.operator === comp || high.operator === ecomp) {\n      return false\n    }\n\n    // If the lowest version comparator has an operator and our version\n    // is less than it then it isn't higher than the range\n    if ((!low.operator || low.operator === comp) &&\n        ltefn(version, low.semver)) {\n      return false\n    } else if (low.operator === ecomp && ltfn(version, low.semver)) {\n      return false\n    }\n  }\n  return true\n}\n\nmodule.exports = outside\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/outside.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/simplify.js":
/*!************************************************!*\
  !*** ./node_modules/semver/ranges/simplify.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// given a set of versions and a range, create a \"simplified\" range\n// that includes the same versions that the original range does\n// If the original range is shorter than the simplified one, return that.\nconst satisfies = __webpack_require__(/*! ../functions/satisfies.js */ \"./node_modules/semver/functions/satisfies.js\")\nconst compare = __webpack_require__(/*! ../functions/compare.js */ \"./node_modules/semver/functions/compare.js\")\nmodule.exports = (versions, range, options) => {\n  const set = []\n  let first = null\n  let prev = null\n  const v = versions.sort((a, b) => compare(a, b, options))\n  for (const version of v) {\n    const included = satisfies(version, range, options)\n    if (included) {\n      prev = version\n      if (!first) {\n        first = version\n      }\n    } else {\n      if (prev) {\n        set.push([first, prev])\n      }\n      prev = null\n      first = null\n    }\n  }\n  if (first) {\n    set.push([first, null])\n  }\n\n  const ranges = []\n  for (const [min, max] of set) {\n    if (min === max) {\n      ranges.push(min)\n    } else if (!max && min === v[0]) {\n      ranges.push('*')\n    } else if (!max) {\n      ranges.push(`>=${min}`)\n    } else if (min === v[0]) {\n      ranges.push(`<=${max}`)\n    } else {\n      ranges.push(`${min} - ${max}`)\n    }\n  }\n  const simplified = ranges.join(' || ')\n  const original = typeof range.raw === 'string' ? range.raw : String(range)\n  return simplified.length < original.length ? simplified : range\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/simplify.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/subset.js":
/*!**********************************************!*\
  !*** ./node_modules/semver/ranges/subset.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range.js */ \"./node_modules/semver/classes/range.js\")\nconst Comparator = __webpack_require__(/*! ../classes/comparator.js */ \"./node_modules/semver/classes/comparator.js\")\nconst { ANY } = Comparator\nconst satisfies = __webpack_require__(/*! ../functions/satisfies.js */ \"./node_modules/semver/functions/satisfies.js\")\nconst compare = __webpack_require__(/*! ../functions/compare.js */ \"./node_modules/semver/functions/compare.js\")\n\n// Complex range `r1 || r2 || ...` is a subset of `R1 || R2 || ...` iff:\n// - Every simple range `r1, r2, ...` is a null set, OR\n// - Every simple range `r1, r2, ...` which is not a null set is a subset of\n//   some `R1, R2, ...`\n//\n// Simple range `c1 c2 ...` is a subset of simple range `C1 C2 ...` iff:\n// - If c is only the ANY comparator\n//   - If C is only the ANY comparator, return true\n//   - Else if in prerelease mode, return false\n//   - else replace c with `[>=0.0.0]`\n// - If C is only the ANY comparator\n//   - if in prerelease mode, return true\n//   - else replace C with `[>=0.0.0]`\n// - Let EQ be the set of = comparators in c\n// - If EQ is more than one, return true (null set)\n// - Let GT be the highest > or >= comparator in c\n// - Let LT be the lowest < or <= comparator in c\n// - If GT and LT, and GT.semver > LT.semver, return true (null set)\n// - If any C is a = range, and GT or LT are set, return false\n// - If EQ\n//   - If GT, and EQ does not satisfy GT, return true (null set)\n//   - If LT, and EQ does not satisfy LT, return true (null set)\n//   - If EQ satisfies every C, return true\n//   - Else return false\n// - If GT\n//   - If GT.semver is lower than any > or >= comp in C, return false\n//   - If GT is >=, and GT.semver does not satisfy every C, return false\n//   - If GT.semver has a prerelease, and not in prerelease mode\n//     - If no C has a prerelease and the GT.semver tuple, return false\n// - If LT\n//   - If LT.semver is greater than any < or <= comp in C, return false\n//   - If LT is <=, and LT.semver does not satisfy every C, return false\n//   - If GT.semver has a prerelease, and not in prerelease mode\n//     - If no C has a prerelease and the LT.semver tuple, return false\n// - Else return true\n\nconst subset = (sub, dom, options = {}) => {\n  if (sub === dom) {\n    return true\n  }\n\n  sub = new Range(sub, options)\n  dom = new Range(dom, options)\n  let sawNonNull = false\n\n  OUTER: for (const simpleSub of sub.set) {\n    for (const simpleDom of dom.set) {\n      const isSub = simpleSubset(simpleSub, simpleDom, options)\n      sawNonNull = sawNonNull || isSub !== null\n      if (isSub) {\n        continue OUTER\n      }\n    }\n    // the null set is a subset of everything, but null simple ranges in\n    // a complex range should be ignored.  so if we saw a non-null range,\n    // then we know this isn't a subset, but if EVERY simple range was null,\n    // then it is a subset.\n    if (sawNonNull) {\n      return false\n    }\n  }\n  return true\n}\n\nconst minimumVersionWithPreRelease = [new Comparator('>=0.0.0-0')]\nconst minimumVersion = [new Comparator('>=0.0.0')]\n\nconst simpleSubset = (sub, dom, options) => {\n  if (sub === dom) {\n    return true\n  }\n\n  if (sub.length === 1 && sub[0].semver === ANY) {\n    if (dom.length === 1 && dom[0].semver === ANY) {\n      return true\n    } else if (options.includePrerelease) {\n      sub = minimumVersionWithPreRelease\n    } else {\n      sub = minimumVersion\n    }\n  }\n\n  if (dom.length === 1 && dom[0].semver === ANY) {\n    if (options.includePrerelease) {\n      return true\n    } else {\n      dom = minimumVersion\n    }\n  }\n\n  const eqSet = new Set()\n  let gt, lt\n  for (const c of sub) {\n    if (c.operator === '>' || c.operator === '>=') {\n      gt = higherGT(gt, c, options)\n    } else if (c.operator === '<' || c.operator === '<=') {\n      lt = lowerLT(lt, c, options)\n    } else {\n      eqSet.add(c.semver)\n    }\n  }\n\n  if (eqSet.size > 1) {\n    return null\n  }\n\n  let gtltComp\n  if (gt && lt) {\n    gtltComp = compare(gt.semver, lt.semver, options)\n    if (gtltComp > 0) {\n      return null\n    } else if (gtltComp === 0 && (gt.operator !== '>=' || lt.operator !== '<=')) {\n      return null\n    }\n  }\n\n  // will iterate one or zero times\n  for (const eq of eqSet) {\n    if (gt && !satisfies(eq, String(gt), options)) {\n      return null\n    }\n\n    if (lt && !satisfies(eq, String(lt), options)) {\n      return null\n    }\n\n    for (const c of dom) {\n      if (!satisfies(eq, String(c), options)) {\n        return false\n      }\n    }\n\n    return true\n  }\n\n  let higher, lower\n  let hasDomLT, hasDomGT\n  // if the subset has a prerelease, we need a comparator in the superset\n  // with the same tuple and a prerelease, or it's not a subset\n  let needDomLTPre = lt &&\n    !options.includePrerelease &&\n    lt.semver.prerelease.length ? lt.semver : false\n  let needDomGTPre = gt &&\n    !options.includePrerelease &&\n    gt.semver.prerelease.length ? gt.semver : false\n  // exception: <1.2.3-0 is the same as <1.2.3\n  if (needDomLTPre && needDomLTPre.prerelease.length === 1 &&\n      lt.operator === '<' && needDomLTPre.prerelease[0] === 0) {\n    needDomLTPre = false\n  }\n\n  for (const c of dom) {\n    hasDomGT = hasDomGT || c.operator === '>' || c.operator === '>='\n    hasDomLT = hasDomLT || c.operator === '<' || c.operator === '<='\n    if (gt) {\n      if (needDomGTPre) {\n        if (c.semver.prerelease && c.semver.prerelease.length &&\n            c.semver.major === needDomGTPre.major &&\n            c.semver.minor === needDomGTPre.minor &&\n            c.semver.patch === needDomGTPre.patch) {\n          needDomGTPre = false\n        }\n      }\n      if (c.operator === '>' || c.operator === '>=') {\n        higher = higherGT(gt, c, options)\n        if (higher === c && higher !== gt) {\n          return false\n        }\n      } else if (gt.operator === '>=' && !satisfies(gt.semver, String(c), options)) {\n        return false\n      }\n    }\n    if (lt) {\n      if (needDomLTPre) {\n        if (c.semver.prerelease && c.semver.prerelease.length &&\n            c.semver.major === needDomLTPre.major &&\n            c.semver.minor === needDomLTPre.minor &&\n            c.semver.patch === needDomLTPre.patch) {\n          needDomLTPre = false\n        }\n      }\n      if (c.operator === '<' || c.operator === '<=') {\n        lower = lowerLT(lt, c, options)\n        if (lower === c && lower !== lt) {\n          return false\n        }\n      } else if (lt.operator === '<=' && !satisfies(lt.semver, String(c), options)) {\n        return false\n      }\n    }\n    if (!c.operator && (lt || gt) && gtltComp !== 0) {\n      return false\n    }\n  }\n\n  // if there was a < or >, and nothing in the dom, then must be false\n  // UNLESS it was limited by another range in the other direction.\n  // Eg, >1.0.0 <1.0.1 is still a subset of <2.0.0\n  if (gt && hasDomLT && !lt && gtltComp !== 0) {\n    return false\n  }\n\n  if (lt && hasDomGT && !gt && gtltComp !== 0) {\n    return false\n  }\n\n  // we needed a prerelease range in a specific tuple, but didn't get one\n  // then this isn't a subset.  eg >=1.2.3-pre is not a subset of >=1.0.0,\n  // because it includes prereleases in the 1.2.3 tuple\n  if (needDomGTPre || needDomLTPre) {\n    return false\n  }\n\n  return true\n}\n\n// >=1.2.3 is lower than >1.2.3\nconst higherGT = (a, b, options) => {\n  if (!a) {\n    return b\n  }\n  const comp = compare(a.semver, b.semver, options)\n  return comp > 0 ? a\n    : comp < 0 ? b\n    : b.operator === '>' && a.operator === '>=' ? b\n    : a\n}\n\n// <=1.2.3 is higher than <1.2.3\nconst lowerLT = (a, b, options) => {\n  if (!a) {\n    return b\n  }\n  const comp = compare(a.semver, b.semver, options)\n  return comp < 0 ? a\n    : comp > 0 ? b\n    : b.operator === '<' && a.operator === '<=' ? b\n    : a\n}\n\nmodule.exports = subset\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/subset.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/to-comparators.js":
/*!******************************************************!*\
  !*** ./node_modules/semver/ranges/to-comparators.js ***!
  \******************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\n\n// Mostly just for testing and legacy API reasons\nconst toComparators = (range, options) =>\n  new Range(range, options).set\n    .map(comp => comp.map(c => c.value).join(' ').trim().split(' '))\n\nmodule.exports = toComparators\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/to-comparators.js?");

/***/ }),

/***/ "./node_modules/semver/ranges/valid.js":
/*!*********************************************!*\
  !*** ./node_modules/semver/ranges/valid.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const Range = __webpack_require__(/*! ../classes/range */ \"./node_modules/semver/classes/range.js\")\nconst validRange = (range, options) => {\n  try {\n    // Return '*' instead of '' so that truthiness works.\n    // This will throw if it's invalid anyway\n    return new Range(range, options).range || '*'\n  } catch (er) {\n    return null\n  }\n}\nmodule.exports = validRange\n\n\n//# sourceURL=webpack://thelambda/./node_modules/semver/ranges/valid.js?");

/***/ }),

/***/ "./node_modules/set-blocking/index.js":
/*!********************************************!*\
  !*** ./node_modules/set-blocking/index.js ***!
  \********************************************/
/***/ ((module) => {

eval("module.exports = function (blocking) {\n  [process.stdout, process.stderr].forEach(function (stream) {\n    if (stream._handle && stream.isTTY && typeof stream._handle.setBlocking === 'function') {\n      stream._handle.setBlocking(blocking)\n    }\n  })\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/set-blocking/index.js?");

/***/ }),

/***/ "./node_modules/set-function-length/index.js":
/*!***************************************************!*\
  !*** ./node_modules/set-function-length/index.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"./node_modules/get-intrinsic/index.js\");\nvar define = __webpack_require__(/*! define-data-property */ \"./node_modules/define-data-property/index.js\");\nvar hasDescriptors = __webpack_require__(/*! has-property-descriptors */ \"./node_modules/has-property-descriptors/index.js\")();\nvar gOPD = __webpack_require__(/*! gopd */ \"./node_modules/gopd/index.js\");\n\nvar $TypeError = __webpack_require__(/*! es-errors/type */ \"./node_modules/es-errors/type.js\");\nvar $floor = GetIntrinsic('%Math.floor%');\n\n/** @type {import('.')} */\nmodule.exports = function setFunctionLength(fn, length) {\n\tif (typeof fn !== 'function') {\n\t\tthrow new $TypeError('`fn` is not a function');\n\t}\n\tif (typeof length !== 'number' || length < 0 || length > 0xFFFFFFFF || $floor(length) !== length) {\n\t\tthrow new $TypeError('`length` must be a positive 32-bit integer');\n\t}\n\n\tvar loose = arguments.length > 2 && !!arguments[2];\n\n\tvar functionLengthIsConfigurable = true;\n\tvar functionLengthIsWritable = true;\n\tif ('length' in fn && gOPD) {\n\t\tvar desc = gOPD(fn, 'length');\n\t\tif (desc && !desc.configurable) {\n\t\t\tfunctionLengthIsConfigurable = false;\n\t\t}\n\t\tif (desc && !desc.writable) {\n\t\t\tfunctionLengthIsWritable = false;\n\t\t}\n\t}\n\n\tif (functionLengthIsConfigurable || functionLengthIsWritable || !loose) {\n\t\tif (hasDescriptors) {\n\t\t\tdefine(/** @type {Parameters<define>[0]} */ (fn), 'length', length, true, true);\n\t\t} else {\n\t\t\tdefine(/** @type {Parameters<define>[0]} */ (fn), 'length', length);\n\t\t}\n\t}\n\treturn fn;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/set-function-length/index.js?");

/***/ }),

/***/ "./node_modules/side-channel/index.js":
/*!********************************************!*\
  !*** ./node_modules/side-channel/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar GetIntrinsic = __webpack_require__(/*! get-intrinsic */ \"./node_modules/get-intrinsic/index.js\");\nvar callBound = __webpack_require__(/*! call-bind/callBound */ \"./node_modules/call-bind/callBound.js\");\nvar inspect = __webpack_require__(/*! object-inspect */ \"./node_modules/object-inspect/index.js\");\n\nvar $TypeError = __webpack_require__(/*! es-errors/type */ \"./node_modules/es-errors/type.js\");\nvar $WeakMap = GetIntrinsic('%WeakMap%', true);\nvar $Map = GetIntrinsic('%Map%', true);\n\nvar $weakMapGet = callBound('WeakMap.prototype.get', true);\nvar $weakMapSet = callBound('WeakMap.prototype.set', true);\nvar $weakMapHas = callBound('WeakMap.prototype.has', true);\nvar $mapGet = callBound('Map.prototype.get', true);\nvar $mapSet = callBound('Map.prototype.set', true);\nvar $mapHas = callBound('Map.prototype.has', true);\n\n/*\n* This function traverses the list returning the node corresponding to the given key.\n*\n* That node is also moved to the head of the list, so that if it's accessed again we don't need to traverse the whole list. By doing so, all the recently used nodes can be accessed relatively quickly.\n*/\n/** @type {import('.').listGetNode} */\nvar listGetNode = function (list, key) { // eslint-disable-line consistent-return\n\t/** @type {typeof list | NonNullable<(typeof list)['next']>} */\n\tvar prev = list;\n\t/** @type {(typeof list)['next']} */\n\tvar curr;\n\tfor (; (curr = prev.next) !== null; prev = curr) {\n\t\tif (curr.key === key) {\n\t\t\tprev.next = curr.next;\n\t\t\t// eslint-disable-next-line no-extra-parens\n\t\t\tcurr.next = /** @type {NonNullable<typeof list.next>} */ (list.next);\n\t\t\tlist.next = curr; // eslint-disable-line no-param-reassign\n\t\t\treturn curr;\n\t\t}\n\t}\n};\n\n/** @type {import('.').listGet} */\nvar listGet = function (objects, key) {\n\tvar node = listGetNode(objects, key);\n\treturn node && node.value;\n};\n/** @type {import('.').listSet} */\nvar listSet = function (objects, key, value) {\n\tvar node = listGetNode(objects, key);\n\tif (node) {\n\t\tnode.value = value;\n\t} else {\n\t\t// Prepend the new node to the beginning of the list\n\t\tobjects.next = /** @type {import('.').ListNode<typeof value>} */ ({ // eslint-disable-line no-param-reassign, no-extra-parens\n\t\t\tkey: key,\n\t\t\tnext: objects.next,\n\t\t\tvalue: value\n\t\t});\n\t}\n};\n/** @type {import('.').listHas} */\nvar listHas = function (objects, key) {\n\treturn !!listGetNode(objects, key);\n};\n\n/** @type {import('.')} */\nmodule.exports = function getSideChannel() {\n\t/** @type {WeakMap<object, unknown>} */ var $wm;\n\t/** @type {Map<object, unknown>} */ var $m;\n\t/** @type {import('.').RootNode<unknown>} */ var $o;\n\n\t/** @type {import('.').Channel} */\n\tvar channel = {\n\t\tassert: function (key) {\n\t\t\tif (!channel.has(key)) {\n\t\t\t\tthrow new $TypeError('Side channel does not contain ' + inspect(key));\n\t\t\t}\n\t\t},\n\t\tget: function (key) { // eslint-disable-line consistent-return\n\t\t\tif ($WeakMap && key && (typeof key === 'object' || typeof key === 'function')) {\n\t\t\t\tif ($wm) {\n\t\t\t\t\treturn $weakMapGet($wm, key);\n\t\t\t\t}\n\t\t\t} else if ($Map) {\n\t\t\t\tif ($m) {\n\t\t\t\t\treturn $mapGet($m, key);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif ($o) { // eslint-disable-line no-lonely-if\n\t\t\t\t\treturn listGet($o, key);\n\t\t\t\t}\n\t\t\t}\n\t\t},\n\t\thas: function (key) {\n\t\t\tif ($WeakMap && key && (typeof key === 'object' || typeof key === 'function')) {\n\t\t\t\tif ($wm) {\n\t\t\t\t\treturn $weakMapHas($wm, key);\n\t\t\t\t}\n\t\t\t} else if ($Map) {\n\t\t\t\tif ($m) {\n\t\t\t\t\treturn $mapHas($m, key);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tif ($o) { // eslint-disable-line no-lonely-if\n\t\t\t\t\treturn listHas($o, key);\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false;\n\t\t},\n\t\tset: function (key, value) {\n\t\t\tif ($WeakMap && key && (typeof key === 'object' || typeof key === 'function')) {\n\t\t\t\tif (!$wm) {\n\t\t\t\t\t$wm = new $WeakMap();\n\t\t\t\t}\n\t\t\t\t$weakMapSet($wm, key, value);\n\t\t\t} else if ($Map) {\n\t\t\t\tif (!$m) {\n\t\t\t\t\t$m = new $Map();\n\t\t\t\t}\n\t\t\t\t$mapSet($m, key, value);\n\t\t\t} else {\n\t\t\t\tif (!$o) {\n\t\t\t\t\t// Initialize the linked list as an empty node, so that we don't have to special-case handling of the first node: we can always refer to it as (previous node).next, instead of something like (list).head\n\t\t\t\t\t$o = { key: {}, next: null };\n\t\t\t\t}\n\t\t\t\tlistSet($o, key, value);\n\t\t\t}\n\t\t}\n\t};\n\treturn channel;\n};\n\n\n//# sourceURL=webpack://thelambda/./node_modules/side-channel/index.js?");

/***/ }),

/***/ "./node_modules/signal-exit/index.js":
/*!*******************************************!*\
  !*** ./node_modules/signal-exit/index.js ***!
  \*******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Note: since nyc uses this module to output coverage, any lines\n// that are in the direct sync flow of nyc's outputCoverage are\n// ignored, since we can never get coverage for them.\n// grab a reference to node's real process object right away\nvar process = __webpack_require__.g.process\n\nconst processOk = function (process) {\n  return process &&\n    typeof process === 'object' &&\n    typeof process.removeListener === 'function' &&\n    typeof process.emit === 'function' &&\n    typeof process.reallyExit === 'function' &&\n    typeof process.listeners === 'function' &&\n    typeof process.kill === 'function' &&\n    typeof process.pid === 'number' &&\n    typeof process.on === 'function'\n}\n\n// some kind of non-node environment, just no-op\n/* istanbul ignore if */\nif (!processOk(process)) {\n  module.exports = function () {\n    return function () {}\n  }\n} else {\n  var assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\n  var signals = __webpack_require__(/*! ./signals.js */ \"./node_modules/signal-exit/signals.js\")\n  var isWin = /^win/i.test(process.platform)\n\n  var EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\n  /* istanbul ignore if */\n  if (typeof EE !== 'function') {\n    EE = EE.EventEmitter\n  }\n\n  var emitter\n  if (process.__signal_exit_emitter__) {\n    emitter = process.__signal_exit_emitter__\n  } else {\n    emitter = process.__signal_exit_emitter__ = new EE()\n    emitter.count = 0\n    emitter.emitted = {}\n  }\n\n  // Because this emitter is a global, we have to check to see if a\n  // previous version of this library failed to enable infinite listeners.\n  // I know what you're about to say.  But literally everything about\n  // signal-exit is a compromise with evil.  Get used to it.\n  if (!emitter.infinite) {\n    emitter.setMaxListeners(Infinity)\n    emitter.infinite = true\n  }\n\n  module.exports = function (cb, opts) {\n    /* istanbul ignore if */\n    if (!processOk(__webpack_require__.g.process)) {\n      return function () {}\n    }\n    assert.equal(typeof cb, 'function', 'a callback must be provided for exit handler')\n\n    if (loaded === false) {\n      load()\n    }\n\n    var ev = 'exit'\n    if (opts && opts.alwaysLast) {\n      ev = 'afterexit'\n    }\n\n    var remove = function () {\n      emitter.removeListener(ev, cb)\n      if (emitter.listeners('exit').length === 0 &&\n          emitter.listeners('afterexit').length === 0) {\n        unload()\n      }\n    }\n    emitter.on(ev, cb)\n\n    return remove\n  }\n\n  var unload = function unload () {\n    if (!loaded || !processOk(__webpack_require__.g.process)) {\n      return\n    }\n    loaded = false\n\n    signals.forEach(function (sig) {\n      try {\n        process.removeListener(sig, sigListeners[sig])\n      } catch (er) {}\n    })\n    process.emit = originalProcessEmit\n    process.reallyExit = originalProcessReallyExit\n    emitter.count -= 1\n  }\n  module.exports.unload = unload\n\n  var emit = function emit (event, code, signal) {\n    /* istanbul ignore if */\n    if (emitter.emitted[event]) {\n      return\n    }\n    emitter.emitted[event] = true\n    emitter.emit(event, code, signal)\n  }\n\n  // { <signal>: <listener fn>, ... }\n  var sigListeners = {}\n  signals.forEach(function (sig) {\n    sigListeners[sig] = function listener () {\n      /* istanbul ignore if */\n      if (!processOk(__webpack_require__.g.process)) {\n        return\n      }\n      // If there are no other listeners, an exit is coming!\n      // Simplest way: remove us and then re-send the signal.\n      // We know that this will kill the process, so we can\n      // safely emit now.\n      var listeners = process.listeners(sig)\n      if (listeners.length === emitter.count) {\n        unload()\n        emit('exit', null, sig)\n        /* istanbul ignore next */\n        emit('afterexit', null, sig)\n        /* istanbul ignore next */\n        if (isWin && sig === 'SIGHUP') {\n          // \"SIGHUP\" throws an `ENOSYS` error on Windows,\n          // so use a supported signal instead\n          sig = 'SIGINT'\n        }\n        /* istanbul ignore next */\n        process.kill(process.pid, sig)\n      }\n    }\n  })\n\n  module.exports.signals = function () {\n    return signals\n  }\n\n  var loaded = false\n\n  var load = function load () {\n    if (loaded || !processOk(__webpack_require__.g.process)) {\n      return\n    }\n    loaded = true\n\n    // This is the number of onSignalExit's that are in play.\n    // It's important so that we can count the correct number of\n    // listeners on signals, and don't wait for the other one to\n    // handle it instead of us.\n    emitter.count += 1\n\n    signals = signals.filter(function (sig) {\n      try {\n        process.on(sig, sigListeners[sig])\n        return true\n      } catch (er) {\n        return false\n      }\n    })\n\n    process.emit = processEmit\n    process.reallyExit = processReallyExit\n  }\n  module.exports.load = load\n\n  var originalProcessReallyExit = process.reallyExit\n  var processReallyExit = function processReallyExit (code) {\n    /* istanbul ignore if */\n    if (!processOk(__webpack_require__.g.process)) {\n      return\n    }\n    process.exitCode = code || /* istanbul ignore next */ 0\n    emit('exit', process.exitCode, null)\n    /* istanbul ignore next */\n    emit('afterexit', process.exitCode, null)\n    /* istanbul ignore next */\n    originalProcessReallyExit.call(process, process.exitCode)\n  }\n\n  var originalProcessEmit = process.emit\n  var processEmit = function processEmit (ev, arg) {\n    if (ev === 'exit' && processOk(__webpack_require__.g.process)) {\n      /* istanbul ignore else */\n      if (arg !== undefined) {\n        process.exitCode = arg\n      }\n      var ret = originalProcessEmit.apply(this, arguments)\n      /* istanbul ignore next */\n      emit('exit', process.exitCode, null)\n      /* istanbul ignore next */\n      emit('afterexit', process.exitCode, null)\n      /* istanbul ignore next */\n      return ret\n    } else {\n      return originalProcessEmit.apply(this, arguments)\n    }\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/signal-exit/index.js?");

/***/ }),

/***/ "./node_modules/signal-exit/signals.js":
/*!*********************************************!*\
  !*** ./node_modules/signal-exit/signals.js ***!
  \*********************************************/
/***/ ((module) => {

eval("// This is not the set of all possible signals.\n//\n// It IS, however, the set of all signals that trigger\n// an exit on either Linux or BSD systems.  Linux is a\n// superset of the signal names supported on BSD, and\n// the unknown signals just fail to register, so we can\n// catch that easily enough.\n//\n// Don't bother with SIGKILL.  It's uncatchable, which\n// means that we can't fire any callbacks anyway.\n//\n// If a user does happen to register a handler on a non-\n// fatal signal like SIGWINCH or something, and then\n// exit, it'll end up firing `process.emit('exit')`, so\n// the handler will be fired anyway.\n//\n// SIGBUS, SIGFPE, SIGSEGV and SIGILL, when not raised\n// artificially, inherently leave the process in a\n// state from which it is not safe to try and enter JS\n// listeners.\nmodule.exports = [\n  'SIGABRT',\n  'SIGALRM',\n  'SIGHUP',\n  'SIGINT',\n  'SIGTERM'\n]\n\nif (process.platform !== 'win32') {\n  module.exports.push(\n    'SIGVTALRM',\n    'SIGXCPU',\n    'SIGXFSZ',\n    'SIGUSR2',\n    'SIGTRAP',\n    'SIGSYS',\n    'SIGQUIT',\n    'SIGIOT'\n    // should detect profiler and enable/disable accordingly.\n    // see #21\n    // 'SIGPROF'\n  )\n}\n\nif (process.platform === 'linux') {\n  module.exports.push(\n    'SIGIO',\n    'SIGPOLL',\n    'SIGPWR',\n    'SIGSTKFLT',\n    'SIGUNUSED'\n  )\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/signal-exit/signals.js?");

/***/ }),

/***/ "./node_modules/string-width/index.js":
/*!********************************************!*\
  !*** ./node_modules/string-width/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst stripAnsi = __webpack_require__(/*! strip-ansi */ \"./node_modules/strip-ansi/index.js\");\nconst isFullwidthCodePoint = __webpack_require__(/*! is-fullwidth-code-point */ \"./node_modules/is-fullwidth-code-point/index.js\");\nconst emojiRegex = __webpack_require__(/*! emoji-regex */ \"./node_modules/emoji-regex/index.js\");\n\nconst stringWidth = string => {\n\tif (typeof string !== 'string' || string.length === 0) {\n\t\treturn 0;\n\t}\n\n\tstring = stripAnsi(string);\n\n\tif (string.length === 0) {\n\t\treturn 0;\n\t}\n\n\tstring = string.replace(emojiRegex(), '  ');\n\n\tlet width = 0;\n\n\tfor (let i = 0; i < string.length; i++) {\n\t\tconst code = string.codePointAt(i);\n\n\t\t// Ignore control characters\n\t\tif (code <= 0x1F || (code >= 0x7F && code <= 0x9F)) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Ignore combining characters\n\t\tif (code >= 0x300 && code <= 0x36F) {\n\t\t\tcontinue;\n\t\t}\n\n\t\t// Surrogates\n\t\tif (code > 0xFFFF) {\n\t\t\ti++;\n\t\t}\n\n\t\twidth += isFullwidthCodePoint(code) ? 2 : 1;\n\t}\n\n\treturn width;\n};\n\nmodule.exports = stringWidth;\n// TODO: remove this in the next major version\nmodule.exports[\"default\"] = stringWidth;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/string-width/index.js?");

/***/ }),

/***/ "./node_modules/string_decoder/lib/string_decoder.js":
/*!***********************************************************!*\
  !*** ./node_modules/string_decoder/lib/string_decoder.js ***!
  \***********************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n/*<replacement>*/\n\nvar Buffer = (__webpack_require__(/*! safe-buffer */ \"./node_modules/safe-buffer/index.js\").Buffer);\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}\n\n//# sourceURL=webpack://thelambda/./node_modules/string_decoder/lib/string_decoder.js?");

/***/ }),

/***/ "./node_modules/strip-ansi/index.js":
/*!******************************************!*\
  !*** ./node_modules/strip-ansi/index.js ***!
  \******************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst ansiRegex = __webpack_require__(/*! ansi-regex */ \"./node_modules/ansi-regex/index.js\");\n\nmodule.exports = string => typeof string === 'string' ? string.replace(ansiRegex(), '') : string;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/strip-ansi/index.js?");

/***/ }),

/***/ "./node_modules/tar/index.js":
/*!***********************************!*\
  !*** ./node_modules/tar/index.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\n\n// high-level commands\nexports.c = exports.create = __webpack_require__(/*! ./lib/create.js */ \"./node_modules/tar/lib/create.js\")\nexports.r = exports.replace = __webpack_require__(/*! ./lib/replace.js */ \"./node_modules/tar/lib/replace.js\")\nexports.t = exports.list = __webpack_require__(/*! ./lib/list.js */ \"./node_modules/tar/lib/list.js\")\nexports.u = exports.update = __webpack_require__(/*! ./lib/update.js */ \"./node_modules/tar/lib/update.js\")\nexports.x = exports.extract = __webpack_require__(/*! ./lib/extract.js */ \"./node_modules/tar/lib/extract.js\")\n\n// classes\nexports.Pack = __webpack_require__(/*! ./lib/pack.js */ \"./node_modules/tar/lib/pack.js\")\nexports.Unpack = __webpack_require__(/*! ./lib/unpack.js */ \"./node_modules/tar/lib/unpack.js\")\nexports.Parse = __webpack_require__(/*! ./lib/parse.js */ \"./node_modules/tar/lib/parse.js\")\nexports.ReadEntry = __webpack_require__(/*! ./lib/read-entry.js */ \"./node_modules/tar/lib/read-entry.js\")\nexports.WriteEntry = __webpack_require__(/*! ./lib/write-entry.js */ \"./node_modules/tar/lib/write-entry.js\")\nexports.Header = __webpack_require__(/*! ./lib/header.js */ \"./node_modules/tar/lib/header.js\")\nexports.Pax = __webpack_require__(/*! ./lib/pax.js */ \"./node_modules/tar/lib/pax.js\")\nexports.types = __webpack_require__(/*! ./lib/types.js */ \"./node_modules/tar/lib/types.js\")\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/index.js?");

/***/ }),

/***/ "./node_modules/tar/lib/create.js":
/*!****************************************!*\
  !*** ./node_modules/tar/lib/create.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// tar -c\nconst hlo = __webpack_require__(/*! ./high-level-opt.js */ \"./node_modules/tar/lib/high-level-opt.js\")\n\nconst Pack = __webpack_require__(/*! ./pack.js */ \"./node_modules/tar/lib/pack.js\")\nconst fsm = __webpack_require__(/*! fs-minipass */ \"./node_modules/fs-minipass/index.js\")\nconst t = __webpack_require__(/*! ./list.js */ \"./node_modules/tar/lib/list.js\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\nmodule.exports = (opt_, files, cb) => {\n  if (typeof files === 'function') {\n    cb = files\n  }\n\n  if (Array.isArray(opt_)) {\n    files = opt_, opt_ = {}\n  }\n\n  if (!files || !Array.isArray(files) || !files.length) {\n    throw new TypeError('no files or directories specified')\n  }\n\n  files = Array.from(files)\n\n  const opt = hlo(opt_)\n\n  if (opt.sync && typeof cb === 'function') {\n    throw new TypeError('callback not supported for sync tar functions')\n  }\n\n  if (!opt.file && typeof cb === 'function') {\n    throw new TypeError('callback only supported with file option')\n  }\n\n  return opt.file && opt.sync ? createFileSync(opt, files)\n    : opt.file ? createFile(opt, files, cb)\n    : opt.sync ? createSync(opt, files)\n    : create(opt, files)\n}\n\nconst createFileSync = (opt, files) => {\n  const p = new Pack.Sync(opt)\n  const stream = new fsm.WriteStreamSync(opt.file, {\n    mode: opt.mode || 0o666,\n  })\n  p.pipe(stream)\n  addFilesSync(p, files)\n}\n\nconst createFile = (opt, files, cb) => {\n  const p = new Pack(opt)\n  const stream = new fsm.WriteStream(opt.file, {\n    mode: opt.mode || 0o666,\n  })\n  p.pipe(stream)\n\n  const promise = new Promise((res, rej) => {\n    stream.on('error', rej)\n    stream.on('close', res)\n    p.on('error', rej)\n  })\n\n  addFilesAsync(p, files)\n\n  return cb ? promise.then(cb, cb) : promise\n}\n\nconst addFilesSync = (p, files) => {\n  files.forEach(file => {\n    if (file.charAt(0) === '@') {\n      t({\n        file: path.resolve(p.cwd, file.slice(1)),\n        sync: true,\n        noResume: true,\n        onentry: entry => p.add(entry),\n      })\n    } else {\n      p.add(file)\n    }\n  })\n  p.end()\n}\n\nconst addFilesAsync = (p, files) => {\n  while (files.length) {\n    const file = files.shift()\n    if (file.charAt(0) === '@') {\n      return t({\n        file: path.resolve(p.cwd, file.slice(1)),\n        noResume: true,\n        onentry: entry => p.add(entry),\n      }).then(_ => addFilesAsync(p, files))\n    } else {\n      p.add(file)\n    }\n  }\n  p.end()\n}\n\nconst createSync = (opt, files) => {\n  const p = new Pack.Sync(opt)\n  addFilesSync(p, files)\n  return p\n}\n\nconst create = (opt, files) => {\n  const p = new Pack(opt)\n  addFilesAsync(p, files)\n  return p\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/create.js?");

/***/ }),

/***/ "./node_modules/tar/lib/extract.js":
/*!*****************************************!*\
  !*** ./node_modules/tar/lib/extract.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// tar -x\nconst hlo = __webpack_require__(/*! ./high-level-opt.js */ \"./node_modules/tar/lib/high-level-opt.js\")\nconst Unpack = __webpack_require__(/*! ./unpack.js */ \"./node_modules/tar/lib/unpack.js\")\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst fsm = __webpack_require__(/*! fs-minipass */ \"./node_modules/fs-minipass/index.js\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst stripSlash = __webpack_require__(/*! ./strip-trailing-slashes.js */ \"./node_modules/tar/lib/strip-trailing-slashes.js\")\n\nmodule.exports = (opt_, files, cb) => {\n  if (typeof opt_ === 'function') {\n    cb = opt_, files = null, opt_ = {}\n  } else if (Array.isArray(opt_)) {\n    files = opt_, opt_ = {}\n  }\n\n  if (typeof files === 'function') {\n    cb = files, files = null\n  }\n\n  if (!files) {\n    files = []\n  } else {\n    files = Array.from(files)\n  }\n\n  const opt = hlo(opt_)\n\n  if (opt.sync && typeof cb === 'function') {\n    throw new TypeError('callback not supported for sync tar functions')\n  }\n\n  if (!opt.file && typeof cb === 'function') {\n    throw new TypeError('callback only supported with file option')\n  }\n\n  if (files.length) {\n    filesFilter(opt, files)\n  }\n\n  return opt.file && opt.sync ? extractFileSync(opt)\n    : opt.file ? extractFile(opt, cb)\n    : opt.sync ? extractSync(opt)\n    : extract(opt)\n}\n\n// construct a filter that limits the file entries listed\n// include child entries if a dir is included\nconst filesFilter = (opt, files) => {\n  const map = new Map(files.map(f => [stripSlash(f), true]))\n  const filter = opt.filter\n\n  const mapHas = (file, r) => {\n    const root = r || path.parse(file).root || '.'\n    const ret = file === root ? false\n      : map.has(file) ? map.get(file)\n      : mapHas(path.dirname(file), root)\n\n    map.set(file, ret)\n    return ret\n  }\n\n  opt.filter = filter\n    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))\n    : file => mapHas(stripSlash(file))\n}\n\nconst extractFileSync = opt => {\n  const u = new Unpack.Sync(opt)\n\n  const file = opt.file\n  const stat = fs.statSync(file)\n  // This trades a zero-byte read() syscall for a stat\n  // However, it will usually result in less memory allocation\n  const readSize = opt.maxReadSize || 16 * 1024 * 1024\n  const stream = new fsm.ReadStreamSync(file, {\n    readSize: readSize,\n    size: stat.size,\n  })\n  stream.pipe(u)\n}\n\nconst extractFile = (opt, cb) => {\n  const u = new Unpack(opt)\n  const readSize = opt.maxReadSize || 16 * 1024 * 1024\n\n  const file = opt.file\n  const p = new Promise((resolve, reject) => {\n    u.on('error', reject)\n    u.on('close', resolve)\n\n    // This trades a zero-byte read() syscall for a stat\n    // However, it will usually result in less memory allocation\n    fs.stat(file, (er, stat) => {\n      if (er) {\n        reject(er)\n      } else {\n        const stream = new fsm.ReadStream(file, {\n          readSize: readSize,\n          size: stat.size,\n        })\n        stream.on('error', reject)\n        stream.pipe(u)\n      }\n    })\n  })\n  return cb ? p.then(cb, cb) : p\n}\n\nconst extractSync = opt => new Unpack.Sync(opt)\n\nconst extract = opt => new Unpack(opt)\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/extract.js?");

/***/ }),

/***/ "./node_modules/tar/lib/get-write-flag.js":
/*!************************************************!*\
  !*** ./node_modules/tar/lib/get-write-flag.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// Get the appropriate flag to use for creating files\n// We use fmap on Windows platforms for files less than\n// 512kb.  This is a fairly low limit, but avoids making\n// things slower in some cases.  Since most of what this\n// library is used for is extracting tarballs of many\n// relatively small files in npm packages and the like,\n// it can be a big boost on Windows platforms.\n// Only supported in Node v12.9.0 and above.\nconst platform = process.env.__FAKE_PLATFORM__ || process.platform\nconst isWindows = platform === 'win32'\nconst fs = __webpack_require__.g.__FAKE_TESTING_FS__ || __webpack_require__(/*! fs */ \"?fde7\")\n\n/* istanbul ignore next */\nconst { O_CREAT, O_TRUNC, O_WRONLY, UV_FS_O_FILEMAP = 0 } = fs.constants\n\nconst fMapEnabled = isWindows && !!UV_FS_O_FILEMAP\nconst fMapLimit = 512 * 1024\nconst fMapFlag = UV_FS_O_FILEMAP | O_TRUNC | O_CREAT | O_WRONLY\nmodule.exports = !fMapEnabled ? () => 'w'\n  : size => size < fMapLimit ? fMapFlag : 'w'\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/get-write-flag.js?");

/***/ }),

/***/ "./node_modules/tar/lib/header.js":
/*!****************************************!*\
  !*** ./node_modules/tar/lib/header.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n// parse a 512-byte header block to a data object, or vice-versa\n// encode returns `true` if a pax extended header is needed, because\n// the data could not be faithfully encoded in a simple header.\n// (Also, check header.needPax to see if it needs a pax header.)\n\nconst types = __webpack_require__(/*! ./types.js */ \"./node_modules/tar/lib/types.js\")\nconst pathModule = (__webpack_require__(/*! path */ \"./node_modules/path/path.js\").posix)\nconst large = __webpack_require__(/*! ./large-numbers.js */ \"./node_modules/tar/lib/large-numbers.js\")\n\nconst SLURP = Symbol('slurp')\nconst TYPE = Symbol('type')\n\nclass Header {\n  constructor (data, off, ex, gex) {\n    this.cksumValid = false\n    this.needPax = false\n    this.nullBlock = false\n\n    this.block = null\n    this.path = null\n    this.mode = null\n    this.uid = null\n    this.gid = null\n    this.size = null\n    this.mtime = null\n    this.cksum = null\n    this[TYPE] = '0'\n    this.linkpath = null\n    this.uname = null\n    this.gname = null\n    this.devmaj = 0\n    this.devmin = 0\n    this.atime = null\n    this.ctime = null\n\n    if (Buffer.isBuffer(data)) {\n      this.decode(data, off || 0, ex, gex)\n    } else if (data) {\n      this.set(data)\n    }\n  }\n\n  decode (buf, off, ex, gex) {\n    if (!off) {\n      off = 0\n    }\n\n    if (!buf || !(buf.length >= off + 512)) {\n      throw new Error('need 512 bytes for header')\n    }\n\n    this.path = decString(buf, off, 100)\n    this.mode = decNumber(buf, off + 100, 8)\n    this.uid = decNumber(buf, off + 108, 8)\n    this.gid = decNumber(buf, off + 116, 8)\n    this.size = decNumber(buf, off + 124, 12)\n    this.mtime = decDate(buf, off + 136, 12)\n    this.cksum = decNumber(buf, off + 148, 12)\n\n    // if we have extended or global extended headers, apply them now\n    // See https://github.com/npm/node-tar/pull/187\n    this[SLURP](ex)\n    this[SLURP](gex, true)\n\n    // old tar versions marked dirs as a file with a trailing /\n    this[TYPE] = decString(buf, off + 156, 1)\n    if (this[TYPE] === '') {\n      this[TYPE] = '0'\n    }\n    if (this[TYPE] === '0' && this.path.slice(-1) === '/') {\n      this[TYPE] = '5'\n    }\n\n    // tar implementations sometimes incorrectly put the stat(dir).size\n    // as the size in the tarball, even though Directory entries are\n    // not able to have any body at all.  In the very rare chance that\n    // it actually DOES have a body, we weren't going to do anything with\n    // it anyway, and it'll just be a warning about an invalid header.\n    if (this[TYPE] === '5') {\n      this.size = 0\n    }\n\n    this.linkpath = decString(buf, off + 157, 100)\n    if (buf.slice(off + 257, off + 265).toString() === 'ustar\\u000000') {\n      this.uname = decString(buf, off + 265, 32)\n      this.gname = decString(buf, off + 297, 32)\n      this.devmaj = decNumber(buf, off + 329, 8)\n      this.devmin = decNumber(buf, off + 337, 8)\n      if (buf[off + 475] !== 0) {\n        // definitely a prefix, definitely >130 chars.\n        const prefix = decString(buf, off + 345, 155)\n        this.path = prefix + '/' + this.path\n      } else {\n        const prefix = decString(buf, off + 345, 130)\n        if (prefix) {\n          this.path = prefix + '/' + this.path\n        }\n        this.atime = decDate(buf, off + 476, 12)\n        this.ctime = decDate(buf, off + 488, 12)\n      }\n    }\n\n    let sum = 8 * 0x20\n    for (let i = off; i < off + 148; i++) {\n      sum += buf[i]\n    }\n\n    for (let i = off + 156; i < off + 512; i++) {\n      sum += buf[i]\n    }\n\n    this.cksumValid = sum === this.cksum\n    if (this.cksum === null && sum === 8 * 0x20) {\n      this.nullBlock = true\n    }\n  }\n\n  [SLURP] (ex, global) {\n    for (const k in ex) {\n      // we slurp in everything except for the path attribute in\n      // a global extended header, because that's weird.\n      if (ex[k] !== null && ex[k] !== undefined &&\n          !(global && k === 'path')) {\n        this[k] = ex[k]\n      }\n    }\n  }\n\n  encode (buf, off) {\n    if (!buf) {\n      buf = this.block = Buffer.alloc(512)\n      off = 0\n    }\n\n    if (!off) {\n      off = 0\n    }\n\n    if (!(buf.length >= off + 512)) {\n      throw new Error('need 512 bytes for header')\n    }\n\n    const prefixSize = this.ctime || this.atime ? 130 : 155\n    const split = splitPrefix(this.path || '', prefixSize)\n    const path = split[0]\n    const prefix = split[1]\n    this.needPax = split[2]\n\n    this.needPax = encString(buf, off, 100, path) || this.needPax\n    this.needPax = encNumber(buf, off + 100, 8, this.mode) || this.needPax\n    this.needPax = encNumber(buf, off + 108, 8, this.uid) || this.needPax\n    this.needPax = encNumber(buf, off + 116, 8, this.gid) || this.needPax\n    this.needPax = encNumber(buf, off + 124, 12, this.size) || this.needPax\n    this.needPax = encDate(buf, off + 136, 12, this.mtime) || this.needPax\n    buf[off + 156] = this[TYPE].charCodeAt(0)\n    this.needPax = encString(buf, off + 157, 100, this.linkpath) || this.needPax\n    buf.write('ustar\\u000000', off + 257, 8)\n    this.needPax = encString(buf, off + 265, 32, this.uname) || this.needPax\n    this.needPax = encString(buf, off + 297, 32, this.gname) || this.needPax\n    this.needPax = encNumber(buf, off + 329, 8, this.devmaj) || this.needPax\n    this.needPax = encNumber(buf, off + 337, 8, this.devmin) || this.needPax\n    this.needPax = encString(buf, off + 345, prefixSize, prefix) || this.needPax\n    if (buf[off + 475] !== 0) {\n      this.needPax = encString(buf, off + 345, 155, prefix) || this.needPax\n    } else {\n      this.needPax = encString(buf, off + 345, 130, prefix) || this.needPax\n      this.needPax = encDate(buf, off + 476, 12, this.atime) || this.needPax\n      this.needPax = encDate(buf, off + 488, 12, this.ctime) || this.needPax\n    }\n\n    let sum = 8 * 0x20\n    for (let i = off; i < off + 148; i++) {\n      sum += buf[i]\n    }\n\n    for (let i = off + 156; i < off + 512; i++) {\n      sum += buf[i]\n    }\n\n    this.cksum = sum\n    encNumber(buf, off + 148, 8, this.cksum)\n    this.cksumValid = true\n\n    return this.needPax\n  }\n\n  set (data) {\n    for (const i in data) {\n      if (data[i] !== null && data[i] !== undefined) {\n        this[i] = data[i]\n      }\n    }\n  }\n\n  get type () {\n    return types.name.get(this[TYPE]) || this[TYPE]\n  }\n\n  get typeKey () {\n    return this[TYPE]\n  }\n\n  set type (type) {\n    if (types.code.has(type)) {\n      this[TYPE] = types.code.get(type)\n    } else {\n      this[TYPE] = type\n    }\n  }\n}\n\nconst splitPrefix = (p, prefixSize) => {\n  const pathSize = 100\n  let pp = p\n  let prefix = ''\n  let ret\n  const root = pathModule.parse(p).root || '.'\n\n  if (Buffer.byteLength(pp) < pathSize) {\n    ret = [pp, prefix, false]\n  } else {\n    // first set prefix to the dir, and path to the base\n    prefix = pathModule.dirname(pp)\n    pp = pathModule.basename(pp)\n\n    do {\n      if (Buffer.byteLength(pp) <= pathSize &&\n          Buffer.byteLength(prefix) <= prefixSize) {\n        // both fit!\n        ret = [pp, prefix, false]\n      } else if (Buffer.byteLength(pp) > pathSize &&\n          Buffer.byteLength(prefix) <= prefixSize) {\n        // prefix fits in prefix, but path doesn't fit in path\n        ret = [pp.slice(0, pathSize - 1), prefix, true]\n      } else {\n        // make path take a bit from prefix\n        pp = pathModule.join(pathModule.basename(prefix), pp)\n        prefix = pathModule.dirname(prefix)\n      }\n    } while (prefix !== root && !ret)\n\n    // at this point, found no resolution, just truncate\n    if (!ret) {\n      ret = [p.slice(0, pathSize - 1), '', true]\n    }\n  }\n  return ret\n}\n\nconst decString = (buf, off, size) =>\n  buf.slice(off, off + size).toString('utf8').replace(/\\0.*/, '')\n\nconst decDate = (buf, off, size) =>\n  numToDate(decNumber(buf, off, size))\n\nconst numToDate = num => num === null ? null : new Date(num * 1000)\n\nconst decNumber = (buf, off, size) =>\n  buf[off] & 0x80 ? large.parse(buf.slice(off, off + size))\n  : decSmallNumber(buf, off, size)\n\nconst nanNull = value => isNaN(value) ? null : value\n\nconst decSmallNumber = (buf, off, size) =>\n  nanNull(parseInt(\n    buf.slice(off, off + size)\n      .toString('utf8').replace(/\\0.*$/, '').trim(), 8))\n\n// the maximum encodable as a null-terminated octal, by field size\nconst MAXNUM = {\n  12: 0o77777777777,\n  8: 0o7777777,\n}\n\nconst encNumber = (buf, off, size, number) =>\n  number === null ? false :\n  number > MAXNUM[size] || number < 0\n    ? (large.encode(number, buf.slice(off, off + size)), true)\n    : (encSmallNumber(buf, off, size, number), false)\n\nconst encSmallNumber = (buf, off, size, number) =>\n  buf.write(octalString(number, size), off, size, 'ascii')\n\nconst octalString = (number, size) =>\n  padOctal(Math.floor(number).toString(8), size)\n\nconst padOctal = (string, size) =>\n  (string.length === size - 1 ? string\n  : new Array(size - string.length - 1).join('0') + string + ' ') + '\\0'\n\nconst encDate = (buf, off, size, date) =>\n  date === null ? false :\n  encNumber(buf, off, size, date.getTime() / 1000)\n\n// enough to fill the longest string we've got\nconst NULLS = new Array(156).join('\\0')\n// pad with nulls, return true if it's longer or non-ascii\nconst encString = (buf, off, size, string) =>\n  string === null ? false :\n  (buf.write(string + NULLS, off, size, 'utf8'),\n  string.length !== Buffer.byteLength(string) || string.length > size)\n\nmodule.exports = Header\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/header.js?");

/***/ }),

/***/ "./node_modules/tar/lib/high-level-opt.js":
/*!************************************************!*\
  !*** ./node_modules/tar/lib/high-level-opt.js ***!
  \************************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// turn tar(1) style args like `C` into the more verbose things like `cwd`\n\nconst argmap = new Map([\n  ['C', 'cwd'],\n  ['f', 'file'],\n  ['z', 'gzip'],\n  ['P', 'preservePaths'],\n  ['U', 'unlink'],\n  ['strip-components', 'strip'],\n  ['stripComponents', 'strip'],\n  ['keep-newer', 'newer'],\n  ['keepNewer', 'newer'],\n  ['keep-newer-files', 'newer'],\n  ['keepNewerFiles', 'newer'],\n  ['k', 'keep'],\n  ['keep-existing', 'keep'],\n  ['keepExisting', 'keep'],\n  ['m', 'noMtime'],\n  ['no-mtime', 'noMtime'],\n  ['p', 'preserveOwner'],\n  ['L', 'follow'],\n  ['h', 'follow'],\n])\n\nmodule.exports = opt => opt ? Object.keys(opt).map(k => [\n  argmap.has(k) ? argmap.get(k) : k, opt[k],\n]).reduce((set, kv) => (set[kv[0]] = kv[1], set), Object.create(null)) : {}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/high-level-opt.js?");

/***/ }),

/***/ "./node_modules/tar/lib/large-numbers.js":
/*!***********************************************!*\
  !*** ./node_modules/tar/lib/large-numbers.js ***!
  \***********************************************/
/***/ ((module) => {

"use strict";
eval("\n// Tar can encode large and negative numbers using a leading byte of\n// 0xff for negative, and 0x80 for positive.\n\nconst encode = (num, buf) => {\n  if (!Number.isSafeInteger(num)) {\n  // The number is so large that javascript cannot represent it with integer\n  // precision.\n    throw Error('cannot encode number outside of javascript safe integer range')\n  } else if (num < 0) {\n    encodeNegative(num, buf)\n  } else {\n    encodePositive(num, buf)\n  }\n  return buf\n}\n\nconst encodePositive = (num, buf) => {\n  buf[0] = 0x80\n\n  for (var i = buf.length; i > 1; i--) {\n    buf[i - 1] = num & 0xff\n    num = Math.floor(num / 0x100)\n  }\n}\n\nconst encodeNegative = (num, buf) => {\n  buf[0] = 0xff\n  var flipped = false\n  num = num * -1\n  for (var i = buf.length; i > 1; i--) {\n    var byte = num & 0xff\n    num = Math.floor(num / 0x100)\n    if (flipped) {\n      buf[i - 1] = onesComp(byte)\n    } else if (byte === 0) {\n      buf[i - 1] = 0\n    } else {\n      flipped = true\n      buf[i - 1] = twosComp(byte)\n    }\n  }\n}\n\nconst parse = (buf) => {\n  const pre = buf[0]\n  const value = pre === 0x80 ? pos(buf.slice(1, buf.length))\n    : pre === 0xff ? twos(buf)\n    : null\n  if (value === null) {\n    throw Error('invalid base256 encoding')\n  }\n\n  if (!Number.isSafeInteger(value)) {\n  // The number is so large that javascript cannot represent it with integer\n  // precision.\n    throw Error('parsed number outside of javascript safe integer range')\n  }\n\n  return value\n}\n\nconst twos = (buf) => {\n  var len = buf.length\n  var sum = 0\n  var flipped = false\n  for (var i = len - 1; i > -1; i--) {\n    var byte = buf[i]\n    var f\n    if (flipped) {\n      f = onesComp(byte)\n    } else if (byte === 0) {\n      f = byte\n    } else {\n      flipped = true\n      f = twosComp(byte)\n    }\n    if (f !== 0) {\n      sum -= f * Math.pow(256, len - i - 1)\n    }\n  }\n  return sum\n}\n\nconst pos = (buf) => {\n  var len = buf.length\n  var sum = 0\n  for (var i = len - 1; i > -1; i--) {\n    var byte = buf[i]\n    if (byte !== 0) {\n      sum += byte * Math.pow(256, len - i - 1)\n    }\n  }\n  return sum\n}\n\nconst onesComp = byte => (0xff ^ byte) & 0xff\n\nconst twosComp = byte => ((0xff ^ byte) + 1) & 0xff\n\nmodule.exports = {\n  encode,\n  parse,\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/large-numbers.js?");

/***/ }),

/***/ "./node_modules/tar/lib/list.js":
/*!**************************************!*\
  !*** ./node_modules/tar/lib/list.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// XXX: This shares a lot in common with extract.js\n// maybe some DRY opportunity here?\n\n// tar -t\nconst hlo = __webpack_require__(/*! ./high-level-opt.js */ \"./node_modules/tar/lib/high-level-opt.js\")\nconst Parser = __webpack_require__(/*! ./parse.js */ \"./node_modules/tar/lib/parse.js\")\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst fsm = __webpack_require__(/*! fs-minipass */ \"./node_modules/fs-minipass/index.js\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst stripSlash = __webpack_require__(/*! ./strip-trailing-slashes.js */ \"./node_modules/tar/lib/strip-trailing-slashes.js\")\n\nmodule.exports = (opt_, files, cb) => {\n  if (typeof opt_ === 'function') {\n    cb = opt_, files = null, opt_ = {}\n  } else if (Array.isArray(opt_)) {\n    files = opt_, opt_ = {}\n  }\n\n  if (typeof files === 'function') {\n    cb = files, files = null\n  }\n\n  if (!files) {\n    files = []\n  } else {\n    files = Array.from(files)\n  }\n\n  const opt = hlo(opt_)\n\n  if (opt.sync && typeof cb === 'function') {\n    throw new TypeError('callback not supported for sync tar functions')\n  }\n\n  if (!opt.file && typeof cb === 'function') {\n    throw new TypeError('callback only supported with file option')\n  }\n\n  if (files.length) {\n    filesFilter(opt, files)\n  }\n\n  if (!opt.noResume) {\n    onentryFunction(opt)\n  }\n\n  return opt.file && opt.sync ? listFileSync(opt)\n    : opt.file ? listFile(opt, cb)\n    : list(opt)\n}\n\nconst onentryFunction = opt => {\n  const onentry = opt.onentry\n  opt.onentry = onentry ? e => {\n    onentry(e)\n    e.resume()\n  } : e => e.resume()\n}\n\n// construct a filter that limits the file entries listed\n// include child entries if a dir is included\nconst filesFilter = (opt, files) => {\n  const map = new Map(files.map(f => [stripSlash(f), true]))\n  const filter = opt.filter\n\n  const mapHas = (file, r) => {\n    const root = r || path.parse(file).root || '.'\n    const ret = file === root ? false\n      : map.has(file) ? map.get(file)\n      : mapHas(path.dirname(file), root)\n\n    map.set(file, ret)\n    return ret\n  }\n\n  opt.filter = filter\n    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))\n    : file => mapHas(stripSlash(file))\n}\n\nconst listFileSync = opt => {\n  const p = list(opt)\n  const file = opt.file\n  let threw = true\n  let fd\n  try {\n    const stat = fs.statSync(file)\n    const readSize = opt.maxReadSize || 16 * 1024 * 1024\n    if (stat.size < readSize) {\n      p.end(fs.readFileSync(file))\n    } else {\n      let pos = 0\n      const buf = Buffer.allocUnsafe(readSize)\n      fd = fs.openSync(file, 'r')\n      while (pos < stat.size) {\n        const bytesRead = fs.readSync(fd, buf, 0, readSize, pos)\n        pos += bytesRead\n        p.write(buf.slice(0, bytesRead))\n      }\n      p.end()\n    }\n    threw = false\n  } finally {\n    if (threw && fd) {\n      try {\n        fs.closeSync(fd)\n      } catch (er) {}\n    }\n  }\n}\n\nconst listFile = (opt, cb) => {\n  const parse = new Parser(opt)\n  const readSize = opt.maxReadSize || 16 * 1024 * 1024\n\n  const file = opt.file\n  const p = new Promise((resolve, reject) => {\n    parse.on('error', reject)\n    parse.on('end', resolve)\n\n    fs.stat(file, (er, stat) => {\n      if (er) {\n        reject(er)\n      } else {\n        const stream = new fsm.ReadStream(file, {\n          readSize: readSize,\n          size: stat.size,\n        })\n        stream.on('error', reject)\n        stream.pipe(parse)\n      }\n    })\n  })\n  return cb ? p.then(cb, cb) : p\n}\n\nconst list = opt => new Parser(opt)\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/list.js?");

/***/ }),

/***/ "./node_modules/tar/lib/mkdir.js":
/*!***************************************!*\
  !*** ./node_modules/tar/lib/mkdir.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n// wrapper around mkdirp for tar's needs.\n\n// TODO: This should probably be a class, not functionally\n// passing around state in a gazillion args.\n\nconst mkdirp = __webpack_require__(/*! mkdirp */ \"./node_modules/mkdirp/index.js\")\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst chownr = __webpack_require__(/*! chownr */ \"./node_modules/chownr/chownr.js\")\nconst normPath = __webpack_require__(/*! ./normalize-windows-path.js */ \"./node_modules/tar/lib/normalize-windows-path.js\")\n\nclass SymlinkError extends Error {\n  constructor (symlink, path) {\n    super('Cannot extract through symbolic link')\n    this.path = path\n    this.symlink = symlink\n  }\n\n  get name () {\n    return 'SylinkError'\n  }\n}\n\nclass CwdError extends Error {\n  constructor (path, code) {\n    super(code + ': Cannot cd into \\'' + path + '\\'')\n    this.path = path\n    this.code = code\n  }\n\n  get name () {\n    return 'CwdError'\n  }\n}\n\nconst cGet = (cache, key) => cache.get(normPath(key))\nconst cSet = (cache, key, val) => cache.set(normPath(key), val)\n\nconst checkCwd = (dir, cb) => {\n  fs.stat(dir, (er, st) => {\n    if (er || !st.isDirectory()) {\n      er = new CwdError(dir, er && er.code || 'ENOTDIR')\n    }\n    cb(er)\n  })\n}\n\nmodule.exports = (dir, opt, cb) => {\n  dir = normPath(dir)\n\n  // if there's any overlap between mask and mode,\n  // then we'll need an explicit chmod\n  const umask = opt.umask\n  const mode = opt.mode | 0o0700\n  const needChmod = (mode & umask) !== 0\n\n  const uid = opt.uid\n  const gid = opt.gid\n  const doChown = typeof uid === 'number' &&\n    typeof gid === 'number' &&\n    (uid !== opt.processUid || gid !== opt.processGid)\n\n  const preserve = opt.preserve\n  const unlink = opt.unlink\n  const cache = opt.cache\n  const cwd = normPath(opt.cwd)\n\n  const done = (er, created) => {\n    if (er) {\n      cb(er)\n    } else {\n      cSet(cache, dir, true)\n      if (created && doChown) {\n        chownr(created, uid, gid, er => done(er))\n      } else if (needChmod) {\n        fs.chmod(dir, mode, cb)\n      } else {\n        cb()\n      }\n    }\n  }\n\n  if (cache && cGet(cache, dir) === true) {\n    return done()\n  }\n\n  if (dir === cwd) {\n    return checkCwd(dir, done)\n  }\n\n  if (preserve) {\n    return mkdirp(dir, { mode }).then(made => done(null, made), done)\n  }\n\n  const sub = normPath(path.relative(cwd, dir))\n  const parts = sub.split('/')\n  mkdir_(cwd, parts, mode, cache, unlink, cwd, null, done)\n}\n\nconst mkdir_ = (base, parts, mode, cache, unlink, cwd, created, cb) => {\n  if (!parts.length) {\n    return cb(null, created)\n  }\n  const p = parts.shift()\n  const part = normPath(path.resolve(base + '/' + p))\n  if (cGet(cache, part)) {\n    return mkdir_(part, parts, mode, cache, unlink, cwd, created, cb)\n  }\n  fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlink, cwd, created, cb))\n}\n\nconst onmkdir = (part, parts, mode, cache, unlink, cwd, created, cb) => er => {\n  if (er) {\n    fs.lstat(part, (statEr, st) => {\n      if (statEr) {\n        statEr.path = statEr.path && normPath(statEr.path)\n        cb(statEr)\n      } else if (st.isDirectory()) {\n        mkdir_(part, parts, mode, cache, unlink, cwd, created, cb)\n      } else if (unlink) {\n        fs.unlink(part, er => {\n          if (er) {\n            return cb(er)\n          }\n          fs.mkdir(part, mode, onmkdir(part, parts, mode, cache, unlink, cwd, created, cb))\n        })\n      } else if (st.isSymbolicLink()) {\n        return cb(new SymlinkError(part, part + '/' + parts.join('/')))\n      } else {\n        cb(er)\n      }\n    })\n  } else {\n    created = created || part\n    mkdir_(part, parts, mode, cache, unlink, cwd, created, cb)\n  }\n}\n\nconst checkCwdSync = dir => {\n  let ok = false\n  let code = 'ENOTDIR'\n  try {\n    ok = fs.statSync(dir).isDirectory()\n  } catch (er) {\n    code = er.code\n  } finally {\n    if (!ok) {\n      throw new CwdError(dir, code)\n    }\n  }\n}\n\nmodule.exports.sync = (dir, opt) => {\n  dir = normPath(dir)\n  // if there's any overlap between mask and mode,\n  // then we'll need an explicit chmod\n  const umask = opt.umask\n  const mode = opt.mode | 0o0700\n  const needChmod = (mode & umask) !== 0\n\n  const uid = opt.uid\n  const gid = opt.gid\n  const doChown = typeof uid === 'number' &&\n    typeof gid === 'number' &&\n    (uid !== opt.processUid || gid !== opt.processGid)\n\n  const preserve = opt.preserve\n  const unlink = opt.unlink\n  const cache = opt.cache\n  const cwd = normPath(opt.cwd)\n\n  const done = (created) => {\n    cSet(cache, dir, true)\n    if (created && doChown) {\n      chownr.sync(created, uid, gid)\n    }\n    if (needChmod) {\n      fs.chmodSync(dir, mode)\n    }\n  }\n\n  if (cache && cGet(cache, dir) === true) {\n    return done()\n  }\n\n  if (dir === cwd) {\n    checkCwdSync(cwd)\n    return done()\n  }\n\n  if (preserve) {\n    return done(mkdirp.sync(dir, mode))\n  }\n\n  const sub = normPath(path.relative(cwd, dir))\n  const parts = sub.split('/')\n  let created = null\n  for (let p = parts.shift(), part = cwd;\n    p && (part += '/' + p);\n    p = parts.shift()) {\n    part = normPath(path.resolve(part))\n    if (cGet(cache, part)) {\n      continue\n    }\n\n    try {\n      fs.mkdirSync(part, mode)\n      created = created || part\n      cSet(cache, part, true)\n    } catch (er) {\n      const st = fs.lstatSync(part)\n      if (st.isDirectory()) {\n        cSet(cache, part, true)\n        continue\n      } else if (unlink) {\n        fs.unlinkSync(part)\n        fs.mkdirSync(part, mode)\n        created = created || part\n        cSet(cache, part, true)\n        continue\n      } else if (st.isSymbolicLink()) {\n        return new SymlinkError(part, part + '/' + parts.join('/'))\n      }\n    }\n  }\n\n  return done(created)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/mkdir.js?");

/***/ }),

/***/ "./node_modules/tar/lib/mode-fix.js":
/*!******************************************!*\
  !*** ./node_modules/tar/lib/mode-fix.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = (mode, isDir, portable) => {\n  mode &= 0o7777\n\n  // in portable mode, use the minimum reasonable umask\n  // if this system creates files with 0o664 by default\n  // (as some linux distros do), then we'll write the\n  // archive with 0o644 instead.  Also, don't ever create\n  // a file that is not readable/writable by the owner.\n  if (portable) {\n    mode = (mode | 0o600) & ~0o22\n  }\n\n  // if dirs are readable, then they should be listable\n  if (isDir) {\n    if (mode & 0o400) {\n      mode |= 0o100\n    }\n    if (mode & 0o40) {\n      mode |= 0o10\n    }\n    if (mode & 0o4) {\n      mode |= 0o1\n    }\n  }\n  return mode\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/mode-fix.js?");

/***/ }),

/***/ "./node_modules/tar/lib/normalize-unicode.js":
/*!***************************************************!*\
  !*** ./node_modules/tar/lib/normalize-unicode.js ***!
  \***************************************************/
/***/ ((module) => {

eval("// warning: extremely hot code path.\n// This has been meticulously optimized for use\n// within npm install on large package trees.\n// Do not edit without careful benchmarking.\nconst normalizeCache = Object.create(null)\nconst { hasOwnProperty } = Object.prototype\nmodule.exports = s => {\n  if (!hasOwnProperty.call(normalizeCache, s)) {\n    normalizeCache[s] = s.normalize('NFD')\n  }\n  return normalizeCache[s]\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/normalize-unicode.js?");

/***/ }),

/***/ "./node_modules/tar/lib/normalize-windows-path.js":
/*!********************************************************!*\
  !*** ./node_modules/tar/lib/normalize-windows-path.js ***!
  \********************************************************/
/***/ ((module) => {

eval("// on windows, either \\ or / are valid directory separators.\n// on unix, \\ is a valid character in filenames.\n// so, on windows, and only on windows, we replace all \\ chars with /,\n// so that we can use / as our one and only directory separator char.\n\nconst platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platform\nmodule.exports = platform !== 'win32' ? p => p\n  : p => p && p.replace(/\\\\/g, '/')\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/normalize-windows-path.js?");

/***/ }),

/***/ "./node_modules/tar/lib/pack.js":
/*!**************************************!*\
  !*** ./node_modules/tar/lib/pack.js ***!
  \**************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// A readable tar stream creator\n// Technically, this is a transform stream that you write paths into,\n// and tar format comes out of.\n// The `add()` method is like `write()` but returns this,\n// and end() return `this` as well, so you can\n// do `new Pack(opt).add('files').add('dir').end().pipe(output)\n// You could also do something like:\n// streamOfPaths().pipe(new Pack()).pipe(new fs.WriteStream('out.tar'))\n\nclass PackJob {\n  constructor (path, absolute) {\n    this.path = path || './'\n    this.absolute = absolute\n    this.entry = null\n    this.stat = null\n    this.readdir = null\n    this.pending = false\n    this.ignore = false\n    this.piped = false\n  }\n}\n\nconst { Minipass } = __webpack_require__(/*! minipass */ \"./node_modules/minipass/index.js\")\nconst zlib = __webpack_require__(/*! minizlib */ \"./node_modules/minizlib/index.js\")\nconst ReadEntry = __webpack_require__(/*! ./read-entry.js */ \"./node_modules/tar/lib/read-entry.js\")\nconst WriteEntry = __webpack_require__(/*! ./write-entry.js */ \"./node_modules/tar/lib/write-entry.js\")\nconst WriteEntrySync = WriteEntry.Sync\nconst WriteEntryTar = WriteEntry.Tar\nconst Yallist = __webpack_require__(/*! yallist */ \"./node_modules/yallist/yallist.js\")\nconst EOF = Buffer.alloc(1024)\nconst ONSTAT = Symbol('onStat')\nconst ENDED = Symbol('ended')\nconst QUEUE = Symbol('queue')\nconst CURRENT = Symbol('current')\nconst PROCESS = Symbol('process')\nconst PROCESSING = Symbol('processing')\nconst PROCESSJOB = Symbol('processJob')\nconst JOBS = Symbol('jobs')\nconst JOBDONE = Symbol('jobDone')\nconst ADDFSENTRY = Symbol('addFSEntry')\nconst ADDTARENTRY = Symbol('addTarEntry')\nconst STAT = Symbol('stat')\nconst READDIR = Symbol('readdir')\nconst ONREADDIR = Symbol('onreaddir')\nconst PIPE = Symbol('pipe')\nconst ENTRY = Symbol('entry')\nconst ENTRYOPT = Symbol('entryOpt')\nconst WRITEENTRYCLASS = Symbol('writeEntryClass')\nconst WRITE = Symbol('write')\nconst ONDRAIN = Symbol('ondrain')\n\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst warner = __webpack_require__(/*! ./warn-mixin.js */ \"./node_modules/tar/lib/warn-mixin.js\")\nconst normPath = __webpack_require__(/*! ./normalize-windows-path.js */ \"./node_modules/tar/lib/normalize-windows-path.js\")\n\nconst Pack = warner(class Pack extends Minipass {\n  constructor (opt) {\n    super(opt)\n    opt = opt || Object.create(null)\n    this.opt = opt\n    this.file = opt.file || ''\n    this.cwd = opt.cwd || process.cwd()\n    this.maxReadSize = opt.maxReadSize\n    this.preservePaths = !!opt.preservePaths\n    this.strict = !!opt.strict\n    this.noPax = !!opt.noPax\n    this.prefix = normPath(opt.prefix || '')\n    this.linkCache = opt.linkCache || new Map()\n    this.statCache = opt.statCache || new Map()\n    this.readdirCache = opt.readdirCache || new Map()\n\n    this[WRITEENTRYCLASS] = WriteEntry\n    if (typeof opt.onwarn === 'function') {\n      this.on('warn', opt.onwarn)\n    }\n\n    this.portable = !!opt.portable\n    this.zip = null\n\n    if (opt.gzip || opt.brotli) {\n      if (opt.gzip && opt.brotli) {\n        throw new TypeError('gzip and brotli are mutually exclusive')\n      }\n      if (opt.gzip) {\n        if (typeof opt.gzip !== 'object') {\n          opt.gzip = {}\n        }\n        if (this.portable) {\n          opt.gzip.portable = true\n        }\n        this.zip = new zlib.Gzip(opt.gzip)\n      }\n      if (opt.brotli) {\n        if (typeof opt.brotli !== 'object') {\n          opt.brotli = {}\n        }\n        this.zip = new zlib.BrotliCompress(opt.brotli)\n      }\n      this.zip.on('data', chunk => super.write(chunk))\n      this.zip.on('end', _ => super.end())\n      this.zip.on('drain', _ => this[ONDRAIN]())\n      this.on('resume', _ => this.zip.resume())\n    } else {\n      this.on('drain', this[ONDRAIN])\n    }\n\n    this.noDirRecurse = !!opt.noDirRecurse\n    this.follow = !!opt.follow\n    this.noMtime = !!opt.noMtime\n    this.mtime = opt.mtime || null\n\n    this.filter = typeof opt.filter === 'function' ? opt.filter : _ => true\n\n    this[QUEUE] = new Yallist()\n    this[JOBS] = 0\n    this.jobs = +opt.jobs || 4\n    this[PROCESSING] = false\n    this[ENDED] = false\n  }\n\n  [WRITE] (chunk) {\n    return super.write(chunk)\n  }\n\n  add (path) {\n    this.write(path)\n    return this\n  }\n\n  end (path) {\n    if (path) {\n      this.write(path)\n    }\n    this[ENDED] = true\n    this[PROCESS]()\n    return this\n  }\n\n  write (path) {\n    if (this[ENDED]) {\n      throw new Error('write after end')\n    }\n\n    if (path instanceof ReadEntry) {\n      this[ADDTARENTRY](path)\n    } else {\n      this[ADDFSENTRY](path)\n    }\n    return this.flowing\n  }\n\n  [ADDTARENTRY] (p) {\n    const absolute = normPath(path.resolve(this.cwd, p.path))\n    // in this case, we don't have to wait for the stat\n    if (!this.filter(p.path, p)) {\n      p.resume()\n    } else {\n      const job = new PackJob(p.path, absolute, false)\n      job.entry = new WriteEntryTar(p, this[ENTRYOPT](job))\n      job.entry.on('end', _ => this[JOBDONE](job))\n      this[JOBS] += 1\n      this[QUEUE].push(job)\n    }\n\n    this[PROCESS]()\n  }\n\n  [ADDFSENTRY] (p) {\n    const absolute = normPath(path.resolve(this.cwd, p))\n    this[QUEUE].push(new PackJob(p, absolute))\n    this[PROCESS]()\n  }\n\n  [STAT] (job) {\n    job.pending = true\n    this[JOBS] += 1\n    const stat = this.follow ? 'stat' : 'lstat'\n    fs[stat](job.absolute, (er, stat) => {\n      job.pending = false\n      this[JOBS] -= 1\n      if (er) {\n        this.emit('error', er)\n      } else {\n        this[ONSTAT](job, stat)\n      }\n    })\n  }\n\n  [ONSTAT] (job, stat) {\n    this.statCache.set(job.absolute, stat)\n    job.stat = stat\n\n    // now we have the stat, we can filter it.\n    if (!this.filter(job.path, stat)) {\n      job.ignore = true\n    }\n\n    this[PROCESS]()\n  }\n\n  [READDIR] (job) {\n    job.pending = true\n    this[JOBS] += 1\n    fs.readdir(job.absolute, (er, entries) => {\n      job.pending = false\n      this[JOBS] -= 1\n      if (er) {\n        return this.emit('error', er)\n      }\n      this[ONREADDIR](job, entries)\n    })\n  }\n\n  [ONREADDIR] (job, entries) {\n    this.readdirCache.set(job.absolute, entries)\n    job.readdir = entries\n    this[PROCESS]()\n  }\n\n  [PROCESS] () {\n    if (this[PROCESSING]) {\n      return\n    }\n\n    this[PROCESSING] = true\n    for (let w = this[QUEUE].head;\n      w !== null && this[JOBS] < this.jobs;\n      w = w.next) {\n      this[PROCESSJOB](w.value)\n      if (w.value.ignore) {\n        const p = w.next\n        this[QUEUE].removeNode(w)\n        w.next = p\n      }\n    }\n\n    this[PROCESSING] = false\n\n    if (this[ENDED] && !this[QUEUE].length && this[JOBS] === 0) {\n      if (this.zip) {\n        this.zip.end(EOF)\n      } else {\n        super.write(EOF)\n        super.end()\n      }\n    }\n  }\n\n  get [CURRENT] () {\n    return this[QUEUE] && this[QUEUE].head && this[QUEUE].head.value\n  }\n\n  [JOBDONE] (job) {\n    this[QUEUE].shift()\n    this[JOBS] -= 1\n    this[PROCESS]()\n  }\n\n  [PROCESSJOB] (job) {\n    if (job.pending) {\n      return\n    }\n\n    if (job.entry) {\n      if (job === this[CURRENT] && !job.piped) {\n        this[PIPE](job)\n      }\n      return\n    }\n\n    if (!job.stat) {\n      if (this.statCache.has(job.absolute)) {\n        this[ONSTAT](job, this.statCache.get(job.absolute))\n      } else {\n        this[STAT](job)\n      }\n    }\n    if (!job.stat) {\n      return\n    }\n\n    // filtered out!\n    if (job.ignore) {\n      return\n    }\n\n    if (!this.noDirRecurse && job.stat.isDirectory() && !job.readdir) {\n      if (this.readdirCache.has(job.absolute)) {\n        this[ONREADDIR](job, this.readdirCache.get(job.absolute))\n      } else {\n        this[READDIR](job)\n      }\n      if (!job.readdir) {\n        return\n      }\n    }\n\n    // we know it doesn't have an entry, because that got checked above\n    job.entry = this[ENTRY](job)\n    if (!job.entry) {\n      job.ignore = true\n      return\n    }\n\n    if (job === this[CURRENT] && !job.piped) {\n      this[PIPE](job)\n    }\n  }\n\n  [ENTRYOPT] (job) {\n    return {\n      onwarn: (code, msg, data) => this.warn(code, msg, data),\n      noPax: this.noPax,\n      cwd: this.cwd,\n      absolute: job.absolute,\n      preservePaths: this.preservePaths,\n      maxReadSize: this.maxReadSize,\n      strict: this.strict,\n      portable: this.portable,\n      linkCache: this.linkCache,\n      statCache: this.statCache,\n      noMtime: this.noMtime,\n      mtime: this.mtime,\n      prefix: this.prefix,\n    }\n  }\n\n  [ENTRY] (job) {\n    this[JOBS] += 1\n    try {\n      return new this[WRITEENTRYCLASS](job.path, this[ENTRYOPT](job))\n        .on('end', () => this[JOBDONE](job))\n        .on('error', er => this.emit('error', er))\n    } catch (er) {\n      this.emit('error', er)\n    }\n  }\n\n  [ONDRAIN] () {\n    if (this[CURRENT] && this[CURRENT].entry) {\n      this[CURRENT].entry.resume()\n    }\n  }\n\n  // like .pipe() but using super, because our write() is special\n  [PIPE] (job) {\n    job.piped = true\n\n    if (job.readdir) {\n      job.readdir.forEach(entry => {\n        const p = job.path\n        const base = p === './' ? '' : p.replace(/\\/*$/, '/')\n        this[ADDFSENTRY](base + entry)\n      })\n    }\n\n    const source = job.entry\n    const zip = this.zip\n\n    if (zip) {\n      source.on('data', chunk => {\n        if (!zip.write(chunk)) {\n          source.pause()\n        }\n      })\n    } else {\n      source.on('data', chunk => {\n        if (!super.write(chunk)) {\n          source.pause()\n        }\n      })\n    }\n  }\n\n  pause () {\n    if (this.zip) {\n      this.zip.pause()\n    }\n    return super.pause()\n  }\n})\n\nclass PackSync extends Pack {\n  constructor (opt) {\n    super(opt)\n    this[WRITEENTRYCLASS] = WriteEntrySync\n  }\n\n  // pause/resume are no-ops in sync streams.\n  pause () {}\n  resume () {}\n\n  [STAT] (job) {\n    const stat = this.follow ? 'statSync' : 'lstatSync'\n    this[ONSTAT](job, fs[stat](job.absolute))\n  }\n\n  [READDIR] (job, stat) {\n    this[ONREADDIR](job, fs.readdirSync(job.absolute))\n  }\n\n  // gotta get it all in this tick\n  [PIPE] (job) {\n    const source = job.entry\n    const zip = this.zip\n\n    if (job.readdir) {\n      job.readdir.forEach(entry => {\n        const p = job.path\n        const base = p === './' ? '' : p.replace(/\\/*$/, '/')\n        this[ADDFSENTRY](base + entry)\n      })\n    }\n\n    if (zip) {\n      source.on('data', chunk => {\n        zip.write(chunk)\n      })\n    } else {\n      source.on('data', chunk => {\n        super[WRITE](chunk)\n      })\n    }\n  }\n}\n\nPack.Sync = PackSync\n\nmodule.exports = Pack\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/pack.js?");

/***/ }),

/***/ "./node_modules/tar/lib/parse.js":
/*!***************************************!*\
  !*** ./node_modules/tar/lib/parse.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// this[BUFFER] is the remainder of a chunk if we're waiting for\n// the full 512 bytes of a header to come in.  We will Buffer.concat()\n// it to the next write(), which is a mem copy, but a small one.\n//\n// this[QUEUE] is a Yallist of entries that haven't been emitted\n// yet this can only get filled up if the user keeps write()ing after\n// a write() returns false, or does a write() with more than one entry\n//\n// We don't buffer chunks, we always parse them and either create an\n// entry, or push it into the active entry.  The ReadEntry class knows\n// to throw data away if .ignore=true\n//\n// Shift entry off the buffer when it emits 'end', and emit 'entry' for\n// the next one in the list.\n//\n// At any time, we're pushing body chunks into the entry at WRITEENTRY,\n// and waiting for 'end' on the entry at READENTRY\n//\n// ignored entries get .resume() called on them straight away\n\nconst warner = __webpack_require__(/*! ./warn-mixin.js */ \"./node_modules/tar/lib/warn-mixin.js\")\nconst Header = __webpack_require__(/*! ./header.js */ \"./node_modules/tar/lib/header.js\")\nconst EE = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst Yallist = __webpack_require__(/*! yallist */ \"./node_modules/yallist/yallist.js\")\nconst maxMetaEntrySize = 1024 * 1024\nconst Entry = __webpack_require__(/*! ./read-entry.js */ \"./node_modules/tar/lib/read-entry.js\")\nconst Pax = __webpack_require__(/*! ./pax.js */ \"./node_modules/tar/lib/pax.js\")\nconst zlib = __webpack_require__(/*! minizlib */ \"./node_modules/minizlib/index.js\")\nconst { nextTick } = __webpack_require__(/*! process */ \"./node_modules/process/browser.js\")\n\nconst gzipHeader = Buffer.from([0x1f, 0x8b])\nconst STATE = Symbol('state')\nconst WRITEENTRY = Symbol('writeEntry')\nconst READENTRY = Symbol('readEntry')\nconst NEXTENTRY = Symbol('nextEntry')\nconst PROCESSENTRY = Symbol('processEntry')\nconst EX = Symbol('extendedHeader')\nconst GEX = Symbol('globalExtendedHeader')\nconst META = Symbol('meta')\nconst EMITMETA = Symbol('emitMeta')\nconst BUFFER = Symbol('buffer')\nconst QUEUE = Symbol('queue')\nconst ENDED = Symbol('ended')\nconst EMITTEDEND = Symbol('emittedEnd')\nconst EMIT = Symbol('emit')\nconst UNZIP = Symbol('unzip')\nconst CONSUMECHUNK = Symbol('consumeChunk')\nconst CONSUMECHUNKSUB = Symbol('consumeChunkSub')\nconst CONSUMEBODY = Symbol('consumeBody')\nconst CONSUMEMETA = Symbol('consumeMeta')\nconst CONSUMEHEADER = Symbol('consumeHeader')\nconst CONSUMING = Symbol('consuming')\nconst BUFFERCONCAT = Symbol('bufferConcat')\nconst MAYBEEND = Symbol('maybeEnd')\nconst WRITING = Symbol('writing')\nconst ABORTED = Symbol('aborted')\nconst DONE = Symbol('onDone')\nconst SAW_VALID_ENTRY = Symbol('sawValidEntry')\nconst SAW_NULL_BLOCK = Symbol('sawNullBlock')\nconst SAW_EOF = Symbol('sawEOF')\nconst CLOSESTREAM = Symbol('closeStream')\n\nconst noop = _ => true\n\nmodule.exports = warner(class Parser extends EE {\n  constructor (opt) {\n    opt = opt || {}\n    super(opt)\n\n    this.file = opt.file || ''\n\n    // set to boolean false when an entry starts.  1024 bytes of \\0\n    // is technically a valid tarball, albeit a boring one.\n    this[SAW_VALID_ENTRY] = null\n\n    // these BADARCHIVE errors can't be detected early. listen on DONE.\n    this.on(DONE, _ => {\n      if (this[STATE] === 'begin' || this[SAW_VALID_ENTRY] === false) {\n        // either less than 1 block of data, or all entries were invalid.\n        // Either way, probably not even a tarball.\n        this.warn('TAR_BAD_ARCHIVE', 'Unrecognized archive format')\n      }\n    })\n\n    if (opt.ondone) {\n      this.on(DONE, opt.ondone)\n    } else {\n      this.on(DONE, _ => {\n        this.emit('prefinish')\n        this.emit('finish')\n        this.emit('end')\n      })\n    }\n\n    this.strict = !!opt.strict\n    this.maxMetaEntrySize = opt.maxMetaEntrySize || maxMetaEntrySize\n    this.filter = typeof opt.filter === 'function' ? opt.filter : noop\n    // Unlike gzip, brotli doesn't have any magic bytes to identify it\n    // Users need to explicitly tell us they're extracting a brotli file\n    // Or we infer from the file extension\n    const isTBR = (opt.file && (\n        opt.file.endsWith('.tar.br') || opt.file.endsWith('.tbr')))\n    // if it's a tbr file it MIGHT be brotli, but we don't know until\n    // we look at it and verify it's not a valid tar file.\n    this.brotli = !opt.gzip && opt.brotli !== undefined ? opt.brotli\n      : isTBR ? undefined\n      : false\n\n    // have to set this so that streams are ok piping into it\n    this.writable = true\n    this.readable = false\n\n    this[QUEUE] = new Yallist()\n    this[BUFFER] = null\n    this[READENTRY] = null\n    this[WRITEENTRY] = null\n    this[STATE] = 'begin'\n    this[META] = ''\n    this[EX] = null\n    this[GEX] = null\n    this[ENDED] = false\n    this[UNZIP] = null\n    this[ABORTED] = false\n    this[SAW_NULL_BLOCK] = false\n    this[SAW_EOF] = false\n\n    this.on('end', () => this[CLOSESTREAM]())\n\n    if (typeof opt.onwarn === 'function') {\n      this.on('warn', opt.onwarn)\n    }\n    if (typeof opt.onentry === 'function') {\n      this.on('entry', opt.onentry)\n    }\n  }\n\n  [CONSUMEHEADER] (chunk, position) {\n    if (this[SAW_VALID_ENTRY] === null) {\n      this[SAW_VALID_ENTRY] = false\n    }\n    let header\n    try {\n      header = new Header(chunk, position, this[EX], this[GEX])\n    } catch (er) {\n      return this.warn('TAR_ENTRY_INVALID', er)\n    }\n\n    if (header.nullBlock) {\n      if (this[SAW_NULL_BLOCK]) {\n        this[SAW_EOF] = true\n        // ending an archive with no entries.  pointless, but legal.\n        if (this[STATE] === 'begin') {\n          this[STATE] = 'header'\n        }\n        this[EMIT]('eof')\n      } else {\n        this[SAW_NULL_BLOCK] = true\n        this[EMIT]('nullBlock')\n      }\n    } else {\n      this[SAW_NULL_BLOCK] = false\n      if (!header.cksumValid) {\n        this.warn('TAR_ENTRY_INVALID', 'checksum failure', { header })\n      } else if (!header.path) {\n        this.warn('TAR_ENTRY_INVALID', 'path is required', { header })\n      } else {\n        const type = header.type\n        if (/^(Symbolic)?Link$/.test(type) && !header.linkpath) {\n          this.warn('TAR_ENTRY_INVALID', 'linkpath required', { header })\n        } else if (!/^(Symbolic)?Link$/.test(type) && header.linkpath) {\n          this.warn('TAR_ENTRY_INVALID', 'linkpath forbidden', { header })\n        } else {\n          const entry = this[WRITEENTRY] = new Entry(header, this[EX], this[GEX])\n\n          // we do this for meta & ignored entries as well, because they\n          // are still valid tar, or else we wouldn't know to ignore them\n          if (!this[SAW_VALID_ENTRY]) {\n            if (entry.remain) {\n              // this might be the one!\n              const onend = () => {\n                if (!entry.invalid) {\n                  this[SAW_VALID_ENTRY] = true\n                }\n              }\n              entry.on('end', onend)\n            } else {\n              this[SAW_VALID_ENTRY] = true\n            }\n          }\n\n          if (entry.meta) {\n            if (entry.size > this.maxMetaEntrySize) {\n              entry.ignore = true\n              this[EMIT]('ignoredEntry', entry)\n              this[STATE] = 'ignore'\n              entry.resume()\n            } else if (entry.size > 0) {\n              this[META] = ''\n              entry.on('data', c => this[META] += c)\n              this[STATE] = 'meta'\n            }\n          } else {\n            this[EX] = null\n            entry.ignore = entry.ignore || !this.filter(entry.path, entry)\n\n            if (entry.ignore) {\n              // probably valid, just not something we care about\n              this[EMIT]('ignoredEntry', entry)\n              this[STATE] = entry.remain ? 'ignore' : 'header'\n              entry.resume()\n            } else {\n              if (entry.remain) {\n                this[STATE] = 'body'\n              } else {\n                this[STATE] = 'header'\n                entry.end()\n              }\n\n              if (!this[READENTRY]) {\n                this[QUEUE].push(entry)\n                this[NEXTENTRY]()\n              } else {\n                this[QUEUE].push(entry)\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  [CLOSESTREAM] () {\n    nextTick(() => this.emit('close'))\n  }\n\n  [PROCESSENTRY] (entry) {\n    let go = true\n\n    if (!entry) {\n      this[READENTRY] = null\n      go = false\n    } else if (Array.isArray(entry)) {\n      this.emit.apply(this, entry)\n    } else {\n      this[READENTRY] = entry\n      this.emit('entry', entry)\n      if (!entry.emittedEnd) {\n        entry.on('end', _ => this[NEXTENTRY]())\n        go = false\n      }\n    }\n\n    return go\n  }\n\n  [NEXTENTRY] () {\n    do {} while (this[PROCESSENTRY](this[QUEUE].shift()))\n\n    if (!this[QUEUE].length) {\n      // At this point, there's nothing in the queue, but we may have an\n      // entry which is being consumed (readEntry).\n      // If we don't, then we definitely can handle more data.\n      // If we do, and either it's flowing, or it has never had any data\n      // written to it, then it needs more.\n      // The only other possibility is that it has returned false from a\n      // write() call, so we wait for the next drain to continue.\n      const re = this[READENTRY]\n      const drainNow = !re || re.flowing || re.size === re.remain\n      if (drainNow) {\n        if (!this[WRITING]) {\n          this.emit('drain')\n        }\n      } else {\n        re.once('drain', _ => this.emit('drain'))\n      }\n    }\n  }\n\n  [CONSUMEBODY] (chunk, position) {\n    // write up to but no  more than writeEntry.blockRemain\n    const entry = this[WRITEENTRY]\n    const br = entry.blockRemain\n    const c = (br >= chunk.length && position === 0) ? chunk\n      : chunk.slice(position, position + br)\n\n    entry.write(c)\n\n    if (!entry.blockRemain) {\n      this[STATE] = 'header'\n      this[WRITEENTRY] = null\n      entry.end()\n    }\n\n    return c.length\n  }\n\n  [CONSUMEMETA] (chunk, position) {\n    const entry = this[WRITEENTRY]\n    const ret = this[CONSUMEBODY](chunk, position)\n\n    // if we finished, then the entry is reset\n    if (!this[WRITEENTRY]) {\n      this[EMITMETA](entry)\n    }\n\n    return ret\n  }\n\n  [EMIT] (ev, data, extra) {\n    if (!this[QUEUE].length && !this[READENTRY]) {\n      this.emit(ev, data, extra)\n    } else {\n      this[QUEUE].push([ev, data, extra])\n    }\n  }\n\n  [EMITMETA] (entry) {\n    this[EMIT]('meta', this[META])\n    switch (entry.type) {\n      case 'ExtendedHeader':\n      case 'OldExtendedHeader':\n        this[EX] = Pax.parse(this[META], this[EX], false)\n        break\n\n      case 'GlobalExtendedHeader':\n        this[GEX] = Pax.parse(this[META], this[GEX], true)\n        break\n\n      case 'NextFileHasLongPath':\n      case 'OldGnuLongPath':\n        this[EX] = this[EX] || Object.create(null)\n        this[EX].path = this[META].replace(/\\0.*/, '')\n        break\n\n      case 'NextFileHasLongLinkpath':\n        this[EX] = this[EX] || Object.create(null)\n        this[EX].linkpath = this[META].replace(/\\0.*/, '')\n        break\n\n      /* istanbul ignore next */\n      default: throw new Error('unknown meta: ' + entry.type)\n    }\n  }\n\n  abort (error) {\n    this[ABORTED] = true\n    this.emit('abort', error)\n    // always throws, even in non-strict mode\n    this.warn('TAR_ABORT', error, { recoverable: false })\n  }\n\n  write (chunk) {\n    if (this[ABORTED]) {\n      return\n    }\n\n    // first write, might be gzipped\n    const needSniff = this[UNZIP] === null ||\n      this.brotli === undefined && this[UNZIP] === false\n    if (needSniff && chunk) {\n      if (this[BUFFER]) {\n        chunk = Buffer.concat([this[BUFFER], chunk])\n        this[BUFFER] = null\n      }\n      if (chunk.length < gzipHeader.length) {\n        this[BUFFER] = chunk\n        return true\n      }\n\n      // look for gzip header\n      for (let i = 0; this[UNZIP] === null && i < gzipHeader.length; i++) {\n        if (chunk[i] !== gzipHeader[i]) {\n          this[UNZIP] = false\n        }\n      }\n\n      const maybeBrotli = this.brotli === undefined\n      if (this[UNZIP] === false && maybeBrotli) {\n        // read the first header to see if it's a valid tar file. If so,\n        // we can safely assume that it's not actually brotli, despite the\n        // .tbr or .tar.br file extension.\n        // if we ended before getting a full chunk, yes, def brotli\n        if (chunk.length < 512) {\n          if (this[ENDED]) {\n            this.brotli = true\n          } else {\n            this[BUFFER] = chunk\n            return true\n          }\n        } else {\n          // if it's tar, it's pretty reliably not brotli, chances of\n          // that happening are astronomical.\n          try {\n            new Header(chunk.slice(0, 512))\n            this.brotli = false\n          } catch (_) {\n            this.brotli = true\n          }\n        }\n      }\n\n      if (this[UNZIP] === null || (this[UNZIP] === false && this.brotli)) {\n        const ended = this[ENDED]\n        this[ENDED] = false\n        this[UNZIP] = this[UNZIP] === null\n          ? new zlib.Unzip()\n          : new zlib.BrotliDecompress()\n        this[UNZIP].on('data', chunk => this[CONSUMECHUNK](chunk))\n        this[UNZIP].on('error', er => this.abort(er))\n        this[UNZIP].on('end', _ => {\n          this[ENDED] = true\n          this[CONSUMECHUNK]()\n        })\n        this[WRITING] = true\n        const ret = this[UNZIP][ended ? 'end' : 'write'](chunk)\n        this[WRITING] = false\n        return ret\n      }\n    }\n\n    this[WRITING] = true\n    if (this[UNZIP]) {\n      this[UNZIP].write(chunk)\n    } else {\n      this[CONSUMECHUNK](chunk)\n    }\n    this[WRITING] = false\n\n    // return false if there's a queue, or if the current entry isn't flowing\n    const ret =\n      this[QUEUE].length ? false :\n      this[READENTRY] ? this[READENTRY].flowing :\n      true\n\n    // if we have no queue, then that means a clogged READENTRY\n    if (!ret && !this[QUEUE].length) {\n      this[READENTRY].once('drain', _ => this.emit('drain'))\n    }\n\n    return ret\n  }\n\n  [BUFFERCONCAT] (c) {\n    if (c && !this[ABORTED]) {\n      this[BUFFER] = this[BUFFER] ? Buffer.concat([this[BUFFER], c]) : c\n    }\n  }\n\n  [MAYBEEND] () {\n    if (this[ENDED] &&\n        !this[EMITTEDEND] &&\n        !this[ABORTED] &&\n        !this[CONSUMING]) {\n      this[EMITTEDEND] = true\n      const entry = this[WRITEENTRY]\n      if (entry && entry.blockRemain) {\n        // truncated, likely a damaged file\n        const have = this[BUFFER] ? this[BUFFER].length : 0\n        this.warn('TAR_BAD_ARCHIVE', `Truncated input (needed ${\n          entry.blockRemain} more bytes, only ${have} available)`, { entry })\n        if (this[BUFFER]) {\n          entry.write(this[BUFFER])\n        }\n        entry.end()\n      }\n      this[EMIT](DONE)\n    }\n  }\n\n  [CONSUMECHUNK] (chunk) {\n    if (this[CONSUMING]) {\n      this[BUFFERCONCAT](chunk)\n    } else if (!chunk && !this[BUFFER]) {\n      this[MAYBEEND]()\n    } else {\n      this[CONSUMING] = true\n      if (this[BUFFER]) {\n        this[BUFFERCONCAT](chunk)\n        const c = this[BUFFER]\n        this[BUFFER] = null\n        this[CONSUMECHUNKSUB](c)\n      } else {\n        this[CONSUMECHUNKSUB](chunk)\n      }\n\n      while (this[BUFFER] &&\n          this[BUFFER].length >= 512 &&\n          !this[ABORTED] &&\n          !this[SAW_EOF]) {\n        const c = this[BUFFER]\n        this[BUFFER] = null\n        this[CONSUMECHUNKSUB](c)\n      }\n      this[CONSUMING] = false\n    }\n\n    if (!this[BUFFER] || this[ENDED]) {\n      this[MAYBEEND]()\n    }\n  }\n\n  [CONSUMECHUNKSUB] (chunk) {\n    // we know that we are in CONSUMING mode, so anything written goes into\n    // the buffer.  Advance the position and put any remainder in the buffer.\n    let position = 0\n    const length = chunk.length\n    while (position + 512 <= length && !this[ABORTED] && !this[SAW_EOF]) {\n      switch (this[STATE]) {\n        case 'begin':\n        case 'header':\n          this[CONSUMEHEADER](chunk, position)\n          position += 512\n          break\n\n        case 'ignore':\n        case 'body':\n          position += this[CONSUMEBODY](chunk, position)\n          break\n\n        case 'meta':\n          position += this[CONSUMEMETA](chunk, position)\n          break\n\n        /* istanbul ignore next */\n        default:\n          throw new Error('invalid state: ' + this[STATE])\n      }\n    }\n\n    if (position < length) {\n      if (this[BUFFER]) {\n        this[BUFFER] = Buffer.concat([chunk.slice(position), this[BUFFER]])\n      } else {\n        this[BUFFER] = chunk.slice(position)\n      }\n    }\n  }\n\n  end (chunk) {\n    if (!this[ABORTED]) {\n      if (this[UNZIP]) {\n        this[UNZIP].end(chunk)\n      } else {\n        this[ENDED] = true\n        if (this.brotli === undefined) chunk = chunk || Buffer.alloc(0)\n        this.write(chunk)\n      }\n    }\n  }\n})\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/parse.js?");

/***/ }),

/***/ "./node_modules/tar/lib/path-reservations.js":
/*!***************************************************!*\
  !*** ./node_modules/tar/lib/path-reservations.js ***!
  \***************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// A path exclusive reservation system\n// reserve([list, of, paths], fn)\n// When the fn is first in line for all its paths, it\n// is called with a cb that clears the reservation.\n//\n// Used by async unpack to avoid clobbering paths in use,\n// while still allowing maximal safe parallelization.\n\nconst assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst normalize = __webpack_require__(/*! ./normalize-unicode.js */ \"./node_modules/tar/lib/normalize-unicode.js\")\nconst stripSlashes = __webpack_require__(/*! ./strip-trailing-slashes.js */ \"./node_modules/tar/lib/strip-trailing-slashes.js\")\nconst { join } = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\nconst platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platform\nconst isWindows = platform === 'win32'\n\nmodule.exports = () => {\n  // path => [function or Set]\n  // A Set object means a directory reservation\n  // A fn is a direct reservation on that path\n  const queues = new Map()\n\n  // fn => {paths:[path,...], dirs:[path, ...]}\n  const reservations = new Map()\n\n  // return a set of parent dirs for a given path\n  // '/a/b/c/d' -> ['/', '/a', '/a/b', '/a/b/c', '/a/b/c/d']\n  const getDirs = path => {\n    const dirs = path.split('/').slice(0, -1).reduce((set, path) => {\n      if (set.length) {\n        path = join(set[set.length - 1], path)\n      }\n      set.push(path || '/')\n      return set\n    }, [])\n    return dirs\n  }\n\n  // functions currently running\n  const running = new Set()\n\n  // return the queues for each path the function cares about\n  // fn => {paths, dirs}\n  const getQueues = fn => {\n    const res = reservations.get(fn)\n    /* istanbul ignore if - unpossible */\n    if (!res) {\n      throw new Error('function does not have any path reservations')\n    }\n    return {\n      paths: res.paths.map(path => queues.get(path)),\n      dirs: [...res.dirs].map(path => queues.get(path)),\n    }\n  }\n\n  // check if fn is first in line for all its paths, and is\n  // included in the first set for all its dir queues\n  const check = fn => {\n    const { paths, dirs } = getQueues(fn)\n    return paths.every(q => q[0] === fn) &&\n      dirs.every(q => q[0] instanceof Set && q[0].has(fn))\n  }\n\n  // run the function if it's first in line and not already running\n  const run = fn => {\n    if (running.has(fn) || !check(fn)) {\n      return false\n    }\n    running.add(fn)\n    fn(() => clear(fn))\n    return true\n  }\n\n  const clear = fn => {\n    if (!running.has(fn)) {\n      return false\n    }\n\n    const { paths, dirs } = reservations.get(fn)\n    const next = new Set()\n\n    paths.forEach(path => {\n      const q = queues.get(path)\n      assert.equal(q[0], fn)\n      if (q.length === 1) {\n        queues.delete(path)\n      } else {\n        q.shift()\n        if (typeof q[0] === 'function') {\n          next.add(q[0])\n        } else {\n          q[0].forEach(fn => next.add(fn))\n        }\n      }\n    })\n\n    dirs.forEach(dir => {\n      const q = queues.get(dir)\n      assert(q[0] instanceof Set)\n      if (q[0].size === 1 && q.length === 1) {\n        queues.delete(dir)\n      } else if (q[0].size === 1) {\n        q.shift()\n\n        // must be a function or else the Set would've been reused\n        next.add(q[0])\n      } else {\n        q[0].delete(fn)\n      }\n    })\n    running.delete(fn)\n\n    next.forEach(fn => run(fn))\n    return true\n  }\n\n  const reserve = (paths, fn) => {\n    // collide on matches across case and unicode normalization\n    // On windows, thanks to the magic of 8.3 shortnames, it is fundamentally\n    // impossible to determine whether two paths refer to the same thing on\n    // disk, without asking the kernel for a shortname.\n    // So, we just pretend that every path matches every other path here,\n    // effectively removing all parallelization on windows.\n    paths = isWindows ? ['win32 parallelization disabled'] : paths.map(p => {\n      // don't need normPath, because we skip this entirely for windows\n      return stripSlashes(join(normalize(p))).toLowerCase()\n    })\n\n    const dirs = new Set(\n      paths.map(path => getDirs(path)).reduce((a, b) => a.concat(b))\n    )\n    reservations.set(fn, { dirs, paths })\n    paths.forEach(path => {\n      const q = queues.get(path)\n      if (!q) {\n        queues.set(path, [fn])\n      } else {\n        q.push(fn)\n      }\n    })\n    dirs.forEach(dir => {\n      const q = queues.get(dir)\n      if (!q) {\n        queues.set(dir, [new Set([fn])])\n      } else if (q[q.length - 1] instanceof Set) {\n        q[q.length - 1].add(fn)\n      } else {\n        q.push(new Set([fn]))\n      }\n    })\n\n    return run(fn)\n  }\n\n  return { check, reserve }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/path-reservations.js?");

/***/ }),

/***/ "./node_modules/tar/lib/pax.js":
/*!*************************************!*\
  !*** ./node_modules/tar/lib/pax.js ***!
  \*************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst Header = __webpack_require__(/*! ./header.js */ \"./node_modules/tar/lib/header.js\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\nclass Pax {\n  constructor (obj, global) {\n    this.atime = obj.atime || null\n    this.charset = obj.charset || null\n    this.comment = obj.comment || null\n    this.ctime = obj.ctime || null\n    this.gid = obj.gid || null\n    this.gname = obj.gname || null\n    this.linkpath = obj.linkpath || null\n    this.mtime = obj.mtime || null\n    this.path = obj.path || null\n    this.size = obj.size || null\n    this.uid = obj.uid || null\n    this.uname = obj.uname || null\n    this.dev = obj.dev || null\n    this.ino = obj.ino || null\n    this.nlink = obj.nlink || null\n    this.global = global || false\n  }\n\n  encode () {\n    const body = this.encodeBody()\n    if (body === '') {\n      return null\n    }\n\n    const bodyLen = Buffer.byteLength(body)\n    // round up to 512 bytes\n    // add 512 for header\n    const bufLen = 512 * Math.ceil(1 + bodyLen / 512)\n    const buf = Buffer.allocUnsafe(bufLen)\n\n    // 0-fill the header section, it might not hit every field\n    for (let i = 0; i < 512; i++) {\n      buf[i] = 0\n    }\n\n    new Header({\n      // XXX split the path\n      // then the path should be PaxHeader + basename, but less than 99,\n      // prepend with the dirname\n      path: ('PaxHeader/' + path.basename(this.path)).slice(0, 99),\n      mode: this.mode || 0o644,\n      uid: this.uid || null,\n      gid: this.gid || null,\n      size: bodyLen,\n      mtime: this.mtime || null,\n      type: this.global ? 'GlobalExtendedHeader' : 'ExtendedHeader',\n      linkpath: '',\n      uname: this.uname || '',\n      gname: this.gname || '',\n      devmaj: 0,\n      devmin: 0,\n      atime: this.atime || null,\n      ctime: this.ctime || null,\n    }).encode(buf)\n\n    buf.write(body, 512, bodyLen, 'utf8')\n\n    // null pad after the body\n    for (let i = bodyLen + 512; i < buf.length; i++) {\n      buf[i] = 0\n    }\n\n    return buf\n  }\n\n  encodeBody () {\n    return (\n      this.encodeField('path') +\n      this.encodeField('ctime') +\n      this.encodeField('atime') +\n      this.encodeField('dev') +\n      this.encodeField('ino') +\n      this.encodeField('nlink') +\n      this.encodeField('charset') +\n      this.encodeField('comment') +\n      this.encodeField('gid') +\n      this.encodeField('gname') +\n      this.encodeField('linkpath') +\n      this.encodeField('mtime') +\n      this.encodeField('size') +\n      this.encodeField('uid') +\n      this.encodeField('uname')\n    )\n  }\n\n  encodeField (field) {\n    if (this[field] === null || this[field] === undefined) {\n      return ''\n    }\n    const v = this[field] instanceof Date ? this[field].getTime() / 1000\n      : this[field]\n    const s = ' ' +\n      (field === 'dev' || field === 'ino' || field === 'nlink'\n        ? 'SCHILY.' : '') +\n      field + '=' + v + '\\n'\n    const byteLen = Buffer.byteLength(s)\n    // the digits includes the length of the digits in ascii base-10\n    // so if it's 9 characters, then adding 1 for the 9 makes it 10\n    // which makes it 11 chars.\n    let digits = Math.floor(Math.log(byteLen) / Math.log(10)) + 1\n    if (byteLen + digits >= Math.pow(10, digits)) {\n      digits += 1\n    }\n    const len = digits + byteLen\n    return len + s\n  }\n}\n\nPax.parse = (string, ex, g) => new Pax(merge(parseKV(string), ex), g)\n\nconst merge = (a, b) =>\n  b ? Object.keys(a).reduce((s, k) => (s[k] = a[k], s), b) : a\n\nconst parseKV = string =>\n  string\n    .replace(/\\n$/, '')\n    .split('\\n')\n    .reduce(parseKVLine, Object.create(null))\n\nconst parseKVLine = (set, line) => {\n  const n = parseInt(line, 10)\n\n  // XXX Values with \\n in them will fail this.\n  // Refactor to not be a naive line-by-line parse.\n  if (n !== Buffer.byteLength(line) + 1) {\n    return set\n  }\n\n  line = line.slice((n + ' ').length)\n  const kv = line.split('=')\n  const k = kv.shift().replace(/^SCHILY\\.(dev|ino|nlink)/, '$1')\n  if (!k) {\n    return set\n  }\n\n  const v = kv.join('=')\n  set[k] = /^([A-Z]+\\.)?([mac]|birth|creation)time$/.test(k)\n    ? new Date(v * 1000)\n    : /^[0-9]+$/.test(v) ? +v\n    : v\n  return set\n}\n\nmodule.exports = Pax\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/pax.js?");

/***/ }),

/***/ "./node_modules/tar/lib/read-entry.js":
/*!********************************************!*\
  !*** ./node_modules/tar/lib/read-entry.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { Minipass } = __webpack_require__(/*! minipass */ \"./node_modules/minipass/index.js\")\nconst normPath = __webpack_require__(/*! ./normalize-windows-path.js */ \"./node_modules/tar/lib/normalize-windows-path.js\")\n\nconst SLURP = Symbol('slurp')\nmodule.exports = class ReadEntry extends Minipass {\n  constructor (header, ex, gex) {\n    super()\n    // read entries always start life paused.  this is to avoid the\n    // situation where Minipass's auto-ending empty streams results\n    // in an entry ending before we're ready for it.\n    this.pause()\n    this.extended = ex\n    this.globalExtended = gex\n    this.header = header\n    this.startBlockSize = 512 * Math.ceil(header.size / 512)\n    this.blockRemain = this.startBlockSize\n    this.remain = header.size\n    this.type = header.type\n    this.meta = false\n    this.ignore = false\n    switch (this.type) {\n      case 'File':\n      case 'OldFile':\n      case 'Link':\n      case 'SymbolicLink':\n      case 'CharacterDevice':\n      case 'BlockDevice':\n      case 'Directory':\n      case 'FIFO':\n      case 'ContiguousFile':\n      case 'GNUDumpDir':\n        break\n\n      case 'NextFileHasLongLinkpath':\n      case 'NextFileHasLongPath':\n      case 'OldGnuLongPath':\n      case 'GlobalExtendedHeader':\n      case 'ExtendedHeader':\n      case 'OldExtendedHeader':\n        this.meta = true\n        break\n\n      // NOTE: gnutar and bsdtar treat unrecognized types as 'File'\n      // it may be worth doing the same, but with a warning.\n      default:\n        this.ignore = true\n    }\n\n    this.path = normPath(header.path)\n    this.mode = header.mode\n    if (this.mode) {\n      this.mode = this.mode & 0o7777\n    }\n    this.uid = header.uid\n    this.gid = header.gid\n    this.uname = header.uname\n    this.gname = header.gname\n    this.size = header.size\n    this.mtime = header.mtime\n    this.atime = header.atime\n    this.ctime = header.ctime\n    this.linkpath = normPath(header.linkpath)\n    this.uname = header.uname\n    this.gname = header.gname\n\n    if (ex) {\n      this[SLURP](ex)\n    }\n    if (gex) {\n      this[SLURP](gex, true)\n    }\n  }\n\n  write (data) {\n    const writeLen = data.length\n    if (writeLen > this.blockRemain) {\n      throw new Error('writing more to entry than is appropriate')\n    }\n\n    const r = this.remain\n    const br = this.blockRemain\n    this.remain = Math.max(0, r - writeLen)\n    this.blockRemain = Math.max(0, br - writeLen)\n    if (this.ignore) {\n      return true\n    }\n\n    if (r >= writeLen) {\n      return super.write(data)\n    }\n\n    // r < writeLen\n    return super.write(data.slice(0, r))\n  }\n\n  [SLURP] (ex, global) {\n    for (const k in ex) {\n      // we slurp in everything except for the path attribute in\n      // a global extended header, because that's weird.\n      if (ex[k] !== null && ex[k] !== undefined &&\n          !(global && k === 'path')) {\n        this[k] = k === 'path' || k === 'linkpath' ? normPath(ex[k]) : ex[k]\n      }\n    }\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/read-entry.js?");

/***/ }),

/***/ "./node_modules/tar/lib/replace.js":
/*!*****************************************!*\
  !*** ./node_modules/tar/lib/replace.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// tar -r\nconst hlo = __webpack_require__(/*! ./high-level-opt.js */ \"./node_modules/tar/lib/high-level-opt.js\")\nconst Pack = __webpack_require__(/*! ./pack.js */ \"./node_modules/tar/lib/pack.js\")\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst fsm = __webpack_require__(/*! fs-minipass */ \"./node_modules/fs-minipass/index.js\")\nconst t = __webpack_require__(/*! ./list.js */ \"./node_modules/tar/lib/list.js\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\n\n// starting at the head of the file, read a Header\n// If the checksum is invalid, that's our position to start writing\n// If it is, jump forward by the specified size (round up to 512)\n// and try again.\n// Write the new Pack stream starting there.\n\nconst Header = __webpack_require__(/*! ./header.js */ \"./node_modules/tar/lib/header.js\")\n\nmodule.exports = (opt_, files, cb) => {\n  const opt = hlo(opt_)\n\n  if (!opt.file) {\n    throw new TypeError('file is required')\n  }\n\n  if (opt.gzip || opt.brotli || opt.file.endsWith('.br') || opt.file.endsWith('.tbr')) {\n    throw new TypeError('cannot append to compressed archives')\n  }\n\n  if (!files || !Array.isArray(files) || !files.length) {\n    throw new TypeError('no files or directories specified')\n  }\n\n  files = Array.from(files)\n\n  return opt.sync ? replaceSync(opt, files)\n    : replace(opt, files, cb)\n}\n\nconst replaceSync = (opt, files) => {\n  const p = new Pack.Sync(opt)\n\n  let threw = true\n  let fd\n  let position\n\n  try {\n    try {\n      fd = fs.openSync(opt.file, 'r+')\n    } catch (er) {\n      if (er.code === 'ENOENT') {\n        fd = fs.openSync(opt.file, 'w+')\n      } else {\n        throw er\n      }\n    }\n\n    const st = fs.fstatSync(fd)\n    const headBuf = Buffer.alloc(512)\n\n    POSITION: for (position = 0; position < st.size; position += 512) {\n      for (let bufPos = 0, bytes = 0; bufPos < 512; bufPos += bytes) {\n        bytes = fs.readSync(\n          fd, headBuf, bufPos, headBuf.length - bufPos, position + bufPos\n        )\n\n        if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b) {\n          throw new Error('cannot append to compressed archives')\n        }\n\n        if (!bytes) {\n          break POSITION\n        }\n      }\n\n      const h = new Header(headBuf)\n      if (!h.cksumValid) {\n        break\n      }\n      const entryBlockSize = 512 * Math.ceil(h.size / 512)\n      if (position + entryBlockSize + 512 > st.size) {\n        break\n      }\n      // the 512 for the header we just parsed will be added as well\n      // also jump ahead all the blocks for the body\n      position += entryBlockSize\n      if (opt.mtimeCache) {\n        opt.mtimeCache.set(h.path, h.mtime)\n      }\n    }\n    threw = false\n\n    streamSync(opt, p, position, fd, files)\n  } finally {\n    if (threw) {\n      try {\n        fs.closeSync(fd)\n      } catch (er) {}\n    }\n  }\n}\n\nconst streamSync = (opt, p, position, fd, files) => {\n  const stream = new fsm.WriteStreamSync(opt.file, {\n    fd: fd,\n    start: position,\n  })\n  p.pipe(stream)\n  addFilesSync(p, files)\n}\n\nconst replace = (opt, files, cb) => {\n  files = Array.from(files)\n  const p = new Pack(opt)\n\n  const getPos = (fd, size, cb_) => {\n    const cb = (er, pos) => {\n      if (er) {\n        fs.close(fd, _ => cb_(er))\n      } else {\n        cb_(null, pos)\n      }\n    }\n\n    let position = 0\n    if (size === 0) {\n      return cb(null, 0)\n    }\n\n    let bufPos = 0\n    const headBuf = Buffer.alloc(512)\n    const onread = (er, bytes) => {\n      if (er) {\n        return cb(er)\n      }\n      bufPos += bytes\n      if (bufPos < 512 && bytes) {\n        return fs.read(\n          fd, headBuf, bufPos, headBuf.length - bufPos,\n          position + bufPos, onread\n        )\n      }\n\n      if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b) {\n        return cb(new Error('cannot append to compressed archives'))\n      }\n\n      // truncated header\n      if (bufPos < 512) {\n        return cb(null, position)\n      }\n\n      const h = new Header(headBuf)\n      if (!h.cksumValid) {\n        return cb(null, position)\n      }\n\n      const entryBlockSize = 512 * Math.ceil(h.size / 512)\n      if (position + entryBlockSize + 512 > size) {\n        return cb(null, position)\n      }\n\n      position += entryBlockSize + 512\n      if (position >= size) {\n        return cb(null, position)\n      }\n\n      if (opt.mtimeCache) {\n        opt.mtimeCache.set(h.path, h.mtime)\n      }\n      bufPos = 0\n      fs.read(fd, headBuf, 0, 512, position, onread)\n    }\n    fs.read(fd, headBuf, 0, 512, position, onread)\n  }\n\n  const promise = new Promise((resolve, reject) => {\n    p.on('error', reject)\n    let flag = 'r+'\n    const onopen = (er, fd) => {\n      if (er && er.code === 'ENOENT' && flag === 'r+') {\n        flag = 'w+'\n        return fs.open(opt.file, flag, onopen)\n      }\n\n      if (er) {\n        return reject(er)\n      }\n\n      fs.fstat(fd, (er, st) => {\n        if (er) {\n          return fs.close(fd, () => reject(er))\n        }\n\n        getPos(fd, st.size, (er, position) => {\n          if (er) {\n            return reject(er)\n          }\n          const stream = new fsm.WriteStream(opt.file, {\n            fd: fd,\n            start: position,\n          })\n          p.pipe(stream)\n          stream.on('error', reject)\n          stream.on('close', resolve)\n          addFilesAsync(p, files)\n        })\n      })\n    }\n    fs.open(opt.file, flag, onopen)\n  })\n\n  return cb ? promise.then(cb, cb) : promise\n}\n\nconst addFilesSync = (p, files) => {\n  files.forEach(file => {\n    if (file.charAt(0) === '@') {\n      t({\n        file: path.resolve(p.cwd, file.slice(1)),\n        sync: true,\n        noResume: true,\n        onentry: entry => p.add(entry),\n      })\n    } else {\n      p.add(file)\n    }\n  })\n  p.end()\n}\n\nconst addFilesAsync = (p, files) => {\n  while (files.length) {\n    const file = files.shift()\n    if (file.charAt(0) === '@') {\n      return t({\n        file: path.resolve(p.cwd, file.slice(1)),\n        noResume: true,\n        onentry: entry => p.add(entry),\n      }).then(_ => addFilesAsync(p, files))\n    } else {\n      p.add(file)\n    }\n  }\n  p.end()\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/replace.js?");

/***/ }),

/***/ "./node_modules/tar/lib/strip-absolute-path.js":
/*!*****************************************************!*\
  !*** ./node_modules/tar/lib/strip-absolute-path.js ***!
  \*****************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("// unix absolute paths are also absolute on win32, so we use this for both\nconst { isAbsolute, parse } = (__webpack_require__(/*! path */ \"./node_modules/path/path.js\").win32)\n\n// returns [root, stripped]\n// Note that windows will think that //x/y/z/a has a \"root\" of //x/y, and in\n// those cases, we want to sanitize it to x/y/z/a, not z/a, so we strip /\n// explicitly if it's the first character.\n// drive-specific relative paths on Windows get their root stripped off even\n// though they are not absolute, so `c:../foo` becomes ['c:', '../foo']\nmodule.exports = path => {\n  let r = ''\n\n  let parsed = parse(path)\n  while (isAbsolute(path) || parsed.root) {\n    // windows will think that //x/y/z has a \"root\" of //x/y/\n    // but strip the //?/C:/ off of //?/C:/path\n    const root = path.charAt(0) === '/' && path.slice(0, 4) !== '//?/' ? '/'\n      : parsed.root\n    path = path.slice(root.length)\n    r += root\n    parsed = parse(path)\n  }\n  return [r, path]\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/strip-absolute-path.js?");

/***/ }),

/***/ "./node_modules/tar/lib/strip-trailing-slashes.js":
/*!********************************************************!*\
  !*** ./node_modules/tar/lib/strip-trailing-slashes.js ***!
  \********************************************************/
/***/ ((module) => {

eval("// warning: extremely hot code path.\n// This has been meticulously optimized for use\n// within npm install on large package trees.\n// Do not edit without careful benchmarking.\nmodule.exports = str => {\n  let i = str.length - 1\n  let slashesStart = -1\n  while (i > -1 && str.charAt(i) === '/') {\n    slashesStart = i\n    i--\n  }\n  return slashesStart === -1 ? str : str.slice(0, slashesStart)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/strip-trailing-slashes.js?");

/***/ }),

/***/ "./node_modules/tar/lib/types.js":
/*!***************************************!*\
  !*** ./node_modules/tar/lib/types.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports) => {

"use strict";
eval("\n// map types from key to human-friendly name\nexports.name = new Map([\n  ['0', 'File'],\n  // same as File\n  ['', 'OldFile'],\n  ['1', 'Link'],\n  ['2', 'SymbolicLink'],\n  // Devices and FIFOs aren't fully supported\n  // they are parsed, but skipped when unpacking\n  ['3', 'CharacterDevice'],\n  ['4', 'BlockDevice'],\n  ['5', 'Directory'],\n  ['6', 'FIFO'],\n  // same as File\n  ['7', 'ContiguousFile'],\n  // pax headers\n  ['g', 'GlobalExtendedHeader'],\n  ['x', 'ExtendedHeader'],\n  // vendor-specific stuff\n  // skip\n  ['A', 'SolarisACL'],\n  // like 5, but with data, which should be skipped\n  ['D', 'GNUDumpDir'],\n  // metadata only, skip\n  ['I', 'Inode'],\n  // data = link path of next file\n  ['K', 'NextFileHasLongLinkpath'],\n  // data = path of next file\n  ['L', 'NextFileHasLongPath'],\n  // skip\n  ['M', 'ContinuationFile'],\n  // like L\n  ['N', 'OldGnuLongPath'],\n  // skip\n  ['S', 'SparseFile'],\n  // skip\n  ['V', 'TapeVolumeHeader'],\n  // like x\n  ['X', 'OldExtendedHeader'],\n])\n\n// map the other direction\nexports.code = new Map(Array.from(exports.name).map(kv => [kv[1], kv[0]]))\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/types.js?");

/***/ }),

/***/ "./node_modules/tar/lib/unpack.js":
/*!****************************************!*\
  !*** ./node_modules/tar/lib/unpack.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// the PEND/UNPEND stuff tracks whether we're ready to emit end/close yet.\n// but the path reservations are required to avoid race conditions where\n// parallelized unpack ops may mess with one another, due to dependencies\n// (like a Link depending on its target) or destructive operations (like\n// clobbering an fs object to create one of a different type.)\n\nconst assert = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'assert'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst Parser = __webpack_require__(/*! ./parse.js */ \"./node_modules/tar/lib/parse.js\")\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst fsm = __webpack_require__(/*! fs-minipass */ \"./node_modules/fs-minipass/index.js\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst mkdir = __webpack_require__(/*! ./mkdir.js */ \"./node_modules/tar/lib/mkdir.js\")\nconst wc = __webpack_require__(/*! ./winchars.js */ \"./node_modules/tar/lib/winchars.js\")\nconst pathReservations = __webpack_require__(/*! ./path-reservations.js */ \"./node_modules/tar/lib/path-reservations.js\")\nconst stripAbsolutePath = __webpack_require__(/*! ./strip-absolute-path.js */ \"./node_modules/tar/lib/strip-absolute-path.js\")\nconst normPath = __webpack_require__(/*! ./normalize-windows-path.js */ \"./node_modules/tar/lib/normalize-windows-path.js\")\nconst stripSlash = __webpack_require__(/*! ./strip-trailing-slashes.js */ \"./node_modules/tar/lib/strip-trailing-slashes.js\")\nconst normalize = __webpack_require__(/*! ./normalize-unicode.js */ \"./node_modules/tar/lib/normalize-unicode.js\")\n\nconst ONENTRY = Symbol('onEntry')\nconst CHECKFS = Symbol('checkFs')\nconst CHECKFS2 = Symbol('checkFs2')\nconst PRUNECACHE = Symbol('pruneCache')\nconst ISREUSABLE = Symbol('isReusable')\nconst MAKEFS = Symbol('makeFs')\nconst FILE = Symbol('file')\nconst DIRECTORY = Symbol('directory')\nconst LINK = Symbol('link')\nconst SYMLINK = Symbol('symlink')\nconst HARDLINK = Symbol('hardlink')\nconst UNSUPPORTED = Symbol('unsupported')\nconst CHECKPATH = Symbol('checkPath')\nconst MKDIR = Symbol('mkdir')\nconst ONERROR = Symbol('onError')\nconst PENDING = Symbol('pending')\nconst PEND = Symbol('pend')\nconst UNPEND = Symbol('unpend')\nconst ENDED = Symbol('ended')\nconst MAYBECLOSE = Symbol('maybeClose')\nconst SKIP = Symbol('skip')\nconst DOCHOWN = Symbol('doChown')\nconst UID = Symbol('uid')\nconst GID = Symbol('gid')\nconst CHECKED_CWD = Symbol('checkedCwd')\nconst crypto = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'crypto'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst getFlag = __webpack_require__(/*! ./get-write-flag.js */ \"./node_modules/tar/lib/get-write-flag.js\")\nconst platform = process.env.TESTING_TAR_FAKE_PLATFORM || process.platform\nconst isWindows = platform === 'win32'\nconst DEFAULT_MAX_DEPTH = 1024\n\n// Unlinks on Windows are not atomic.\n//\n// This means that if you have a file entry, followed by another\n// file entry with an identical name, and you cannot re-use the file\n// (because it's a hardlink, or because unlink:true is set, or it's\n// Windows, which does not have useful nlink values), then the unlink\n// will be committed to the disk AFTER the new file has been written\n// over the old one, deleting the new file.\n//\n// To work around this, on Windows systems, we rename the file and then\n// delete the renamed file.  It's a sloppy kludge, but frankly, I do not\n// know of a better way to do this, given windows' non-atomic unlink\n// semantics.\n//\n// See: https://github.com/npm/node-tar/issues/183\n/* istanbul ignore next */\nconst unlinkFile = (path, cb) => {\n  if (!isWindows) {\n    return fs.unlink(path, cb)\n  }\n\n  const name = path + '.DELETE.' + crypto.randomBytes(16).toString('hex')\n  fs.rename(path, name, er => {\n    if (er) {\n      return cb(er)\n    }\n    fs.unlink(name, cb)\n  })\n}\n\n/* istanbul ignore next */\nconst unlinkFileSync = path => {\n  if (!isWindows) {\n    return fs.unlinkSync(path)\n  }\n\n  const name = path + '.DELETE.' + crypto.randomBytes(16).toString('hex')\n  fs.renameSync(path, name)\n  fs.unlinkSync(name)\n}\n\n// this.gid, entry.gid, this.processUid\nconst uint32 = (a, b, c) =>\n  a === a >>> 0 ? a\n  : b === b >>> 0 ? b\n  : c\n\n// clear the cache if it's a case-insensitive unicode-squashing match.\n// we can't know if the current file system is case-sensitive or supports\n// unicode fully, so we check for similarity on the maximally compatible\n// representation.  Err on the side of pruning, since all it's doing is\n// preventing lstats, and it's not the end of the world if we get a false\n// positive.\n// Note that on windows, we always drop the entire cache whenever a\n// symbolic link is encountered, because 8.3 filenames are impossible\n// to reason about, and collisions are hazards rather than just failures.\nconst cacheKeyNormalize = path => stripSlash(normPath(normalize(path)))\n  .toLowerCase()\n\nconst pruneCache = (cache, abs) => {\n  abs = cacheKeyNormalize(abs)\n  for (const path of cache.keys()) {\n    const pnorm = cacheKeyNormalize(path)\n    if (pnorm === abs || pnorm.indexOf(abs + '/') === 0) {\n      cache.delete(path)\n    }\n  }\n}\n\nconst dropCache = cache => {\n  for (const key of cache.keys()) {\n    cache.delete(key)\n  }\n}\n\nclass Unpack extends Parser {\n  constructor (opt) {\n    if (!opt) {\n      opt = {}\n    }\n\n    opt.ondone = _ => {\n      this[ENDED] = true\n      this[MAYBECLOSE]()\n    }\n\n    super(opt)\n\n    this[CHECKED_CWD] = false\n\n    this.reservations = pathReservations()\n\n    this.transform = typeof opt.transform === 'function' ? opt.transform : null\n\n    this.writable = true\n    this.readable = false\n\n    this[PENDING] = 0\n    this[ENDED] = false\n\n    this.dirCache = opt.dirCache || new Map()\n\n    if (typeof opt.uid === 'number' || typeof opt.gid === 'number') {\n      // need both or neither\n      if (typeof opt.uid !== 'number' || typeof opt.gid !== 'number') {\n        throw new TypeError('cannot set owner without number uid and gid')\n      }\n      if (opt.preserveOwner) {\n        throw new TypeError(\n          'cannot preserve owner in archive and also set owner explicitly')\n      }\n      this.uid = opt.uid\n      this.gid = opt.gid\n      this.setOwner = true\n    } else {\n      this.uid = null\n      this.gid = null\n      this.setOwner = false\n    }\n\n    // default true for root\n    if (opt.preserveOwner === undefined && typeof opt.uid !== 'number') {\n      this.preserveOwner = process.getuid && process.getuid() === 0\n    } else {\n      this.preserveOwner = !!opt.preserveOwner\n    }\n\n    this.processUid = (this.preserveOwner || this.setOwner) && process.getuid ?\n      process.getuid() : null\n    this.processGid = (this.preserveOwner || this.setOwner) && process.getgid ?\n      process.getgid() : null\n\n    // prevent excessively deep nesting of subfolders\n    // set to `Infinity` to remove this restriction\n    this.maxDepth = typeof opt.maxDepth === 'number'\n      ? opt.maxDepth\n      : DEFAULT_MAX_DEPTH\n\n    // mostly just for testing, but useful in some cases.\n    // Forcibly trigger a chown on every entry, no matter what\n    this.forceChown = opt.forceChown === true\n\n    // turn ><?| in filenames into 0xf000-higher encoded forms\n    this.win32 = !!opt.win32 || isWindows\n\n    // do not unpack over files that are newer than what's in the archive\n    this.newer = !!opt.newer\n\n    // do not unpack over ANY files\n    this.keep = !!opt.keep\n\n    // do not set mtime/atime of extracted entries\n    this.noMtime = !!opt.noMtime\n\n    // allow .., absolute path entries, and unpacking through symlinks\n    // without this, warn and skip .., relativize absolutes, and error\n    // on symlinks in extraction path\n    this.preservePaths = !!opt.preservePaths\n\n    // unlink files and links before writing. This breaks existing hard\n    // links, and removes symlink directories rather than erroring\n    this.unlink = !!opt.unlink\n\n    this.cwd = normPath(path.resolve(opt.cwd || process.cwd()))\n    this.strip = +opt.strip || 0\n    // if we're not chmodding, then we don't need the process umask\n    this.processUmask = opt.noChmod ? 0 : process.umask()\n    this.umask = typeof opt.umask === 'number' ? opt.umask : this.processUmask\n\n    // default mode for dirs created as parents\n    this.dmode = opt.dmode || (0o0777 & (~this.umask))\n    this.fmode = opt.fmode || (0o0666 & (~this.umask))\n\n    this.on('entry', entry => this[ONENTRY](entry))\n  }\n\n  // a bad or damaged archive is a warning for Parser, but an error\n  // when extracting.  Mark those errors as unrecoverable, because\n  // the Unpack contract cannot be met.\n  warn (code, msg, data = {}) {\n    if (code === 'TAR_BAD_ARCHIVE' || code === 'TAR_ABORT') {\n      data.recoverable = false\n    }\n    return super.warn(code, msg, data)\n  }\n\n  [MAYBECLOSE] () {\n    if (this[ENDED] && this[PENDING] === 0) {\n      this.emit('prefinish')\n      this.emit('finish')\n      this.emit('end')\n    }\n  }\n\n  [CHECKPATH] (entry) {\n    const p = normPath(entry.path)\n    const parts = p.split('/')\n\n    if (this.strip) {\n      if (parts.length < this.strip) {\n        return false\n      }\n      if (entry.type === 'Link') {\n        const linkparts = normPath(entry.linkpath).split('/')\n        if (linkparts.length >= this.strip) {\n          entry.linkpath = linkparts.slice(this.strip).join('/')\n        } else {\n          return false\n        }\n      }\n      parts.splice(0, this.strip)\n      entry.path = parts.join('/')\n    }\n\n    if (isFinite(this.maxDepth) && parts.length > this.maxDepth) {\n      this.warn('TAR_ENTRY_ERROR', 'path excessively deep', {\n        entry,\n        path: p,\n        depth: parts.length,\n        maxDepth: this.maxDepth,\n      })\n      return false\n    }\n\n    if (!this.preservePaths) {\n      if (parts.includes('..') || isWindows && /^[a-z]:\\.\\.$/i.test(parts[0])) {\n        this.warn('TAR_ENTRY_ERROR', `path contains '..'`, {\n          entry,\n          path: p,\n        })\n        return false\n      }\n\n      // strip off the root\n      const [root, stripped] = stripAbsolutePath(p)\n      if (root) {\n        entry.path = stripped\n        this.warn('TAR_ENTRY_INFO', `stripping ${root} from absolute path`, {\n          entry,\n          path: p,\n        })\n      }\n    }\n\n    if (path.isAbsolute(entry.path)) {\n      entry.absolute = normPath(path.resolve(entry.path))\n    } else {\n      entry.absolute = normPath(path.resolve(this.cwd, entry.path))\n    }\n\n    // if we somehow ended up with a path that escapes the cwd, and we are\n    // not in preservePaths mode, then something is fishy!  This should have\n    // been prevented above, so ignore this for coverage.\n    /* istanbul ignore if - defense in depth */\n    if (!this.preservePaths &&\n        entry.absolute.indexOf(this.cwd + '/') !== 0 &&\n        entry.absolute !== this.cwd) {\n      this.warn('TAR_ENTRY_ERROR', 'path escaped extraction target', {\n        entry,\n        path: normPath(entry.path),\n        resolvedPath: entry.absolute,\n        cwd: this.cwd,\n      })\n      return false\n    }\n\n    // an archive can set properties on the extraction directory, but it\n    // may not replace the cwd with a different kind of thing entirely.\n    if (entry.absolute === this.cwd &&\n        entry.type !== 'Directory' &&\n        entry.type !== 'GNUDumpDir') {\n      return false\n    }\n\n    // only encode : chars that aren't drive letter indicators\n    if (this.win32) {\n      const { root: aRoot } = path.win32.parse(entry.absolute)\n      entry.absolute = aRoot + wc.encode(entry.absolute.slice(aRoot.length))\n      const { root: pRoot } = path.win32.parse(entry.path)\n      entry.path = pRoot + wc.encode(entry.path.slice(pRoot.length))\n    }\n\n    return true\n  }\n\n  [ONENTRY] (entry) {\n    if (!this[CHECKPATH](entry)) {\n      return entry.resume()\n    }\n\n    assert.equal(typeof entry.absolute, 'string')\n\n    switch (entry.type) {\n      case 'Directory':\n      case 'GNUDumpDir':\n        if (entry.mode) {\n          entry.mode = entry.mode | 0o700\n        }\n\n      // eslint-disable-next-line no-fallthrough\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n      case 'Link':\n      case 'SymbolicLink':\n        return this[CHECKFS](entry)\n\n      case 'CharacterDevice':\n      case 'BlockDevice':\n      case 'FIFO':\n      default:\n        return this[UNSUPPORTED](entry)\n    }\n  }\n\n  [ONERROR] (er, entry) {\n    // Cwd has to exist, or else nothing works. That's serious.\n    // Other errors are warnings, which raise the error in strict\n    // mode, but otherwise continue on.\n    if (er.name === 'CwdError') {\n      this.emit('error', er)\n    } else {\n      this.warn('TAR_ENTRY_ERROR', er, { entry })\n      this[UNPEND]()\n      entry.resume()\n    }\n  }\n\n  [MKDIR] (dir, mode, cb) {\n    mkdir(normPath(dir), {\n      uid: this.uid,\n      gid: this.gid,\n      processUid: this.processUid,\n      processGid: this.processGid,\n      umask: this.processUmask,\n      preserve: this.preservePaths,\n      unlink: this.unlink,\n      cache: this.dirCache,\n      cwd: this.cwd,\n      mode: mode,\n      noChmod: this.noChmod,\n    }, cb)\n  }\n\n  [DOCHOWN] (entry) {\n    // in preserve owner mode, chown if the entry doesn't match process\n    // in set owner mode, chown if setting doesn't match process\n    return this.forceChown ||\n      this.preserveOwner &&\n      (typeof entry.uid === 'number' && entry.uid !== this.processUid ||\n        typeof entry.gid === 'number' && entry.gid !== this.processGid)\n      ||\n      (typeof this.uid === 'number' && this.uid !== this.processUid ||\n        typeof this.gid === 'number' && this.gid !== this.processGid)\n  }\n\n  [UID] (entry) {\n    return uint32(this.uid, entry.uid, this.processUid)\n  }\n\n  [GID] (entry) {\n    return uint32(this.gid, entry.gid, this.processGid)\n  }\n\n  [FILE] (entry, fullyDone) {\n    const mode = entry.mode & 0o7777 || this.fmode\n    const stream = new fsm.WriteStream(entry.absolute, {\n      flags: getFlag(entry.size),\n      mode: mode,\n      autoClose: false,\n    })\n    stream.on('error', er => {\n      if (stream.fd) {\n        fs.close(stream.fd, () => {})\n      }\n\n      // flush all the data out so that we aren't left hanging\n      // if the error wasn't actually fatal.  otherwise the parse\n      // is blocked, and we never proceed.\n      stream.write = () => true\n      this[ONERROR](er, entry)\n      fullyDone()\n    })\n\n    let actions = 1\n    const done = er => {\n      if (er) {\n        /* istanbul ignore else - we should always have a fd by now */\n        if (stream.fd) {\n          fs.close(stream.fd, () => {})\n        }\n\n        this[ONERROR](er, entry)\n        fullyDone()\n        return\n      }\n\n      if (--actions === 0) {\n        fs.close(stream.fd, er => {\n          if (er) {\n            this[ONERROR](er, entry)\n          } else {\n            this[UNPEND]()\n          }\n          fullyDone()\n        })\n      }\n    }\n\n    stream.on('finish', _ => {\n      // if futimes fails, try utimes\n      // if utimes fails, fail with the original error\n      // same for fchown/chown\n      const abs = entry.absolute\n      const fd = stream.fd\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        fs.futimes(fd, atime, mtime, er =>\n          er ? fs.utimes(abs, atime, mtime, er2 => done(er2 && er))\n          : done())\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n        fs.fchown(fd, uid, gid, er =>\n          er ? fs.chown(abs, uid, gid, er2 => done(er2 && er))\n          : done())\n      }\n\n      done()\n    })\n\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry) {\n      tx.on('error', er => {\n        this[ONERROR](er, entry)\n        fullyDone()\n      })\n      entry.pipe(tx)\n    }\n    tx.pipe(stream)\n  }\n\n  [DIRECTORY] (entry, fullyDone) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    this[MKDIR](entry.absolute, mode, er => {\n      if (er) {\n        this[ONERROR](er, entry)\n        fullyDone()\n        return\n      }\n\n      let actions = 1\n      const done = _ => {\n        if (--actions === 0) {\n          fullyDone()\n          this[UNPEND]()\n          entry.resume()\n        }\n      }\n\n      if (entry.mtime && !this.noMtime) {\n        actions++\n        fs.utimes(entry.absolute, entry.atime || new Date(), entry.mtime, done)\n      }\n\n      if (this[DOCHOWN](entry)) {\n        actions++\n        fs.chown(entry.absolute, this[UID](entry), this[GID](entry), done)\n      }\n\n      done()\n    })\n  }\n\n  [UNSUPPORTED] (entry) {\n    entry.unsupported = true\n    this.warn('TAR_ENTRY_UNSUPPORTED',\n      `unsupported entry type: ${entry.type}`, { entry })\n    entry.resume()\n  }\n\n  [SYMLINK] (entry, done) {\n    this[LINK](entry, entry.linkpath, 'symlink', done)\n  }\n\n  [HARDLINK] (entry, done) {\n    const linkpath = normPath(path.resolve(this.cwd, entry.linkpath))\n    this[LINK](entry, linkpath, 'link', done)\n  }\n\n  [PEND] () {\n    this[PENDING]++\n  }\n\n  [UNPEND] () {\n    this[PENDING]--\n    this[MAYBECLOSE]()\n  }\n\n  [SKIP] (entry) {\n    this[UNPEND]()\n    entry.resume()\n  }\n\n  // Check if we can reuse an existing filesystem entry safely and\n  // overwrite it, rather than unlinking and recreating\n  // Windows doesn't report a useful nlink, so we just never reuse entries\n  [ISREUSABLE] (entry, st) {\n    return entry.type === 'File' &&\n      !this.unlink &&\n      st.isFile() &&\n      st.nlink <= 1 &&\n      !isWindows\n  }\n\n  // check if a thing is there, and if so, try to clobber it\n  [CHECKFS] (entry) {\n    this[PEND]()\n    const paths = [entry.path]\n    if (entry.linkpath) {\n      paths.push(entry.linkpath)\n    }\n    this.reservations.reserve(paths, done => this[CHECKFS2](entry, done))\n  }\n\n  [PRUNECACHE] (entry) {\n    // if we are not creating a directory, and the path is in the dirCache,\n    // then that means we are about to delete the directory we created\n    // previously, and it is no longer going to be a directory, and neither\n    // is any of its children.\n    // If a symbolic link is encountered, all bets are off.  There is no\n    // reasonable way to sanitize the cache in such a way we will be able to\n    // avoid having filesystem collisions.  If this happens with a non-symlink\n    // entry, it'll just fail to unpack, but a symlink to a directory, using an\n    // 8.3 shortname or certain unicode attacks, can evade detection and lead\n    // to arbitrary writes to anywhere on the system.\n    if (entry.type === 'SymbolicLink') {\n      dropCache(this.dirCache)\n    } else if (entry.type !== 'Directory') {\n      pruneCache(this.dirCache, entry.absolute)\n    }\n  }\n\n  [CHECKFS2] (entry, fullyDone) {\n    this[PRUNECACHE](entry)\n\n    const done = er => {\n      this[PRUNECACHE](entry)\n      fullyDone(er)\n    }\n\n    const checkCwd = () => {\n      this[MKDIR](this.cwd, this.dmode, er => {\n        if (er) {\n          this[ONERROR](er, entry)\n          done()\n          return\n        }\n        this[CHECKED_CWD] = true\n        start()\n      })\n    }\n\n    const start = () => {\n      if (entry.absolute !== this.cwd) {\n        const parent = normPath(path.dirname(entry.absolute))\n        if (parent !== this.cwd) {\n          return this[MKDIR](parent, this.dmode, er => {\n            if (er) {\n              this[ONERROR](er, entry)\n              done()\n              return\n            }\n            afterMakeParent()\n          })\n        }\n      }\n      afterMakeParent()\n    }\n\n    const afterMakeParent = () => {\n      fs.lstat(entry.absolute, (lstatEr, st) => {\n        if (st && (this.keep || this.newer && st.mtime > entry.mtime)) {\n          this[SKIP](entry)\n          done()\n          return\n        }\n        if (lstatEr || this[ISREUSABLE](entry, st)) {\n          return this[MAKEFS](null, entry, done)\n        }\n\n        if (st.isDirectory()) {\n          if (entry.type === 'Directory') {\n            const needChmod = !this.noChmod &&\n              entry.mode &&\n              (st.mode & 0o7777) !== entry.mode\n            const afterChmod = er => this[MAKEFS](er, entry, done)\n            if (!needChmod) {\n              return afterChmod()\n            }\n            return fs.chmod(entry.absolute, entry.mode, afterChmod)\n          }\n          // Not a dir entry, have to remove it.\n          // NB: the only way to end up with an entry that is the cwd\n          // itself, in such a way that == does not detect, is a\n          // tricky windows absolute path with UNC or 8.3 parts (and\n          // preservePaths:true, or else it will have been stripped).\n          // In that case, the user has opted out of path protections\n          // explicitly, so if they blow away the cwd, c'est la vie.\n          if (entry.absolute !== this.cwd) {\n            return fs.rmdir(entry.absolute, er =>\n              this[MAKEFS](er, entry, done))\n          }\n        }\n\n        // not a dir, and not reusable\n        // don't remove if the cwd, we want that error\n        if (entry.absolute === this.cwd) {\n          return this[MAKEFS](null, entry, done)\n        }\n\n        unlinkFile(entry.absolute, er =>\n          this[MAKEFS](er, entry, done))\n      })\n    }\n\n    if (this[CHECKED_CWD]) {\n      start()\n    } else {\n      checkCwd()\n    }\n  }\n\n  [MAKEFS] (er, entry, done) {\n    if (er) {\n      this[ONERROR](er, entry)\n      done()\n      return\n    }\n\n    switch (entry.type) {\n      case 'File':\n      case 'OldFile':\n      case 'ContiguousFile':\n        return this[FILE](entry, done)\n\n      case 'Link':\n        return this[HARDLINK](entry, done)\n\n      case 'SymbolicLink':\n        return this[SYMLINK](entry, done)\n\n      case 'Directory':\n      case 'GNUDumpDir':\n        return this[DIRECTORY](entry, done)\n    }\n  }\n\n  [LINK] (entry, linkpath, link, done) {\n    // XXX: get the type ('symlink' or 'junction') for windows\n    fs[link](linkpath, entry.absolute, er => {\n      if (er) {\n        this[ONERROR](er, entry)\n      } else {\n        this[UNPEND]()\n        entry.resume()\n      }\n      done()\n    })\n  }\n}\n\nconst callSync = fn => {\n  try {\n    return [null, fn()]\n  } catch (er) {\n    return [er, null]\n  }\n}\nclass UnpackSync extends Unpack {\n  [MAKEFS] (er, entry) {\n    return super[MAKEFS](er, entry, () => {})\n  }\n\n  [CHECKFS] (entry) {\n    this[PRUNECACHE](entry)\n\n    if (!this[CHECKED_CWD]) {\n      const er = this[MKDIR](this.cwd, this.dmode)\n      if (er) {\n        return this[ONERROR](er, entry)\n      }\n      this[CHECKED_CWD] = true\n    }\n\n    // don't bother to make the parent if the current entry is the cwd,\n    // we've already checked it.\n    if (entry.absolute !== this.cwd) {\n      const parent = normPath(path.dirname(entry.absolute))\n      if (parent !== this.cwd) {\n        const mkParent = this[MKDIR](parent, this.dmode)\n        if (mkParent) {\n          return this[ONERROR](mkParent, entry)\n        }\n      }\n    }\n\n    const [lstatEr, st] = callSync(() => fs.lstatSync(entry.absolute))\n    if (st && (this.keep || this.newer && st.mtime > entry.mtime)) {\n      return this[SKIP](entry)\n    }\n\n    if (lstatEr || this[ISREUSABLE](entry, st)) {\n      return this[MAKEFS](null, entry)\n    }\n\n    if (st.isDirectory()) {\n      if (entry.type === 'Directory') {\n        const needChmod = !this.noChmod &&\n          entry.mode &&\n          (st.mode & 0o7777) !== entry.mode\n        const [er] = needChmod ? callSync(() => {\n          fs.chmodSync(entry.absolute, entry.mode)\n        }) : []\n        return this[MAKEFS](er, entry)\n      }\n      // not a dir entry, have to remove it\n      const [er] = callSync(() => fs.rmdirSync(entry.absolute))\n      this[MAKEFS](er, entry)\n    }\n\n    // not a dir, and not reusable.\n    // don't remove if it's the cwd, since we want that error.\n    const [er] = entry.absolute === this.cwd ? []\n      : callSync(() => unlinkFileSync(entry.absolute))\n    this[MAKEFS](er, entry)\n  }\n\n  [FILE] (entry, done) {\n    const mode = entry.mode & 0o7777 || this.fmode\n\n    const oner = er => {\n      let closeError\n      try {\n        fs.closeSync(fd)\n      } catch (e) {\n        closeError = e\n      }\n      if (er || closeError) {\n        this[ONERROR](er || closeError, entry)\n      }\n      done()\n    }\n\n    let fd\n    try {\n      fd = fs.openSync(entry.absolute, getFlag(entry.size), mode)\n    } catch (er) {\n      return oner(er)\n    }\n    const tx = this.transform ? this.transform(entry) || entry : entry\n    if (tx !== entry) {\n      tx.on('error', er => this[ONERROR](er, entry))\n      entry.pipe(tx)\n    }\n\n    tx.on('data', chunk => {\n      try {\n        fs.writeSync(fd, chunk, 0, chunk.length)\n      } catch (er) {\n        oner(er)\n      }\n    })\n\n    tx.on('end', _ => {\n      let er = null\n      // try both, falling futimes back to utimes\n      // if either fails, handle the first error\n      if (entry.mtime && !this.noMtime) {\n        const atime = entry.atime || new Date()\n        const mtime = entry.mtime\n        try {\n          fs.futimesSync(fd, atime, mtime)\n        } catch (futimeser) {\n          try {\n            fs.utimesSync(entry.absolute, atime, mtime)\n          } catch (utimeser) {\n            er = futimeser\n          }\n        }\n      }\n\n      if (this[DOCHOWN](entry)) {\n        const uid = this[UID](entry)\n        const gid = this[GID](entry)\n\n        try {\n          fs.fchownSync(fd, uid, gid)\n        } catch (fchowner) {\n          try {\n            fs.chownSync(entry.absolute, uid, gid)\n          } catch (chowner) {\n            er = er || fchowner\n          }\n        }\n      }\n\n      oner(er)\n    })\n  }\n\n  [DIRECTORY] (entry, done) {\n    const mode = entry.mode & 0o7777 || this.dmode\n    const er = this[MKDIR](entry.absolute, mode)\n    if (er) {\n      this[ONERROR](er, entry)\n      done()\n      return\n    }\n    if (entry.mtime && !this.noMtime) {\n      try {\n        fs.utimesSync(entry.absolute, entry.atime || new Date(), entry.mtime)\n      } catch (er) {}\n    }\n    if (this[DOCHOWN](entry)) {\n      try {\n        fs.chownSync(entry.absolute, this[UID](entry), this[GID](entry))\n      } catch (er) {}\n    }\n    done()\n    entry.resume()\n  }\n\n  [MKDIR] (dir, mode) {\n    try {\n      return mkdir.sync(normPath(dir), {\n        uid: this.uid,\n        gid: this.gid,\n        processUid: this.processUid,\n        processGid: this.processGid,\n        umask: this.processUmask,\n        preserve: this.preservePaths,\n        unlink: this.unlink,\n        cache: this.dirCache,\n        cwd: this.cwd,\n        mode: mode,\n      })\n    } catch (er) {\n      return er\n    }\n  }\n\n  [LINK] (entry, linkpath, link, done) {\n    try {\n      fs[link + 'Sync'](linkpath, entry.absolute)\n      done()\n      entry.resume()\n    } catch (er) {\n      return this[ONERROR](er, entry)\n    }\n  }\n}\n\nUnpack.Sync = UnpackSync\nmodule.exports = Unpack\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/unpack.js?");

/***/ }),

/***/ "./node_modules/tar/lib/update.js":
/*!****************************************!*\
  !*** ./node_modules/tar/lib/update.js ***!
  \****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\n// tar -u\n\nconst hlo = __webpack_require__(/*! ./high-level-opt.js */ \"./node_modules/tar/lib/high-level-opt.js\")\nconst r = __webpack_require__(/*! ./replace.js */ \"./node_modules/tar/lib/replace.js\")\n// just call tar.r with the filter and mtimeCache\n\nmodule.exports = (opt_, files, cb) => {\n  const opt = hlo(opt_)\n\n  if (!opt.file) {\n    throw new TypeError('file is required')\n  }\n\n  if (opt.gzip || opt.brotli || opt.file.endsWith('.br') || opt.file.endsWith('.tbr')) {\n    throw new TypeError('cannot append to compressed archives')\n  }\n\n  if (!files || !Array.isArray(files) || !files.length) {\n    throw new TypeError('no files or directories specified')\n  }\n\n  files = Array.from(files)\n\n  mtimeFilter(opt)\n  return r(opt, files, cb)\n}\n\nconst mtimeFilter = opt => {\n  const filter = opt.filter\n\n  if (!opt.mtimeCache) {\n    opt.mtimeCache = new Map()\n  }\n\n  opt.filter = filter ? (path, stat) =>\n    filter(path, stat) && !(opt.mtimeCache.get(path) > stat.mtime)\n    : (path, stat) => !(opt.mtimeCache.get(path) > stat.mtime)\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/update.js?");

/***/ }),

/***/ "./node_modules/tar/lib/warn-mixin.js":
/*!********************************************!*\
  !*** ./node_modules/tar/lib/warn-mixin.js ***!
  \********************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = Base => class extends Base {\n  warn (code, message, data = {}) {\n    if (this.file) {\n      data.file = this.file\n    }\n    if (this.cwd) {\n      data.cwd = this.cwd\n    }\n    data.code = message instanceof Error && message.code || code\n    data.tarCode = code\n    if (!this.strict && data.recoverable !== false) {\n      if (message instanceof Error) {\n        data = Object.assign(message, data)\n        message = message.message\n      }\n      this.emit('warn', data.tarCode, message, data)\n    } else if (message instanceof Error) {\n      this.emit('error', Object.assign(message, data))\n    } else {\n      this.emit('error', Object.assign(new Error(`${code}: ${message}`), data))\n    }\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/warn-mixin.js?");

/***/ }),

/***/ "./node_modules/tar/lib/winchars.js":
/*!******************************************!*\
  !*** ./node_modules/tar/lib/winchars.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\n\n// When writing files on Windows, translate the characters to their\n// 0xf000 higher-encoded versions.\n\nconst raw = [\n  '|',\n  '<',\n  '>',\n  '?',\n  ':',\n]\n\nconst win = raw.map(char =>\n  String.fromCharCode(0xf000 + char.charCodeAt(0)))\n\nconst toWin = new Map(raw.map((char, i) => [char, win[i]]))\nconst toRaw = new Map(win.map((char, i) => [char, raw[i]]))\n\nmodule.exports = {\n  encode: s => raw.reduce((s, c) => s.split(c).join(toWin.get(c)), s),\n  decode: s => win.reduce((s, c) => s.split(c).join(toRaw.get(c)), s),\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/winchars.js?");

/***/ }),

/***/ "./node_modules/tar/lib/write-entry.js":
/*!*********************************************!*\
  !*** ./node_modules/tar/lib/write-entry.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nconst { Minipass } = __webpack_require__(/*! minipass */ \"./node_modules/minipass/index.js\")\nconst Pax = __webpack_require__(/*! ./pax.js */ \"./node_modules/tar/lib/pax.js\")\nconst Header = __webpack_require__(/*! ./header.js */ \"./node_modules/tar/lib/header.js\")\nconst fs = __webpack_require__(/*! fs */ \"?fde7\")\nconst path = __webpack_require__(/*! path */ \"./node_modules/path/path.js\")\nconst normPath = __webpack_require__(/*! ./normalize-windows-path.js */ \"./node_modules/tar/lib/normalize-windows-path.js\")\nconst stripSlash = __webpack_require__(/*! ./strip-trailing-slashes.js */ \"./node_modules/tar/lib/strip-trailing-slashes.js\")\n\nconst prefixPath = (path, prefix) => {\n  if (!prefix) {\n    return normPath(path)\n  }\n  path = normPath(path).replace(/^\\.(\\/|$)/, '')\n  return stripSlash(prefix) + '/' + path\n}\n\nconst maxReadSize = 16 * 1024 * 1024\nconst PROCESS = Symbol('process')\nconst FILE = Symbol('file')\nconst DIRECTORY = Symbol('directory')\nconst SYMLINK = Symbol('symlink')\nconst HARDLINK = Symbol('hardlink')\nconst HEADER = Symbol('header')\nconst READ = Symbol('read')\nconst LSTAT = Symbol('lstat')\nconst ONLSTAT = Symbol('onlstat')\nconst ONREAD = Symbol('onread')\nconst ONREADLINK = Symbol('onreadlink')\nconst OPENFILE = Symbol('openfile')\nconst ONOPENFILE = Symbol('onopenfile')\nconst CLOSE = Symbol('close')\nconst MODE = Symbol('mode')\nconst AWAITDRAIN = Symbol('awaitDrain')\nconst ONDRAIN = Symbol('ondrain')\nconst PREFIX = Symbol('prefix')\nconst HAD_ERROR = Symbol('hadError')\nconst warner = __webpack_require__(/*! ./warn-mixin.js */ \"./node_modules/tar/lib/warn-mixin.js\")\nconst winchars = __webpack_require__(/*! ./winchars.js */ \"./node_modules/tar/lib/winchars.js\")\nconst stripAbsolutePath = __webpack_require__(/*! ./strip-absolute-path.js */ \"./node_modules/tar/lib/strip-absolute-path.js\")\n\nconst modeFix = __webpack_require__(/*! ./mode-fix.js */ \"./node_modules/tar/lib/mode-fix.js\")\n\nconst WriteEntry = warner(class WriteEntry extends Minipass {\n  constructor (p, opt) {\n    opt = opt || {}\n    super(opt)\n    if (typeof p !== 'string') {\n      throw new TypeError('path is required')\n    }\n    this.path = normPath(p)\n    // suppress atime, ctime, uid, gid, uname, gname\n    this.portable = !!opt.portable\n    // until node has builtin pwnam functions, this'll have to do\n    this.myuid = process.getuid && process.getuid() || 0\n    this.myuser = process.env.USER || ''\n    this.maxReadSize = opt.maxReadSize || maxReadSize\n    this.linkCache = opt.linkCache || new Map()\n    this.statCache = opt.statCache || new Map()\n    this.preservePaths = !!opt.preservePaths\n    this.cwd = normPath(opt.cwd || process.cwd())\n    this.strict = !!opt.strict\n    this.noPax = !!opt.noPax\n    this.noMtime = !!opt.noMtime\n    this.mtime = opt.mtime || null\n    this.prefix = opt.prefix ? normPath(opt.prefix) : null\n\n    this.fd = null\n    this.blockLen = null\n    this.blockRemain = null\n    this.buf = null\n    this.offset = null\n    this.length = null\n    this.pos = null\n    this.remain = null\n\n    if (typeof opt.onwarn === 'function') {\n      this.on('warn', opt.onwarn)\n    }\n\n    let pathWarn = false\n    if (!this.preservePaths) {\n      const [root, stripped] = stripAbsolutePath(this.path)\n      if (root) {\n        this.path = stripped\n        pathWarn = root\n      }\n    }\n\n    this.win32 = !!opt.win32 || process.platform === 'win32'\n    if (this.win32) {\n      // force the \\ to / normalization, since we might not *actually*\n      // be on windows, but want \\ to be considered a path separator.\n      this.path = winchars.decode(this.path.replace(/\\\\/g, '/'))\n      p = p.replace(/\\\\/g, '/')\n    }\n\n    this.absolute = normPath(opt.absolute || path.resolve(this.cwd, p))\n\n    if (this.path === '') {\n      this.path = './'\n    }\n\n    if (pathWarn) {\n      this.warn('TAR_ENTRY_INFO', `stripping ${pathWarn} from absolute path`, {\n        entry: this,\n        path: pathWarn + this.path,\n      })\n    }\n\n    if (this.statCache.has(this.absolute)) {\n      this[ONLSTAT](this.statCache.get(this.absolute))\n    } else {\n      this[LSTAT]()\n    }\n  }\n\n  emit (ev, ...data) {\n    if (ev === 'error') {\n      this[HAD_ERROR] = true\n    }\n    return super.emit(ev, ...data)\n  }\n\n  [LSTAT] () {\n    fs.lstat(this.absolute, (er, stat) => {\n      if (er) {\n        return this.emit('error', er)\n      }\n      this[ONLSTAT](stat)\n    })\n  }\n\n  [ONLSTAT] (stat) {\n    this.statCache.set(this.absolute, stat)\n    this.stat = stat\n    if (!stat.isFile()) {\n      stat.size = 0\n    }\n    this.type = getType(stat)\n    this.emit('stat', stat)\n    this[PROCESS]()\n  }\n\n  [PROCESS] () {\n    switch (this.type) {\n      case 'File': return this[FILE]()\n      case 'Directory': return this[DIRECTORY]()\n      case 'SymbolicLink': return this[SYMLINK]()\n      // unsupported types are ignored.\n      default: return this.end()\n    }\n  }\n\n  [MODE] (mode) {\n    return modeFix(mode, this.type === 'Directory', this.portable)\n  }\n\n  [PREFIX] (path) {\n    return prefixPath(path, this.prefix)\n  }\n\n  [HEADER] () {\n    if (this.type === 'Directory' && this.portable) {\n      this.noMtime = true\n    }\n\n    this.header = new Header({\n      path: this[PREFIX](this.path),\n      // only apply the prefix to hard links.\n      linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n      : this.linkpath,\n      // only the permissions and setuid/setgid/sticky bitflags\n      // not the higher-order bits that specify file type\n      mode: this[MODE](this.stat.mode),\n      uid: this.portable ? null : this.stat.uid,\n      gid: this.portable ? null : this.stat.gid,\n      size: this.stat.size,\n      mtime: this.noMtime ? null : this.mtime || this.stat.mtime,\n      type: this.type,\n      uname: this.portable ? null :\n      this.stat.uid === this.myuid ? this.myuser : '',\n      atime: this.portable ? null : this.stat.atime,\n      ctime: this.portable ? null : this.stat.ctime,\n    })\n\n    if (this.header.encode() && !this.noPax) {\n      super.write(new Pax({\n        atime: this.portable ? null : this.header.atime,\n        ctime: this.portable ? null : this.header.ctime,\n        gid: this.portable ? null : this.header.gid,\n        mtime: this.noMtime ? null : this.mtime || this.header.mtime,\n        path: this[PREFIX](this.path),\n        linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n        : this.linkpath,\n        size: this.header.size,\n        uid: this.portable ? null : this.header.uid,\n        uname: this.portable ? null : this.header.uname,\n        dev: this.portable ? null : this.stat.dev,\n        ino: this.portable ? null : this.stat.ino,\n        nlink: this.portable ? null : this.stat.nlink,\n      }).encode())\n    }\n    super.write(this.header.block)\n  }\n\n  [DIRECTORY] () {\n    if (this.path.slice(-1) !== '/') {\n      this.path += '/'\n    }\n    this.stat.size = 0\n    this[HEADER]()\n    this.end()\n  }\n\n  [SYMLINK] () {\n    fs.readlink(this.absolute, (er, linkpath) => {\n      if (er) {\n        return this.emit('error', er)\n      }\n      this[ONREADLINK](linkpath)\n    })\n  }\n\n  [ONREADLINK] (linkpath) {\n    this.linkpath = normPath(linkpath)\n    this[HEADER]()\n    this.end()\n  }\n\n  [HARDLINK] (linkpath) {\n    this.type = 'Link'\n    this.linkpath = normPath(path.relative(this.cwd, linkpath))\n    this.stat.size = 0\n    this[HEADER]()\n    this.end()\n  }\n\n  [FILE] () {\n    if (this.stat.nlink > 1) {\n      const linkKey = this.stat.dev + ':' + this.stat.ino\n      if (this.linkCache.has(linkKey)) {\n        const linkpath = this.linkCache.get(linkKey)\n        if (linkpath.indexOf(this.cwd) === 0) {\n          return this[HARDLINK](linkpath)\n        }\n      }\n      this.linkCache.set(linkKey, this.absolute)\n    }\n\n    this[HEADER]()\n    if (this.stat.size === 0) {\n      return this.end()\n    }\n\n    this[OPENFILE]()\n  }\n\n  [OPENFILE] () {\n    fs.open(this.absolute, 'r', (er, fd) => {\n      if (er) {\n        return this.emit('error', er)\n      }\n      this[ONOPENFILE](fd)\n    })\n  }\n\n  [ONOPENFILE] (fd) {\n    this.fd = fd\n    if (this[HAD_ERROR]) {\n      return this[CLOSE]()\n    }\n\n    this.blockLen = 512 * Math.ceil(this.stat.size / 512)\n    this.blockRemain = this.blockLen\n    const bufLen = Math.min(this.blockLen, this.maxReadSize)\n    this.buf = Buffer.allocUnsafe(bufLen)\n    this.offset = 0\n    this.pos = 0\n    this.remain = this.stat.size\n    this.length = this.buf.length\n    this[READ]()\n  }\n\n  [READ] () {\n    const { fd, buf, offset, length, pos } = this\n    fs.read(fd, buf, offset, length, pos, (er, bytesRead) => {\n      if (er) {\n        // ignoring the error from close(2) is a bad practice, but at\n        // this point we already have an error, don't need another one\n        return this[CLOSE](() => this.emit('error', er))\n      }\n      this[ONREAD](bytesRead)\n    })\n  }\n\n  [CLOSE] (cb) {\n    fs.close(this.fd, cb)\n  }\n\n  [ONREAD] (bytesRead) {\n    if (bytesRead <= 0 && this.remain > 0) {\n      const er = new Error('encountered unexpected EOF')\n      er.path = this.absolute\n      er.syscall = 'read'\n      er.code = 'EOF'\n      return this[CLOSE](() => this.emit('error', er))\n    }\n\n    if (bytesRead > this.remain) {\n      const er = new Error('did not encounter expected EOF')\n      er.path = this.absolute\n      er.syscall = 'read'\n      er.code = 'EOF'\n      return this[CLOSE](() => this.emit('error', er))\n    }\n\n    // null out the rest of the buffer, if we could fit the block padding\n    // at the end of this loop, we've incremented bytesRead and this.remain\n    // to be incremented up to the blockRemain level, as if we had expected\n    // to get a null-padded file, and read it until the end.  then we will\n    // decrement both remain and blockRemain by bytesRead, and know that we\n    // reached the expected EOF, without any null buffer to append.\n    if (bytesRead === this.remain) {\n      for (let i = bytesRead; i < this.length && bytesRead < this.blockRemain; i++) {\n        this.buf[i + this.offset] = 0\n        bytesRead++\n        this.remain++\n      }\n    }\n\n    const writeBuf = this.offset === 0 && bytesRead === this.buf.length ?\n      this.buf : this.buf.slice(this.offset, this.offset + bytesRead)\n\n    const flushed = this.write(writeBuf)\n    if (!flushed) {\n      this[AWAITDRAIN](() => this[ONDRAIN]())\n    } else {\n      this[ONDRAIN]()\n    }\n  }\n\n  [AWAITDRAIN] (cb) {\n    this.once('drain', cb)\n  }\n\n  write (writeBuf) {\n    if (this.blockRemain < writeBuf.length) {\n      const er = new Error('writing more data than expected')\n      er.path = this.absolute\n      return this.emit('error', er)\n    }\n    this.remain -= writeBuf.length\n    this.blockRemain -= writeBuf.length\n    this.pos += writeBuf.length\n    this.offset += writeBuf.length\n    return super.write(writeBuf)\n  }\n\n  [ONDRAIN] () {\n    if (!this.remain) {\n      if (this.blockRemain) {\n        super.write(Buffer.alloc(this.blockRemain))\n      }\n      return this[CLOSE](er => er ? this.emit('error', er) : this.end())\n    }\n\n    if (this.offset >= this.length) {\n      // if we only have a smaller bit left to read, alloc a smaller buffer\n      // otherwise, keep it the same length it was before.\n      this.buf = Buffer.allocUnsafe(Math.min(this.blockRemain, this.buf.length))\n      this.offset = 0\n    }\n    this.length = this.buf.length - this.offset\n    this[READ]()\n  }\n})\n\nclass WriteEntrySync extends WriteEntry {\n  [LSTAT] () {\n    this[ONLSTAT](fs.lstatSync(this.absolute))\n  }\n\n  [SYMLINK] () {\n    this[ONREADLINK](fs.readlinkSync(this.absolute))\n  }\n\n  [OPENFILE] () {\n    this[ONOPENFILE](fs.openSync(this.absolute, 'r'))\n  }\n\n  [READ] () {\n    let threw = true\n    try {\n      const { fd, buf, offset, length, pos } = this\n      const bytesRead = fs.readSync(fd, buf, offset, length, pos)\n      this[ONREAD](bytesRead)\n      threw = false\n    } finally {\n      // ignoring the error from close(2) is a bad practice, but at\n      // this point we already have an error, don't need another one\n      if (threw) {\n        try {\n          this[CLOSE](() => {})\n        } catch (er) {}\n      }\n    }\n  }\n\n  [AWAITDRAIN] (cb) {\n    cb()\n  }\n\n  [CLOSE] (cb) {\n    fs.closeSync(this.fd)\n    cb()\n  }\n}\n\nconst WriteEntryTar = warner(class WriteEntryTar extends Minipass {\n  constructor (readEntry, opt) {\n    opt = opt || {}\n    super(opt)\n    this.preservePaths = !!opt.preservePaths\n    this.portable = !!opt.portable\n    this.strict = !!opt.strict\n    this.noPax = !!opt.noPax\n    this.noMtime = !!opt.noMtime\n\n    this.readEntry = readEntry\n    this.type = readEntry.type\n    if (this.type === 'Directory' && this.portable) {\n      this.noMtime = true\n    }\n\n    this.prefix = opt.prefix || null\n\n    this.path = normPath(readEntry.path)\n    this.mode = this[MODE](readEntry.mode)\n    this.uid = this.portable ? null : readEntry.uid\n    this.gid = this.portable ? null : readEntry.gid\n    this.uname = this.portable ? null : readEntry.uname\n    this.gname = this.portable ? null : readEntry.gname\n    this.size = readEntry.size\n    this.mtime = this.noMtime ? null : opt.mtime || readEntry.mtime\n    this.atime = this.portable ? null : readEntry.atime\n    this.ctime = this.portable ? null : readEntry.ctime\n    this.linkpath = normPath(readEntry.linkpath)\n\n    if (typeof opt.onwarn === 'function') {\n      this.on('warn', opt.onwarn)\n    }\n\n    let pathWarn = false\n    if (!this.preservePaths) {\n      const [root, stripped] = stripAbsolutePath(this.path)\n      if (root) {\n        this.path = stripped\n        pathWarn = root\n      }\n    }\n\n    this.remain = readEntry.size\n    this.blockRemain = readEntry.startBlockSize\n\n    this.header = new Header({\n      path: this[PREFIX](this.path),\n      linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n      : this.linkpath,\n      // only the permissions and setuid/setgid/sticky bitflags\n      // not the higher-order bits that specify file type\n      mode: this.mode,\n      uid: this.portable ? null : this.uid,\n      gid: this.portable ? null : this.gid,\n      size: this.size,\n      mtime: this.noMtime ? null : this.mtime,\n      type: this.type,\n      uname: this.portable ? null : this.uname,\n      atime: this.portable ? null : this.atime,\n      ctime: this.portable ? null : this.ctime,\n    })\n\n    if (pathWarn) {\n      this.warn('TAR_ENTRY_INFO', `stripping ${pathWarn} from absolute path`, {\n        entry: this,\n        path: pathWarn + this.path,\n      })\n    }\n\n    if (this.header.encode() && !this.noPax) {\n      super.write(new Pax({\n        atime: this.portable ? null : this.atime,\n        ctime: this.portable ? null : this.ctime,\n        gid: this.portable ? null : this.gid,\n        mtime: this.noMtime ? null : this.mtime,\n        path: this[PREFIX](this.path),\n        linkpath: this.type === 'Link' ? this[PREFIX](this.linkpath)\n        : this.linkpath,\n        size: this.size,\n        uid: this.portable ? null : this.uid,\n        uname: this.portable ? null : this.uname,\n        dev: this.portable ? null : this.readEntry.dev,\n        ino: this.portable ? null : this.readEntry.ino,\n        nlink: this.portable ? null : this.readEntry.nlink,\n      }).encode())\n    }\n\n    super.write(this.header.block)\n    readEntry.pipe(this)\n  }\n\n  [PREFIX] (path) {\n    return prefixPath(path, this.prefix)\n  }\n\n  [MODE] (mode) {\n    return modeFix(mode, this.type === 'Directory', this.portable)\n  }\n\n  write (data) {\n    const writeLen = data.length\n    if (writeLen > this.blockRemain) {\n      throw new Error('writing more to entry than is appropriate')\n    }\n    this.blockRemain -= writeLen\n    return super.write(data)\n  }\n\n  end () {\n    if (this.blockRemain) {\n      super.write(Buffer.alloc(this.blockRemain))\n    }\n    return super.end()\n  }\n})\n\nWriteEntry.Sync = WriteEntrySync\nWriteEntry.Tar = WriteEntryTar\n\nconst getType = stat =>\n  stat.isFile() ? 'File'\n  : stat.isDirectory() ? 'Directory'\n  : stat.isSymbolicLink() ? 'SymbolicLink'\n  : 'Unsupported'\n\nmodule.exports = WriteEntry\n\n\n//# sourceURL=webpack://thelambda/./node_modules/tar/lib/write-entry.js?");

/***/ }),

/***/ "./node_modules/url/node_modules/punycode/punycode.js":
/*!************************************************************!*\
  !*** ./node_modules/url/node_modules/punycode/punycode.js ***!
  \************************************************************/
/***/ (function(module, exports, __webpack_require__) {

eval("/* module decorator */ module = __webpack_require__.nmd(module);\nvar __WEBPACK_AMD_DEFINE_RESULT__;/*! https://mths.be/punycode v1.4.1 by @mathias */\n;(function(root) {\n\n\t/** Detect free variables */\n\tvar freeExports =  true && exports &&\n\t\t!exports.nodeType && exports;\n\tvar freeModule =  true && module &&\n\t\t!module.nodeType && module;\n\tvar freeGlobal = typeof __webpack_require__.g == 'object' && __webpack_require__.g;\n\tif (\n\t\tfreeGlobal.global === freeGlobal ||\n\t\tfreeGlobal.window === freeGlobal ||\n\t\tfreeGlobal.self === freeGlobal\n\t) {\n\t\troot = freeGlobal;\n\t}\n\n\t/**\n\t * The `punycode` object.\n\t * @name punycode\n\t * @type Object\n\t */\n\tvar punycode,\n\n\t/** Highest positive signed 32-bit float value */\n\tmaxInt = 2147483647, // aka. 0x7FFFFFFF or 2^31-1\n\n\t/** Bootstring parameters */\n\tbase = 36,\n\ttMin = 1,\n\ttMax = 26,\n\tskew = 38,\n\tdamp = 700,\n\tinitialBias = 72,\n\tinitialN = 128, // 0x80\n\tdelimiter = '-', // '\\x2D'\n\n\t/** Regular expressions */\n\tregexPunycode = /^xn--/,\n\tregexNonASCII = /[^\\x20-\\x7E]/, // unprintable ASCII chars + non-ASCII chars\n\tregexSeparators = /[\\x2E\\u3002\\uFF0E\\uFF61]/g, // RFC 3490 separators\n\n\t/** Error messages */\n\terrors = {\n\t\t'overflow': 'Overflow: input needs wider integers to process',\n\t\t'not-basic': 'Illegal input >= 0x80 (not a basic code point)',\n\t\t'invalid-input': 'Invalid input'\n\t},\n\n\t/** Convenience shortcuts */\n\tbaseMinusTMin = base - tMin,\n\tfloor = Math.floor,\n\tstringFromCharCode = String.fromCharCode,\n\n\t/** Temporary variable */\n\tkey;\n\n\t/*--------------------------------------------------------------------------*/\n\n\t/**\n\t * A generic error utility function.\n\t * @private\n\t * @param {String} type The error type.\n\t * @returns {Error} Throws a `RangeError` with the applicable error message.\n\t */\n\tfunction error(type) {\n\t\tthrow new RangeError(errors[type]);\n\t}\n\n\t/**\n\t * A generic `Array#map` utility function.\n\t * @private\n\t * @param {Array} array The array to iterate over.\n\t * @param {Function} callback The function that gets called for every array\n\t * item.\n\t * @returns {Array} A new array of values returned by the callback function.\n\t */\n\tfunction map(array, fn) {\n\t\tvar length = array.length;\n\t\tvar result = [];\n\t\twhile (length--) {\n\t\t\tresult[length] = fn(array[length]);\n\t\t}\n\t\treturn result;\n\t}\n\n\t/**\n\t * A simple `Array#map`-like wrapper to work with domain name strings or email\n\t * addresses.\n\t * @private\n\t * @param {String} domain The domain name or email address.\n\t * @param {Function} callback The function that gets called for every\n\t * character.\n\t * @returns {Array} A new string of characters returned by the callback\n\t * function.\n\t */\n\tfunction mapDomain(string, fn) {\n\t\tvar parts = string.split('@');\n\t\tvar result = '';\n\t\tif (parts.length > 1) {\n\t\t\t// In email addresses, only the domain name should be punycoded. Leave\n\t\t\t// the local part (i.e. everything up to `@`) intact.\n\t\t\tresult = parts[0] + '@';\n\t\t\tstring = parts[1];\n\t\t}\n\t\t// Avoid `split(regex)` for IE8 compatibility. See #17.\n\t\tstring = string.replace(regexSeparators, '\\x2E');\n\t\tvar labels = string.split('.');\n\t\tvar encoded = map(labels, fn).join('.');\n\t\treturn result + encoded;\n\t}\n\n\t/**\n\t * Creates an array containing the numeric code points of each Unicode\n\t * character in the string. While JavaScript uses UCS-2 internally,\n\t * this function will convert a pair of surrogate halves (each of which\n\t * UCS-2 exposes as separate characters) into a single code point,\n\t * matching UTF-16.\n\t * @see `punycode.ucs2.encode`\n\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t * @memberOf punycode.ucs2\n\t * @name decode\n\t * @param {String} string The Unicode input string (UCS-2).\n\t * @returns {Array} The new array of code points.\n\t */\n\tfunction ucs2decode(string) {\n\t\tvar output = [],\n\t\t    counter = 0,\n\t\t    length = string.length,\n\t\t    value,\n\t\t    extra;\n\t\twhile (counter < length) {\n\t\t\tvalue = string.charCodeAt(counter++);\n\t\t\tif (value >= 0xD800 && value <= 0xDBFF && counter < length) {\n\t\t\t\t// high surrogate, and there is a next character\n\t\t\t\textra = string.charCodeAt(counter++);\n\t\t\t\tif ((extra & 0xFC00) == 0xDC00) { // low surrogate\n\t\t\t\t\toutput.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);\n\t\t\t\t} else {\n\t\t\t\t\t// unmatched surrogate; only append this code unit, in case the next\n\t\t\t\t\t// code unit is the high surrogate of a surrogate pair\n\t\t\t\t\toutput.push(value);\n\t\t\t\t\tcounter--;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\toutput.push(value);\n\t\t\t}\n\t\t}\n\t\treturn output;\n\t}\n\n\t/**\n\t * Creates a string based on an array of numeric code points.\n\t * @see `punycode.ucs2.decode`\n\t * @memberOf punycode.ucs2\n\t * @name encode\n\t * @param {Array} codePoints The array of numeric code points.\n\t * @returns {String} The new Unicode string (UCS-2).\n\t */\n\tfunction ucs2encode(array) {\n\t\treturn map(array, function(value) {\n\t\t\tvar output = '';\n\t\t\tif (value > 0xFFFF) {\n\t\t\t\tvalue -= 0x10000;\n\t\t\t\toutput += stringFromCharCode(value >>> 10 & 0x3FF | 0xD800);\n\t\t\t\tvalue = 0xDC00 | value & 0x3FF;\n\t\t\t}\n\t\t\toutput += stringFromCharCode(value);\n\t\t\treturn output;\n\t\t}).join('');\n\t}\n\n\t/**\n\t * Converts a basic code point into a digit/integer.\n\t * @see `digitToBasic()`\n\t * @private\n\t * @param {Number} codePoint The basic numeric code point value.\n\t * @returns {Number} The numeric value of a basic code point (for use in\n\t * representing integers) in the range `0` to `base - 1`, or `base` if\n\t * the code point does not represent a value.\n\t */\n\tfunction basicToDigit(codePoint) {\n\t\tif (codePoint - 48 < 10) {\n\t\t\treturn codePoint - 22;\n\t\t}\n\t\tif (codePoint - 65 < 26) {\n\t\t\treturn codePoint - 65;\n\t\t}\n\t\tif (codePoint - 97 < 26) {\n\t\t\treturn codePoint - 97;\n\t\t}\n\t\treturn base;\n\t}\n\n\t/**\n\t * Converts a digit/integer into a basic code point.\n\t * @see `basicToDigit()`\n\t * @private\n\t * @param {Number} digit The numeric value of a basic code point.\n\t * @returns {Number} The basic code point whose value (when used for\n\t * representing integers) is `digit`, which needs to be in the range\n\t * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is\n\t * used; else, the lowercase form is used. The behavior is undefined\n\t * if `flag` is non-zero and `digit` has no uppercase form.\n\t */\n\tfunction digitToBasic(digit, flag) {\n\t\t//  0..25 map to ASCII a..z or A..Z\n\t\t// 26..35 map to ASCII 0..9\n\t\treturn digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);\n\t}\n\n\t/**\n\t * Bias adaptation function as per section 3.4 of RFC 3492.\n\t * https://tools.ietf.org/html/rfc3492#section-3.4\n\t * @private\n\t */\n\tfunction adapt(delta, numPoints, firstTime) {\n\t\tvar k = 0;\n\t\tdelta = firstTime ? floor(delta / damp) : delta >> 1;\n\t\tdelta += floor(delta / numPoints);\n\t\tfor (/* no initialization */; delta > baseMinusTMin * tMax >> 1; k += base) {\n\t\t\tdelta = floor(delta / baseMinusTMin);\n\t\t}\n\t\treturn floor(k + (baseMinusTMin + 1) * delta / (delta + skew));\n\t}\n\n\t/**\n\t * Converts a Punycode string of ASCII-only symbols to a string of Unicode\n\t * symbols.\n\t * @memberOf punycode\n\t * @param {String} input The Punycode string of ASCII-only symbols.\n\t * @returns {String} The resulting string of Unicode symbols.\n\t */\n\tfunction decode(input) {\n\t\t// Don't use UCS-2\n\t\tvar output = [],\n\t\t    inputLength = input.length,\n\t\t    out,\n\t\t    i = 0,\n\t\t    n = initialN,\n\t\t    bias = initialBias,\n\t\t    basic,\n\t\t    j,\n\t\t    index,\n\t\t    oldi,\n\t\t    w,\n\t\t    k,\n\t\t    digit,\n\t\t    t,\n\t\t    /** Cached calculation results */\n\t\t    baseMinusT;\n\n\t\t// Handle the basic code points: let `basic` be the number of input code\n\t\t// points before the last delimiter, or `0` if there is none, then copy\n\t\t// the first basic code points to the output.\n\n\t\tbasic = input.lastIndexOf(delimiter);\n\t\tif (basic < 0) {\n\t\t\tbasic = 0;\n\t\t}\n\n\t\tfor (j = 0; j < basic; ++j) {\n\t\t\t// if it's not a basic code point\n\t\t\tif (input.charCodeAt(j) >= 0x80) {\n\t\t\t\terror('not-basic');\n\t\t\t}\n\t\t\toutput.push(input.charCodeAt(j));\n\t\t}\n\n\t\t// Main decoding loop: start just after the last delimiter if any basic code\n\t\t// points were copied; start at the beginning otherwise.\n\n\t\tfor (index = basic > 0 ? basic + 1 : 0; index < inputLength; /* no final expression */) {\n\n\t\t\t// `index` is the index of the next character to be consumed.\n\t\t\t// Decode a generalized variable-length integer into `delta`,\n\t\t\t// which gets added to `i`. The overflow checking is easier\n\t\t\t// if we increase `i` as we go, then subtract off its starting\n\t\t\t// value at the end to obtain `delta`.\n\t\t\tfor (oldi = i, w = 1, k = base; /* no condition */; k += base) {\n\n\t\t\t\tif (index >= inputLength) {\n\t\t\t\t\terror('invalid-input');\n\t\t\t\t}\n\n\t\t\t\tdigit = basicToDigit(input.charCodeAt(index++));\n\n\t\t\t\tif (digit >= base || digit > floor((maxInt - i) / w)) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\ti += digit * w;\n\t\t\t\tt = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\n\t\t\t\tif (digit < t) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tbaseMinusT = base - t;\n\t\t\t\tif (w > floor(maxInt / baseMinusT)) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\tw *= baseMinusT;\n\n\t\t\t}\n\n\t\t\tout = output.length + 1;\n\t\t\tbias = adapt(i - oldi, out, oldi == 0);\n\n\t\t\t// `i` was supposed to wrap around from `out` to `0`,\n\t\t\t// incrementing `n` each time, so we'll fix that now:\n\t\t\tif (floor(i / out) > maxInt - n) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tn += floor(i / out);\n\t\t\ti %= out;\n\n\t\t\t// Insert `n` at position `i` of the output\n\t\t\toutput.splice(i++, 0, n);\n\n\t\t}\n\n\t\treturn ucs2encode(output);\n\t}\n\n\t/**\n\t * Converts a string of Unicode symbols (e.g. a domain name label) to a\n\t * Punycode string of ASCII-only symbols.\n\t * @memberOf punycode\n\t * @param {String} input The string of Unicode symbols.\n\t * @returns {String} The resulting Punycode string of ASCII-only symbols.\n\t */\n\tfunction encode(input) {\n\t\tvar n,\n\t\t    delta,\n\t\t    handledCPCount,\n\t\t    basicLength,\n\t\t    bias,\n\t\t    j,\n\t\t    m,\n\t\t    q,\n\t\t    k,\n\t\t    t,\n\t\t    currentValue,\n\t\t    output = [],\n\t\t    /** `inputLength` will hold the number of code points in `input`. */\n\t\t    inputLength,\n\t\t    /** Cached calculation results */\n\t\t    handledCPCountPlusOne,\n\t\t    baseMinusT,\n\t\t    qMinusT;\n\n\t\t// Convert the input in UCS-2 to Unicode\n\t\tinput = ucs2decode(input);\n\n\t\t// Cache the length\n\t\tinputLength = input.length;\n\n\t\t// Initialize the state\n\t\tn = initialN;\n\t\tdelta = 0;\n\t\tbias = initialBias;\n\n\t\t// Handle the basic code points\n\t\tfor (j = 0; j < inputLength; ++j) {\n\t\t\tcurrentValue = input[j];\n\t\t\tif (currentValue < 0x80) {\n\t\t\t\toutput.push(stringFromCharCode(currentValue));\n\t\t\t}\n\t\t}\n\n\t\thandledCPCount = basicLength = output.length;\n\n\t\t// `handledCPCount` is the number of code points that have been handled;\n\t\t// `basicLength` is the number of basic code points.\n\n\t\t// Finish the basic string - if it is not empty - with a delimiter\n\t\tif (basicLength) {\n\t\t\toutput.push(delimiter);\n\t\t}\n\n\t\t// Main encoding loop:\n\t\twhile (handledCPCount < inputLength) {\n\n\t\t\t// All non-basic code points < n have been handled already. Find the next\n\t\t\t// larger one:\n\t\t\tfor (m = maxInt, j = 0; j < inputLength; ++j) {\n\t\t\t\tcurrentValue = input[j];\n\t\t\t\tif (currentValue >= n && currentValue < m) {\n\t\t\t\t\tm = currentValue;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,\n\t\t\t// but guard against overflow\n\t\t\thandledCPCountPlusOne = handledCPCount + 1;\n\t\t\tif (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {\n\t\t\t\terror('overflow');\n\t\t\t}\n\n\t\t\tdelta += (m - n) * handledCPCountPlusOne;\n\t\t\tn = m;\n\n\t\t\tfor (j = 0; j < inputLength; ++j) {\n\t\t\t\tcurrentValue = input[j];\n\n\t\t\t\tif (currentValue < n && ++delta > maxInt) {\n\t\t\t\t\terror('overflow');\n\t\t\t\t}\n\n\t\t\t\tif (currentValue == n) {\n\t\t\t\t\t// Represent delta as a generalized variable-length integer\n\t\t\t\t\tfor (q = delta, k = base; /* no condition */; k += base) {\n\t\t\t\t\t\tt = k <= bias ? tMin : (k >= bias + tMax ? tMax : k - bias);\n\t\t\t\t\t\tif (q < t) {\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tqMinusT = q - t;\n\t\t\t\t\t\tbaseMinusT = base - t;\n\t\t\t\t\t\toutput.push(\n\t\t\t\t\t\t\tstringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0))\n\t\t\t\t\t\t);\n\t\t\t\t\t\tq = floor(qMinusT / baseMinusT);\n\t\t\t\t\t}\n\n\t\t\t\t\toutput.push(stringFromCharCode(digitToBasic(q, 0)));\n\t\t\t\t\tbias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);\n\t\t\t\t\tdelta = 0;\n\t\t\t\t\t++handledCPCount;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t++delta;\n\t\t\t++n;\n\n\t\t}\n\t\treturn output.join('');\n\t}\n\n\t/**\n\t * Converts a Punycode string representing a domain name or an email address\n\t * to Unicode. Only the Punycoded parts of the input will be converted, i.e.\n\t * it doesn't matter if you call it on a string that has already been\n\t * converted to Unicode.\n\t * @memberOf punycode\n\t * @param {String} input The Punycoded domain name or email address to\n\t * convert to Unicode.\n\t * @returns {String} The Unicode representation of the given Punycode\n\t * string.\n\t */\n\tfunction toUnicode(input) {\n\t\treturn mapDomain(input, function(string) {\n\t\t\treturn regexPunycode.test(string)\n\t\t\t\t? decode(string.slice(4).toLowerCase())\n\t\t\t\t: string;\n\t\t});\n\t}\n\n\t/**\n\t * Converts a Unicode string representing a domain name or an email address to\n\t * Punycode. Only the non-ASCII parts of the domain name will be converted,\n\t * i.e. it doesn't matter if you call it with a domain that's already in\n\t * ASCII.\n\t * @memberOf punycode\n\t * @param {String} input The domain name or email address to convert, as a\n\t * Unicode string.\n\t * @returns {String} The Punycode representation of the given domain name or\n\t * email address.\n\t */\n\tfunction toASCII(input) {\n\t\treturn mapDomain(input, function(string) {\n\t\t\treturn regexNonASCII.test(string)\n\t\t\t\t? 'xn--' + encode(string)\n\t\t\t\t: string;\n\t\t});\n\t}\n\n\t/*--------------------------------------------------------------------------*/\n\n\t/** Define the public API */\n\tpunycode = {\n\t\t/**\n\t\t * A string representing the current Punycode.js version number.\n\t\t * @memberOf punycode\n\t\t * @type String\n\t\t */\n\t\t'version': '1.4.1',\n\t\t/**\n\t\t * An object of methods to convert from JavaScript's internal character\n\t\t * representation (UCS-2) to Unicode code points, and back.\n\t\t * @see <https://mathiasbynens.be/notes/javascript-encoding>\n\t\t * @memberOf punycode\n\t\t * @type Object\n\t\t */\n\t\t'ucs2': {\n\t\t\t'decode': ucs2decode,\n\t\t\t'encode': ucs2encode\n\t\t},\n\t\t'decode': decode,\n\t\t'encode': encode,\n\t\t'toASCII': toASCII,\n\t\t'toUnicode': toUnicode\n\t};\n\n\t/** Expose `punycode` */\n\t// Some AMD build optimizers, like r.js, check for specific condition patterns\n\t// like the following:\n\tif (\n\t\ttrue\n\t) {\n\t\t!(__WEBPACK_AMD_DEFINE_RESULT__ = (function() {\n\t\t\treturn punycode;\n\t\t}).call(exports, __webpack_require__, exports, module),\n\t\t__WEBPACK_AMD_DEFINE_RESULT__ !== undefined && (module.exports = __WEBPACK_AMD_DEFINE_RESULT__));\n\t} else {}\n\n}(this));\n\n\n//# sourceURL=webpack://thelambda/./node_modules/url/node_modules/punycode/punycode.js?");

/***/ }),

/***/ "./node_modules/url/url.js":
/*!*********************************!*\
  !*** ./node_modules/url/url.js ***!
  \*********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("/*\n * Copyright Joyent, Inc. and other Node contributors.\n *\n * Permission is hereby granted, free of charge, to any person obtaining a\n * copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sublicense, and/or sell copies of the Software, and to permit\n * persons to whom the Software is furnished to do so, subject to the\n * following conditions:\n *\n * The above copyright notice and this permission notice shall be included\n * in all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n * NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n * USE OR OTHER DEALINGS IN THE SOFTWARE.\n */\n\n\n\nvar punycode = __webpack_require__(/*! punycode/ */ \"./node_modules/url/node_modules/punycode/punycode.js\");\n\nfunction Url() {\n  this.protocol = null;\n  this.slashes = null;\n  this.auth = null;\n  this.host = null;\n  this.port = null;\n  this.hostname = null;\n  this.hash = null;\n  this.search = null;\n  this.query = null;\n  this.pathname = null;\n  this.path = null;\n  this.href = null;\n}\n\n// Reference: RFC 3986, RFC 1808, RFC 2396\n\n/*\n * define these here so at least they only have to be\n * compiled once on the first module load.\n */\nvar protocolPattern = /^([a-z0-9.+-]+:)/i,\n  portPattern = /:[0-9]*$/,\n\n  // Special case for a simple path URL\n  simplePathPattern = /^(\\/\\/?(?!\\/)[^?\\s]*)(\\?[^\\s]*)?$/,\n\n  /*\n   * RFC 2396: characters reserved for delimiting URLs.\n   * We actually just auto-escape these.\n   */\n  delims = [\n    '<', '>', '\"', '`', ' ', '\\r', '\\n', '\\t'\n  ],\n\n  // RFC 2396: characters not allowed for various reasons.\n  unwise = [\n    '{', '}', '|', '\\\\', '^', '`'\n  ].concat(delims),\n\n  // Allowed by RFCs, but cause of XSS attacks.  Always escape these.\n  autoEscape = ['\\''].concat(unwise),\n  /*\n   * Characters that are never ever allowed in a hostname.\n   * Note that any invalid chars are also handled, but these\n   * are the ones that are *expected* to be seen, so we fast-path\n   * them.\n   */\n  nonHostChars = [\n    '%', '/', '?', ';', '#'\n  ].concat(autoEscape),\n  hostEndingChars = [\n    '/', '?', '#'\n  ],\n  hostnameMaxLen = 255,\n  hostnamePartPattern = /^[+a-z0-9A-Z_-]{0,63}$/,\n  hostnamePartStart = /^([+a-z0-9A-Z_-]{0,63})(.*)$/,\n  // protocols that can allow \"unsafe\" and \"unwise\" chars.\n  unsafeProtocol = {\n    javascript: true,\n    'javascript:': true\n  },\n  // protocols that never have a hostname.\n  hostlessProtocol = {\n    javascript: true,\n    'javascript:': true\n  },\n  // protocols that always contain a // bit.\n  slashedProtocol = {\n    http: true,\n    https: true,\n    ftp: true,\n    gopher: true,\n    file: true,\n    'http:': true,\n    'https:': true,\n    'ftp:': true,\n    'gopher:': true,\n    'file:': true\n  },\n  querystring = __webpack_require__(/*! qs */ \"./node_modules/qs/lib/index.js\");\n\nfunction urlParse(url, parseQueryString, slashesDenoteHost) {\n  if (url && typeof url === 'object' && url instanceof Url) { return url; }\n\n  var u = new Url();\n  u.parse(url, parseQueryString, slashesDenoteHost);\n  return u;\n}\n\nUrl.prototype.parse = function (url, parseQueryString, slashesDenoteHost) {\n  if (typeof url !== 'string') {\n    throw new TypeError(\"Parameter 'url' must be a string, not \" + typeof url);\n  }\n\n  /*\n   * Copy chrome, IE, opera backslash-handling behavior.\n   * Back slashes before the query string get converted to forward slashes\n   * See: https://code.google.com/p/chromium/issues/detail?id=25916\n   */\n  var queryIndex = url.indexOf('?'),\n    splitter = queryIndex !== -1 && queryIndex < url.indexOf('#') ? '?' : '#',\n    uSplit = url.split(splitter),\n    slashRegex = /\\\\/g;\n  uSplit[0] = uSplit[0].replace(slashRegex, '/');\n  url = uSplit.join(splitter);\n\n  var rest = url;\n\n  /*\n   * trim before proceeding.\n   * This is to support parse stuff like \"  http://foo.com  \\n\"\n   */\n  rest = rest.trim();\n\n  if (!slashesDenoteHost && url.split('#').length === 1) {\n    // Try fast path regexp\n    var simplePath = simplePathPattern.exec(rest);\n    if (simplePath) {\n      this.path = rest;\n      this.href = rest;\n      this.pathname = simplePath[1];\n      if (simplePath[2]) {\n        this.search = simplePath[2];\n        if (parseQueryString) {\n          this.query = querystring.parse(this.search.substr(1));\n        } else {\n          this.query = this.search.substr(1);\n        }\n      } else if (parseQueryString) {\n        this.search = '';\n        this.query = {};\n      }\n      return this;\n    }\n  }\n\n  var proto = protocolPattern.exec(rest);\n  if (proto) {\n    proto = proto[0];\n    var lowerProto = proto.toLowerCase();\n    this.protocol = lowerProto;\n    rest = rest.substr(proto.length);\n  }\n\n  /*\n   * figure out if it's got a host\n   * user@server is *always* interpreted as a hostname, and url\n   * resolution will treat //foo/bar as host=foo,path=bar because that's\n   * how the browser resolves relative URLs.\n   */\n  if (slashesDenoteHost || proto || rest.match(/^\\/\\/[^@/]+@[^@/]+/)) {\n    var slashes = rest.substr(0, 2) === '//';\n    if (slashes && !(proto && hostlessProtocol[proto])) {\n      rest = rest.substr(2);\n      this.slashes = true;\n    }\n  }\n\n  if (!hostlessProtocol[proto] && (slashes || (proto && !slashedProtocol[proto]))) {\n\n    /*\n     * there's a hostname.\n     * the first instance of /, ?, ;, or # ends the host.\n     *\n     * If there is an @ in the hostname, then non-host chars *are* allowed\n     * to the left of the last @ sign, unless some host-ending character\n     * comes *before* the @-sign.\n     * URLs are obnoxious.\n     *\n     * ex:\n     * http://a@b@c/ => user:a@b host:c\n     * http://a@b?@c => user:a host:c path:/?@c\n     */\n\n    /*\n     * v0.12 TODO(isaacs): This is not quite how Chrome does things.\n     * Review our test case against browsers more comprehensively.\n     */\n\n    // find the first instance of any hostEndingChars\n    var hostEnd = -1;\n    for (var i = 0; i < hostEndingChars.length; i++) {\n      var hec = rest.indexOf(hostEndingChars[i]);\n      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd)) { hostEnd = hec; }\n    }\n\n    /*\n     * at this point, either we have an explicit point where the\n     * auth portion cannot go past, or the last @ char is the decider.\n     */\n    var auth, atSign;\n    if (hostEnd === -1) {\n      // atSign can be anywhere.\n      atSign = rest.lastIndexOf('@');\n    } else {\n      /*\n       * atSign must be in auth portion.\n       * http://a@b/c@d => host:b auth:a path:/c@d\n       */\n      atSign = rest.lastIndexOf('@', hostEnd);\n    }\n\n    /*\n     * Now we have a portion which is definitely the auth.\n     * Pull that off.\n     */\n    if (atSign !== -1) {\n      auth = rest.slice(0, atSign);\n      rest = rest.slice(atSign + 1);\n      this.auth = decodeURIComponent(auth);\n    }\n\n    // the host is the remaining to the left of the first non-host char\n    hostEnd = -1;\n    for (var i = 0; i < nonHostChars.length; i++) {\n      var hec = rest.indexOf(nonHostChars[i]);\n      if (hec !== -1 && (hostEnd === -1 || hec < hostEnd)) { hostEnd = hec; }\n    }\n    // if we still have not hit it, then the entire thing is a host.\n    if (hostEnd === -1) { hostEnd = rest.length; }\n\n    this.host = rest.slice(0, hostEnd);\n    rest = rest.slice(hostEnd);\n\n    // pull out port.\n    this.parseHost();\n\n    /*\n     * we've indicated that there is a hostname,\n     * so even if it's empty, it has to be present.\n     */\n    this.hostname = this.hostname || '';\n\n    /*\n     * if hostname begins with [ and ends with ]\n     * assume that it's an IPv6 address.\n     */\n    var ipv6Hostname = this.hostname[0] === '[' && this.hostname[this.hostname.length - 1] === ']';\n\n    // validate a little.\n    if (!ipv6Hostname) {\n      var hostparts = this.hostname.split(/\\./);\n      for (var i = 0, l = hostparts.length; i < l; i++) {\n        var part = hostparts[i];\n        if (!part) { continue; }\n        if (!part.match(hostnamePartPattern)) {\n          var newpart = '';\n          for (var j = 0, k = part.length; j < k; j++) {\n            if (part.charCodeAt(j) > 127) {\n              /*\n               * we replace non-ASCII char with a temporary placeholder\n               * we need this to make sure size of hostname is not\n               * broken by replacing non-ASCII by nothing\n               */\n              newpart += 'x';\n            } else {\n              newpart += part[j];\n            }\n          }\n          // we test again with ASCII char only\n          if (!newpart.match(hostnamePartPattern)) {\n            var validParts = hostparts.slice(0, i);\n            var notHost = hostparts.slice(i + 1);\n            var bit = part.match(hostnamePartStart);\n            if (bit) {\n              validParts.push(bit[1]);\n              notHost.unshift(bit[2]);\n            }\n            if (notHost.length) {\n              rest = '/' + notHost.join('.') + rest;\n            }\n            this.hostname = validParts.join('.');\n            break;\n          }\n        }\n      }\n    }\n\n    if (this.hostname.length > hostnameMaxLen) {\n      this.hostname = '';\n    } else {\n      // hostnames are always lower case.\n      this.hostname = this.hostname.toLowerCase();\n    }\n\n    if (!ipv6Hostname) {\n      /*\n       * IDNA Support: Returns a punycoded representation of \"domain\".\n       * It only converts parts of the domain name that\n       * have non-ASCII characters, i.e. it doesn't matter if\n       * you call it with a domain that already is ASCII-only.\n       */\n      this.hostname = punycode.toASCII(this.hostname);\n    }\n\n    var p = this.port ? ':' + this.port : '';\n    var h = this.hostname || '';\n    this.host = h + p;\n    this.href += this.host;\n\n    /*\n     * strip [ and ] from the hostname\n     * the host field still retains them, though\n     */\n    if (ipv6Hostname) {\n      this.hostname = this.hostname.substr(1, this.hostname.length - 2);\n      if (rest[0] !== '/') {\n        rest = '/' + rest;\n      }\n    }\n  }\n\n  /*\n   * now rest is set to the post-host stuff.\n   * chop off any delim chars.\n   */\n  if (!unsafeProtocol[lowerProto]) {\n\n    /*\n     * First, make 100% sure that any \"autoEscape\" chars get\n     * escaped, even if encodeURIComponent doesn't think they\n     * need to be.\n     */\n    for (var i = 0, l = autoEscape.length; i < l; i++) {\n      var ae = autoEscape[i];\n      if (rest.indexOf(ae) === -1) { continue; }\n      var esc = encodeURIComponent(ae);\n      if (esc === ae) {\n        esc = escape(ae);\n      }\n      rest = rest.split(ae).join(esc);\n    }\n  }\n\n  // chop off from the tail first.\n  var hash = rest.indexOf('#');\n  if (hash !== -1) {\n    // got a fragment string.\n    this.hash = rest.substr(hash);\n    rest = rest.slice(0, hash);\n  }\n  var qm = rest.indexOf('?');\n  if (qm !== -1) {\n    this.search = rest.substr(qm);\n    this.query = rest.substr(qm + 1);\n    if (parseQueryString) {\n      this.query = querystring.parse(this.query);\n    }\n    rest = rest.slice(0, qm);\n  } else if (parseQueryString) {\n    // no query string, but parseQueryString still requested\n    this.search = '';\n    this.query = {};\n  }\n  if (rest) { this.pathname = rest; }\n  if (slashedProtocol[lowerProto] && this.hostname && !this.pathname) {\n    this.pathname = '/';\n  }\n\n  // to support http.request\n  if (this.pathname || this.search) {\n    var p = this.pathname || '';\n    var s = this.search || '';\n    this.path = p + s;\n  }\n\n  // finally, reconstruct the href based on what has been validated.\n  this.href = this.format();\n  return this;\n};\n\n// format a parsed object into a url string\nfunction urlFormat(obj) {\n  /*\n   * ensure it's an object, and not a string url.\n   * If it's an obj, this is a no-op.\n   * this way, you can call url_format() on strings\n   * to clean up potentially wonky urls.\n   */\n  if (typeof obj === 'string') { obj = urlParse(obj); }\n  if (!(obj instanceof Url)) { return Url.prototype.format.call(obj); }\n  return obj.format();\n}\n\nUrl.prototype.format = function () {\n  var auth = this.auth || '';\n  if (auth) {\n    auth = encodeURIComponent(auth);\n    auth = auth.replace(/%3A/i, ':');\n    auth += '@';\n  }\n\n  var protocol = this.protocol || '',\n    pathname = this.pathname || '',\n    hash = this.hash || '',\n    host = false,\n    query = '';\n\n  if (this.host) {\n    host = auth + this.host;\n  } else if (this.hostname) {\n    host = auth + (this.hostname.indexOf(':') === -1 ? this.hostname : '[' + this.hostname + ']');\n    if (this.port) {\n      host += ':' + this.port;\n    }\n  }\n\n  if (this.query && typeof this.query === 'object' && Object.keys(this.query).length) {\n    query = querystring.stringify(this.query, {\n      arrayFormat: 'repeat',\n      addQueryPrefix: false\n    });\n  }\n\n  var search = this.search || (query && ('?' + query)) || '';\n\n  if (protocol && protocol.substr(-1) !== ':') { protocol += ':'; }\n\n  /*\n   * only the slashedProtocols get the //.  Not mailto:, xmpp:, etc.\n   * unless they had them to begin with.\n   */\n  if (this.slashes || (!protocol || slashedProtocol[protocol]) && host !== false) {\n    host = '//' + (host || '');\n    if (pathname && pathname.charAt(0) !== '/') { pathname = '/' + pathname; }\n  } else if (!host) {\n    host = '';\n  }\n\n  if (hash && hash.charAt(0) !== '#') { hash = '#' + hash; }\n  if (search && search.charAt(0) !== '?') { search = '?' + search; }\n\n  pathname = pathname.replace(/[?#]/g, function (match) {\n    return encodeURIComponent(match);\n  });\n  search = search.replace('#', '%23');\n\n  return protocol + host + pathname + search + hash;\n};\n\nfunction urlResolve(source, relative) {\n  return urlParse(source, false, true).resolve(relative);\n}\n\nUrl.prototype.resolve = function (relative) {\n  return this.resolveObject(urlParse(relative, false, true)).format();\n};\n\nfunction urlResolveObject(source, relative) {\n  if (!source) { return relative; }\n  return urlParse(source, false, true).resolveObject(relative);\n}\n\nUrl.prototype.resolveObject = function (relative) {\n  if (typeof relative === 'string') {\n    var rel = new Url();\n    rel.parse(relative, false, true);\n    relative = rel;\n  }\n\n  var result = new Url();\n  var tkeys = Object.keys(this);\n  for (var tk = 0; tk < tkeys.length; tk++) {\n    var tkey = tkeys[tk];\n    result[tkey] = this[tkey];\n  }\n\n  /*\n   * hash is always overridden, no matter what.\n   * even href=\"\" will remove it.\n   */\n  result.hash = relative.hash;\n\n  // if the relative url is empty, then there's nothing left to do here.\n  if (relative.href === '') {\n    result.href = result.format();\n    return result;\n  }\n\n  // hrefs like //foo/bar always cut to the protocol.\n  if (relative.slashes && !relative.protocol) {\n    // take everything except the protocol from relative\n    var rkeys = Object.keys(relative);\n    for (var rk = 0; rk < rkeys.length; rk++) {\n      var rkey = rkeys[rk];\n      if (rkey !== 'protocol') { result[rkey] = relative[rkey]; }\n    }\n\n    // urlParse appends trailing / to urls like http://www.example.com\n    if (slashedProtocol[result.protocol] && result.hostname && !result.pathname) {\n      result.pathname = '/';\n      result.path = result.pathname;\n    }\n\n    result.href = result.format();\n    return result;\n  }\n\n  if (relative.protocol && relative.protocol !== result.protocol) {\n    /*\n     * if it's a known url protocol, then changing\n     * the protocol does weird things\n     * first, if it's not file:, then we MUST have a host,\n     * and if there was a path\n     * to begin with, then we MUST have a path.\n     * if it is file:, then the host is dropped,\n     * because that's known to be hostless.\n     * anything else is assumed to be absolute.\n     */\n    if (!slashedProtocol[relative.protocol]) {\n      var keys = Object.keys(relative);\n      for (var v = 0; v < keys.length; v++) {\n        var k = keys[v];\n        result[k] = relative[k];\n      }\n      result.href = result.format();\n      return result;\n    }\n\n    result.protocol = relative.protocol;\n    if (!relative.host && !hostlessProtocol[relative.protocol]) {\n      var relPath = (relative.pathname || '').split('/');\n      while (relPath.length && !(relative.host = relPath.shift())) { }\n      if (!relative.host) { relative.host = ''; }\n      if (!relative.hostname) { relative.hostname = ''; }\n      if (relPath[0] !== '') { relPath.unshift(''); }\n      if (relPath.length < 2) { relPath.unshift(''); }\n      result.pathname = relPath.join('/');\n    } else {\n      result.pathname = relative.pathname;\n    }\n    result.search = relative.search;\n    result.query = relative.query;\n    result.host = relative.host || '';\n    result.auth = relative.auth;\n    result.hostname = relative.hostname || relative.host;\n    result.port = relative.port;\n    // to support http.request\n    if (result.pathname || result.search) {\n      var p = result.pathname || '';\n      var s = result.search || '';\n      result.path = p + s;\n    }\n    result.slashes = result.slashes || relative.slashes;\n    result.href = result.format();\n    return result;\n  }\n\n  var isSourceAbs = result.pathname && result.pathname.charAt(0) === '/',\n    isRelAbs = relative.host || relative.pathname && relative.pathname.charAt(0) === '/',\n    mustEndAbs = isRelAbs || isSourceAbs || (result.host && relative.pathname),\n    removeAllDots = mustEndAbs,\n    srcPath = result.pathname && result.pathname.split('/') || [],\n    relPath = relative.pathname && relative.pathname.split('/') || [],\n    psychotic = result.protocol && !slashedProtocol[result.protocol];\n\n  /*\n   * if the url is a non-slashed url, then relative\n   * links like ../.. should be able\n   * to crawl up to the hostname, as well.  This is strange.\n   * result.protocol has already been set by now.\n   * Later on, put the first path part into the host field.\n   */\n  if (psychotic) {\n    result.hostname = '';\n    result.port = null;\n    if (result.host) {\n      if (srcPath[0] === '') { srcPath[0] = result.host; } else { srcPath.unshift(result.host); }\n    }\n    result.host = '';\n    if (relative.protocol) {\n      relative.hostname = null;\n      relative.port = null;\n      if (relative.host) {\n        if (relPath[0] === '') { relPath[0] = relative.host; } else { relPath.unshift(relative.host); }\n      }\n      relative.host = null;\n    }\n    mustEndAbs = mustEndAbs && (relPath[0] === '' || srcPath[0] === '');\n  }\n\n  if (isRelAbs) {\n    // it's absolute.\n    result.host = relative.host || relative.host === '' ? relative.host : result.host;\n    result.hostname = relative.hostname || relative.hostname === '' ? relative.hostname : result.hostname;\n    result.search = relative.search;\n    result.query = relative.query;\n    srcPath = relPath;\n    // fall through to the dot-handling below.\n  } else if (relPath.length) {\n    /*\n     * it's relative\n     * throw away the existing file, and take the new path instead.\n     */\n    if (!srcPath) { srcPath = []; }\n    srcPath.pop();\n    srcPath = srcPath.concat(relPath);\n    result.search = relative.search;\n    result.query = relative.query;\n  } else if (relative.search != null) {\n    /*\n     * just pull out the search.\n     * like href='?foo'.\n     * Put this after the other two cases because it simplifies the booleans\n     */\n    if (psychotic) {\n      result.host = srcPath.shift();\n      result.hostname = result.host;\n      /*\n       * occationaly the auth can get stuck only in host\n       * this especially happens in cases like\n       * url.resolveObject('mailto:local1@domain1', 'local2@domain2')\n       */\n      var authInHost = result.host && result.host.indexOf('@') > 0 ? result.host.split('@') : false;\n      if (authInHost) {\n        result.auth = authInHost.shift();\n        result.hostname = authInHost.shift();\n        result.host = result.hostname;\n      }\n    }\n    result.search = relative.search;\n    result.query = relative.query;\n    // to support http.request\n    if (result.pathname !== null || result.search !== null) {\n      result.path = (result.pathname ? result.pathname : '') + (result.search ? result.search : '');\n    }\n    result.href = result.format();\n    return result;\n  }\n\n  if (!srcPath.length) {\n    /*\n     * no path at all.  easy.\n     * we've already handled the other stuff above.\n     */\n    result.pathname = null;\n    // to support http.request\n    if (result.search) {\n      result.path = '/' + result.search;\n    } else {\n      result.path = null;\n    }\n    result.href = result.format();\n    return result;\n  }\n\n  /*\n   * if a url ENDs in . or .., then it must get a trailing slash.\n   * however, if it ends in anything else non-slashy,\n   * then it must NOT get a trailing slash.\n   */\n  var last = srcPath.slice(-1)[0];\n  var hasTrailingSlash = (result.host || relative.host || srcPath.length > 1) && (last === '.' || last === '..') || last === '';\n\n  /*\n   * strip single dots, resolve double dots to parent dir\n   * if the path tries to go above the root, `up` ends up > 0\n   */\n  var up = 0;\n  for (var i = srcPath.length; i >= 0; i--) {\n    last = srcPath[i];\n    if (last === '.') {\n      srcPath.splice(i, 1);\n    } else if (last === '..') {\n      srcPath.splice(i, 1);\n      up++;\n    } else if (up) {\n      srcPath.splice(i, 1);\n      up--;\n    }\n  }\n\n  // if the path is allowed to go above the root, restore leading ..s\n  if (!mustEndAbs && !removeAllDots) {\n    for (; up--; up) {\n      srcPath.unshift('..');\n    }\n  }\n\n  if (mustEndAbs && srcPath[0] !== '' && (!srcPath[0] || srcPath[0].charAt(0) !== '/')) {\n    srcPath.unshift('');\n  }\n\n  if (hasTrailingSlash && (srcPath.join('/').substr(-1) !== '/')) {\n    srcPath.push('');\n  }\n\n  var isAbsolute = srcPath[0] === '' || (srcPath[0] && srcPath[0].charAt(0) === '/');\n\n  // put the host back\n  if (psychotic) {\n    result.hostname = isAbsolute ? '' : srcPath.length ? srcPath.shift() : '';\n    result.host = result.hostname;\n    /*\n     * occationaly the auth can get stuck only in host\n     * this especially happens in cases like\n     * url.resolveObject('mailto:local1@domain1', 'local2@domain2')\n     */\n    var authInHost = result.host && result.host.indexOf('@') > 0 ? result.host.split('@') : false;\n    if (authInHost) {\n      result.auth = authInHost.shift();\n      result.hostname = authInHost.shift();\n      result.host = result.hostname;\n    }\n  }\n\n  mustEndAbs = mustEndAbs || (result.host && srcPath.length);\n\n  if (mustEndAbs && !isAbsolute) {\n    srcPath.unshift('');\n  }\n\n  if (srcPath.length > 0) {\n    result.pathname = srcPath.join('/');\n  } else {\n    result.pathname = null;\n    result.path = null;\n  }\n\n  // to support request.http\n  if (result.pathname !== null || result.search !== null) {\n    result.path = (result.pathname ? result.pathname : '') + (result.search ? result.search : '');\n  }\n  result.auth = relative.auth || result.auth;\n  result.slashes = result.slashes || relative.slashes;\n  result.href = result.format();\n  return result;\n};\n\nUrl.prototype.parseHost = function () {\n  var host = this.host;\n  var port = portPattern.exec(host);\n  if (port) {\n    port = port[0];\n    if (port !== ':') {\n      this.port = port.substr(1);\n    }\n    host = host.substr(0, host.length - port.length);\n  }\n  if (host) { this.hostname = host; }\n};\n\nexports.parse = urlParse;\nexports.resolve = urlResolve;\nexports.resolveObject = urlResolveObject;\nexports.format = urlFormat;\n\nexports.Url = Url;\n\n\n//# sourceURL=webpack://thelambda/./node_modules/url/url.js?");

/***/ }),

/***/ "./node_modules/util-deprecate/browser.js":
/*!************************************************!*\
  !*** ./node_modules/util-deprecate/browser.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!__webpack_require__.g.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = __webpack_require__.g.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/util-deprecate/browser.js?");

/***/ }),

/***/ "./node_modules/util/node_modules/inherits/inherits_browser.js":
/*!*********************************************************************!*\
  !*** ./node_modules/util/node_modules/inherits/inherits_browser.js ***!
  \*********************************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    ctor.prototype = Object.create(superCtor.prototype, {\n      constructor: {\n        value: ctor,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    ctor.super_ = superCtor\n    var TempCtor = function () {}\n    TempCtor.prototype = superCtor.prototype\n    ctor.prototype = new TempCtor()\n    ctor.prototype.constructor = ctor\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/util/node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "./node_modules/util/support/isBufferBrowser.js":
/*!******************************************************!*\
  !*** ./node_modules/util/support/isBufferBrowser.js ***!
  \******************************************************/
/***/ ((module) => {

eval("module.exports = function isBuffer(arg) {\n  return arg && typeof arg === 'object'\n    && typeof arg.copy === 'function'\n    && typeof arg.fill === 'function'\n    && typeof arg.readUInt8 === 'function';\n}\n\n//# sourceURL=webpack://thelambda/./node_modules/util/support/isBufferBrowser.js?");

/***/ }),

/***/ "./node_modules/util/util.js":
/*!***********************************!*\
  !*** ./node_modules/util/util.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nvar formatRegExp = /%[sdj%]/g;\nexports.format = function(f) {\n  if (!isString(f)) {\n    var objects = [];\n    for (var i = 0; i < arguments.length; i++) {\n      objects.push(inspect(arguments[i]));\n    }\n    return objects.join(' ');\n  }\n\n  var i = 1;\n  var args = arguments;\n  var len = args.length;\n  var str = String(f).replace(formatRegExp, function(x) {\n    if (x === '%%') return '%';\n    if (i >= len) return x;\n    switch (x) {\n      case '%s': return String(args[i++]);\n      case '%d': return Number(args[i++]);\n      case '%j':\n        try {\n          return JSON.stringify(args[i++]);\n        } catch (_) {\n          return '[Circular]';\n        }\n      default:\n        return x;\n    }\n  });\n  for (var x = args[i]; i < len; x = args[++i]) {\n    if (isNull(x) || !isObject(x)) {\n      str += ' ' + x;\n    } else {\n      str += ' ' + inspect(x);\n    }\n  }\n  return str;\n};\n\n\n// Mark that a method should not be used.\n// Returns a modified function which warns once by default.\n// If --no-deprecation is set, then it is a no-op.\nexports.deprecate = function(fn, msg) {\n  // Allow for deprecating things in the process of starting up.\n  if (isUndefined(__webpack_require__.g.process)) {\n    return function() {\n      return exports.deprecate(fn, msg).apply(this, arguments);\n    };\n  }\n\n  if (process.noDeprecation === true) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (process.throwDeprecation) {\n        throw new Error(msg);\n      } else if (process.traceDeprecation) {\n        console.trace(msg);\n      } else {\n        console.error(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n};\n\n\nvar debugs = {};\nvar debugEnviron;\nexports.debuglog = function(set) {\n  if (isUndefined(debugEnviron))\n    debugEnviron = process.env.NODE_DEBUG || '';\n  set = set.toUpperCase();\n  if (!debugs[set]) {\n    if (new RegExp('\\\\b' + set + '\\\\b', 'i').test(debugEnviron)) {\n      var pid = process.pid;\n      debugs[set] = function() {\n        var msg = exports.format.apply(exports, arguments);\n        console.error('%s %d: %s', set, pid, msg);\n      };\n    } else {\n      debugs[set] = function() {};\n    }\n  }\n  return debugs[set];\n};\n\n\n/**\n * Echos the value of a value. Trys to print the value out\n * in the best way possible given the different types.\n *\n * @param {Object} obj The object to print out.\n * @param {Object} opts Optional options object that alters the output.\n */\n/* legacy: obj, showHidden, depth, colors*/\nfunction inspect(obj, opts) {\n  // default options\n  var ctx = {\n    seen: [],\n    stylize: stylizeNoColor\n  };\n  // legacy...\n  if (arguments.length >= 3) ctx.depth = arguments[2];\n  if (arguments.length >= 4) ctx.colors = arguments[3];\n  if (isBoolean(opts)) {\n    // legacy...\n    ctx.showHidden = opts;\n  } else if (opts) {\n    // got an \"options\" object\n    exports._extend(ctx, opts);\n  }\n  // set default options\n  if (isUndefined(ctx.showHidden)) ctx.showHidden = false;\n  if (isUndefined(ctx.depth)) ctx.depth = 2;\n  if (isUndefined(ctx.colors)) ctx.colors = false;\n  if (isUndefined(ctx.customInspect)) ctx.customInspect = true;\n  if (ctx.colors) ctx.stylize = stylizeWithColor;\n  return formatValue(ctx, obj, ctx.depth);\n}\nexports.inspect = inspect;\n\n\n// http://en.wikipedia.org/wiki/ANSI_escape_code#graphics\ninspect.colors = {\n  'bold' : [1, 22],\n  'italic' : [3, 23],\n  'underline' : [4, 24],\n  'inverse' : [7, 27],\n  'white' : [37, 39],\n  'grey' : [90, 39],\n  'black' : [30, 39],\n  'blue' : [34, 39],\n  'cyan' : [36, 39],\n  'green' : [32, 39],\n  'magenta' : [35, 39],\n  'red' : [31, 39],\n  'yellow' : [33, 39]\n};\n\n// Don't use 'blue' not visible on cmd.exe\ninspect.styles = {\n  'special': 'cyan',\n  'number': 'yellow',\n  'boolean': 'yellow',\n  'undefined': 'grey',\n  'null': 'bold',\n  'string': 'green',\n  'date': 'magenta',\n  // \"name\": intentionally not styling\n  'regexp': 'red'\n};\n\n\nfunction stylizeWithColor(str, styleType) {\n  var style = inspect.styles[styleType];\n\n  if (style) {\n    return '\\u001b[' + inspect.colors[style][0] + 'm' + str +\n           '\\u001b[' + inspect.colors[style][1] + 'm';\n  } else {\n    return str;\n  }\n}\n\n\nfunction stylizeNoColor(str, styleType) {\n  return str;\n}\n\n\nfunction arrayToHash(array) {\n  var hash = {};\n\n  array.forEach(function(val, idx) {\n    hash[val] = true;\n  });\n\n  return hash;\n}\n\n\nfunction formatValue(ctx, value, recurseTimes) {\n  // Provide a hook for user-specified inspect functions.\n  // Check that value is an object with an inspect function on it\n  if (ctx.customInspect &&\n      value &&\n      isFunction(value.inspect) &&\n      // Filter out the util module, it's inspect function is special\n      value.inspect !== exports.inspect &&\n      // Also filter out any prototype objects using the circular check.\n      !(value.constructor && value.constructor.prototype === value)) {\n    var ret = value.inspect(recurseTimes, ctx);\n    if (!isString(ret)) {\n      ret = formatValue(ctx, ret, recurseTimes);\n    }\n    return ret;\n  }\n\n  // Primitive types cannot have properties\n  var primitive = formatPrimitive(ctx, value);\n  if (primitive) {\n    return primitive;\n  }\n\n  // Look up the keys of the object.\n  var keys = Object.keys(value);\n  var visibleKeys = arrayToHash(keys);\n\n  if (ctx.showHidden) {\n    keys = Object.getOwnPropertyNames(value);\n  }\n\n  // IE doesn't make error fields non-enumerable\n  // http://msdn.microsoft.com/en-us/library/ie/dww52sbt(v=vs.94).aspx\n  if (isError(value)\n      && (keys.indexOf('message') >= 0 || keys.indexOf('description') >= 0)) {\n    return formatError(value);\n  }\n\n  // Some type of object without properties can be shortcutted.\n  if (keys.length === 0) {\n    if (isFunction(value)) {\n      var name = value.name ? ': ' + value.name : '';\n      return ctx.stylize('[Function' + name + ']', 'special');\n    }\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    }\n    if (isDate(value)) {\n      return ctx.stylize(Date.prototype.toString.call(value), 'date');\n    }\n    if (isError(value)) {\n      return formatError(value);\n    }\n  }\n\n  var base = '', array = false, braces = ['{', '}'];\n\n  // Make Array say that they are Array\n  if (isArray(value)) {\n    array = true;\n    braces = ['[', ']'];\n  }\n\n  // Make functions say that they are functions\n  if (isFunction(value)) {\n    var n = value.name ? ': ' + value.name : '';\n    base = ' [Function' + n + ']';\n  }\n\n  // Make RegExps say that they are RegExps\n  if (isRegExp(value)) {\n    base = ' ' + RegExp.prototype.toString.call(value);\n  }\n\n  // Make dates with properties first say the date\n  if (isDate(value)) {\n    base = ' ' + Date.prototype.toUTCString.call(value);\n  }\n\n  // Make error with message first say the error\n  if (isError(value)) {\n    base = ' ' + formatError(value);\n  }\n\n  if (keys.length === 0 && (!array || value.length == 0)) {\n    return braces[0] + base + braces[1];\n  }\n\n  if (recurseTimes < 0) {\n    if (isRegExp(value)) {\n      return ctx.stylize(RegExp.prototype.toString.call(value), 'regexp');\n    } else {\n      return ctx.stylize('[Object]', 'special');\n    }\n  }\n\n  ctx.seen.push(value);\n\n  var output;\n  if (array) {\n    output = formatArray(ctx, value, recurseTimes, visibleKeys, keys);\n  } else {\n    output = keys.map(function(key) {\n      return formatProperty(ctx, value, recurseTimes, visibleKeys, key, array);\n    });\n  }\n\n  ctx.seen.pop();\n\n  return reduceToSingleString(output, base, braces);\n}\n\n\nfunction formatPrimitive(ctx, value) {\n  if (isUndefined(value))\n    return ctx.stylize('undefined', 'undefined');\n  if (isString(value)) {\n    var simple = '\\'' + JSON.stringify(value).replace(/^\"|\"$/g, '')\n                                             .replace(/'/g, \"\\\\'\")\n                                             .replace(/\\\\\"/g, '\"') + '\\'';\n    return ctx.stylize(simple, 'string');\n  }\n  if (isNumber(value))\n    return ctx.stylize('' + value, 'number');\n  if (isBoolean(value))\n    return ctx.stylize('' + value, 'boolean');\n  // For some reason typeof null is \"object\", so special case here.\n  if (isNull(value))\n    return ctx.stylize('null', 'null');\n}\n\n\nfunction formatError(value) {\n  return '[' + Error.prototype.toString.call(value) + ']';\n}\n\n\nfunction formatArray(ctx, value, recurseTimes, visibleKeys, keys) {\n  var output = [];\n  for (var i = 0, l = value.length; i < l; ++i) {\n    if (hasOwnProperty(value, String(i))) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          String(i), true));\n    } else {\n      output.push('');\n    }\n  }\n  keys.forEach(function(key) {\n    if (!key.match(/^\\d+$/)) {\n      output.push(formatProperty(ctx, value, recurseTimes, visibleKeys,\n          key, true));\n    }\n  });\n  return output;\n}\n\n\nfunction formatProperty(ctx, value, recurseTimes, visibleKeys, key, array) {\n  var name, str, desc;\n  desc = Object.getOwnPropertyDescriptor(value, key) || { value: value[key] };\n  if (desc.get) {\n    if (desc.set) {\n      str = ctx.stylize('[Getter/Setter]', 'special');\n    } else {\n      str = ctx.stylize('[Getter]', 'special');\n    }\n  } else {\n    if (desc.set) {\n      str = ctx.stylize('[Setter]', 'special');\n    }\n  }\n  if (!hasOwnProperty(visibleKeys, key)) {\n    name = '[' + key + ']';\n  }\n  if (!str) {\n    if (ctx.seen.indexOf(desc.value) < 0) {\n      if (isNull(recurseTimes)) {\n        str = formatValue(ctx, desc.value, null);\n      } else {\n        str = formatValue(ctx, desc.value, recurseTimes - 1);\n      }\n      if (str.indexOf('\\n') > -1) {\n        if (array) {\n          str = str.split('\\n').map(function(line) {\n            return '  ' + line;\n          }).join('\\n').substr(2);\n        } else {\n          str = '\\n' + str.split('\\n').map(function(line) {\n            return '   ' + line;\n          }).join('\\n');\n        }\n      }\n    } else {\n      str = ctx.stylize('[Circular]', 'special');\n    }\n  }\n  if (isUndefined(name)) {\n    if (array && key.match(/^\\d+$/)) {\n      return str;\n    }\n    name = JSON.stringify('' + key);\n    if (name.match(/^\"([a-zA-Z_][a-zA-Z_0-9]*)\"$/)) {\n      name = name.substr(1, name.length - 2);\n      name = ctx.stylize(name, 'name');\n    } else {\n      name = name.replace(/'/g, \"\\\\'\")\n                 .replace(/\\\\\"/g, '\"')\n                 .replace(/(^\"|\"$)/g, \"'\");\n      name = ctx.stylize(name, 'string');\n    }\n  }\n\n  return name + ': ' + str;\n}\n\n\nfunction reduceToSingleString(output, base, braces) {\n  var numLinesEst = 0;\n  var length = output.reduce(function(prev, cur) {\n    numLinesEst++;\n    if (cur.indexOf('\\n') >= 0) numLinesEst++;\n    return prev + cur.replace(/\\u001b\\[\\d\\d?m/g, '').length + 1;\n  }, 0);\n\n  if (length > 60) {\n    return braces[0] +\n           (base === '' ? '' : base + '\\n ') +\n           ' ' +\n           output.join(',\\n  ') +\n           ' ' +\n           braces[1];\n  }\n\n  return braces[0] + base + ' ' + output.join(', ') + ' ' + braces[1];\n}\n\n\n// NOTE: These type checking functions intentionally don't use `instanceof`\n// because it is fragile and can be easily faked with `Object.create()`.\nfunction isArray(ar) {\n  return Array.isArray(ar);\n}\nexports.isArray = isArray;\n\nfunction isBoolean(arg) {\n  return typeof arg === 'boolean';\n}\nexports.isBoolean = isBoolean;\n\nfunction isNull(arg) {\n  return arg === null;\n}\nexports.isNull = isNull;\n\nfunction isNullOrUndefined(arg) {\n  return arg == null;\n}\nexports.isNullOrUndefined = isNullOrUndefined;\n\nfunction isNumber(arg) {\n  return typeof arg === 'number';\n}\nexports.isNumber = isNumber;\n\nfunction isString(arg) {\n  return typeof arg === 'string';\n}\nexports.isString = isString;\n\nfunction isSymbol(arg) {\n  return typeof arg === 'symbol';\n}\nexports.isSymbol = isSymbol;\n\nfunction isUndefined(arg) {\n  return arg === void 0;\n}\nexports.isUndefined = isUndefined;\n\nfunction isRegExp(re) {\n  return isObject(re) && objectToString(re) === '[object RegExp]';\n}\nexports.isRegExp = isRegExp;\n\nfunction isObject(arg) {\n  return typeof arg === 'object' && arg !== null;\n}\nexports.isObject = isObject;\n\nfunction isDate(d) {\n  return isObject(d) && objectToString(d) === '[object Date]';\n}\nexports.isDate = isDate;\n\nfunction isError(e) {\n  return isObject(e) &&\n      (objectToString(e) === '[object Error]' || e instanceof Error);\n}\nexports.isError = isError;\n\nfunction isFunction(arg) {\n  return typeof arg === 'function';\n}\nexports.isFunction = isFunction;\n\nfunction isPrimitive(arg) {\n  return arg === null ||\n         typeof arg === 'boolean' ||\n         typeof arg === 'number' ||\n         typeof arg === 'string' ||\n         typeof arg === 'symbol' ||  // ES6 symbol\n         typeof arg === 'undefined';\n}\nexports.isPrimitive = isPrimitive;\n\nexports.isBuffer = __webpack_require__(/*! ./support/isBuffer */ \"./node_modules/util/support/isBufferBrowser.js\");\n\nfunction objectToString(o) {\n  return Object.prototype.toString.call(o);\n}\n\n\nfunction pad(n) {\n  return n < 10 ? '0' + n.toString(10) : n.toString(10);\n}\n\n\nvar months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep',\n              'Oct', 'Nov', 'Dec'];\n\n// 26 Feb 16:19:34\nfunction timestamp() {\n  var d = new Date();\n  var time = [pad(d.getHours()),\n              pad(d.getMinutes()),\n              pad(d.getSeconds())].join(':');\n  return [d.getDate(), months[d.getMonth()], time].join(' ');\n}\n\n\n// log is just a thin wrapper to console.log that prepends a timestamp\nexports.log = function() {\n  console.log('%s - %s', timestamp(), exports.format.apply(exports, arguments));\n};\n\n\n/**\n * Inherit the prototype methods from one constructor into another.\n *\n * The Function.prototype.inherits from lang.js rewritten as a standalone\n * function (not on Function.prototype). NOTE: If this file is to be loaded\n * during bootstrapping this function needs to be rewritten using some native\n * functions as prototype setup using normal JavaScript does not work as\n * expected during bootstrapping (see mirror.js in r114903).\n *\n * @param {function} ctor Constructor function which needs to inherit the\n *     prototype.\n * @param {function} superCtor Constructor function to inherit prototype from.\n */\nexports.inherits = __webpack_require__(/*! inherits */ \"./node_modules/util/node_modules/inherits/inherits_browser.js\");\n\nexports._extend = function(origin, add) {\n  // Don't do anything if add isn't an object\n  if (!add || !isObject(add)) return origin;\n\n  var keys = Object.keys(add);\n  var i = keys.length;\n  while (i--) {\n    origin[keys[i]] = add[keys[i]];\n  }\n  return origin;\n};\n\nfunction hasOwnProperty(obj, prop) {\n  return Object.prototype.hasOwnProperty.call(obj, prop);\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/util/util.js?");

/***/ }),

/***/ "./node_modules/wide-align/align.js":
/*!******************************************!*\
  !*** ./node_modules/wide-align/align.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nvar stringWidth = __webpack_require__(/*! string-width */ \"./node_modules/string-width/index.js\")\n\nexports.center = alignCenter\nexports.left = alignLeft\nexports.right = alignRight\n\n// lodash's way of generating pad characters.\n\nfunction createPadding (width) {\n  var result = ''\n  var string = ' '\n  var n = width\n  do {\n    if (n % 2) {\n      result += string;\n    }\n    n = Math.floor(n / 2);\n    string += string;\n  } while (n);\n\n  return result;\n}\n\nfunction alignLeft (str, width) {\n  var trimmed = str.trimRight()\n  if (trimmed.length === 0 && str.length >= width) return str\n  var padding = ''\n  var strWidth = stringWidth(trimmed)\n\n  if (strWidth < width) {\n    padding = createPadding(width - strWidth)\n  }\n\n  return trimmed + padding\n}\n\nfunction alignRight (str, width) {\n  var trimmed = str.trimLeft()\n  if (trimmed.length === 0 && str.length >= width) return str\n  var padding = ''\n  var strWidth = stringWidth(trimmed)\n\n  if (strWidth < width) {\n    padding = createPadding(width - strWidth)\n  }\n\n  return padding + trimmed\n}\n\nfunction alignCenter (str, width) {\n  var trimmed = str.trim()\n  if (trimmed.length === 0 && str.length >= width) return str\n  var padLeft = ''\n  var padRight = ''\n  var strWidth = stringWidth(trimmed)\n\n  if (strWidth < width) {\n    var padLeftBy = parseInt((width - strWidth) / 2, 10) \n    padLeft = createPadding(padLeftBy)\n    padRight = createPadding(width - (strWidth + padLeftBy))\n  }\n\n  return padLeft + trimmed + padRight\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/wide-align/align.js?");

/***/ }),

/***/ "./node_modules/wrappy/wrappy.js":
/*!***************************************!*\
  !*** ./node_modules/wrappy/wrappy.js ***!
  \***************************************/
/***/ ((module) => {

eval("// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/wrappy/wrappy.js?");

/***/ }),

/***/ "./node_modules/yallist/iterator.js":
/*!******************************************!*\
  !*** ./node_modules/yallist/iterator.js ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("\nmodule.exports = function (Yallist) {\n  Yallist.prototype[Symbol.iterator] = function* () {\n    for (let walker = this.head; walker; walker = walker.next) {\n      yield walker.value\n    }\n  }\n}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/yallist/iterator.js?");

/***/ }),

/***/ "./node_modules/yallist/yallist.js":
/*!*****************************************!*\
  !*** ./node_modules/yallist/yallist.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\nmodule.exports = Yallist\n\nYallist.Node = Node\nYallist.create = Yallist\n\nfunction Yallist (list) {\n  var self = this\n  if (!(self instanceof Yallist)) {\n    self = new Yallist()\n  }\n\n  self.tail = null\n  self.head = null\n  self.length = 0\n\n  if (list && typeof list.forEach === 'function') {\n    list.forEach(function (item) {\n      self.push(item)\n    })\n  } else if (arguments.length > 0) {\n    for (var i = 0, l = arguments.length; i < l; i++) {\n      self.push(arguments[i])\n    }\n  }\n\n  return self\n}\n\nYallist.prototype.removeNode = function (node) {\n  if (node.list !== this) {\n    throw new Error('removing node which does not belong to this list')\n  }\n\n  var next = node.next\n  var prev = node.prev\n\n  if (next) {\n    next.prev = prev\n  }\n\n  if (prev) {\n    prev.next = next\n  }\n\n  if (node === this.head) {\n    this.head = next\n  }\n  if (node === this.tail) {\n    this.tail = prev\n  }\n\n  node.list.length--\n  node.next = null\n  node.prev = null\n  node.list = null\n\n  return next\n}\n\nYallist.prototype.unshiftNode = function (node) {\n  if (node === this.head) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var head = this.head\n  node.list = this\n  node.next = head\n  if (head) {\n    head.prev = node\n  }\n\n  this.head = node\n  if (!this.tail) {\n    this.tail = node\n  }\n  this.length++\n}\n\nYallist.prototype.pushNode = function (node) {\n  if (node === this.tail) {\n    return\n  }\n\n  if (node.list) {\n    node.list.removeNode(node)\n  }\n\n  var tail = this.tail\n  node.list = this\n  node.prev = tail\n  if (tail) {\n    tail.next = node\n  }\n\n  this.tail = node\n  if (!this.head) {\n    this.head = node\n  }\n  this.length++\n}\n\nYallist.prototype.push = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    push(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.unshift = function () {\n  for (var i = 0, l = arguments.length; i < l; i++) {\n    unshift(this, arguments[i])\n  }\n  return this.length\n}\n\nYallist.prototype.pop = function () {\n  if (!this.tail) {\n    return undefined\n  }\n\n  var res = this.tail.value\n  this.tail = this.tail.prev\n  if (this.tail) {\n    this.tail.next = null\n  } else {\n    this.head = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.shift = function () {\n  if (!this.head) {\n    return undefined\n  }\n\n  var res = this.head.value\n  this.head = this.head.next\n  if (this.head) {\n    this.head.prev = null\n  } else {\n    this.tail = null\n  }\n  this.length--\n  return res\n}\n\nYallist.prototype.forEach = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.head, i = 0; walker !== null; i++) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.next\n  }\n}\n\nYallist.prototype.forEachReverse = function (fn, thisp) {\n  thisp = thisp || this\n  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {\n    fn.call(thisp, walker.value, i, this)\n    walker = walker.prev\n  }\n}\n\nYallist.prototype.get = function (n) {\n  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.next\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.getReverse = function (n) {\n  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {\n    // abort out of the list early if we hit a cycle\n    walker = walker.prev\n  }\n  if (i === n && walker !== null) {\n    return walker.value\n  }\n}\n\nYallist.prototype.map = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.head; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.next\n  }\n  return res\n}\n\nYallist.prototype.mapReverse = function (fn, thisp) {\n  thisp = thisp || this\n  var res = new Yallist()\n  for (var walker = this.tail; walker !== null;) {\n    res.push(fn.call(thisp, walker.value, this))\n    walker = walker.prev\n  }\n  return res\n}\n\nYallist.prototype.reduce = function (fn, initial) {\n  var acc\n  var walker = this.head\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.head) {\n    walker = this.head.next\n    acc = this.head.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = 0; walker !== null; i++) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.next\n  }\n\n  return acc\n}\n\nYallist.prototype.reduceReverse = function (fn, initial) {\n  var acc\n  var walker = this.tail\n  if (arguments.length > 1) {\n    acc = initial\n  } else if (this.tail) {\n    walker = this.tail.prev\n    acc = this.tail.value\n  } else {\n    throw new TypeError('Reduce of empty list with no initial value')\n  }\n\n  for (var i = this.length - 1; walker !== null; i--) {\n    acc = fn(acc, walker.value, i)\n    walker = walker.prev\n  }\n\n  return acc\n}\n\nYallist.prototype.toArray = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.head; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.next\n  }\n  return arr\n}\n\nYallist.prototype.toArrayReverse = function () {\n  var arr = new Array(this.length)\n  for (var i = 0, walker = this.tail; walker !== null; i++) {\n    arr[i] = walker.value\n    walker = walker.prev\n  }\n  return arr\n}\n\nYallist.prototype.slice = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {\n    walker = walker.next\n  }\n  for (; walker !== null && i < to; i++, walker = walker.next) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.sliceReverse = function (from, to) {\n  to = to || this.length\n  if (to < 0) {\n    to += this.length\n  }\n  from = from || 0\n  if (from < 0) {\n    from += this.length\n  }\n  var ret = new Yallist()\n  if (to < from || to < 0) {\n    return ret\n  }\n  if (from < 0) {\n    from = 0\n  }\n  if (to > this.length) {\n    to = this.length\n  }\n  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {\n    walker = walker.prev\n  }\n  for (; walker !== null && i > from; i--, walker = walker.prev) {\n    ret.push(walker.value)\n  }\n  return ret\n}\n\nYallist.prototype.splice = function (start, deleteCount, ...nodes) {\n  if (start > this.length) {\n    start = this.length - 1\n  }\n  if (start < 0) {\n    start = this.length + start;\n  }\n\n  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {\n    walker = walker.next\n  }\n\n  var ret = []\n  for (var i = 0; walker && i < deleteCount; i++) {\n    ret.push(walker.value)\n    walker = this.removeNode(walker)\n  }\n  if (walker === null) {\n    walker = this.tail\n  }\n\n  if (walker !== this.head && walker !== this.tail) {\n    walker = walker.prev\n  }\n\n  for (var i = 0; i < nodes.length; i++) {\n    walker = insert(this, walker, nodes[i])\n  }\n  return ret;\n}\n\nYallist.prototype.reverse = function () {\n  var head = this.head\n  var tail = this.tail\n  for (var walker = head; walker !== null; walker = walker.prev) {\n    var p = walker.prev\n    walker.prev = walker.next\n    walker.next = p\n  }\n  this.head = tail\n  this.tail = head\n  return this\n}\n\nfunction insert (self, node, value) {\n  var inserted = node === self.head ?\n    new Node(value, null, node, self) :\n    new Node(value, node, node.next, self)\n\n  if (inserted.next === null) {\n    self.tail = inserted\n  }\n  if (inserted.prev === null) {\n    self.head = inserted\n  }\n\n  self.length++\n\n  return inserted\n}\n\nfunction push (self, item) {\n  self.tail = new Node(item, self.tail, null, self)\n  if (!self.head) {\n    self.head = self.tail\n  }\n  self.length++\n}\n\nfunction unshift (self, item) {\n  self.head = new Node(item, null, self.head, self)\n  if (!self.tail) {\n    self.tail = self.head\n  }\n  self.length++\n}\n\nfunction Node (value, prev, next, list) {\n  if (!(this instanceof Node)) {\n    return new Node(value, prev, next, list)\n  }\n\n  this.list = list\n  this.value = value\n\n  if (prev) {\n    prev.next = this\n    this.prev = prev\n  } else {\n    this.prev = null\n  }\n\n  if (next) {\n    next.prev = this\n    this.next = next\n  } else {\n    this.next = null\n  }\n}\n\ntry {\n  // add if support for Symbol.iterator is present\n  __webpack_require__(/*! ./iterator.js */ \"./node_modules/yallist/iterator.js\")(Yallist)\n} catch (er) {}\n\n\n//# sourceURL=webpack://thelambda/./node_modules/yallist/yallist.js?");

/***/ }),

/***/ "?bb19":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?12c0":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?6e8d":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?2c1d":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?a0c3":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?beec":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?6882":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?a40c":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?f129":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?c311":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?4f7e":
/*!********************************!*\
  !*** ./util.inspect (ignored) ***!
  \********************************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/./util.inspect_(ignored)?");

/***/ }),

/***/ "?ed1b":
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/util_(ignored)?");

/***/ }),

/***/ "?d17e":
/*!**********************!*\
  !*** util (ignored) ***!
  \**********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/util_(ignored)?");

/***/ }),

/***/ "?3e89":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "?fde7":
/*!********************!*\
  !*** fs (ignored) ***!
  \********************/
/***/ (() => {

eval("/* (ignored) */\n\n//# sourceURL=webpack://thelambda/fs_(ignored)?");

/***/ }),

/***/ "./node_modules/@supabase/postgrest-js/dist/esm/wrapper.mjs":
/*!******************************************************************!*\
  !*** ./node_modules/@supabase/postgrest-js/dist/esm/wrapper.mjs ***!
  \******************************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   PostgrestBuilder: () => (/* binding */ PostgrestBuilder),\n/* harmony export */   PostgrestClient: () => (/* binding */ PostgrestClient),\n/* harmony export */   PostgrestFilterBuilder: () => (/* binding */ PostgrestFilterBuilder),\n/* harmony export */   PostgrestQueryBuilder: () => (/* binding */ PostgrestQueryBuilder),\n/* harmony export */   PostgrestTransformBuilder: () => (/* binding */ PostgrestTransformBuilder),\n/* harmony export */   \"default\": () => (__WEBPACK_DEFAULT_EXPORT__)\n/* harmony export */ });\n/* harmony import */ var _cjs_index_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../cjs/index.js */ \"./node_modules/@supabase/postgrest-js/dist/cjs/index.js\");\n\nconst {\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n} = _cjs_index_js__WEBPACK_IMPORTED_MODULE_0__\n\n\n\n// compatibility with CJS output\n/* harmony default export */ const __WEBPACK_DEFAULT_EXPORT__ = ({\n  PostgrestClient,\n  PostgrestQueryBuilder,\n  PostgrestFilterBuilder,\n  PostgrestTransformBuilder,\n  PostgrestBuilder,\n});\n\n\n//# sourceURL=webpack://thelambda/./node_modules/@supabase/postgrest-js/dist/esm/wrapper.mjs?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/abi_crosswalk.json":
/*!***********************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/abi_crosswalk.json ***!
  \***********************************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('{\"0.1.14\":{\"node_abi\":null,\"v8\":\"1.3\"},\"0.1.15\":{\"node_abi\":null,\"v8\":\"1.3\"},\"0.1.16\":{\"node_abi\":null,\"v8\":\"1.3\"},\"0.1.17\":{\"node_abi\":null,\"v8\":\"1.3\"},\"0.1.18\":{\"node_abi\":null,\"v8\":\"1.3\"},\"0.1.19\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.20\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.21\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.22\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.23\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.24\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.25\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.26\":{\"node_abi\":null,\"v8\":\"2.0\"},\"0.1.27\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.28\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.29\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.30\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.31\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.32\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.33\":{\"node_abi\":null,\"v8\":\"2.1\"},\"0.1.90\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.91\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.92\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.93\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.94\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.95\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.96\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.97\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.98\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.99\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.100\":{\"node_abi\":null,\"v8\":\"2.2\"},\"0.1.101\":{\"node_abi\":null,\"v8\":\"2.3\"},\"0.1.102\":{\"node_abi\":null,\"v8\":\"2.3\"},\"0.1.103\":{\"node_abi\":null,\"v8\":\"2.3\"},\"0.1.104\":{\"node_abi\":null,\"v8\":\"2.3\"},\"0.2.0\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.2.1\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.2.2\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.2.3\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.2.4\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.2.5\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.2.6\":{\"node_abi\":1,\"v8\":\"2.3\"},\"0.3.0\":{\"node_abi\":1,\"v8\":\"2.5\"},\"0.3.1\":{\"node_abi\":1,\"v8\":\"2.5\"},\"0.3.2\":{\"node_abi\":1,\"v8\":\"3.0\"},\"0.3.3\":{\"node_abi\":1,\"v8\":\"3.0\"},\"0.3.4\":{\"node_abi\":1,\"v8\":\"3.0\"},\"0.3.5\":{\"node_abi\":1,\"v8\":\"3.0\"},\"0.3.6\":{\"node_abi\":1,\"v8\":\"3.0\"},\"0.3.7\":{\"node_abi\":1,\"v8\":\"3.0\"},\"0.3.8\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.0\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.1\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.2\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.3\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.4\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.5\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.6\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.7\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.8\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.9\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.10\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.11\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.4.12\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.5.0\":{\"node_abi\":1,\"v8\":\"3.1\"},\"0.5.1\":{\"node_abi\":1,\"v8\":\"3.4\"},\"0.5.2\":{\"node_abi\":1,\"v8\":\"3.4\"},\"0.5.3\":{\"node_abi\":1,\"v8\":\"3.4\"},\"0.5.4\":{\"node_abi\":1,\"v8\":\"3.5\"},\"0.5.5\":{\"node_abi\":1,\"v8\":\"3.5\"},\"0.5.6\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.5.7\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.5.8\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.5.9\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.5.10\":{\"node_abi\":1,\"v8\":\"3.7\"},\"0.6.0\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.1\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.2\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.3\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.4\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.5\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.6\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.7\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.8\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.9\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.10\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.11\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.12\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.13\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.14\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.15\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.16\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.17\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.18\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.19\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.20\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.6.21\":{\"node_abi\":1,\"v8\":\"3.6\"},\"0.7.0\":{\"node_abi\":1,\"v8\":\"3.8\"},\"0.7.1\":{\"node_abi\":1,\"v8\":\"3.8\"},\"0.7.2\":{\"node_abi\":1,\"v8\":\"3.8\"},\"0.7.3\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.4\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.5\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.6\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.7\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.8\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.9\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.7.10\":{\"node_abi\":1,\"v8\":\"3.9\"},\"0.7.11\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.7.12\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.0\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.1\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.2\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.3\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.4\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.5\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.6\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.7\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.8\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.9\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.10\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.11\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.12\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.13\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.14\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.15\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.16\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.17\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.18\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.19\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.20\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.21\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.22\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.23\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.24\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.25\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.26\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.27\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.8.28\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.9.0\":{\"node_abi\":1,\"v8\":\"3.11\"},\"0.9.1\":{\"node_abi\":10,\"v8\":\"3.11\"},\"0.9.2\":{\"node_abi\":10,\"v8\":\"3.11\"},\"0.9.3\":{\"node_abi\":10,\"v8\":\"3.13\"},\"0.9.4\":{\"node_abi\":10,\"v8\":\"3.13\"},\"0.9.5\":{\"node_abi\":10,\"v8\":\"3.13\"},\"0.9.6\":{\"node_abi\":10,\"v8\":\"3.15\"},\"0.9.7\":{\"node_abi\":10,\"v8\":\"3.15\"},\"0.9.8\":{\"node_abi\":10,\"v8\":\"3.15\"},\"0.9.9\":{\"node_abi\":11,\"v8\":\"3.15\"},\"0.9.10\":{\"node_abi\":11,\"v8\":\"3.15\"},\"0.9.11\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.9.12\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.0\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.1\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.2\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.3\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.4\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.5\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.6\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.7\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.8\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.9\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.10\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.11\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.12\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.13\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.14\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.15\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.16\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.17\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.18\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.19\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.20\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.21\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.22\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.23\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.24\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.25\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.26\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.27\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.28\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.29\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.30\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.31\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.32\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.33\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.34\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.35\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.36\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.37\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.38\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.39\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.40\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.41\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.42\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.43\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.44\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.45\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.46\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.47\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.10.48\":{\"node_abi\":11,\"v8\":\"3.14\"},\"0.11.0\":{\"node_abi\":12,\"v8\":\"3.17\"},\"0.11.1\":{\"node_abi\":12,\"v8\":\"3.18\"},\"0.11.2\":{\"node_abi\":12,\"v8\":\"3.19\"},\"0.11.3\":{\"node_abi\":12,\"v8\":\"3.19\"},\"0.11.4\":{\"node_abi\":12,\"v8\":\"3.20\"},\"0.11.5\":{\"node_abi\":12,\"v8\":\"3.20\"},\"0.11.6\":{\"node_abi\":12,\"v8\":\"3.20\"},\"0.11.7\":{\"node_abi\":12,\"v8\":\"3.20\"},\"0.11.8\":{\"node_abi\":13,\"v8\":\"3.21\"},\"0.11.9\":{\"node_abi\":13,\"v8\":\"3.22\"},\"0.11.10\":{\"node_abi\":13,\"v8\":\"3.22\"},\"0.11.11\":{\"node_abi\":14,\"v8\":\"3.22\"},\"0.11.12\":{\"node_abi\":14,\"v8\":\"3.22\"},\"0.11.13\":{\"node_abi\":14,\"v8\":\"3.25\"},\"0.11.14\":{\"node_abi\":14,\"v8\":\"3.26\"},\"0.11.15\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.11.16\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.0\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.1\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.2\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.3\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.4\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.5\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.6\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.7\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.8\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.9\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.10\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.11\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.12\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.13\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.14\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.15\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.16\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.17\":{\"node_abi\":14,\"v8\":\"3.28\"},\"0.12.18\":{\"node_abi\":14,\"v8\":\"3.28\"},\"1.0.0\":{\"node_abi\":42,\"v8\":\"3.31\"},\"1.0.1\":{\"node_abi\":42,\"v8\":\"3.31\"},\"1.0.2\":{\"node_abi\":42,\"v8\":\"3.31\"},\"1.0.3\":{\"node_abi\":42,\"v8\":\"4.1\"},\"1.0.4\":{\"node_abi\":42,\"v8\":\"4.1\"},\"1.1.0\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.2.0\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.3.0\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.4.1\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.4.2\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.4.3\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.5.0\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.5.1\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.6.0\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.6.1\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.6.2\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.6.3\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.6.4\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.7.1\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.8.1\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.8.2\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.8.3\":{\"node_abi\":43,\"v8\":\"4.1\"},\"1.8.4\":{\"node_abi\":43,\"v8\":\"4.1\"},\"2.0.0\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.0.1\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.0.2\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.1.0\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.2.0\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.2.1\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.3.0\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.3.1\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.3.2\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.3.3\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.3.4\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.4.0\":{\"node_abi\":44,\"v8\":\"4.2\"},\"2.5.0\":{\"node_abi\":44,\"v8\":\"4.2\"},\"3.0.0\":{\"node_abi\":45,\"v8\":\"4.4\"},\"3.1.0\":{\"node_abi\":45,\"v8\":\"4.4\"},\"3.2.0\":{\"node_abi\":45,\"v8\":\"4.4\"},\"3.3.0\":{\"node_abi\":45,\"v8\":\"4.4\"},\"3.3.1\":{\"node_abi\":45,\"v8\":\"4.4\"},\"4.0.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.1.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.1.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.1.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.3\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.4\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.5\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.2.6\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.3.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.3.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.3.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.3\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.4\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.5\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.6\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.4.7\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.5.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.6.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.6.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.6.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.7.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.7.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.7.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.7.3\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.2\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.3\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.4\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.5\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.6\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.8.7\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.9.0\":{\"node_abi\":46,\"v8\":\"4.5\"},\"4.9.1\":{\"node_abi\":46,\"v8\":\"4.5\"},\"5.0.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.1.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.1.1\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.2.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.3.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.4.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.4.1\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.5.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.6.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.7.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.7.1\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.8.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.9.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.9.1\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.10.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.10.1\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.11.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.11.1\":{\"node_abi\":47,\"v8\":\"4.6\"},\"5.12.0\":{\"node_abi\":47,\"v8\":\"4.6\"},\"6.0.0\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.1.0\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.2.0\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.2.1\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.2.2\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.3.0\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.3.1\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.4.0\":{\"node_abi\":48,\"v8\":\"5.0\"},\"6.5.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.6.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.7.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.8.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.8.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.9.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.9.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.9.2\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.9.3\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.9.4\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.9.5\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.10.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.10.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.10.2\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.10.3\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.11.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.11.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.11.2\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.11.3\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.11.4\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.11.5\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.12.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.12.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.12.2\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.12.3\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.13.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.13.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.14.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.14.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.14.2\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.14.3\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.14.4\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.15.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.15.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.16.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.17.0\":{\"node_abi\":48,\"v8\":\"5.1\"},\"6.17.1\":{\"node_abi\":48,\"v8\":\"5.1\"},\"7.0.0\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.1.0\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.2.0\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.2.1\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.3.0\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.4.0\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.5.0\":{\"node_abi\":51,\"v8\":\"5.4\"},\"7.6.0\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.7.0\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.7.1\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.7.2\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.7.3\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.7.4\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.8.0\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.9.0\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.10.0\":{\"node_abi\":51,\"v8\":\"5.5\"},\"7.10.1\":{\"node_abi\":51,\"v8\":\"5.5\"},\"8.0.0\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.1.0\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.1.1\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.1.2\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.1.3\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.1.4\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.2.0\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.2.1\":{\"node_abi\":57,\"v8\":\"5.8\"},\"8.3.0\":{\"node_abi\":57,\"v8\":\"6.0\"},\"8.4.0\":{\"node_abi\":57,\"v8\":\"6.0\"},\"8.5.0\":{\"node_abi\":57,\"v8\":\"6.0\"},\"8.6.0\":{\"node_abi\":57,\"v8\":\"6.0\"},\"8.7.0\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.8.0\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.8.1\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.9.0\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.9.1\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.9.2\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.9.3\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.9.4\":{\"node_abi\":57,\"v8\":\"6.1\"},\"8.10.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.11.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.11.1\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.11.2\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.11.3\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.11.4\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.12.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.13.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.14.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.14.1\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.15.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.15.1\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.16.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.16.1\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.16.2\":{\"node_abi\":57,\"v8\":\"6.2\"},\"8.17.0\":{\"node_abi\":57,\"v8\":\"6.2\"},\"9.0.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.1.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.2.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.2.1\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.3.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.4.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.5.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.6.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.6.1\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.7.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.7.1\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.8.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.9.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.10.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.10.1\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.11.0\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.11.1\":{\"node_abi\":59,\"v8\":\"6.2\"},\"9.11.2\":{\"node_abi\":59,\"v8\":\"6.2\"},\"10.0.0\":{\"node_abi\":64,\"v8\":\"6.6\"},\"10.1.0\":{\"node_abi\":64,\"v8\":\"6.6\"},\"10.2.0\":{\"node_abi\":64,\"v8\":\"6.6\"},\"10.2.1\":{\"node_abi\":64,\"v8\":\"6.6\"},\"10.3.0\":{\"node_abi\":64,\"v8\":\"6.6\"},\"10.4.0\":{\"node_abi\":64,\"v8\":\"6.7\"},\"10.4.1\":{\"node_abi\":64,\"v8\":\"6.7\"},\"10.5.0\":{\"node_abi\":64,\"v8\":\"6.7\"},\"10.6.0\":{\"node_abi\":64,\"v8\":\"6.7\"},\"10.7.0\":{\"node_abi\":64,\"v8\":\"6.7\"},\"10.8.0\":{\"node_abi\":64,\"v8\":\"6.7\"},\"10.9.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.10.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.11.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.12.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.13.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.14.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.14.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.14.2\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.15.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.15.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.15.2\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.15.3\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.16.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.16.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.16.2\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.16.3\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.17.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.18.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.18.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.19.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.20.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.20.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.21.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.22.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.22.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.23.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.23.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.23.2\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.23.3\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.24.0\":{\"node_abi\":64,\"v8\":\"6.8\"},\"10.24.1\":{\"node_abi\":64,\"v8\":\"6.8\"},\"11.0.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.1.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.2.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.3.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.4.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.5.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.6.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.7.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.8.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.9.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.10.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.10.1\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.11.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.12.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.13.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.14.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"11.15.0\":{\"node_abi\":67,\"v8\":\"7.0\"},\"12.0.0\":{\"node_abi\":72,\"v8\":\"7.4\"},\"12.1.0\":{\"node_abi\":72,\"v8\":\"7.4\"},\"12.2.0\":{\"node_abi\":72,\"v8\":\"7.4\"},\"12.3.0\":{\"node_abi\":72,\"v8\":\"7.4\"},\"12.3.1\":{\"node_abi\":72,\"v8\":\"7.4\"},\"12.4.0\":{\"node_abi\":72,\"v8\":\"7.4\"},\"12.5.0\":{\"node_abi\":72,\"v8\":\"7.5\"},\"12.6.0\":{\"node_abi\":72,\"v8\":\"7.5\"},\"12.7.0\":{\"node_abi\":72,\"v8\":\"7.5\"},\"12.8.0\":{\"node_abi\":72,\"v8\":\"7.5\"},\"12.8.1\":{\"node_abi\":72,\"v8\":\"7.5\"},\"12.9.0\":{\"node_abi\":72,\"v8\":\"7.6\"},\"12.9.1\":{\"node_abi\":72,\"v8\":\"7.6\"},\"12.10.0\":{\"node_abi\":72,\"v8\":\"7.6\"},\"12.11.0\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.11.1\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.12.0\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.13.0\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.13.1\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.14.0\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.14.1\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.15.0\":{\"node_abi\":72,\"v8\":\"7.7\"},\"12.16.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.16.1\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.16.2\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.16.3\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.17.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.18.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.18.1\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.18.2\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.18.3\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.18.4\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.19.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.19.1\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.20.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.20.1\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.20.2\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.21.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.0\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.1\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.2\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.3\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.4\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.5\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.6\":{\"node_abi\":72,\"v8\":\"7.8\"},\"12.22.7\":{\"node_abi\":72,\"v8\":\"7.8\"},\"13.0.0\":{\"node_abi\":79,\"v8\":\"7.8\"},\"13.0.1\":{\"node_abi\":79,\"v8\":\"7.8\"},\"13.1.0\":{\"node_abi\":79,\"v8\":\"7.8\"},\"13.2.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.3.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.4.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.5.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.6.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.7.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.8.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.9.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.10.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.10.1\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.11.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.12.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.13.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"13.14.0\":{\"node_abi\":79,\"v8\":\"7.9\"},\"14.0.0\":{\"node_abi\":83,\"v8\":\"8.1\"},\"14.1.0\":{\"node_abi\":83,\"v8\":\"8.1\"},\"14.2.0\":{\"node_abi\":83,\"v8\":\"8.1\"},\"14.3.0\":{\"node_abi\":83,\"v8\":\"8.1\"},\"14.4.0\":{\"node_abi\":83,\"v8\":\"8.1\"},\"14.5.0\":{\"node_abi\":83,\"v8\":\"8.3\"},\"14.6.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.7.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.8.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.9.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.10.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.10.1\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.11.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.12.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.13.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.13.1\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.14.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.15.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.15.1\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.15.2\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.15.3\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.15.4\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.15.5\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.16.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.16.1\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.1\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.2\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.3\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.4\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.5\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.17.6\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.18.0\":{\"node_abi\":83,\"v8\":\"8.4\"},\"14.18.1\":{\"node_abi\":83,\"v8\":\"8.4\"},\"15.0.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.0.1\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.1.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.2.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.2.1\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.3.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.4.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.5.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.5.1\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.6.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.7.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.8.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.9.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.10.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.11.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.12.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.13.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"15.14.0\":{\"node_abi\":88,\"v8\":\"8.6\"},\"16.0.0\":{\"node_abi\":93,\"v8\":\"9.0\"},\"16.1.0\":{\"node_abi\":93,\"v8\":\"9.0\"},\"16.2.0\":{\"node_abi\":93,\"v8\":\"9.0\"},\"16.3.0\":{\"node_abi\":93,\"v8\":\"9.0\"},\"16.4.0\":{\"node_abi\":93,\"v8\":\"9.1\"},\"16.4.1\":{\"node_abi\":93,\"v8\":\"9.1\"},\"16.4.2\":{\"node_abi\":93,\"v8\":\"9.1\"},\"16.5.0\":{\"node_abi\":93,\"v8\":\"9.1\"},\"16.6.0\":{\"node_abi\":93,\"v8\":\"9.2\"},\"16.6.1\":{\"node_abi\":93,\"v8\":\"9.2\"},\"16.6.2\":{\"node_abi\":93,\"v8\":\"9.2\"},\"16.7.0\":{\"node_abi\":93,\"v8\":\"9.2\"},\"16.8.0\":{\"node_abi\":93,\"v8\":\"9.2\"},\"16.9.0\":{\"node_abi\":93,\"v8\":\"9.3\"},\"16.9.1\":{\"node_abi\":93,\"v8\":\"9.3\"},\"16.10.0\":{\"node_abi\":93,\"v8\":\"9.3\"},\"16.11.0\":{\"node_abi\":93,\"v8\":\"9.4\"},\"16.11.1\":{\"node_abi\":93,\"v8\":\"9.4\"},\"16.12.0\":{\"node_abi\":93,\"v8\":\"9.4\"},\"16.13.0\":{\"node_abi\":93,\"v8\":\"9.4\"},\"17.0.0\":{\"node_abi\":102,\"v8\":\"9.5\"},\"17.0.1\":{\"node_abi\":102,\"v8\":\"9.5\"},\"17.1.0\":{\"node_abi\":102,\"v8\":\"9.5\"}}');\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/abi_crosswalk.json?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/package.json":
/*!****************************************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/package.json ***!
  \****************************************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('{\"main\":\"index.html\",\"name\":\"nw-pre-gyp-module-test\",\"description\":\"Node-webkit-based module test.\",\"version\":\"0.0.1\",\"window\":{\"show\":false}}');\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/lib/util/nw-pre-gyp/package.json?");

/***/ }),

/***/ "./node_modules/@mapbox/node-pre-gyp/package.json":
/*!********************************************************!*\
  !*** ./node_modules/@mapbox/node-pre-gyp/package.json ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('{\"name\":\"@mapbox/node-pre-gyp\",\"description\":\"Node.js native addon binary install tool\",\"version\":\"1.0.11\",\"keywords\":[\"native\",\"addon\",\"module\",\"c\",\"c++\",\"bindings\",\"binary\"],\"license\":\"BSD-3-Clause\",\"author\":\"Dane Springmeyer <dane@mapbox.com>\",\"repository\":{\"type\":\"git\",\"url\":\"git://github.com/mapbox/node-pre-gyp.git\"},\"bin\":\"./bin/node-pre-gyp\",\"main\":\"./lib/node-pre-gyp.js\",\"dependencies\":{\"detect-libc\":\"^2.0.0\",\"https-proxy-agent\":\"^5.0.0\",\"make-dir\":\"^3.1.0\",\"node-fetch\":\"^2.6.7\",\"nopt\":\"^5.0.0\",\"npmlog\":\"^5.0.1\",\"rimraf\":\"^3.0.2\",\"semver\":\"^7.3.5\",\"tar\":\"^6.1.11\"},\"devDependencies\":{\"@mapbox/cloudfriend\":\"^5.1.0\",\"@mapbox/eslint-config-mapbox\":\"^3.0.0\",\"aws-sdk\":\"^2.1087.0\",\"codecov\":\"^3.8.3\",\"eslint\":\"^7.32.0\",\"eslint-plugin-node\":\"^11.1.0\",\"mock-aws-s3\":\"^4.0.2\",\"nock\":\"^12.0.3\",\"node-addon-api\":\"^4.3.0\",\"nyc\":\"^15.1.0\",\"tape\":\"^5.5.2\",\"tar-fs\":\"^2.1.1\"},\"nyc\":{\"all\":true,\"skip-full\":false,\"exclude\":[\"test/**\"]},\"scripts\":{\"coverage\":\"nyc --all --include index.js --include lib/ npm test\",\"upload-coverage\":\"nyc report --reporter json && codecov --clear --flags=unit --file=./coverage/coverage-final.json\",\"lint\":\"eslint bin/node-pre-gyp lib/*js lib/util/*js test/*js scripts/*js\",\"fix\":\"npm run lint -- --fix\",\"update-crosswalk\":\"node scripts/abi_crosswalk.js\",\"test\":\"tape test/*test.js\"}}');\n\n//# sourceURL=webpack://thelambda/./node_modules/@mapbox/node-pre-gyp/package.json?");

/***/ }),

/***/ "./node_modules/dotenv/package.json":
/*!******************************************!*\
  !*** ./node_modules/dotenv/package.json ***!
  \******************************************/
/***/ ((module) => {

"use strict";
eval("module.exports = /*#__PURE__*/JSON.parse('{\"name\":\"dotenv\",\"version\":\"16.4.5\",\"description\":\"Loads environment variables from .env file\",\"main\":\"lib/main.js\",\"types\":\"lib/main.d.ts\",\"exports\":{\".\":{\"types\":\"./lib/main.d.ts\",\"require\":\"./lib/main.js\",\"default\":\"./lib/main.js\"},\"./config\":\"./config.js\",\"./config.js\":\"./config.js\",\"./lib/env-options\":\"./lib/env-options.js\",\"./lib/env-options.js\":\"./lib/env-options.js\",\"./lib/cli-options\":\"./lib/cli-options.js\",\"./lib/cli-options.js\":\"./lib/cli-options.js\",\"./package.json\":\"./package.json\"},\"scripts\":{\"dts-check\":\"tsc --project tests/types/tsconfig.json\",\"lint\":\"standard\",\"lint-readme\":\"standard-markdown\",\"pretest\":\"npm run lint && npm run dts-check\",\"test\":\"tap tests/*.js --100 -Rspec\",\"test:coverage\":\"tap --coverage-report=lcov\",\"prerelease\":\"npm test\",\"release\":\"standard-version\"},\"repository\":{\"type\":\"git\",\"url\":\"git://github.com/motdotla/dotenv.git\"},\"funding\":\"https://dotenvx.com\",\"keywords\":[\"dotenv\",\"env\",\".env\",\"environment\",\"variables\",\"config\",\"settings\"],\"readmeFilename\":\"README.md\",\"license\":\"BSD-2-Clause\",\"devDependencies\":{\"@definitelytyped/dtslint\":\"^0.0.133\",\"@types/node\":\"^18.11.3\",\"decache\":\"^4.6.1\",\"sinon\":\"^14.0.1\",\"standard\":\"^17.0.0\",\"standard-markdown\":\"^7.1.0\",\"standard-version\":\"^9.5.0\",\"tap\":\"^16.3.0\",\"tar\":\"^6.1.11\",\"typescript\":\"^4.8.4\"},\"engines\":{\"node\":\">=12\"},\"browser\":{\"fs\":false}}');\n\n//# sourceURL=webpack://thelambda/./node_modules/dotenv/package.json?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			id: moduleId,
/******/ 			loaded: false,
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Flag the module as loaded
/******/ 		module.loaded = true;
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = __webpack_modules__;
/******/ 	
/************************************************************************/
/******/ 	/* webpack/runtime/compat get default export */
/******/ 	(() => {
/******/ 		// getDefaultExport function for compatibility with non-harmony modules
/******/ 		__webpack_require__.n = (module) => {
/******/ 			var getter = module && module.__esModule ?
/******/ 				() => (module['default']) :
/******/ 				() => (module);
/******/ 			__webpack_require__.d(getter, { a: getter });
/******/ 			return getter;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/create fake namespace object */
/******/ 	(() => {
/******/ 		var getProto = Object.getPrototypeOf ? (obj) => (Object.getPrototypeOf(obj)) : (obj) => (obj.__proto__);
/******/ 		var leafPrototypes;
/******/ 		// create a fake namespace object
/******/ 		// mode & 1: value is a module id, require it
/******/ 		// mode & 2: merge all properties of value into the ns
/******/ 		// mode & 4: return value when already ns object
/******/ 		// mode & 16: return value when it's Promise-like
/******/ 		// mode & 8|1: behave like require
/******/ 		__webpack_require__.t = function(value, mode) {
/******/ 			if(mode & 1) value = this(value);
/******/ 			if(mode & 8) return value;
/******/ 			if(typeof value === 'object' && value) {
/******/ 				if((mode & 4) && value.__esModule) return value;
/******/ 				if((mode & 16) && typeof value.then === 'function') return value;
/******/ 			}
/******/ 			var ns = Object.create(null);
/******/ 			__webpack_require__.r(ns);
/******/ 			var def = {};
/******/ 			leafPrototypes = leafPrototypes || [null, getProto({}), getProto([]), getProto(getProto)];
/******/ 			for(var current = mode & 2 && value; typeof current == 'object' && !~leafPrototypes.indexOf(current); current = getProto(current)) {
/******/ 				Object.getOwnPropertyNames(current).forEach((key) => (def[key] = () => (value[key])));
/******/ 			}
/******/ 			def['default'] = () => (value);
/******/ 			__webpack_require__.d(ns, def);
/******/ 			return ns;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/define property getters */
/******/ 	(() => {
/******/ 		// define getter functions for harmony exports
/******/ 		__webpack_require__.d = (exports, definition) => {
/******/ 			for(var key in definition) {
/******/ 				if(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {
/******/ 					Object.defineProperty(exports, key, { enumerable: true, get: definition[key] });
/******/ 				}
/******/ 			}
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/ensure chunk */
/******/ 	(() => {
/******/ 		__webpack_require__.f = {};
/******/ 		// This file contains only the entry chunk.
/******/ 		// The chunk loading function for additional chunks
/******/ 		__webpack_require__.e = (chunkId) => {
/******/ 			return Promise.all(Object.keys(__webpack_require__.f).reduce((promises, key) => {
/******/ 				__webpack_require__.f[key](chunkId, promises);
/******/ 				return promises;
/******/ 			}, []));
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/get javascript chunk filename */
/******/ 	(() => {
/******/ 		// This function allow to reference async chunks
/******/ 		__webpack_require__.u = (chunkId) => {
/******/ 			// return url for filenames based on template
/******/ 			return "" + chunkId + ".main.js";
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/global */
/******/ 	(() => {
/******/ 		__webpack_require__.g = (function() {
/******/ 			if (typeof globalThis === 'object') return globalThis;
/******/ 			try {
/******/ 				return this || new Function('return this')();
/******/ 			} catch (e) {
/******/ 				if (typeof window === 'object') return window;
/******/ 			}
/******/ 		})();
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/hasOwnProperty shorthand */
/******/ 	(() => {
/******/ 		__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/load script */
/******/ 	(() => {
/******/ 		var inProgress = {};
/******/ 		var dataWebpackPrefix = "thelambda:";
/******/ 		// loadScript function to load a script via script tag
/******/ 		__webpack_require__.l = (url, done, key, chunkId) => {
/******/ 			if(inProgress[url]) { inProgress[url].push(done); return; }
/******/ 			var script, needAttach;
/******/ 			if(key !== undefined) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				for(var i = 0; i < scripts.length; i++) {
/******/ 					var s = scripts[i];
/******/ 					if(s.getAttribute("src") == url || s.getAttribute("data-webpack") == dataWebpackPrefix + key) { script = s; break; }
/******/ 				}
/******/ 			}
/******/ 			if(!script) {
/******/ 				needAttach = true;
/******/ 				script = document.createElement('script');
/******/ 		
/******/ 				script.charset = 'utf-8';
/******/ 				script.timeout = 120;
/******/ 				if (__webpack_require__.nc) {
/******/ 					script.setAttribute("nonce", __webpack_require__.nc);
/******/ 				}
/******/ 				script.setAttribute("data-webpack", dataWebpackPrefix + key);
/******/ 		
/******/ 				script.src = url;
/******/ 			}
/******/ 			inProgress[url] = [done];
/******/ 			var onScriptComplete = (prev, event) => {
/******/ 				// avoid mem leaks in IE.
/******/ 				script.onerror = script.onload = null;
/******/ 				clearTimeout(timeout);
/******/ 				var doneFns = inProgress[url];
/******/ 				delete inProgress[url];
/******/ 				script.parentNode && script.parentNode.removeChild(script);
/******/ 				doneFns && doneFns.forEach((fn) => (fn(event)));
/******/ 				if(prev) return prev(event);
/******/ 			}
/******/ 			var timeout = setTimeout(onScriptComplete.bind(null, undefined, { type: 'timeout', target: script }), 120000);
/******/ 			script.onerror = onScriptComplete.bind(null, script.onerror);
/******/ 			script.onload = onScriptComplete.bind(null, script.onload);
/******/ 			needAttach && document.head.appendChild(script);
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/make namespace object */
/******/ 	(() => {
/******/ 		// define __esModule on exports
/******/ 		__webpack_require__.r = (exports) => {
/******/ 			if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 				Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 			}
/******/ 			Object.defineProperty(exports, '__esModule', { value: true });
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/node module decorator */
/******/ 	(() => {
/******/ 		__webpack_require__.nmd = (module) => {
/******/ 			module.paths = [];
/******/ 			if (!module.children) module.children = [];
/******/ 			return module;
/******/ 		};
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/publicPath */
/******/ 	(() => {
/******/ 		var scriptUrl;
/******/ 		if (__webpack_require__.g.importScripts) scriptUrl = __webpack_require__.g.location + "";
/******/ 		var document = __webpack_require__.g.document;
/******/ 		if (!scriptUrl && document) {
/******/ 			if (document.currentScript && document.currentScript.tagName.toUpperCase() === 'SCRIPT')
/******/ 				scriptUrl = document.currentScript.src;
/******/ 			if (!scriptUrl) {
/******/ 				var scripts = document.getElementsByTagName("script");
/******/ 				if(scripts.length) {
/******/ 					var i = scripts.length - 1;
/******/ 					while (i > -1 && (!scriptUrl || !/^http(s?):/.test(scriptUrl))) scriptUrl = scripts[i--].src;
/******/ 				}
/******/ 			}
/******/ 		}
/******/ 		// When supporting browsers where an automatic publicPath is not supported you must specify an output.publicPath manually via configuration
/******/ 		// or pass an empty string ("") and set the __webpack_public_path__ variable from your code to use your own logic.
/******/ 		if (!scriptUrl) throw new Error("Automatic publicPath is not supported in this browser");
/******/ 		scriptUrl = scriptUrl.replace(/#.*$/, "").replace(/\?.*$/, "").replace(/\/[^\/]+$/, "/");
/******/ 		__webpack_require__.p = scriptUrl;
/******/ 	})();
/******/ 	
/******/ 	/* webpack/runtime/jsonp chunk loading */
/******/ 	(() => {
/******/ 		// no baseURI
/******/ 		
/******/ 		// object to store loaded and loading chunks
/******/ 		// undefined = chunk not loaded, null = chunk preloaded/prefetched
/******/ 		// [resolve, reject, Promise] = chunk loading, 0 = chunk loaded
/******/ 		var installedChunks = {
/******/ 			"main": 0
/******/ 		};
/******/ 		
/******/ 		__webpack_require__.f.j = (chunkId, promises) => {
/******/ 				// JSONP chunk loading for javascript
/******/ 				var installedChunkData = __webpack_require__.o(installedChunks, chunkId) ? installedChunks[chunkId] : undefined;
/******/ 				if(installedChunkData !== 0) { // 0 means "already installed".
/******/ 		
/******/ 					// a Promise means "currently loading".
/******/ 					if(installedChunkData) {
/******/ 						promises.push(installedChunkData[2]);
/******/ 					} else {
/******/ 						if(true) { // all chunks have JS
/******/ 							// setup Promise in chunk cache
/******/ 							var promise = new Promise((resolve, reject) => (installedChunkData = installedChunks[chunkId] = [resolve, reject]));
/******/ 							promises.push(installedChunkData[2] = promise);
/******/ 		
/******/ 							// start chunk loading
/******/ 							var url = __webpack_require__.p + __webpack_require__.u(chunkId);
/******/ 							// create error before stack unwound to get useful stacktrace later
/******/ 							var error = new Error();
/******/ 							var loadingEnded = (event) => {
/******/ 								if(__webpack_require__.o(installedChunks, chunkId)) {
/******/ 									installedChunkData = installedChunks[chunkId];
/******/ 									if(installedChunkData !== 0) installedChunks[chunkId] = undefined;
/******/ 									if(installedChunkData) {
/******/ 										var errorType = event && (event.type === 'load' ? 'missing' : event.type);
/******/ 										var realSrc = event && event.target && event.target.src;
/******/ 										error.message = 'Loading chunk ' + chunkId + ' failed.\n(' + errorType + ': ' + realSrc + ')';
/******/ 										error.name = 'ChunkLoadError';
/******/ 										error.type = errorType;
/******/ 										error.request = realSrc;
/******/ 										installedChunkData[1](error);
/******/ 									}
/******/ 								}
/******/ 							};
/******/ 							__webpack_require__.l(url, loadingEnded, "chunk-" + chunkId, chunkId);
/******/ 						}
/******/ 					}
/******/ 				}
/******/ 		};
/******/ 		
/******/ 		// no prefetching
/******/ 		
/******/ 		// no preloaded
/******/ 		
/******/ 		// no HMR
/******/ 		
/******/ 		// no HMR manifest
/******/ 		
/******/ 		// no on chunks loaded
/******/ 		
/******/ 		// install a JSONP callback for chunk loading
/******/ 		var webpackJsonpCallback = (parentChunkLoadingFunction, data) => {
/******/ 			var [chunkIds, moreModules, runtime] = data;
/******/ 			// add "moreModules" to the modules object,
/******/ 			// then flag all "chunkIds" as loaded and fire callback
/******/ 			var moduleId, chunkId, i = 0;
/******/ 			if(chunkIds.some((id) => (installedChunks[id] !== 0))) {
/******/ 				for(moduleId in moreModules) {
/******/ 					if(__webpack_require__.o(moreModules, moduleId)) {
/******/ 						__webpack_require__.m[moduleId] = moreModules[moduleId];
/******/ 					}
/******/ 				}
/******/ 				if(runtime) var result = runtime(__webpack_require__);
/******/ 			}
/******/ 			if(parentChunkLoadingFunction) parentChunkLoadingFunction(data);
/******/ 			for(;i < chunkIds.length; i++) {
/******/ 				chunkId = chunkIds[i];
/******/ 				if(__webpack_require__.o(installedChunks, chunkId) && installedChunks[chunkId]) {
/******/ 					installedChunks[chunkId][0]();
/******/ 				}
/******/ 				installedChunks[chunkId] = 0;
/******/ 			}
/******/ 		
/******/ 		}
/******/ 		
/******/ 		var chunkLoadingGlobal = self["webpackChunkthelambda"] = self["webpackChunkthelambda"] || [];
/******/ 		chunkLoadingGlobal.forEach(webpackJsonpCallback.bind(null, 0));
/******/ 		chunkLoadingGlobal.push = webpackJsonpCallback.bind(null, chunkLoadingGlobal.push.bind(chunkLoadingGlobal));
/******/ 	})();
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./src/index.js");
/******/ 	
/******/ })()
;